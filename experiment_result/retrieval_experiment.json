[
    {
        "name": "ubyteArrayOf",
        "language": "kotlin",
        "popularity": "low",
        "label_result": {
            "functionality": {
                "finetuned_dpr": 0.0,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.1
            },
            "concept": {
                "finetuned_dpr": 0.2,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.1
            },
            "performance": {
                "finetuned_dpr": 0.1,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.1
            },
            "directive": {
                "finetuned_dpr": 0.0,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.1
            },
            "pattern": {
                "finetuned_dpr": 0.1,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.1
            },
            "environment": {
                "finetuned_dpr": 0.0,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.0
            },
            "alternative": {
                "finetuned_dpr": 0.1,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.0
            },
            "total": {
                "finetuned_dpr": 0.07142857142857142,
                "dpr": 0.09999999999999999,
                "e5": 0.0,
                "bm25": 0.07142857142857142
            }
        },
        "retrieve_result": {
            "functionality": {
                "finetuned_dpr": [
                    {
                        "id": 76727626,
                        "answer_post": "The data you want to receive is a Short value stored in two bytes at position 5 and 6. The easiest way to decode bytes to primitive in kotlin jvm is to wrap this part of the data into a ByteBuffer and decode it.\nFrom one of your line\n\n[-6, 5, 0, 3, 0, 1, 108, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ========364gm\n\n\nHere, buffer only contains bytes 5 and 6. So when getShort is called, the buffer read the first two bytes and return the corresponding short value.\nIf you want to read other parts of the ble information, you may want to wrap() the whole ByteArray and then read multiple parts of it with other methods of ByteBuffer.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64852886,
                        "answer_post": "The following is an object serializable class which is helpful to convert the object to bytes array and vice versa in Kotlin.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59937660,
                        "answer_post": "Yes you need to decode the base64 into a ByteArray then write the bytes to a location with the postfix .apk.  What you have is a String where the bytes are encoded using the base64 encoding scheme.\nSince your using kotlin you might what to look here to get the ByteArray![1] from the String.  Then just ensure the file you write has .apk extension.\n[1] https://developer.android.com/reference/kotlin/java/util/Base64.Decoder#decode(kotlin.String)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69143994,
                        "answer_post": "You are writing the gamemode as a normal Byte, however the Minecraf client expects it to be an Unsigned Byte.\nThe difference between the two is that Unsigned Byte doesn't have a sign (+/-). Therefore, it takes less memory and is practically a completely different data type.\nIn Kotlin Unsigned Byte is represented by UByte class. You can write it to Output using .writeUByte() extension function.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56695167,
                        "answer_post": "Kotlin 1.4 provides a common ByteArray.decodeToString function.\nIt takes a ByteArray containing bytes of string encoded with utf8 encoding and decodes it to kotlin String. So you can use it like:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63014202,
                        "answer_post": "The readText(charset: Charset = Charsets.UTF_8) decodes the bytes into UTF-8 character set, which is why it says \"This could mean either than the input has been truncated\" it probably have tried to convert 8-bits into a Char and build a String out of it.\nUse the readBytes() to get ByteArray which is represented same as byte[] in JVM platform.\nExample:\n\nEdit:\nFor reading bytes, you shouldn't be using the Reader, it is meant for reading the Text in UTF-8 format as defined in the Kotlin's InputStream.bufferedReader:\n\nThe InputStream.readBytes() will read the bytes at a buffer of 8KB itself.\n\nSo you just have to do:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76830156,
                        "answer_post": "Kotlin 1.9 introduced experimental fun String.hexToByteArray(): ByteArray.\nIt can be used as follows:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65669006,
                        "answer_post": "The equivalent is toByteArray() which does essentially the same thing.\nI'm a bit confused by your question, to clarify, there's no asBytes() on a Kotlin String.\ntoByteArray returns a ByteArray which (for Kotlin/JVM) is actually the same type as byte[].\nThe naming difference just stems from what the Kotlin designers chose to be more idiomatic for Kotlin itself.\n\nRelated documentation:\n\nhttps://kotlinlang.org/docs/reference/basic-types.html#primitive-type-arrays\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75384600,
                        "answer_post": "Eventually, I came up with the following solution:\n\nThe ArrayList<Byte> above can be replaced with either okio.Buffer from okio or kotlinx.io.core.BytePacketBuilder from kotlinx-io, e.g.:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 78119084,
                        "answer_post": "You can use following extension method to convert string to UTF_8 format.\n\nExplanation\nFirst string is converted to ByteArray using UTF_8 character set. Then convert that ByteArray to string using ByteArray.decodeToString function provided in Kotlin 1.4.\nByteArray.decodeToString function takes a ByteArray containing bytes of string encoded with utf8 encoding and decodes it to kotlin String. So you can use it like:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 67633606,
                        "answer_post": "According to the API documentation, the parameter should be called key rather than api_key:\n\nEvery request must either specify an API key (with the key parameter) or provide an OAuth 2.0 token. Your API key is available in the Developer Console's API Access pane for your project.\n\nSource: https://developers.google.com/youtube/v3/docs\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77330031,
                        "answer_post": "You can build the resource id dynamically as follows:\ncontext.resources.getIdentifier(beStringID, \"string\", context.packageName)\nThis is the id that you can pass to stringResource(...)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64054463,
                        "answer_post": "toUByteArray: Returns an array of type UByteArray, which is a copy of this array where each element is an unsigned reinterpretation of the corresponding element of this array.\nasUByteArray: Returns an array of type UByteArray, which is a view of this array where each element is an unsigned reinterpretation of the corresponding element of this array.\nExplanation about difference between in copy and view:\n\nWhile executing the functions, some of them return a copy of the input array, while some return the view. When the contents are physically stored in another location, it is called Copy. If on the other hand, a different view of the same memory content is provided, we call it as View\n\nReferences:\ntoUByteArray\nasUByteArray\nNumPy - Copies & Views\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74931505,
                        "answer_post": "configurations.runtimeClasspath is a generated Gradle Kotlin DSL accessor, and these are only available inside *.gradle.kts files.\nInstead you'll have to access the configuration by the name, using ConfigurationContainer.getByName().\nConveniently, JavaPlugin provides the name of the runtimeClasspath Configuration, so it can be imported and used directly (rather than using a 'magic' string).\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62869570,
                        "answer_post": "The value passed in @RequestController is not the URL mapping but the name of Spring bean. The root mapping has to be provided explicitly at class level using @RequestMapping or on each method with @GetMapping/@PostMapping..\n\nor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62716225,
                        "answer_post": "A RequestBody's content can be written out using the following method:\n\nOkio also has a Buffer type which is both a BufferedSink (meaning you can write to it) and a BufferedSource (meaning you can read from it).\nThus, we can write the body to a Buffer and then read it back as a string.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70070679,
                        "answer_post": "ObjectMapper.writeValueAsBytes converts its argument to JSON. Since your payload string is already JSON, you can skip the call to objectMapper.writeValueAsBytes and just call ByteString.copyFrom(payload.toByteArray()).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61575169,
                        "answer_post": "If you really need to, you could access MyText and alter its value by passing a reference of it to MyClass and to MyFunction() as a parameter.\nMainActivity.kt\n\nMyClass.kt\n\nPlease note also that following naming conventions is good software practice and therefore all function names should start with a small letter, myFunction().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55570269,
                        "answer_post": "Kotlin (since 1.3) provides the extension method InputStream.readBytes() for reading all bytes of an InputStream into a ByteArray.\nIn your case use:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60844731,
                        "answer_post": "You can use String(byteArray) to convert ByteArray to 'String' in kotlin\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 66396834,
                        "answer_post": "Xml:\n\nKotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71723371,
                        "answer_post": "\nhere how it works with fragment\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61137291,
                        "answer_post": "example for Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62829880,
                        "answer_post": "Here is the kotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72599846,
                        "answer_post": "In Kotlin API interface:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73232094,
                        "answer_post": "\nand with timerTask kotlin\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63493144,
                        "answer_post": "Here is how to do it with Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64518071,
                        "answer_post": "Api Interface\n\nKotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64805430,
                        "answer_post": "\nsource: Android : How to read file in bytes?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59944261,
                        "answer_post": "if use kotlin\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "\nOutput:\n\nEdit: added the following version with an array containing 1 million unsigned bytes.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "when you write a byteArray in kotlin like this :\n\ndocumentation says\n\nAn array of bytes. When targeting the JVM, instances of this class are represented as byte[].\n    @constructor Creates a new array of the specified [size], with all elements initialized to zero.\n\nto prove it, checking the byte code created is this:\n\ntherefor in your case a can code like this.\n\nbut type of size is int and entry.size needs a long value, just add .toLong() to size for fixing this issue.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can use destructuring to access the first two bytes in an array.\nTo convert them to an integer, you can use toInt to convert the first byte, shl to bitshift it left by 8 bits, and then add the 2nd byte.\n\nOutput:\n\nI am converting the signed byte array toUByteArray() here, because toInt() preserves the numeric value of the signed bytes, meaning negative bytes would produce negative integers, which is not what you want if you are only concerned with the raw bits. Using unsigned bytes is what you really want here.\nIf you wanted to avoid converting the whole array, you could convert only the first two bytes by doing this instead:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Solved!\nI ended up with the following solution:\n\nChanges in comparison to code posted in the question:\n\nThe transformation between the signed _bytes and unsigned bytes was performed wrong. Now I'm getting the first 65536 bytes first, then transforming them to unsigned by applying bitwise and to each byte instead of simply adding 256\nAll operations for getting UInt16 and UInt32 values from the byte array were moved to separate functions\nFixed the wrong offset incrementation inside while loop\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "System.currentTimeMillis() returns a Long so toByteArray has to be implemented for Long like this:\n\nIf you need this for unsigned bytes use:\n\nThis can be used like in the following example:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "It looks like the input string represents 16 bytes, where each byte is coded with two hex digit chars of that string.\nOn the contrary toByteArray(UTF_8) encodes the string in UTF-8 encoding turning each char into one or more bytes. When you convert these bytes to base64, first you get the longer result and second \u2014 these are completely different bytes.\nI suppose the correct way to convert the input hex string into byte array would be:\n\nThen you encode these bytes to base64 as usual.\nUpdate: recent versions of Kotlin got API to work with hex encoded values and to convert byte arrays to Base64 and back. So the task can now be solved with the following straightforward code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "If you want an integer from the first two bytes, just use a ByteBuffer:\n\nThis will only read the first two bytes of the array, in big endian order (you can change this with order), or throw an exception if there are fewer than 2 bytes in the array.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The Java equivalent of \"BigUInt64\" is an unsigned long. Java's long is signed, but can be treated as unsigned using the xxxUnsigned() methods of Long.\nSince you likely don't care about signed vs unsigned, except when printing the value, using long is fine. If that's not good enough, then you'd need to use BigInteger.\nTo read the value from the returned bytes from the digest, use a ByteBuffer, which is similar to the Node.js Buffer.\n\nIf the JavaScript method name had ended with \"LE\", you would need to specify that.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Return true if any value matches\n\nOr use intersect(\nReturns a set containing all elements that are contained by both this array and the specified collection)\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Notice that in Java, the array created by new A[2][2] contains only null elements. There are no instances of As in there. In Kotlin, this would be represented as a Array<Array<A?>>, rather than Array<Array<A>>, because the As are null initially.\nIn terms of one dimensional arrays, you essentially have an array of 2 elements, and each of those is an array of 2 elements containing nulls only. Hence, you can write:\n\nor a little bit shorter:\n\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "concept": {
                "finetuned_dpr": [
                    {
                        "id": 76727626,
                        "answer_post": "The data you want to receive is a Short value stored in two bytes at position 5 and 6. The easiest way to decode bytes to primitive in kotlin jvm is to wrap this part of the data into a ByteBuffer and decode it.\nFrom one of your line\n\n[-6, 5, 0, 3, 0, 1, 108, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ========364gm\n\n\nHere, buffer only contains bytes 5 and 6. So when getShort is called, the buffer read the first two bytes and return the corresponding short value.\nIf you want to read other parts of the ble information, you may want to wrap() the whole ByteArray and then read multiple parts of it with other methods of ByteBuffer.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64852886,
                        "answer_post": "The following is an object serializable class which is helpful to convert the object to bytes array and vice versa in Kotlin.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59937660,
                        "answer_post": "Yes you need to decode the base64 into a ByteArray then write the bytes to a location with the postfix .apk.  What you have is a String where the bytes are encoded using the base64 encoding scheme.\nSince your using kotlin you might what to look here to get the ByteArray![1] from the String.  Then just ensure the file you write has .apk extension.\n[1] https://developer.android.com/reference/kotlin/java/util/Base64.Decoder#decode(kotlin.String)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74958875,
                        "answer_post": "For people arriving from search engines and looking to get an answer to the question as written in the title, the way to read bytes from a fetch response is to use Response.arrayBuffer or Response.blob.\nMore information can be found here: https://developer.mozilla.org/en-US/docs/Web/API/Response\nSome unsolicited tips for working with array buffers:\n\nTo access individual bytes use Uint8Array - i.e. new Uint8Array(array)\nTo view bytes as a (a.k.a primitive hexdump) decode them as iso-8859-1 using TextDecoder - i.e. new TextDecoder(\"iso-8859-1\")\nTo convert bytes to normal strings, also use TextDecoder.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69143994,
                        "answer_post": "You are writing the gamemode as a normal Byte, however the Minecraf client expects it to be an Unsigned Byte.\nThe difference between the two is that Unsigned Byte doesn't have a sign (+/-). Therefore, it takes less memory and is practically a completely different data type.\nIn Kotlin Unsigned Byte is represented by UByte class. You can write it to Output using .writeUByte() extension function.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63014202,
                        "answer_post": "The readText(charset: Charset = Charsets.UTF_8) decodes the bytes into UTF-8 character set, which is why it says \"This could mean either than the input has been truncated\" it probably have tried to convert 8-bits into a Char and build a String out of it.\nUse the readBytes() to get ByteArray which is represented same as byte[] in JVM platform.\nExample:\n\nEdit:\nFor reading bytes, you shouldn't be using the Reader, it is meant for reading the Text in UTF-8 format as defined in the Kotlin's InputStream.bufferedReader:\n\nThe InputStream.readBytes() will read the bytes at a buffer of 8KB itself.\n\nSo you just have to do:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65669006,
                        "answer_post": "The equivalent is toByteArray() which does essentially the same thing.\nI'm a bit confused by your question, to clarify, there's no asBytes() on a Kotlin String.\ntoByteArray returns a ByteArray which (for Kotlin/JVM) is actually the same type as byte[].\nThe naming difference just stems from what the Kotlin designers chose to be more idiomatic for Kotlin itself.\n\nRelated documentation:\n\nhttps://kotlinlang.org/docs/reference/basic-types.html#primitive-type-arrays\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56695167,
                        "answer_post": "Kotlin 1.4 provides a common ByteArray.decodeToString function.\nIt takes a ByteArray containing bytes of string encoded with utf8 encoding and decodes it to kotlin String. So you can use it like:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75384600,
                        "answer_post": "Eventually, I came up with the following solution:\n\nThe ArrayList<Byte> above can be replaced with either okio.Buffer from okio or kotlinx.io.core.BytePacketBuilder from kotlinx-io, e.g.:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76830156,
                        "answer_post": "Kotlin 1.9 introduced experimental fun String.hexToByteArray(): ByteArray.\nIt can be used as follows:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 67633606,
                        "answer_post": "According to the API documentation, the parameter should be called key rather than api_key:\n\nEvery request must either specify an API key (with the key parameter) or provide an OAuth 2.0 token. Your API key is available in the Developer Console's API Access pane for your project.\n\nSource: https://developers.google.com/youtube/v3/docs\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65390883,
                        "answer_post": "Open an input stream for the obtained uri and then use BitmapFactory.decodeStream().\nIn Java:\n\nThat's all.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64054463,
                        "answer_post": "toUByteArray: Returns an array of type UByteArray, which is a copy of this array where each element is an unsigned reinterpretation of the corresponding element of this array.\nasUByteArray: Returns an array of type UByteArray, which is a view of this array where each element is an unsigned reinterpretation of the corresponding element of this array.\nExplanation about difference between in copy and view:\n\nWhile executing the functions, some of them return a copy of the input array, while some return the view. When the contents are physically stored in another location, it is called Copy. If on the other hand, a different view of the same memory content is provided, we call it as View\n\nReferences:\ntoUByteArray\nasUByteArray\nNumPy - Copies & Views\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77330031,
                        "answer_post": "You can build the resource id dynamically as follows:\ncontext.resources.getIdentifier(beStringID, \"string\", context.packageName)\nThis is the id that you can pass to stringResource(...)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62716225,
                        "answer_post": "A RequestBody's content can be written out using the following method:\n\nOkio also has a Buffer type which is both a BufferedSink (meaning you can write to it) and a BufferedSource (meaning you can read from it).\nThus, we can write the body to a Buffer and then read it back as a string.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74931505,
                        "answer_post": "configurations.runtimeClasspath is a generated Gradle Kotlin DSL accessor, and these are only available inside *.gradle.kts files.\nInstead you'll have to access the configuration by the name, using ConfigurationContainer.getByName().\nConveniently, JavaPlugin provides the name of the runtimeClasspath Configuration, so it can be imported and used directly (rather than using a 'magic' string).\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62869570,
                        "answer_post": "The value passed in @RequestController is not the URL mapping but the name of Spring bean. The root mapping has to be provided explicitly at class level using @RequestMapping or on each method with @GetMapping/@PostMapping..\n\nor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61575169,
                        "answer_post": "If you really need to, you could access MyText and alter its value by passing a reference of it to MyClass and to MyFunction() as a parameter.\nMainActivity.kt\n\nMyClass.kt\n\nPlease note also that following naming conventions is good software practice and therefore all function names should start with a small letter, myFunction().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69039398,
                        "answer_post": "This declaration:\n\ndeclares a generic interface, with a type parameter called Int. This is similar to how MutableList is a generic interface with a type parameter called E:\n\nTherefore, inside the interface, the unqualified name \"Int\" refers to the type parameter, (similar to how inside MutableList, E refers to the type parameter) not the kotlin.Int type.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70070679,
                        "answer_post": "ObjectMapper.writeValueAsBytes converts its argument to JSON. Since your payload string is already JSON, you can skip the call to objectMapper.writeValueAsBytes and just call ByteString.copyFrom(payload.toByteArray()).\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 66396834,
                        "answer_post": "Xml:\n\nKotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61137291,
                        "answer_post": "example for Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72599846,
                        "answer_post": "In Kotlin API interface:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62829880,
                        "answer_post": "Here is the kotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64518071,
                        "answer_post": "Api Interface\n\nKotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73232094,
                        "answer_post": "\nand with timerTask kotlin\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64805430,
                        "answer_post": "\nsource: Android : How to read file in bytes?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63789514,
                        "answer_post": "Kotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71723371,
                        "answer_post": "\nhere how it works with fragment\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63493144,
                        "answer_post": "Here is how to do it with Kotlin\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "\nOutput:\n\nEdit: added the following version with an array containing 1 million unsigned bytes.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "when you write a byteArray in kotlin like this :\n\ndocumentation says\n\nAn array of bytes. When targeting the JVM, instances of this class are represented as byte[].\n    @constructor Creates a new array of the specified [size], with all elements initialized to zero.\n\nto prove it, checking the byte code created is this:\n\ntherefor in your case a can code like this.\n\nbut type of size is int and entry.size needs a long value, just add .toLong() to size for fixing this issue.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can use destructuring to access the first two bytes in an array.\nTo convert them to an integer, you can use toInt to convert the first byte, shl to bitshift it left by 8 bits, and then add the 2nd byte.\n\nOutput:\n\nI am converting the signed byte array toUByteArray() here, because toInt() preserves the numeric value of the signed bytes, meaning negative bytes would produce negative integers, which is not what you want if you are only concerned with the raw bits. Using unsigned bytes is what you really want here.\nIf you wanted to avoid converting the whole array, you could convert only the first two bytes by doing this instead:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Solved!\nI ended up with the following solution:\n\nChanges in comparison to code posted in the question:\n\nThe transformation between the signed _bytes and unsigned bytes was performed wrong. Now I'm getting the first 65536 bytes first, then transforming them to unsigned by applying bitwise and to each byte instead of simply adding 256\nAll operations for getting UInt16 and UInt32 values from the byte array were moved to separate functions\nFixed the wrong offset incrementation inside while loop\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "System.currentTimeMillis() returns a Long so toByteArray has to be implemented for Long like this:\n\nIf you need this for unsigned bytes use:\n\nThis can be used like in the following example:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "If you want an integer from the first two bytes, just use a ByteBuffer:\n\nThis will only read the first two bytes of the array, in big endian order (you can change this with order), or throw an exception if there are fewer than 2 bytes in the array.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The Java equivalent of \"BigUInt64\" is an unsigned long. Java's long is signed, but can be treated as unsigned using the xxxUnsigned() methods of Long.\nSince you likely don't care about signed vs unsigned, except when printing the value, using long is fine. If that's not good enough, then you'd need to use BigInteger.\nTo read the value from the returned bytes from the digest, use a ByteBuffer, which is similar to the Node.js Buffer.\n\nIf the JavaScript method name had ended with \"LE\", you would need to specify that.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Return true if any value matches\n\nOr use intersect(\nReturns a set containing all elements that are contained by both this array and the specified collection)\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Notice that in Java, the array created by new A[2][2] contains only null elements. There are no instances of As in there. In Kotlin, this would be represented as a Array<Array<A?>>, rather than Array<Array<A>>, because the As are null initially.\nIn terms of one dimensional arrays, you essentially have an array of 2 elements, and each of those is an array of 2 elements containing nulls only. Hence, you can write:\n\nor a little bit shorter:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The arrays in Kotlin are fixed-size. That means once created, we can\u2019t resize them. To get a resizable-array implementation, consider using MutableList instead, which can grow or shrink automatically as needed.\nHowever, if you\u2019re stuck on using arrays, you can create a new array to accommodate the additional element.\nThe trick is to convert the array into a MutableList, add the specified element at the end of the list, and finally return an array containing all the elements in this list.\nTry this\n\n}\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "performance": {
                "finetuned_dpr": [
                    {
                        "id": 76727626,
                        "answer_post": "The data you want to receive is a Short value stored in two bytes at position 5 and 6. The easiest way to decode bytes to primitive in kotlin jvm is to wrap this part of the data into a ByteBuffer and decode it.\nFrom one of your line\n\n[-6, 5, 0, 3, 0, 1, 108, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ========364gm\n\n\nHere, buffer only contains bytes 5 and 6. So when getShort is called, the buffer read the first two bytes and return the corresponding short value.\nIf you want to read other parts of the ble information, you may want to wrap() the whole ByteArray and then read multiple parts of it with other methods of ByteBuffer.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64852886,
                        "answer_post": "The following is an object serializable class which is helpful to convert the object to bytes array and vice versa in Kotlin.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69143994,
                        "answer_post": "You are writing the gamemode as a normal Byte, however the Minecraf client expects it to be an Unsigned Byte.\nThe difference between the two is that Unsigned Byte doesn't have a sign (+/-). Therefore, it takes less memory and is practically a completely different data type.\nIn Kotlin Unsigned Byte is represented by UByte class. You can write it to Output using .writeUByte() extension function.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 59937660,
                        "answer_post": "Yes you need to decode the base64 into a ByteArray then write the bytes to a location with the postfix .apk.  What you have is a String where the bytes are encoded using the base64 encoding scheme.\nSince your using kotlin you might what to look here to get the ByteArray![1] from the String.  Then just ensure the file you write has .apk extension.\n[1] https://developer.android.com/reference/kotlin/java/util/Base64.Decoder#decode(kotlin.String)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63014202,
                        "answer_post": "The readText(charset: Charset = Charsets.UTF_8) decodes the bytes into UTF-8 character set, which is why it says \"This could mean either than the input has been truncated\" it probably have tried to convert 8-bits into a Char and build a String out of it.\nUse the readBytes() to get ByteArray which is represented same as byte[] in JVM platform.\nExample:\n\nEdit:\nFor reading bytes, you shouldn't be using the Reader, it is meant for reading the Text in UTF-8 format as defined in the Kotlin's InputStream.bufferedReader:\n\nThe InputStream.readBytes() will read the bytes at a buffer of 8KB itself.\n\nSo you just have to do:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76830156,
                        "answer_post": "Kotlin 1.9 introduced experimental fun String.hexToByteArray(): ByteArray.\nIt can be used as follows:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56695167,
                        "answer_post": "Kotlin 1.4 provides a common ByteArray.decodeToString function.\nIt takes a ByteArray containing bytes of string encoded with utf8 encoding and decodes it to kotlin String. So you can use it like:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75384600,
                        "answer_post": "Eventually, I came up with the following solution:\n\nThe ArrayList<Byte> above can be replaced with either okio.Buffer from okio or kotlinx.io.core.BytePacketBuilder from kotlinx-io, e.g.:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74958875,
                        "answer_post": "For people arriving from search engines and looking to get an answer to the question as written in the title, the way to read bytes from a fetch response is to use Response.arrayBuffer or Response.blob.\nMore information can be found here: https://developer.mozilla.org/en-US/docs/Web/API/Response\nSome unsolicited tips for working with array buffers:\n\nTo access individual bytes use Uint8Array - i.e. new Uint8Array(array)\nTo view bytes as a (a.k.a primitive hexdump) decode them as iso-8859-1 using TextDecoder - i.e. new TextDecoder(\"iso-8859-1\")\nTo convert bytes to normal strings, also use TextDecoder.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71309125,
                        "answer_post": "\nBinary     -> 1 Kilobyte = 1024 Byte\nNon-Binary -> 1 Kilobyte = 1000 Byte\n\nNative kotlin method below, if your API level is less than or equal to 24(Nougat), it uses binary format. If greater, it uses non-binary format.\n\nSo i suggest to add your custom method. Here is the mine:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 65390883,
                        "answer_post": "Open an input stream for the obtained uri and then use BitmapFactory.decodeStream().\nIn Java:\n\nThat's all.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64054463,
                        "answer_post": "toUByteArray: Returns an array of type UByteArray, which is a copy of this array where each element is an unsigned reinterpretation of the corresponding element of this array.\nasUByteArray: Returns an array of type UByteArray, which is a view of this array where each element is an unsigned reinterpretation of the corresponding element of this array.\nExplanation about difference between in copy and view:\n\nWhile executing the functions, some of them return a copy of the input array, while some return the view. When the contents are physically stored in another location, it is called Copy. If on the other hand, a different view of the same memory content is provided, we call it as View\n\nReferences:\ntoUByteArray\nasUByteArray\nNumPy - Copies & Views\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67633606,
                        "answer_post": "According to the API documentation, the parameter should be called key rather than api_key:\n\nEvery request must either specify an API key (with the key parameter) or provide an OAuth 2.0 token. Your API key is available in the Developer Console's API Access pane for your project.\n\nSource: https://developers.google.com/youtube/v3/docs\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77330031,
                        "answer_post": "You can build the resource id dynamically as follows:\ncontext.resources.getIdentifier(beStringID, \"string\", context.packageName)\nThis is the id that you can pass to stringResource(...)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62869570,
                        "answer_post": "The value passed in @RequestController is not the URL mapping but the name of Spring bean. The root mapping has to be provided explicitly at class level using @RequestMapping or on each method with @GetMapping/@PostMapping..\n\nor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70070679,
                        "answer_post": "ObjectMapper.writeValueAsBytes converts its argument to JSON. Since your payload string is already JSON, you can skip the call to objectMapper.writeValueAsBytes and just call ByteString.copyFrom(payload.toByteArray()).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62716225,
                        "answer_post": "A RequestBody's content can be written out using the following method:\n\nOkio also has a Buffer type which is both a BufferedSink (meaning you can write to it) and a BufferedSource (meaning you can read from it).\nThus, we can write the body to a Buffer and then read it back as a string.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74931505,
                        "answer_post": "configurations.runtimeClasspath is a generated Gradle Kotlin DSL accessor, and these are only available inside *.gradle.kts files.\nInstead you'll have to access the configuration by the name, using ConfigurationContainer.getByName().\nConveniently, JavaPlugin provides the name of the runtimeClasspath Configuration, so it can be imported and used directly (rather than using a 'magic' string).\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56764143,
                        "answer_post": "In Okio, we declare two additional source sets, nativeMain and nativeTest, and configure the built in native source sets to depend on them:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57439323,
                        "answer_post": "First create a new httpUrl instance from the existing request adding your query parameter and value:\nvar request = chain.request()\nval httpUrl = request.url().newBuilder().addQueryParameter(\"token\", authToken).build()\nThen update the request:\nrequest = request.newBuilder().url(httpUrl).build()\nand proceed with it:\nreturn chain.proceed(request)\n\nWhen you recall the request from the chain (the one you proceed with after manipulation) you are getting the unmodified request again.\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 66396834,
                        "answer_post": "Xml:\n\nKotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61137291,
                        "answer_post": "example for Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62829880,
                        "answer_post": "Here is the kotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72599846,
                        "answer_post": "In Kotlin API interface:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73232094,
                        "answer_post": "\nand with timerTask kotlin\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71723371,
                        "answer_post": "\nhere how it works with fragment\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64518071,
                        "answer_post": "Api Interface\n\nKotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59944261,
                        "answer_post": "if use kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63493144,
                        "answer_post": "Here is how to do it with Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64805430,
                        "answer_post": "\nsource: Android : How to read file in bytes?\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "\nOutput:\n\nEdit: added the following version with an array containing 1 million unsigned bytes.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "when you write a byteArray in kotlin like this :\n\ndocumentation says\n\nAn array of bytes. When targeting the JVM, instances of this class are represented as byte[].\n    @constructor Creates a new array of the specified [size], with all elements initialized to zero.\n\nto prove it, checking the byte code created is this:\n\ntherefor in your case a can code like this.\n\nbut type of size is int and entry.size needs a long value, just add .toLong() to size for fixing this issue.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can use destructuring to access the first two bytes in an array.\nTo convert them to an integer, you can use toInt to convert the first byte, shl to bitshift it left by 8 bits, and then add the 2nd byte.\n\nOutput:\n\nI am converting the signed byte array toUByteArray() here, because toInt() preserves the numeric value of the signed bytes, meaning negative bytes would produce negative integers, which is not what you want if you are only concerned with the raw bits. Using unsigned bytes is what you really want here.\nIf you wanted to avoid converting the whole array, you could convert only the first two bytes by doing this instead:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Solved!\nI ended up with the following solution:\n\nChanges in comparison to code posted in the question:\n\nThe transformation between the signed _bytes and unsigned bytes was performed wrong. Now I'm getting the first 65536 bytes first, then transforming them to unsigned by applying bitwise and to each byte instead of simply adding 256\nAll operations for getting UInt16 and UInt32 values from the byte array were moved to separate functions\nFixed the wrong offset incrementation inside while loop\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "System.currentTimeMillis() returns a Long so toByteArray has to be implemented for Long like this:\n\nIf you need this for unsigned bytes use:\n\nThis can be used like in the following example:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "If you want an integer from the first two bytes, just use a ByteBuffer:\n\nThis will only read the first two bytes of the array, in big endian order (you can change this with order), or throw an exception if there are fewer than 2 bytes in the array.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The Java equivalent of \"BigUInt64\" is an unsigned long. Java's long is signed, but can be treated as unsigned using the xxxUnsigned() methods of Long.\nSince you likely don't care about signed vs unsigned, except when printing the value, using long is fine. If that's not good enough, then you'd need to use BigInteger.\nTo read the value from the returned bytes from the digest, use a ByteBuffer, which is similar to the Node.js Buffer.\n\nIf the JavaScript method name had ended with \"LE\", you would need to specify that.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Return true if any value matches\n\nOr use intersect(\nReturns a set containing all elements that are contained by both this array and the specified collection)\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Notice that in Java, the array created by new A[2][2] contains only null elements. There are no instances of As in there. In Kotlin, this would be represented as a Array<Array<A?>>, rather than Array<Array<A>>, because the As are null initially.\nIn terms of one dimensional arrays, you essentially have an array of 2 elements, and each of those is an array of 2 elements containing nulls only. Hence, you can write:\n\nor a little bit shorter:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The arrays in Kotlin are fixed-size. That means once created, we can\u2019t resize them. To get a resizable-array implementation, consider using MutableList instead, which can grow or shrink automatically as needed.\nHowever, if you\u2019re stuck on using arrays, you can create a new array to accommodate the additional element.\nThe trick is to convert the array into a MutableList, add the specified element at the end of the list, and finally return an array containing all the elements in this list.\nTry this\n\n}\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "directive": {
                "finetuned_dpr": [
                    {
                        "id": 76727626,
                        "answer_post": "The data you want to receive is a Short value stored in two bytes at position 5 and 6. The easiest way to decode bytes to primitive in kotlin jvm is to wrap this part of the data into a ByteBuffer and decode it.\nFrom one of your line\n\n[-6, 5, 0, 3, 0, 1, 108, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ========364gm\n\n\nHere, buffer only contains bytes 5 and 6. So when getShort is called, the buffer read the first two bytes and return the corresponding short value.\nIf you want to read other parts of the ble information, you may want to wrap() the whole ByteArray and then read multiple parts of it with other methods of ByteBuffer.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64852886,
                        "answer_post": "The following is an object serializable class which is helpful to convert the object to bytes array and vice versa in Kotlin.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59937660,
                        "answer_post": "Yes you need to decode the base64 into a ByteArray then write the bytes to a location with the postfix .apk.  What you have is a String where the bytes are encoded using the base64 encoding scheme.\nSince your using kotlin you might what to look here to get the ByteArray![1] from the String.  Then just ensure the file you write has .apk extension.\n[1] https://developer.android.com/reference/kotlin/java/util/Base64.Decoder#decode(kotlin.String)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56695167,
                        "answer_post": "Kotlin 1.4 provides a common ByteArray.decodeToString function.\nIt takes a ByteArray containing bytes of string encoded with utf8 encoding and decodes it to kotlin String. So you can use it like:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69143994,
                        "answer_post": "You are writing the gamemode as a normal Byte, however the Minecraf client expects it to be an Unsigned Byte.\nThe difference between the two is that Unsigned Byte doesn't have a sign (+/-). Therefore, it takes less memory and is practically a completely different data type.\nIn Kotlin Unsigned Byte is represented by UByte class. You can write it to Output using .writeUByte() extension function.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59832312,
                        "answer_post": "this is the key describes:\n\nStore uses generic keys as identifiers for data. A key can be any value object that properly implements toString(), equals() and hashCode(). When your Fetcher function is called, it will be passed a particular Key value. Similarly, the key will be used as a primary identifier within caches (Make sure to have a proper hashCode()!!).\n\nthe key is to define your data, the object which you use as key have to override the hashCode method, define your own rule.\nhere is some use in Store:\n\nsuspend fun Store.get(key: Key): Value: This method returns a single value for the given key. If available, it will be returned from the in memory cache or the persister\n\nit is according to your set key to return the data. its functions as the key in hashmap\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74958875,
                        "answer_post": "For people arriving from search engines and looking to get an answer to the question as written in the title, the way to read bytes from a fetch response is to use Response.arrayBuffer or Response.blob.\nMore information can be found here: https://developer.mozilla.org/en-US/docs/Web/API/Response\nSome unsolicited tips for working with array buffers:\n\nTo access individual bytes use Uint8Array - i.e. new Uint8Array(array)\nTo view bytes as a (a.k.a primitive hexdump) decode them as iso-8859-1 using TextDecoder - i.e. new TextDecoder(\"iso-8859-1\")\nTo convert bytes to normal strings, also use TextDecoder.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65669006,
                        "answer_post": "The equivalent is toByteArray() which does essentially the same thing.\nI'm a bit confused by your question, to clarify, there's no asBytes() on a Kotlin String.\ntoByteArray returns a ByteArray which (for Kotlin/JVM) is actually the same type as byte[].\nThe naming difference just stems from what the Kotlin designers chose to be more idiomatic for Kotlin itself.\n\nRelated documentation:\n\nhttps://kotlinlang.org/docs/reference/basic-types.html#primitive-type-arrays\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63014202,
                        "answer_post": "The readText(charset: Charset = Charsets.UTF_8) decodes the bytes into UTF-8 character set, which is why it says \"This could mean either than the input has been truncated\" it probably have tried to convert 8-bits into a Char and build a String out of it.\nUse the readBytes() to get ByteArray which is represented same as byte[] in JVM platform.\nExample:\n\nEdit:\nFor reading bytes, you shouldn't be using the Reader, it is meant for reading the Text in UTF-8 format as defined in the Kotlin's InputStream.bufferedReader:\n\nThe InputStream.readBytes() will read the bytes at a buffer of 8KB itself.\n\nSo you just have to do:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76013423,
                        "answer_post": "ByteBuffer supports putInt(), putLong() etc, so you can call buf.putInt(unsignedInt.toInt()). Alternatively use https://github.com/mvysny/kotlin-unsigned-jvm\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 67633606,
                        "answer_post": "According to the API documentation, the parameter should be called key rather than api_key:\n\nEvery request must either specify an API key (with the key parameter) or provide an OAuth 2.0 token. Your API key is available in the Developer Console's API Access pane for your project.\n\nSource: https://developers.google.com/youtube/v3/docs\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65390883,
                        "answer_post": "Open an input stream for the obtained uri and then use BitmapFactory.decodeStream().\nIn Java:\n\nThat's all.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62869570,
                        "answer_post": "The value passed in @RequestController is not the URL mapping but the name of Spring bean. The root mapping has to be provided explicitly at class level using @RequestMapping or on each method with @GetMapping/@PostMapping..\n\nor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64054463,
                        "answer_post": "toUByteArray: Returns an array of type UByteArray, which is a copy of this array where each element is an unsigned reinterpretation of the corresponding element of this array.\nasUByteArray: Returns an array of type UByteArray, which is a view of this array where each element is an unsigned reinterpretation of the corresponding element of this array.\nExplanation about difference between in copy and view:\n\nWhile executing the functions, some of them return a copy of the input array, while some return the view. When the contents are physically stored in another location, it is called Copy. If on the other hand, a different view of the same memory content is provided, we call it as View\n\nReferences:\ntoUByteArray\nasUByteArray\nNumPy - Copies & Views\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77330031,
                        "answer_post": "You can build the resource id dynamically as follows:\ncontext.resources.getIdentifier(beStringID, \"string\", context.packageName)\nThis is the id that you can pass to stringResource(...)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62716225,
                        "answer_post": "A RequestBody's content can be written out using the following method:\n\nOkio also has a Buffer type which is both a BufferedSink (meaning you can write to it) and a BufferedSource (meaning you can read from it).\nThus, we can write the body to a Buffer and then read it back as a string.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75118419,
                        "answer_post": "OnUserEarnedRewardListener should be an interface object that overrides onUserEarnedReward(). Change your code to this\n\n}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61575169,
                        "answer_post": "If you really need to, you could access MyText and alter its value by passing a reference of it to MyClass and to MyFunction() as a parameter.\nMainActivity.kt\n\nMyClass.kt\n\nPlease note also that following naming conventions is good software practice and therefore all function names should start with a small letter, myFunction().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77246298,
                        "answer_post": "Check if the URL you're trying to download from needs to be URL-encoded. Use Uri.encodeFull(url) to encode the URL before making the HTTP request.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75151567,
                        "answer_post": "OAuth2UserService is defined as singleton scope, not request scope. As such, the HttpServletRequest, HttpServletResponse, and HttpSession are not available for autowiring.\nInstead of trying to interact with the HttpSession at the service layer, I'd recommend implementing the OAuth2User interface and extend your User object, similar to:\n\nThen, when you return that:\n\nSpring Security will save it to the session as part of the Authentication instance it creates later on in the request.\nAs a side note, I'm not sure why you are recreating the DefaultOAuth2UserService on each loadUser invocation. I think you can have that as a member variable instead.\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 66396834,
                        "answer_post": "Xml:\n\nKotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61137291,
                        "answer_post": "example for Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72599846,
                        "answer_post": "In Kotlin API interface:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62829880,
                        "answer_post": "Here is the kotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59944261,
                        "answer_post": "if use kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73232094,
                        "answer_post": "\nand with timerTask kotlin\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64518071,
                        "answer_post": "Api Interface\n\nKotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63493144,
                        "answer_post": "Here is how to do it with Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63789514,
                        "answer_post": "Kotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63145875,
                        "answer_post": "using kotlin function as\n\nusing from  your data\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "\nOutput:\n\nEdit: added the following version with an array containing 1 million unsigned bytes.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "when you write a byteArray in kotlin like this :\n\ndocumentation says\n\nAn array of bytes. When targeting the JVM, instances of this class are represented as byte[].\n    @constructor Creates a new array of the specified [size], with all elements initialized to zero.\n\nto prove it, checking the byte code created is this:\n\ntherefor in your case a can code like this.\n\nbut type of size is int and entry.size needs a long value, just add .toLong() to size for fixing this issue.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You can use destructuring to access the first two bytes in an array.\nTo convert them to an integer, you can use toInt to convert the first byte, shl to bitshift it left by 8 bits, and then add the 2nd byte.\n\nOutput:\n\nI am converting the signed byte array toUByteArray() here, because toInt() preserves the numeric value of the signed bytes, meaning negative bytes would produce negative integers, which is not what you want if you are only concerned with the raw bits. Using unsigned bytes is what you really want here.\nIf you wanted to avoid converting the whole array, you could convert only the first two bytes by doing this instead:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Solved!\nI ended up with the following solution:\n\nChanges in comparison to code posted in the question:\n\nThe transformation between the signed _bytes and unsigned bytes was performed wrong. Now I'm getting the first 65536 bytes first, then transforming them to unsigned by applying bitwise and to each byte instead of simply adding 256\nAll operations for getting UInt16 and UInt32 values from the byte array were moved to separate functions\nFixed the wrong offset incrementation inside while loop\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "System.currentTimeMillis() returns a Long so toByteArray has to be implemented for Long like this:\n\nIf you need this for unsigned bytes use:\n\nThis can be used like in the following example:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "If you want an integer from the first two bytes, just use a ByteBuffer:\n\nThis will only read the first two bytes of the array, in big endian order (you can change this with order), or throw an exception if there are fewer than 2 bytes in the array.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The Java equivalent of \"BigUInt64\" is an unsigned long. Java's long is signed, but can be treated as unsigned using the xxxUnsigned() methods of Long.\nSince you likely don't care about signed vs unsigned, except when printing the value, using long is fine. If that's not good enough, then you'd need to use BigInteger.\nTo read the value from the returned bytes from the digest, use a ByteBuffer, which is similar to the Node.js Buffer.\n\nIf the JavaScript method name had ended with \"LE\", you would need to specify that.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Return true if any value matches\n\nOr use intersect(\nReturns a set containing all elements that are contained by both this array and the specified collection)\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "I'm not sure why every proposed solution here iterates the elements inner array if only one its value is required.\nHere is a way to print numbers in the main diagonal of a square 2D array with one loop:\n\nNote however that this will throw if there are more rows than columns in this array, i.e. if the array is not square. You can add a check to ensure that there's a column with the row index in each row array:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Notice that in Java, the array created by new A[2][2] contains only null elements. There are no instances of As in there. In Kotlin, this would be represented as a Array<Array<A?>>, rather than Array<Array<A>>, because the As are null initially.\nIn terms of one dimensional arrays, you essentially have an array of 2 elements, and each of those is an array of 2 elements containing nulls only. Hence, you can write:\n\nor a little bit shorter:\n\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "pattern": {
                "finetuned_dpr": [
                    {
                        "id": 76727626,
                        "answer_post": "The data you want to receive is a Short value stored in two bytes at position 5 and 6. The easiest way to decode bytes to primitive in kotlin jvm is to wrap this part of the data into a ByteBuffer and decode it.\nFrom one of your line\n\n[-6, 5, 0, 3, 0, 1, 108, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ========364gm\n\n\nHere, buffer only contains bytes 5 and 6. So when getShort is called, the buffer read the first two bytes and return the corresponding short value.\nIf you want to read other parts of the ble information, you may want to wrap() the whole ByteArray and then read multiple parts of it with other methods of ByteBuffer.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64852886,
                        "answer_post": "The following is an object serializable class which is helpful to convert the object to bytes array and vice versa in Kotlin.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59937660,
                        "answer_post": "Yes you need to decode the base64 into a ByteArray then write the bytes to a location with the postfix .apk.  What you have is a String where the bytes are encoded using the base64 encoding scheme.\nSince your using kotlin you might what to look here to get the ByteArray![1] from the String.  Then just ensure the file you write has .apk extension.\n[1] https://developer.android.com/reference/kotlin/java/util/Base64.Decoder#decode(kotlin.String)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69143994,
                        "answer_post": "You are writing the gamemode as a normal Byte, however the Minecraf client expects it to be an Unsigned Byte.\nThe difference between the two is that Unsigned Byte doesn't have a sign (+/-). Therefore, it takes less memory and is practically a completely different data type.\nIn Kotlin Unsigned Byte is represented by UByte class. You can write it to Output using .writeUByte() extension function.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74958875,
                        "answer_post": "For people arriving from search engines and looking to get an answer to the question as written in the title, the way to read bytes from a fetch response is to use Response.arrayBuffer or Response.blob.\nMore information can be found here: https://developer.mozilla.org/en-US/docs/Web/API/Response\nSome unsolicited tips for working with array buffers:\n\nTo access individual bytes use Uint8Array - i.e. new Uint8Array(array)\nTo view bytes as a (a.k.a primitive hexdump) decode them as iso-8859-1 using TextDecoder - i.e. new TextDecoder(\"iso-8859-1\")\nTo convert bytes to normal strings, also use TextDecoder.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56695167,
                        "answer_post": "Kotlin 1.4 provides a common ByteArray.decodeToString function.\nIt takes a ByteArray containing bytes of string encoded with utf8 encoding and decodes it to kotlin String. So you can use it like:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63014202,
                        "answer_post": "The readText(charset: Charset = Charsets.UTF_8) decodes the bytes into UTF-8 character set, which is why it says \"This could mean either than the input has been truncated\" it probably have tried to convert 8-bits into a Char and build a String out of it.\nUse the readBytes() to get ByteArray which is represented same as byte[] in JVM platform.\nExample:\n\nEdit:\nFor reading bytes, you shouldn't be using the Reader, it is meant for reading the Text in UTF-8 format as defined in the Kotlin's InputStream.bufferedReader:\n\nThe InputStream.readBytes() will read the bytes at a buffer of 8KB itself.\n\nSo you just have to do:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59832312,
                        "answer_post": "this is the key describes:\n\nStore uses generic keys as identifiers for data. A key can be any value object that properly implements toString(), equals() and hashCode(). When your Fetcher function is called, it will be passed a particular Key value. Similarly, the key will be used as a primary identifier within caches (Make sure to have a proper hashCode()!!).\n\nthe key is to define your data, the object which you use as key have to override the hashCode method, define your own rule.\nhere is some use in Store:\n\nsuspend fun Store.get(key: Key): Value: This method returns a single value for the given key. If available, it will be returned from the in memory cache or the persister\n\nit is according to your set key to return the data. its functions as the key in hashmap\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65669006,
                        "answer_post": "The equivalent is toByteArray() which does essentially the same thing.\nI'm a bit confused by your question, to clarify, there's no asBytes() on a Kotlin String.\ntoByteArray returns a ByteArray which (for Kotlin/JVM) is actually the same type as byte[].\nThe naming difference just stems from what the Kotlin designers chose to be more idiomatic for Kotlin itself.\n\nRelated documentation:\n\nhttps://kotlinlang.org/docs/reference/basic-types.html#primitive-type-arrays\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75384600,
                        "answer_post": "Eventually, I came up with the following solution:\n\nThe ArrayList<Byte> above can be replaced with either okio.Buffer from okio or kotlinx.io.core.BytePacketBuilder from kotlinx-io, e.g.:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 67633606,
                        "answer_post": "According to the API documentation, the parameter should be called key rather than api_key:\n\nEvery request must either specify an API key (with the key parameter) or provide an OAuth 2.0 token. Your API key is available in the Developer Console's API Access pane for your project.\n\nSource: https://developers.google.com/youtube/v3/docs\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65390883,
                        "answer_post": "Open an input stream for the obtained uri and then use BitmapFactory.decodeStream().\nIn Java:\n\nThat's all.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62869570,
                        "answer_post": "The value passed in @RequestController is not the URL mapping but the name of Spring bean. The root mapping has to be provided explicitly at class level using @RequestMapping or on each method with @GetMapping/@PostMapping..\n\nor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77330031,
                        "answer_post": "You can build the resource id dynamically as follows:\ncontext.resources.getIdentifier(beStringID, \"string\", context.packageName)\nThis is the id that you can pass to stringResource(...)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64054463,
                        "answer_post": "toUByteArray: Returns an array of type UByteArray, which is a copy of this array where each element is an unsigned reinterpretation of the corresponding element of this array.\nasUByteArray: Returns an array of type UByteArray, which is a view of this array where each element is an unsigned reinterpretation of the corresponding element of this array.\nExplanation about difference between in copy and view:\n\nWhile executing the functions, some of them return a copy of the input array, while some return the view. When the contents are physically stored in another location, it is called Copy. If on the other hand, a different view of the same memory content is provided, we call it as View\n\nReferences:\ntoUByteArray\nasUByteArray\nNumPy - Copies & Views\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62716225,
                        "answer_post": "A RequestBody's content can be written out using the following method:\n\nOkio also has a Buffer type which is both a BufferedSink (meaning you can write to it) and a BufferedSource (meaning you can read from it).\nThus, we can write the body to a Buffer and then read it back as a string.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57093872,
                        "answer_post": "you need to create an object of type okhttp3.Request.Builder and add okhttp3.RequestBody via the post method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61575169,
                        "answer_post": "If you really need to, you could access MyText and alter its value by passing a reference of it to MyClass and to MyFunction() as a parameter.\nMainActivity.kt\n\nMyClass.kt\n\nPlease note also that following naming conventions is good software practice and therefore all function names should start with a small letter, myFunction().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55570269,
                        "answer_post": "Kotlin (since 1.3) provides the extension method InputStream.readBytes() for reading all bytes of an InputStream into a ByteArray.\nIn your case use:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57439323,
                        "answer_post": "First create a new httpUrl instance from the existing request adding your query parameter and value:\nvar request = chain.request()\nval httpUrl = request.url().newBuilder().addQueryParameter(\"token\", authToken).build()\nThen update the request:\nrequest = request.newBuilder().url(httpUrl).build()\nand proceed with it:\nreturn chain.proceed(request)\n\nWhen you recall the request from the chain (the one you proceed with after manipulation) you are getting the unmodified request again.\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 61137291,
                        "answer_post": "example for Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66396834,
                        "answer_post": "Xml:\n\nKotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72599846,
                        "answer_post": "In Kotlin API interface:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62829880,
                        "answer_post": "Here is the kotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59944261,
                        "answer_post": "if use kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73232094,
                        "answer_post": "\nand with timerTask kotlin\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64518071,
                        "answer_post": "Api Interface\n\nKotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63493144,
                        "answer_post": "Here is how to do it with Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63145875,
                        "answer_post": "using kotlin function as\n\nusing from  your data\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57637304,
                        "answer_post": "Here how can you use that in Kotlin\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "\nOutput:\n\nEdit: added the following version with an array containing 1 million unsigned bytes.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "when you write a byteArray in kotlin like this :\n\ndocumentation says\n\nAn array of bytes. When targeting the JVM, instances of this class are represented as byte[].\n    @constructor Creates a new array of the specified [size], with all elements initialized to zero.\n\nto prove it, checking the byte code created is this:\n\ntherefor in your case a can code like this.\n\nbut type of size is int and entry.size needs a long value, just add .toLong() to size for fixing this issue.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can use destructuring to access the first two bytes in an array.\nTo convert them to an integer, you can use toInt to convert the first byte, shl to bitshift it left by 8 bits, and then add the 2nd byte.\n\nOutput:\n\nI am converting the signed byte array toUByteArray() here, because toInt() preserves the numeric value of the signed bytes, meaning negative bytes would produce negative integers, which is not what you want if you are only concerned with the raw bits. Using unsigned bytes is what you really want here.\nIf you wanted to avoid converting the whole array, you could convert only the first two bytes by doing this instead:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Solved!\nI ended up with the following solution:\n\nChanges in comparison to code posted in the question:\n\nThe transformation between the signed _bytes and unsigned bytes was performed wrong. Now I'm getting the first 65536 bytes first, then transforming them to unsigned by applying bitwise and to each byte instead of simply adding 256\nAll operations for getting UInt16 and UInt32 values from the byte array were moved to separate functions\nFixed the wrong offset incrementation inside while loop\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "System.currentTimeMillis() returns a Long so toByteArray has to be implemented for Long like this:\n\nIf you need this for unsigned bytes use:\n\nThis can be used like in the following example:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "If you want an integer from the first two bytes, just use a ByteBuffer:\n\nThis will only read the first two bytes of the array, in big endian order (you can change this with order), or throw an exception if there are fewer than 2 bytes in the array.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "If you follow the call chain, listOf(vararg elements: T) on JVM calls Arrays.asList(elements), which looks like:\n\nThis is not the commonly used Java ArrayList, but rather a private class with the same name. But just like the public ArrayList, the items are stored in a backing Object Array. In this case, the vararg Object array is used directly as the backing array, so there is no redundant copying or allocating. The source code can be viewed here.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The Java equivalent of \"BigUInt64\" is an unsigned long. Java's long is signed, but can be treated as unsigned using the xxxUnsigned() methods of Long.\nSince you likely don't care about signed vs unsigned, except when printing the value, using long is fine. If that's not good enough, then you'd need to use BigInteger.\nTo read the value from the returned bytes from the digest, use a ByteBuffer, which is similar to the Node.js Buffer.\n\nIf the JavaScript method name had ended with \"LE\", you would need to specify that.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Return true if any value matches\n\nOr use intersect(\nReturns a set containing all elements that are contained by both this array and the specified collection)\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Notice that in Java, the array created by new A[2][2] contains only null elements. There are no instances of As in there. In Kotlin, this would be represented as a Array<Array<A?>>, rather than Array<Array<A>>, because the As are null initially.\nIn terms of one dimensional arrays, you essentially have an array of 2 elements, and each of those is an array of 2 elements containing nulls only. Hence, you can write:\n\nor a little bit shorter:\n\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "environment": {
                "finetuned_dpr": [
                    {
                        "id": 76727626,
                        "answer_post": "The data you want to receive is a Short value stored in two bytes at position 5 and 6. The easiest way to decode bytes to primitive in kotlin jvm is to wrap this part of the data into a ByteBuffer and decode it.\nFrom one of your line\n\n[-6, 5, 0, 3, 0, 1, 108, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ========364gm\n\n\nHere, buffer only contains bytes 5 and 6. So when getShort is called, the buffer read the first two bytes and return the corresponding short value.\nIf you want to read other parts of the ble information, you may want to wrap() the whole ByteArray and then read multiple parts of it with other methods of ByteBuffer.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59937660,
                        "answer_post": "Yes you need to decode the base64 into a ByteArray then write the bytes to a location with the postfix .apk.  What you have is a String where the bytes are encoded using the base64 encoding scheme.\nSince your using kotlin you might what to look here to get the ByteArray![1] from the String.  Then just ensure the file you write has .apk extension.\n[1] https://developer.android.com/reference/kotlin/java/util/Base64.Decoder#decode(kotlin.String)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64852886,
                        "answer_post": "The following is an object serializable class which is helpful to convert the object to bytes array and vice versa in Kotlin.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69143994,
                        "answer_post": "You are writing the gamemode as a normal Byte, however the Minecraf client expects it to be an Unsigned Byte.\nThe difference between the two is that Unsigned Byte doesn't have a sign (+/-). Therefore, it takes less memory and is practically a completely different data type.\nIn Kotlin Unsigned Byte is represented by UByte class. You can write it to Output using .writeUByte() extension function.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74958875,
                        "answer_post": "For people arriving from search engines and looking to get an answer to the question as written in the title, the way to read bytes from a fetch response is to use Response.arrayBuffer or Response.blob.\nMore information can be found here: https://developer.mozilla.org/en-US/docs/Web/API/Response\nSome unsolicited tips for working with array buffers:\n\nTo access individual bytes use Uint8Array - i.e. new Uint8Array(array)\nTo view bytes as a (a.k.a primitive hexdump) decode them as iso-8859-1 using TextDecoder - i.e. new TextDecoder(\"iso-8859-1\")\nTo convert bytes to normal strings, also use TextDecoder.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56695167,
                        "answer_post": "Kotlin 1.4 provides a common ByteArray.decodeToString function.\nIt takes a ByteArray containing bytes of string encoded with utf8 encoding and decodes it to kotlin String. So you can use it like:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63014202,
                        "answer_post": "The readText(charset: Charset = Charsets.UTF_8) decodes the bytes into UTF-8 character set, which is why it says \"This could mean either than the input has been truncated\" it probably have tried to convert 8-bits into a Char and build a String out of it.\nUse the readBytes() to get ByteArray which is represented same as byte[] in JVM platform.\nExample:\n\nEdit:\nFor reading bytes, you shouldn't be using the Reader, it is meant for reading the Text in UTF-8 format as defined in the Kotlin's InputStream.bufferedReader:\n\nThe InputStream.readBytes() will read the bytes at a buffer of 8KB itself.\n\nSo you just have to do:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65669006,
                        "answer_post": "The equivalent is toByteArray() which does essentially the same thing.\nI'm a bit confused by your question, to clarify, there's no asBytes() on a Kotlin String.\ntoByteArray returns a ByteArray which (for Kotlin/JVM) is actually the same type as byte[].\nThe naming difference just stems from what the Kotlin designers chose to be more idiomatic for Kotlin itself.\n\nRelated documentation:\n\nhttps://kotlinlang.org/docs/reference/basic-types.html#primitive-type-arrays\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75384600,
                        "answer_post": "Eventually, I came up with the following solution:\n\nThe ArrayList<Byte> above can be replaced with either okio.Buffer from okio or kotlinx.io.core.BytePacketBuilder from kotlinx-io, e.g.:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75857372,
                        "answer_post": "Uff, finally fixed in Kotlin 1.8.20-RC2.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 67633606,
                        "answer_post": "According to the API documentation, the parameter should be called key rather than api_key:\n\nEvery request must either specify an API key (with the key parameter) or provide an OAuth 2.0 token. Your API key is available in the Developer Console's API Access pane for your project.\n\nSource: https://developers.google.com/youtube/v3/docs\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77330031,
                        "answer_post": "You can build the resource id dynamically as follows:\ncontext.resources.getIdentifier(beStringID, \"string\", context.packageName)\nThis is the id that you can pass to stringResource(...)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64054463,
                        "answer_post": "toUByteArray: Returns an array of type UByteArray, which is a copy of this array where each element is an unsigned reinterpretation of the corresponding element of this array.\nasUByteArray: Returns an array of type UByteArray, which is a view of this array where each element is an unsigned reinterpretation of the corresponding element of this array.\nExplanation about difference between in copy and view:\n\nWhile executing the functions, some of them return a copy of the input array, while some return the view. When the contents are physically stored in another location, it is called Copy. If on the other hand, a different view of the same memory content is provided, we call it as View\n\nReferences:\ntoUByteArray\nasUByteArray\nNumPy - Copies & Views\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62869570,
                        "answer_post": "The value passed in @RequestController is not the URL mapping but the name of Spring bean. The root mapping has to be provided explicitly at class level using @RequestMapping or on each method with @GetMapping/@PostMapping..\n\nor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74931505,
                        "answer_post": "configurations.runtimeClasspath is a generated Gradle Kotlin DSL accessor, and these are only available inside *.gradle.kts files.\nInstead you'll have to access the configuration by the name, using ConfigurationContainer.getByName().\nConveniently, JavaPlugin provides the name of the runtimeClasspath Configuration, so it can be imported and used directly (rather than using a 'magic' string).\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62716225,
                        "answer_post": "A RequestBody's content can be written out using the following method:\n\nOkio also has a Buffer type which is both a BufferedSink (meaning you can write to it) and a BufferedSource (meaning you can read from it).\nThus, we can write the body to a Buffer and then read it back as a string.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70070679,
                        "answer_post": "ObjectMapper.writeValueAsBytes converts its argument to JSON. Since your payload string is already JSON, you can skip the call to objectMapper.writeValueAsBytes and just call ByteString.copyFrom(payload.toByteArray()).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75151567,
                        "answer_post": "OAuth2UserService is defined as singleton scope, not request scope. As such, the HttpServletRequest, HttpServletResponse, and HttpSession are not available for autowiring.\nInstead of trying to interact with the HttpSession at the service layer, I'd recommend implementing the OAuth2User interface and extend your User object, similar to:\n\nThen, when you return that:\n\nSpring Security will save it to the session as part of the Authentication instance it creates later on in the request.\nAs a side note, I'm not sure why you are recreating the DefaultOAuth2UserService on each loadUser invocation. I think you can have that as a member variable instead.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75118419,
                        "answer_post": "OnUserEarnedRewardListener should be an interface object that overrides onUserEarnedReward(). Change your code to this\n\n}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57093872,
                        "answer_post": "you need to create an object of type okhttp3.Request.Builder and add okhttp3.RequestBody via the post method\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 66396834,
                        "answer_post": "Xml:\n\nKotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61137291,
                        "answer_post": "example for Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62829880,
                        "answer_post": "Here is the kotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72599846,
                        "answer_post": "In Kotlin API interface:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64518071,
                        "answer_post": "Api Interface\n\nKotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64578940,
                        "answer_post": "Hi your json file content must be\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64805430,
                        "answer_post": "\nsource: Android : How to read file in bytes?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59944261,
                        "answer_post": "if use kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64107142,
                        "answer_post": "in activity\n\nin XML\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63493144,
                        "answer_post": "Here is how to do it with Kotlin\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "\nOutput:\n\nEdit: added the following version with an array containing 1 million unsigned bytes.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "when you write a byteArray in kotlin like this :\n\ndocumentation says\n\nAn array of bytes. When targeting the JVM, instances of this class are represented as byte[].\n    @constructor Creates a new array of the specified [size], with all elements initialized to zero.\n\nto prove it, checking the byte code created is this:\n\ntherefor in your case a can code like this.\n\nbut type of size is int and entry.size needs a long value, just add .toLong() to size for fixing this issue.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can use destructuring to access the first two bytes in an array.\nTo convert them to an integer, you can use toInt to convert the first byte, shl to bitshift it left by 8 bits, and then add the 2nd byte.\n\nOutput:\n\nI am converting the signed byte array toUByteArray() here, because toInt() preserves the numeric value of the signed bytes, meaning negative bytes would produce negative integers, which is not what you want if you are only concerned with the raw bits. Using unsigned bytes is what you really want here.\nIf you wanted to avoid converting the whole array, you could convert only the first two bytes by doing this instead:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Solved!\nI ended up with the following solution:\n\nChanges in comparison to code posted in the question:\n\nThe transformation between the signed _bytes and unsigned bytes was performed wrong. Now I'm getting the first 65536 bytes first, then transforming them to unsigned by applying bitwise and to each byte instead of simply adding 256\nAll operations for getting UInt16 and UInt32 values from the byte array were moved to separate functions\nFixed the wrong offset incrementation inside while loop\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "System.currentTimeMillis() returns a Long so toByteArray has to be implemented for Long like this:\n\nIf you need this for unsigned bytes use:\n\nThis can be used like in the following example:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "If you want an integer from the first two bytes, just use a ByteBuffer:\n\nThis will only read the first two bytes of the array, in big endian order (you can change this with order), or throw an exception if there are fewer than 2 bytes in the array.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The Java equivalent of \"BigUInt64\" is an unsigned long. Java's long is signed, but can be treated as unsigned using the xxxUnsigned() methods of Long.\nSince you likely don't care about signed vs unsigned, except when printing the value, using long is fine. If that's not good enough, then you'd need to use BigInteger.\nTo read the value from the returned bytes from the digest, use a ByteBuffer, which is similar to the Node.js Buffer.\n\nIf the JavaScript method name had ended with \"LE\", you would need to specify that.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Return true if any value matches\n\nOr use intersect(\nReturns a set containing all elements that are contained by both this array and the specified collection)\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Notice that in Java, the array created by new A[2][2] contains only null elements. There are no instances of As in there. In Kotlin, this would be represented as a Array<Array<A?>>, rather than Array<Array<A>>, because the As are null initially.\nIn terms of one dimensional arrays, you essentially have an array of 2 elements, and each of those is an array of 2 elements containing nulls only. Hence, you can write:\n\nor a little bit shorter:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The arrays in Kotlin are fixed-size. That means once created, we can\u2019t resize them. To get a resizable-array implementation, consider using MutableList instead, which can grow or shrink automatically as needed.\nHowever, if you\u2019re stuck on using arrays, you can create a new array to accommodate the additional element.\nThe trick is to convert the array into a MutableList, add the specified element at the end of the list, and finally return an array containing all the elements in this list.\nTry this\n\n}\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "alternative": {
                "finetuned_dpr": [
                    {
                        "id": 76727626,
                        "answer_post": "The data you want to receive is a Short value stored in two bytes at position 5 and 6. The easiest way to decode bytes to primitive in kotlin jvm is to wrap this part of the data into a ByteBuffer and decode it.\nFrom one of your line\n\n[-6, 5, 0, 3, 0, 1, 108, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ========364gm\n\n\nHere, buffer only contains bytes 5 and 6. So when getShort is called, the buffer read the first two bytes and return the corresponding short value.\nIf you want to read other parts of the ble information, you may want to wrap() the whole ByteArray and then read multiple parts of it with other methods of ByteBuffer.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64852886,
                        "answer_post": "The following is an object serializable class which is helpful to convert the object to bytes array and vice versa in Kotlin.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59937660,
                        "answer_post": "Yes you need to decode the base64 into a ByteArray then write the bytes to a location with the postfix .apk.  What you have is a String where the bytes are encoded using the base64 encoding scheme.\nSince your using kotlin you might what to look here to get the ByteArray![1] from the String.  Then just ensure the file you write has .apk extension.\n[1] https://developer.android.com/reference/kotlin/java/util/Base64.Decoder#decode(kotlin.String)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69143994,
                        "answer_post": "You are writing the gamemode as a normal Byte, however the Minecraf client expects it to be an Unsigned Byte.\nThe difference between the two is that Unsigned Byte doesn't have a sign (+/-). Therefore, it takes less memory and is practically a completely different data type.\nIn Kotlin Unsigned Byte is represented by UByte class. You can write it to Output using .writeUByte() extension function.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74958875,
                        "answer_post": "For people arriving from search engines and looking to get an answer to the question as written in the title, the way to read bytes from a fetch response is to use Response.arrayBuffer or Response.blob.\nMore information can be found here: https://developer.mozilla.org/en-US/docs/Web/API/Response\nSome unsolicited tips for working with array buffers:\n\nTo access individual bytes use Uint8Array - i.e. new Uint8Array(array)\nTo view bytes as a (a.k.a primitive hexdump) decode them as iso-8859-1 using TextDecoder - i.e. new TextDecoder(\"iso-8859-1\")\nTo convert bytes to normal strings, also use TextDecoder.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65669006,
                        "answer_post": "The equivalent is toByteArray() which does essentially the same thing.\nI'm a bit confused by your question, to clarify, there's no asBytes() on a Kotlin String.\ntoByteArray returns a ByteArray which (for Kotlin/JVM) is actually the same type as byte[].\nThe naming difference just stems from what the Kotlin designers chose to be more idiomatic for Kotlin itself.\n\nRelated documentation:\n\nhttps://kotlinlang.org/docs/reference/basic-types.html#primitive-type-arrays\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75384600,
                        "answer_post": "Eventually, I came up with the following solution:\n\nThe ArrayList<Byte> above can be replaced with either okio.Buffer from okio or kotlinx.io.core.BytePacketBuilder from kotlinx-io, e.g.:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76013423,
                        "answer_post": "ByteBuffer supports putInt(), putLong() etc, so you can call buf.putInt(unsignedInt.toInt()). Alternatively use https://github.com/mvysny/kotlin-unsigned-jvm\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63014202,
                        "answer_post": "The readText(charset: Charset = Charsets.UTF_8) decodes the bytes into UTF-8 character set, which is why it says \"This could mean either than the input has been truncated\" it probably have tried to convert 8-bits into a Char and build a String out of it.\nUse the readBytes() to get ByteArray which is represented same as byte[] in JVM platform.\nExample:\n\nEdit:\nFor reading bytes, you shouldn't be using the Reader, it is meant for reading the Text in UTF-8 format as defined in the Kotlin's InputStream.bufferedReader:\n\nThe InputStream.readBytes() will read the bytes at a buffer of 8KB itself.\n\nSo you just have to do:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56695167,
                        "answer_post": "Kotlin 1.4 provides a common ByteArray.decodeToString function.\nIt takes a ByteArray containing bytes of string encoded with utf8 encoding and decodes it to kotlin String. So you can use it like:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 64054463,
                        "answer_post": "toUByteArray: Returns an array of type UByteArray, which is a copy of this array where each element is an unsigned reinterpretation of the corresponding element of this array.\nasUByteArray: Returns an array of type UByteArray, which is a view of this array where each element is an unsigned reinterpretation of the corresponding element of this array.\nExplanation about difference between in copy and view:\n\nWhile executing the functions, some of them return a copy of the input array, while some return the view. When the contents are physically stored in another location, it is called Copy. If on the other hand, a different view of the same memory content is provided, we call it as View\n\nReferences:\ntoUByteArray\nasUByteArray\nNumPy - Copies & Views\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65390883,
                        "answer_post": "Open an input stream for the obtained uri and then use BitmapFactory.decodeStream().\nIn Java:\n\nThat's all.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67633606,
                        "answer_post": "According to the API documentation, the parameter should be called key rather than api_key:\n\nEvery request must either specify an API key (with the key parameter) or provide an OAuth 2.0 token. Your API key is available in the Developer Console's API Access pane for your project.\n\nSource: https://developers.google.com/youtube/v3/docs\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77330031,
                        "answer_post": "You can build the resource id dynamically as follows:\ncontext.resources.getIdentifier(beStringID, \"string\", context.packageName)\nThis is the id that you can pass to stringResource(...)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70070679,
                        "answer_post": "ObjectMapper.writeValueAsBytes converts its argument to JSON. Since your payload string is already JSON, you can skip the call to objectMapper.writeValueAsBytes and just call ByteString.copyFrom(payload.toByteArray()).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62869570,
                        "answer_post": "The value passed in @RequestController is not the URL mapping but the name of Spring bean. The root mapping has to be provided explicitly at class level using @RequestMapping or on each method with @GetMapping/@PostMapping..\n\nor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74931505,
                        "answer_post": "configurations.runtimeClasspath is a generated Gradle Kotlin DSL accessor, and these are only available inside *.gradle.kts files.\nInstead you'll have to access the configuration by the name, using ConfigurationContainer.getByName().\nConveniently, JavaPlugin provides the name of the runtimeClasspath Configuration, so it can be imported and used directly (rather than using a 'magic' string).\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75118419,
                        "answer_post": "OnUserEarnedRewardListener should be an interface object that overrides onUserEarnedReward(). Change your code to this\n\n}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75151567,
                        "answer_post": "OAuth2UserService is defined as singleton scope, not request scope. As such, the HttpServletRequest, HttpServletResponse, and HttpSession are not available for autowiring.\nInstead of trying to interact with the HttpSession at the service layer, I'd recommend implementing the OAuth2User interface and extend your User object, similar to:\n\nThen, when you return that:\n\nSpring Security will save it to the session as part of the Authentication instance it creates later on in the request.\nAs a side note, I'm not sure why you are recreating the DefaultOAuth2UserService on each loadUser invocation. I think you can have that as a member variable instead.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61575169,
                        "answer_post": "If you really need to, you could access MyText and alter its value by passing a reference of it to MyClass and to MyFunction() as a parameter.\nMainActivity.kt\n\nMyClass.kt\n\nPlease note also that following naming conventions is good software practice and therefore all function names should start with a small letter, myFunction().\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 66396834,
                        "answer_post": "Xml:\n\nKotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61137291,
                        "answer_post": "example for Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72599846,
                        "answer_post": "In Kotlin API interface:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62829880,
                        "answer_post": "Here is the kotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59944261,
                        "answer_post": "if use kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73232094,
                        "answer_post": "\nand with timerTask kotlin\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63789514,
                        "answer_post": "Kotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64518071,
                        "answer_post": "Api Interface\n\nKotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64805430,
                        "answer_post": "\nsource: Android : How to read file in bytes?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63493144,
                        "answer_post": "Here is how to do it with Kotlin\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "\nOutput:\n\nEdit: added the following version with an array containing 1 million unsigned bytes.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "when you write a byteArray in kotlin like this :\n\ndocumentation says\n\nAn array of bytes. When targeting the JVM, instances of this class are represented as byte[].\n    @constructor Creates a new array of the specified [size], with all elements initialized to zero.\n\nto prove it, checking the byte code created is this:\n\ntherefor in your case a can code like this.\n\nbut type of size is int and entry.size needs a long value, just add .toLong() to size for fixing this issue.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can use destructuring to access the first two bytes in an array.\nTo convert them to an integer, you can use toInt to convert the first byte, shl to bitshift it left by 8 bits, and then add the 2nd byte.\n\nOutput:\n\nI am converting the signed byte array toUByteArray() here, because toInt() preserves the numeric value of the signed bytes, meaning negative bytes would produce negative integers, which is not what you want if you are only concerned with the raw bits. Using unsigned bytes is what you really want here.\nIf you wanted to avoid converting the whole array, you could convert only the first two bytes by doing this instead:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Solved!\nI ended up with the following solution:\n\nChanges in comparison to code posted in the question:\n\nThe transformation between the signed _bytes and unsigned bytes was performed wrong. Now I'm getting the first 65536 bytes first, then transforming them to unsigned by applying bitwise and to each byte instead of simply adding 256\nAll operations for getting UInt16 and UInt32 values from the byte array were moved to separate functions\nFixed the wrong offset incrementation inside while loop\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "System.currentTimeMillis() returns a Long so toByteArray has to be implemented for Long like this:\n\nIf you need this for unsigned bytes use:\n\nThis can be used like in the following example:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "If you want an integer from the first two bytes, just use a ByteBuffer:\n\nThis will only read the first two bytes of the array, in big endian order (you can change this with order), or throw an exception if there are fewer than 2 bytes in the array.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The Java equivalent of \"BigUInt64\" is an unsigned long. Java's long is signed, but can be treated as unsigned using the xxxUnsigned() methods of Long.\nSince you likely don't care about signed vs unsigned, except when printing the value, using long is fine. If that's not good enough, then you'd need to use BigInteger.\nTo read the value from the returned bytes from the digest, use a ByteBuffer, which is similar to the Node.js Buffer.\n\nIf the JavaScript method name had ended with \"LE\", you would need to specify that.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Return true if any value matches\n\nOr use intersect(\nReturns a set containing all elements that are contained by both this array and the specified collection)\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "In general, hash (digest) functions take a byte array as input and produce a byte array as an output. Therefore, to hash\na string, you first need to convert it into a byte array. A common way of doing this is to encode the string as an array of UTF-8 bytes: string.toByteArray(UTF_8)\nA common way to display a byte array as a string, is to convert the individual bytes to their hexadecimal values and concatenate them. Here is an extension function that does that:\n\nMD5 produces a byte array of length 16. When converted to hex, it is represented by a string of length 32.\nThe full code looks like this:\n\nNote that MD5 has well known weaknesses that make it inappropriate for many use cases. Alternatives include the SHA family of hashing functions. Here is how to apply SHA-256 on a string:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Notice that in Java, the array created by new A[2][2] contains only null elements. There are no instances of As in there. In Kotlin, this would be represented as a Array<Array<A?>>, rather than Array<Array<A>>, because the As are null initially.\nIn terms of one dimensional arrays, you essentially have an array of 2 elements, and each of those is an array of 2 elements containing nulls only. Hence, you can write:\n\nor a little bit shorter:\n\n",
                        "contain_knowledge": 0
                    }
                ]
            }
        }
    },
    {
        "name": "charArrayOf",
        "language": "kotlin",
        "popularity": "middle",
        "label_result": {
            "functionality": {
                "finetuned_dpr": 0.1,
                "dpr": 0.0,
                "e5": 0.0,
                "bm25": 0.1
            },
            "concept": {
                "finetuned_dpr": 0.4,
                "dpr": 0.0,
                "e5": 0.0,
                "bm25": 0.2
            },
            "performance": {
                "finetuned_dpr": 0.2,
                "dpr": 0.0,
                "e5": 0.0,
                "bm25": 0.3
            },
            "directive": {
                "finetuned_dpr": 0.2,
                "dpr": 0.0,
                "e5": 0.0,
                "bm25": 0.1
            },
            "pattern": {
                "finetuned_dpr": 0.4,
                "dpr": 0.0,
                "e5": 0.0,
                "bm25": 0.3
            },
            "environment": {
                "finetuned_dpr": 0.0,
                "dpr": 0.0,
                "e5": 0.0,
                "bm25": 0.2
            },
            "alternative": {
                "finetuned_dpr": 0.2,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.2
            },
            "total": {
                "finetuned_dpr": 0.21428571428571425,
                "dpr": 0.014285714285714287,
                "e5": 0.0,
                "bm25": 0.19999999999999998
            }
        },
        "retrieve_result": {
            "functionality": {
                "finetuned_dpr": [
                    {
                        "id": 57515320,
                        "answer_post": "You'll have to convert your Char to a String in order to convert it to a Digit. Otherwise, you will get the integer used to represent the Char internally.\nUPDATE: If you are using Kotlin 1.5 or higher\nKotlin 1.5 introduced Char.digitToInt(), which does this conversion for you. You can even specify the radix, but it conveniently defaults to base 10.\n\nBefore Kotlin 1.5\n\nAnd you could define an extension function to make this cleaner:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63402531,
                        "answer_post": "If I understand correctly, you want this for loop to result in a true or false based on whether any inner array has the same sequence and number of chars as the key String.\nFirst of all, the inner array should be a CharArray instead of an Array<Char>, to avoid boxing.\n\nThen you can use all and contentEquals to check if any of the inner CharArrays are a match for the key.\n\nIf you want to skip the step of converting the key to a CharArray, you can manually check it like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65944604,
                        "answer_post": "There are many ways to initialize arrays in Kotlin.  The easiest, if all values are the same (here I'm using blanks), is this:\n\nIf you have a specific set of characters (here I made it a constant), I found this to be an easy way:\n\nIf you want to copy one to another (clone), you can do this:\n\nIn the example you gave above, you're trying to initialize an array of CharArray.  Not sure if that's what you really want, but you can do it this way (I have an array of 25 items, each of which is an array with 5 blanks):\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75910340,
                        "answer_post": "In Kotlin you can get Char input by using read() method of the System class.\n\nHere, System.in.read() returns ASCII value (Integer) of the Character entered by the user.\nThen toChar() method converts the Integer value to Char.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75110171,
                        "answer_post": "A Kotlin Char is, basically, just a regular number that represents a Unicode character (What are Unicode, UTF-8, and UTF-16?). Each number is assigned to a character, which we can look up in a unicode table. In this we can see that the letter a has a decimal representation of 97.\n\nYou could also get the decimal value using Char.code\n\n\nRun in Kotlin Playground\nTherefore, in decimal, 97 + 25 = 122.\nLooking up 122 in the Unicode table reveals that this is the decimal representation of z. You can again use Char.code to get the decimal representation.\n\n\nRun in Kotlin Playground\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76792619,
                        "answer_post": "Kotlin does not have an array syntax (varray = {1,2,3,4,5}). To create an array in Kotlin, you must use a function such as arrayOf or intArrayOf.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54874814,
                        "answer_post": "The issue isn't disambiguation but rather an incorrect type. In Kotlin, an Array<Char> is equivalent to a Java Character[]. That means that when you use *delim, you're actually creating a vararg Character (instead of vararg Char). \nInstead, you should prefer the primitive-specific CharArray:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56825391,
                        "answer_post": "Which char do you want?\nThis will return the first char of the String, since a String is essentially a CharArray.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69815786,
                        "answer_post": "I am theorizing from looking at this old issue that the Kotlin developers at one time accidentally treated CharBuffer.charAt() and CharBuffer.get() as equivalent and hid the charAt() method in Kotlin and mapped it to get(). They might have done this in an effort to promote the use of array-access syntax (brackets) and avoid supposed redundancy.\nAnd perhaps later when the above issue was fixed, they missed unhiding the method.\nbuffer.charAt(i) would be buffer[buffer.position() + i] in Kotlin. You could write an extension function so you can continue to use it:\n\nThe error message if you choose an out-of-bounds index will be slightly less informative than the one in the original method.\nMaybe someone should open an issue on YouTrack for this...\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55275484,
                        "answer_post": "Since Kotlin 1.2, you can use array literals in annotations. These are not part of the actual Kotlin syntax and only reserved for annotations. This might change in the future but currently you cannot make use of array literals in your actual code.\nRead about annotations here.\n\nFor other arguments that have an array type, you need to use the array\n  literal syntax (since Kotlin 1.2) or arrayOf(...):\n// Java\n\n// Kotlin 1.2+:\n\n// Older Kotlin versions:\n\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 76792619,
                        "answer_post": "Kotlin does not have an array syntax (varray = {1,2,3,4,5}). To create an array in Kotlin, you must use a function such as arrayOf or intArrayOf.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68317723,
                        "answer_post": "CharBuffer is pretty low-level and really meant for I/O stuff, so it may seem illogical at first. In your example it actually returned a string containing remaining 8 bytes that you didn't set. To make it return your data you need to invoke flip() like this:\n\nYou can find more in the docs of the Buffer\nFor more typical use cases it is much easier to use StringBuilder:\n\nOr even use a Kotlin util that wraps StringBuilder:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70419158,
                        "answer_post": "Replace org.mockito.Mockito with org.mockito.kotlin.*\nand you can code like this\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54854295,
                        "answer_post": "Kotlin has two sets of collection interfaces, the regular List, Set, etc. which are read-only, and the same ones with the Mutable prefix, which can be modified.\nlistOf will give you a List instance, while mutableListOf gives you a MutableList instance. If you use the latter for creating your nested lists, you can use the exact syntax you've asked about:\n\n(I've added the explicit type for myList for clarity's sake, it can be omitted from the left side of the assignment.)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65743882,
                        "answer_post": "Kotlin has a split function too. It will return a List<String>. If you you need an array in the end, call toTypedArray():\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60876779,
                        "answer_post": "Kotlin provides a Char.isDefined() extension method that seems to do just what you want (or at least, the direct opposite).\nSo you can do e.g.:\n\n(This function is available in Kotlin/JVM and Kotlin/Native, but not in Kotlin/JS yet.)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62005375,
                        "answer_post": "$ is a special kotlin metacharacter for string templates. You can use the string templating mechanism itself to insert a literal $:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60034694,
                        "answer_post": "xor (being an infix function-docs) in Kotlin has lower precedence than the arithmetic operators(*, /, %,+, -) and has higher precedence than Comparison(<, >, <=, >=),Equality(==, !==) & Assignment(=, +=, -=, *=, /=, %=) operators.(check for full reference for precedence here).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59557972,
                        "answer_post": "In Java/Kotlin, a String is a sequence of characters, each character has a given index, the index is starting from 0, for example:\n\nFrom substring Kotlin documentation:\n\nReturns the substring of this string starting at the startIndex and\n  ending right before the endIndex.\n\n\nBack to your example:\n\npass.substring(0,3) will returns a substring at the startIndex (0) and ending right before the endIndex (endIndex - 1 = 3 - 1 = 2). But 2 is an invalid index, so the program throws IndexOutOfBoundsException and make your app crash.\nYou can check the length of editText before calling substring() on it.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75910340,
                        "answer_post": "In Kotlin you can get Char input by using read() method of the System class.\n\nHere, System.in.read() returns ASCII value (Integer) of the Character entered by the user.\nThen toChar() method converts the Integer value to Char.\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 61137291,
                        "answer_post": "example for Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62829880,
                        "answer_post": "Here is the kotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66396834,
                        "answer_post": "Xml:\n\nKotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57622602,
                        "answer_post": "Try this \n\nFor kotlin \n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59944261,
                        "answer_post": "if use kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74960577,
                        "answer_post": "Try this in Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63493144,
                        "answer_post": "Here is how to do it with Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65085597,
                        "answer_post": "In kotlin\n\nIn Java\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72599846,
                        "answer_post": "In Kotlin API interface:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63145875,
                        "answer_post": "using kotlin function as\n\nusing from  your data\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "When you write var  arrFirstLetter = charArrayOf() you are creating an empty array.\nThen when you write arrFirstLetter[x] = firstWord[0], you are trying to assign to the element at index x of an empty array. Because the array is empty, this is generating ArrayIndexOutOfBoundsException.\nIn general it's better to avoid trying to loop over collections by using their index and instead use a for loop or the map extension function.\nYou can print out the first letters of each word like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Since Kotlin 1.2, you can use array literals in annotations. These are not part of the actual Kotlin syntax and only reserved for annotations. This might change in the future but currently you cannot make use of array literals in your actual code.\nRead about annotations here.\n\nFor other arguments that have an array type, you need to use the array\n  literal syntax (since Kotlin 1.2) or arrayOf(...):\n// Java\n\n// Kotlin 1.2+:\n\n// Older Kotlin versions:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This happens because in Kotlin Array<Char> is equal to Character[] in Java, not to char[] in Java. \nTo use the spread operator on an array of characters and pass it to a vararg Char parameter, you need to use CharArray which is equal to char[] in Java.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Frame challenge: what you're doing is splitting the string into individual characters \u2014 and there are several existing methods which can do that to a string, such as:\n\nasSequence() gives a Sequence of characters.\nasIterable() gives an Iterable of characters.\u2002(You can do most things to an Iterable that you can to a List.)\ntoCharArray() gives a CharArray.\u2002(Though iterables are generally preferred in Kotlin as they're more flexible and better-supported.)\nforEach() performs a given action on each character.\u2002(This means you can do e.g. for (c in myString) { \u2026 }.)\n\nUsing one of these will be simpler than splitting, and probably more efficient; it'll also make the intent of the code easier to anyone reading it.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "57 is the Ascii code for the character 9.\nTo get the value 9 you need to use: \n\nThis works because the Ascii digit characters are right next to each other in ascending order '0' is 48. In many languages, including Kotlin, the Characters are just numbers so basic mathematical operations work as normal.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "try this\n\nOutput:\n\nYou should avoid Special character in Api\nURL encoding is often required to convert special characters (such as \"/\", \"&\", \"#\", ...), because special characters: \n\nFor instance, the \"#\" character needs to be encoded because it has a special meaning of that of an HTML anchor. \nThe  character needs to be encoded because it is not a valid URL character. Also, some characters, such as \"~\" might not transport properly across the internet. Instead of proceeding with the complex process you should focus on correcting the old one.\nMore you can read here.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Starting from the version 1.3.50 Kotlin has guaranteed sequential array initialization order in its API documentation: https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-array/-init-.html\n\nThe function init is called for each array element sequentially starting from the first one. It should return the value for an array element given its index.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Just like in Java, ' is for character literals, and \" is for String literals. \nYou want \"commons-net:commons-net:3.6\". \nAnd compile() is deprecated. Use implementation().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The equivalent in Java and Kotlin is simply to store an index into the array (or String).\nRemember that the JVM has very powerful dynamic compilation and optimisation, so while in C that would be less efficient, on the JVM it generally won't be.  (The difference generally wouldn't be significant in most applications, anyway.)\nAlso note that Kotlin uses Unicode, so a character is not the same as a byte.  A Character is an unsigned two-byte number.  (Characters outside the Basic Multilingual Plane are stored as a surrogate pair.)\nSo the equivalent would be:\n\nor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can maintain the character mapping and replace required characters by iterating over each character in the word.\n\nIf you want to do it for multiple words, you can create an extension function for better readability\n\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "concept": {
                "finetuned_dpr": [
                    {
                        "id": 57515320,
                        "answer_post": "You'll have to convert your Char to a String in order to convert it to a Digit. Otherwise, you will get the integer used to represent the Char internally.\nUPDATE: If you are using Kotlin 1.5 or higher\nKotlin 1.5 introduced Char.digitToInt(), which does this conversion for you. You can even specify the radix, but it conveniently defaults to base 10.\n\nBefore Kotlin 1.5\n\nAnd you could define an extension function to make this cleaner:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65944604,
                        "answer_post": "There are many ways to initialize arrays in Kotlin.  The easiest, if all values are the same (here I'm using blanks), is this:\n\nIf you have a specific set of characters (here I made it a constant), I found this to be an easy way:\n\nIf you want to copy one to another (clone), you can do this:\n\nIn the example you gave above, you're trying to initialize an array of CharArray.  Not sure if that's what you really want, but you can do it this way (I have an array of 25 items, each of which is an array with 5 blanks):\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75910340,
                        "answer_post": "In Kotlin you can get Char input by using read() method of the System class.\n\nHere, System.in.read() returns ASCII value (Integer) of the Character entered by the user.\nThen toChar() method converts the Integer value to Char.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63402531,
                        "answer_post": "If I understand correctly, you want this for loop to result in a true or false based on whether any inner array has the same sequence and number of chars as the key String.\nFirst of all, the inner array should be a CharArray instead of an Array<Char>, to avoid boxing.\n\nThen you can use all and contentEquals to check if any of the inner CharArrays are a match for the key.\n\nIf you want to skip the step of converting the key to a CharArray, you can manually check it like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 54874814,
                        "answer_post": "The issue isn't disambiguation but rather an incorrect type. In Kotlin, an Array<Char> is equivalent to a Java Character[]. That means that when you use *delim, you're actually creating a vararg Character (instead of vararg Char). \nInstead, you should prefer the primitive-specific CharArray:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75110171,
                        "answer_post": "A Kotlin Char is, basically, just a regular number that represents a Unicode character (What are Unicode, UTF-8, and UTF-16?). Each number is assigned to a character, which we can look up in a unicode table. In this we can see that the letter a has a decimal representation of 97.\n\nYou could also get the decimal value using Char.code\n\n\nRun in Kotlin Playground\nTherefore, in decimal, 97 + 25 = 122.\nLooking up 122 in the Unicode table reveals that this is the decimal representation of z. You can again use Char.code to get the decimal representation.\n\n\nRun in Kotlin Playground\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76792619,
                        "answer_post": "Kotlin does not have an array syntax (varray = {1,2,3,4,5}). To create an array in Kotlin, you must use a function such as arrayOf or intArrayOf.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56825391,
                        "answer_post": "Which char do you want?\nThis will return the first char of the String, since a String is essentially a CharArray.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55275484,
                        "answer_post": "Since Kotlin 1.2, you can use array literals in annotations. These are not part of the actual Kotlin syntax and only reserved for annotations. This might change in the future but currently you cannot make use of array literals in your actual code.\nRead about annotations here.\n\nFor other arguments that have an array type, you need to use the array\n  literal syntax (since Kotlin 1.2) or arrayOf(...):\n// Java\n\n// Kotlin 1.2+:\n\n// Older Kotlin versions:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55908561,
                        "answer_post": "You have declared a variable of type CharArray, but haven't assigned it with any instance. \nBefore you can set elements of that CharArray, you have to create an instance of CharArray. It looks like you know the size of that array in advance, then you can use the following array constructor:\n\nBonus point: if you have a function that can provide an array element value given its index you can use the similar constructor to create instance and initialized its elements at once:\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 68317723,
                        "answer_post": "CharBuffer is pretty low-level and really meant for I/O stuff, so it may seem illogical at first. In your example it actually returned a string containing remaining 8 bytes that you didn't set. To make it return your data you need to invoke flip() like this:\n\nYou can find more in the docs of the Buffer\nFor more typical use cases it is much easier to use StringBuilder:\n\nOr even use a Kotlin util that wraps StringBuilder:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70419158,
                        "answer_post": "Replace org.mockito.Mockito with org.mockito.kotlin.*\nand you can code like this\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76792619,
                        "answer_post": "Kotlin does not have an array syntax (varray = {1,2,3,4,5}). To create an array in Kotlin, you must use a function such as arrayOf or intArrayOf.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54854295,
                        "answer_post": "Kotlin has two sets of collection interfaces, the regular List, Set, etc. which are read-only, and the same ones with the Mutable prefix, which can be modified.\nlistOf will give you a List instance, while mutableListOf gives you a MutableList instance. If you use the latter for creating your nested lists, you can use the exact syntax you've asked about:\n\n(I've added the explicit type for myList for clarity's sake, it can be omitted from the left side of the assignment.)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60876779,
                        "answer_post": "Kotlin provides a Char.isDefined() extension method that seems to do just what you want (or at least, the direct opposite).\nSo you can do e.g.:\n\n(This function is available in Kotlin/JVM and Kotlin/Native, but not in Kotlin/JS yet.)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62005375,
                        "answer_post": "$ is a special kotlin metacharacter for string templates. You can use the string templating mechanism itself to insert a literal $:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59530434,
                        "answer_post": "As described in the documentation arrayListOf is a function that creates an ArrayList instance. If I understand it correctly it serves the purpose of determining the generic type from the passed input values and it's a convenience function.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60034694,
                        "answer_post": "xor (being an infix function-docs) in Kotlin has lower precedence than the arithmetic operators(*, /, %,+, -) and has higher precedence than Comparison(<, >, <=, >=),Equality(==, !==) & Assignment(=, +=, -=, *=, /=, %=) operators.(check for full reference for precedence here).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65743882,
                        "answer_post": "Kotlin has a split function too. It will return a List<String>. If you you need an array in the end, call toTypedArray():\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59557972,
                        "answer_post": "In Java/Kotlin, a String is a sequence of characters, each character has a given index, the index is starting from 0, for example:\n\nFrom substring Kotlin documentation:\n\nReturns the substring of this string starting at the startIndex and\n  ending right before the endIndex.\n\n\nBack to your example:\n\npass.substring(0,3) will returns a substring at the startIndex (0) and ending right before the endIndex (endIndex - 1 = 3 - 1 = 2). But 2 is an invalid index, so the program throws IndexOutOfBoundsException and make your app crash.\nYou can check the length of editText before calling substring() on it.\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 61137291,
                        "answer_post": "example for Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66396834,
                        "answer_post": "Xml:\n\nKotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62829880,
                        "answer_post": "Here is the kotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72599846,
                        "answer_post": "In Kotlin API interface:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59944261,
                        "answer_post": "if use kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63789514,
                        "answer_post": "Kotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65085597,
                        "answer_post": "In kotlin\n\nIn Java\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63145875,
                        "answer_post": "using kotlin function as\n\nusing from  your data\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57622602,
                        "answer_post": "Try this \n\nFor kotlin \n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74960577,
                        "answer_post": "Try this in Kotlin\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "When you write var  arrFirstLetter = charArrayOf() you are creating an empty array.\nThen when you write arrFirstLetter[x] = firstWord[0], you are trying to assign to the element at index x of an empty array. Because the array is empty, this is generating ArrayIndexOutOfBoundsException.\nIn general it's better to avoid trying to loop over collections by using their index and instead use a for loop or the map extension function.\nYou can print out the first letters of each word like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Since Kotlin 1.2, you can use array literals in annotations. These are not part of the actual Kotlin syntax and only reserved for annotations. This might change in the future but currently you cannot make use of array literals in your actual code.\nRead about annotations here.\n\nFor other arguments that have an array type, you need to use the array\n  literal syntax (since Kotlin 1.2) or arrayOf(...):\n// Java\n\n// Kotlin 1.2+:\n\n// Older Kotlin versions:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This happens because in Kotlin Array<Char> is equal to Character[] in Java, not to char[] in Java. \nTo use the spread operator on an array of characters and pass it to a vararg Char parameter, you need to use CharArray which is equal to char[] in Java.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Frame challenge: what you're doing is splitting the string into individual characters \u2014 and there are several existing methods which can do that to a string, such as:\n\nasSequence() gives a Sequence of characters.\nasIterable() gives an Iterable of characters.\u2002(You can do most things to an Iterable that you can to a List.)\ntoCharArray() gives a CharArray.\u2002(Though iterables are generally preferred in Kotlin as they're more flexible and better-supported.)\nforEach() performs a given action on each character.\u2002(This means you can do e.g. for (c in myString) { \u2026 }.)\n\nUsing one of these will be simpler than splitting, and probably more efficient; it'll also make the intent of the code easier to anyone reading it.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "try this\n\nOutput:\n\nYou should avoid Special character in Api\nURL encoding is often required to convert special characters (such as \"/\", \"&\", \"#\", ...), because special characters: \n\nFor instance, the \"#\" character needs to be encoded because it has a special meaning of that of an HTML anchor. \nThe  character needs to be encoded because it is not a valid URL character. Also, some characters, such as \"~\" might not transport properly across the internet. Instead of proceeding with the complex process you should focus on correcting the old one.\nMore you can read here.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Starting from the version 1.3.50 Kotlin has guaranteed sequential array initialization order in its API documentation: https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-array/-init-.html\n\nThe function init is called for each array element sequentially starting from the first one. It should return the value for an array element given its index.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Just like in Java, ' is for character literals, and \" is for String literals. \nYou want \"commons-net:commons-net:3.6\". \nAnd compile() is deprecated. Use implementation().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The equivalent in Java and Kotlin is simply to store an index into the array (or String).\nRemember that the JVM has very powerful dynamic compilation and optimisation, so while in C that would be less efficient, on the JVM it generally won't be.  (The difference generally wouldn't be significant in most applications, anyway.)\nAlso note that Kotlin uses Unicode, so a character is not the same as a byte.  A Character is an unsigned two-byte number.  (Characters outside the Basic Multilingual Plane are stored as a surrogate pair.)\nSo the equivalent would be:\n\nor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can maintain the character mapping and replace required characters by iterating over each character in the word.\n\nIf you want to do it for multiple words, you can create an extension function for better readability\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Well first, that is not how to define a list in Kotlin. Since there are no list literals in Kotlin.\nInstead, it's like listOf(1, 2, 3, 4,) for a normal list, and mutableListOf(1, 2, 3, 4,) for a mutable (editable) list.\nMutableList is basically an ArrayList in Kotlin. But there is still arrayListOf() in Kotlin.\nThere is also toMutableList() extension to most Collection subclasses in Kotlin\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "performance": {
                "finetuned_dpr": [
                    {
                        "id": 57515320,
                        "answer_post": "You'll have to convert your Char to a String in order to convert it to a Digit. Otherwise, you will get the integer used to represent the Char internally.\nUPDATE: If you are using Kotlin 1.5 or higher\nKotlin 1.5 introduced Char.digitToInt(), which does this conversion for you. You can even specify the radix, but it conveniently defaults to base 10.\n\nBefore Kotlin 1.5\n\nAnd you could define an extension function to make this cleaner:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75910340,
                        "answer_post": "In Kotlin you can get Char input by using read() method of the System class.\n\nHere, System.in.read() returns ASCII value (Integer) of the Character entered by the user.\nThen toChar() method converts the Integer value to Char.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65944604,
                        "answer_post": "There are many ways to initialize arrays in Kotlin.  The easiest, if all values are the same (here I'm using blanks), is this:\n\nIf you have a specific set of characters (here I made it a constant), I found this to be an easy way:\n\nIf you want to copy one to another (clone), you can do this:\n\nIn the example you gave above, you're trying to initialize an array of CharArray.  Not sure if that's what you really want, but you can do it this way (I have an array of 25 items, each of which is an array with 5 blanks):\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75110171,
                        "answer_post": "A Kotlin Char is, basically, just a regular number that represents a Unicode character (What are Unicode, UTF-8, and UTF-16?). Each number is assigned to a character, which we can look up in a unicode table. In this we can see that the letter a has a decimal representation of 97.\n\nYou could also get the decimal value using Char.code\n\n\nRun in Kotlin Playground\nTherefore, in decimal, 97 + 25 = 122.\nLooking up 122 in the Unicode table reveals that this is the decimal representation of z. You can again use Char.code to get the decimal representation.\n\n\nRun in Kotlin Playground\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54874814,
                        "answer_post": "The issue isn't disambiguation but rather an incorrect type. In Kotlin, an Array<Char> is equivalent to a Java Character[]. That means that when you use *delim, you're actually creating a vararg Character (instead of vararg Char). \nInstead, you should prefer the primitive-specific CharArray:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 69815786,
                        "answer_post": "I am theorizing from looking at this old issue that the Kotlin developers at one time accidentally treated CharBuffer.charAt() and CharBuffer.get() as equivalent and hid the charAt() method in Kotlin and mapped it to get(). They might have done this in an effort to promote the use of array-access syntax (brackets) and avoid supposed redundancy.\nAnd perhaps later when the above issue was fixed, they missed unhiding the method.\nbuffer.charAt(i) would be buffer[buffer.position() + i] in Kotlin. You could write an extension function so you can continue to use it:\n\nThe error message if you choose an out-of-bounds index will be slightly less informative than the one in the original method.\nMaybe someone should open an issue on YouTrack for this...\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76792619,
                        "answer_post": "Kotlin does not have an array syntax (varray = {1,2,3,4,5}). To create an array in Kotlin, you must use a function such as arrayOf or intArrayOf.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61709254,
                        "answer_post": "\nthis is my try with kotlin only\n\n\n\nhere is your snake string: this_is_camel_case\nconvert from snake to camel\n\n\n\n\nsnakeCaseString\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63402531,
                        "answer_post": "If I understand correctly, you want this for loop to result in a true or false based on whether any inner array has the same sequence and number of chars as the key String.\nFirst of all, the inner array should be a CharArray instead of an Array<Char>, to avoid boxing.\n\nThen you can use all and contentEquals to check if any of the inner CharArrays are a match for the key.\n\nIf you want to skip the step of converting the key to a CharArray, you can manually check it like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55275484,
                        "answer_post": "Since Kotlin 1.2, you can use array literals in annotations. These are not part of the actual Kotlin syntax and only reserved for annotations. This might change in the future but currently you cannot make use of array literals in your actual code.\nRead about annotations here.\n\nFor other arguments that have an array type, you need to use the array\n  literal syntax (since Kotlin 1.2) or arrayOf(...):\n// Java\n\n// Kotlin 1.2+:\n\n// Older Kotlin versions:\n\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 70419158,
                        "answer_post": "Replace org.mockito.Mockito with org.mockito.kotlin.*\nand you can code like this\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76792619,
                        "answer_post": "Kotlin does not have an array syntax (varray = {1,2,3,4,5}). To create an array in Kotlin, you must use a function such as arrayOf or intArrayOf.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68317723,
                        "answer_post": "CharBuffer is pretty low-level and really meant for I/O stuff, so it may seem illogical at first. In your example it actually returned a string containing remaining 8 bytes that you didn't set. To make it return your data you need to invoke flip() like this:\n\nYou can find more in the docs of the Buffer\nFor more typical use cases it is much easier to use StringBuilder:\n\nOr even use a Kotlin util that wraps StringBuilder:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54854295,
                        "answer_post": "Kotlin has two sets of collection interfaces, the regular List, Set, etc. which are read-only, and the same ones with the Mutable prefix, which can be modified.\nlistOf will give you a List instance, while mutableListOf gives you a MutableList instance. If you use the latter for creating your nested lists, you can use the exact syntax you've asked about:\n\n(I've added the explicit type for myList for clarity's sake, it can be omitted from the left side of the assignment.)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60034694,
                        "answer_post": "xor (being an infix function-docs) in Kotlin has lower precedence than the arithmetic operators(*, /, %,+, -) and has higher precedence than Comparison(<, >, <=, >=),Equality(==, !==) & Assignment(=, +=, -=, *=, /=, %=) operators.(check for full reference for precedence here).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60876779,
                        "answer_post": "Kotlin provides a Char.isDefined() extension method that seems to do just what you want (or at least, the direct opposite).\nSo you can do e.g.:\n\n(This function is available in Kotlin/JVM and Kotlin/Native, but not in Kotlin/JS yet.)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65743882,
                        "answer_post": "Kotlin has a split function too. It will return a List<String>. If you you need an array in the end, call toTypedArray():\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70596209,
                        "answer_post": "Use CacheDataSource.Factory() instead of CacheDataSourceFactory and StandaloneDatabaseProvider instead of ExoDatabaseProvider.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62005375,
                        "answer_post": "$ is a special kotlin metacharacter for string templates. You can use the string templating mechanism itself to insert a literal $:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59557972,
                        "answer_post": "In Java/Kotlin, a String is a sequence of characters, each character has a given index, the index is starting from 0, for example:\n\nFrom substring Kotlin documentation:\n\nReturns the substring of this string starting at the startIndex and\n  ending right before the endIndex.\n\n\nBack to your example:\n\npass.substring(0,3) will returns a substring at the startIndex (0) and ending right before the endIndex (endIndex - 1 = 3 - 1 = 2). But 2 is an invalid index, so the program throws IndexOutOfBoundsException and make your app crash.\nYou can check the length of editText before calling substring() on it.\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 61137291,
                        "answer_post": "example for Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66396834,
                        "answer_post": "Xml:\n\nKotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62829880,
                        "answer_post": "Here is the kotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59944261,
                        "answer_post": "if use kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72599846,
                        "answer_post": "In Kotlin API interface:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63145875,
                        "answer_post": "using kotlin function as\n\nusing from  your data\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57622602,
                        "answer_post": "Try this \n\nFor kotlin \n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63789514,
                        "answer_post": "Kotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65085597,
                        "answer_post": "In kotlin\n\nIn Java\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63493144,
                        "answer_post": "Here is how to do it with Kotlin\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "When you write var  arrFirstLetter = charArrayOf() you are creating an empty array.\nThen when you write arrFirstLetter[x] = firstWord[0], you are trying to assign to the element at index x of an empty array. Because the array is empty, this is generating ArrayIndexOutOfBoundsException.\nIn general it's better to avoid trying to loop over collections by using their index and instead use a for loop or the map extension function.\nYou can print out the first letters of each word like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Since Kotlin 1.2, you can use array literals in annotations. These are not part of the actual Kotlin syntax and only reserved for annotations. This might change in the future but currently you cannot make use of array literals in your actual code.\nRead about annotations here.\n\nFor other arguments that have an array type, you need to use the array\n  literal syntax (since Kotlin 1.2) or arrayOf(...):\n// Java\n\n// Kotlin 1.2+:\n\n// Older Kotlin versions:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This happens because in Kotlin Array<Char> is equal to Character[] in Java, not to char[] in Java. \nTo use the spread operator on an array of characters and pass it to a vararg Char parameter, you need to use CharArray which is equal to char[] in Java.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Assumptions: both 2D arrays have the same dimensions, and if both arrays have a non-' ' character at a coordinate, the first array wins.\nI think the easiest way would be to use the Array constructor to create the merged array while iterating the sizes from one of the source arrays, like this. Might as well use CharArray for performance.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Frame challenge: what you're doing is splitting the string into individual characters \u2014 and there are several existing methods which can do that to a string, such as:\n\nasSequence() gives a Sequence of characters.\nasIterable() gives an Iterable of characters.\u2002(You can do most things to an Iterable that you can to a List.)\ntoCharArray() gives a CharArray.\u2002(Though iterables are generally preferred in Kotlin as they're more flexible and better-supported.)\nforEach() performs a given action on each character.\u2002(This means you can do e.g. for (c in myString) { \u2026 }.)\n\nUsing one of these will be simpler than splitting, and probably more efficient; it'll also make the intent of the code easier to anyone reading it.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "try this\n\nOutput:\n\nYou should avoid Special character in Api\nURL encoding is often required to convert special characters (such as \"/\", \"&\", \"#\", ...), because special characters: \n\nFor instance, the \"#\" character needs to be encoded because it has a special meaning of that of an HTML anchor. \nThe  character needs to be encoded because it is not a valid URL character. Also, some characters, such as \"~\" might not transport properly across the internet. Instead of proceeding with the complex process you should focus on correcting the old one.\nMore you can read here.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Starting from the version 1.3.50 Kotlin has guaranteed sequential array initialization order in its API documentation: https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-array/-init-.html\n\nThe function init is called for each array element sequentially starting from the first one. It should return the value for an array element given its index.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Just like in Java, ' is for character literals, and \" is for String literals. \nYou want \"commons-net:commons-net:3.6\". \nAnd compile() is deprecated. Use implementation().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The equivalent in Java and Kotlin is simply to store an index into the array (or String).\nRemember that the JVM has very powerful dynamic compilation and optimisation, so while in C that would be less efficient, on the JVM it generally won't be.  (The difference generally wouldn't be significant in most applications, anyway.)\nAlso note that Kotlin uses Unicode, so a character is not the same as a byte.  A Character is an unsigned two-byte number.  (Characters outside the Basic Multilingual Plane are stored as a surrogate pair.)\nSo the equivalent would be:\n\nor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can maintain the character mapping and replace required characters by iterating over each character in the word.\n\nIf you want to do it for multiple words, you can create an extension function for better readability\n\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "directive": {
                "finetuned_dpr": [
                    {
                        "id": 57515320,
                        "answer_post": "You'll have to convert your Char to a String in order to convert it to a Digit. Otherwise, you will get the integer used to represent the Char internally.\nUPDATE: If you are using Kotlin 1.5 or higher\nKotlin 1.5 introduced Char.digitToInt(), which does this conversion for you. You can even specify the radix, but it conveniently defaults to base 10.\n\nBefore Kotlin 1.5\n\nAnd you could define an extension function to make this cleaner:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63402531,
                        "answer_post": "If I understand correctly, you want this for loop to result in a true or false based on whether any inner array has the same sequence and number of chars as the key String.\nFirst of all, the inner array should be a CharArray instead of an Array<Char>, to avoid boxing.\n\nThen you can use all and contentEquals to check if any of the inner CharArrays are a match for the key.\n\nIf you want to skip the step of converting the key to a CharArray, you can manually check it like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65944604,
                        "answer_post": "There are many ways to initialize arrays in Kotlin.  The easiest, if all values are the same (here I'm using blanks), is this:\n\nIf you have a specific set of characters (here I made it a constant), I found this to be an easy way:\n\nIf you want to copy one to another (clone), you can do this:\n\nIn the example you gave above, you're trying to initialize an array of CharArray.  Not sure if that's what you really want, but you can do it this way (I have an array of 25 items, each of which is an array with 5 blanks):\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75910340,
                        "answer_post": "In Kotlin you can get Char input by using read() method of the System class.\n\nHere, System.in.read() returns ASCII value (Integer) of the Character entered by the user.\nThen toChar() method converts the Integer value to Char.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69815786,
                        "answer_post": "I am theorizing from looking at this old issue that the Kotlin developers at one time accidentally treated CharBuffer.charAt() and CharBuffer.get() as equivalent and hid the charAt() method in Kotlin and mapped it to get(). They might have done this in an effort to promote the use of array-access syntax (brackets) and avoid supposed redundancy.\nAnd perhaps later when the above issue was fixed, they missed unhiding the method.\nbuffer.charAt(i) would be buffer[buffer.position() + i] in Kotlin. You could write an extension function so you can continue to use it:\n\nThe error message if you choose an out-of-bounds index will be slightly less informative than the one in the original method.\nMaybe someone should open an issue on YouTrack for this...\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75110171,
                        "answer_post": "A Kotlin Char is, basically, just a regular number that represents a Unicode character (What are Unicode, UTF-8, and UTF-16?). Each number is assigned to a character, which we can look up in a unicode table. In this we can see that the letter a has a decimal representation of 97.\n\nYou could also get the decimal value using Char.code\n\n\nRun in Kotlin Playground\nTherefore, in decimal, 97 + 25 = 122.\nLooking up 122 in the Unicode table reveals that this is the decimal representation of z. You can again use Char.code to get the decimal representation.\n\n\nRun in Kotlin Playground\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54874814,
                        "answer_post": "The issue isn't disambiguation but rather an incorrect type. In Kotlin, an Array<Char> is equivalent to a Java Character[]. That means that when you use *delim, you're actually creating a vararg Character (instead of vararg Char). \nInstead, you should prefer the primitive-specific CharArray:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76792619,
                        "answer_post": "Kotlin does not have an array syntax (varray = {1,2,3,4,5}). To create an array in Kotlin, you must use a function such as arrayOf or intArrayOf.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68586238,
                        "answer_post": "To convert Char back to Int use code property:\n\n\n\nChar type in Kotlin represents a 16-bit Unicode character. Code 49 corresponds to character '1'.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56825391,
                        "answer_post": "Which char do you want?\nThis will return the first char of the String, since a String is essentially a CharArray.\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 68317723,
                        "answer_post": "CharBuffer is pretty low-level and really meant for I/O stuff, so it may seem illogical at first. In your example it actually returned a string containing remaining 8 bytes that you didn't set. To make it return your data you need to invoke flip() like this:\n\nYou can find more in the docs of the Buffer\nFor more typical use cases it is much easier to use StringBuilder:\n\nOr even use a Kotlin util that wraps StringBuilder:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70419158,
                        "answer_post": "Replace org.mockito.Mockito with org.mockito.kotlin.*\nand you can code like this\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76792619,
                        "answer_post": "Kotlin does not have an array syntax (varray = {1,2,3,4,5}). To create an array in Kotlin, you must use a function such as arrayOf or intArrayOf.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54854295,
                        "answer_post": "Kotlin has two sets of collection interfaces, the regular List, Set, etc. which are read-only, and the same ones with the Mutable prefix, which can be modified.\nlistOf will give you a List instance, while mutableListOf gives you a MutableList instance. If you use the latter for creating your nested lists, you can use the exact syntax you've asked about:\n\n(I've added the explicit type for myList for clarity's sake, it can be omitted from the left side of the assignment.)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60034694,
                        "answer_post": "xor (being an infix function-docs) in Kotlin has lower precedence than the arithmetic operators(*, /, %,+, -) and has higher precedence than Comparison(<, >, <=, >=),Equality(==, !==) & Assignment(=, +=, -=, *=, /=, %=) operators.(check for full reference for precedence here).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65743882,
                        "answer_post": "Kotlin has a split function too. It will return a List<String>. If you you need an array in the end, call toTypedArray():\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56166743,
                        "answer_post": "arrayListOf is a function, that has optional variable length arguments\nIn case of using it without arguments, there is no difference\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62005375,
                        "answer_post": "$ is a special kotlin metacharacter for string templates. You can use the string templating mechanism itself to insert a literal $:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60876779,
                        "answer_post": "Kotlin provides a Char.isDefined() extension method that seems to do just what you want (or at least, the direct opposite).\nSo you can do e.g.:\n\n(This function is available in Kotlin/JVM and Kotlin/Native, but not in Kotlin/JS yet.)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59557972,
                        "answer_post": "In Java/Kotlin, a String is a sequence of characters, each character has a given index, the index is starting from 0, for example:\n\nFrom substring Kotlin documentation:\n\nReturns the substring of this string starting at the startIndex and\n  ending right before the endIndex.\n\n\nBack to your example:\n\npass.substring(0,3) will returns a substring at the startIndex (0) and ending right before the endIndex (endIndex - 1 = 3 - 1 = 2). But 2 is an invalid index, so the program throws IndexOutOfBoundsException and make your app crash.\nYou can check the length of editText before calling substring() on it.\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 61137291,
                        "answer_post": "example for Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66396834,
                        "answer_post": "Xml:\n\nKotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62829880,
                        "answer_post": "Here is the kotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59944261,
                        "answer_post": "if use kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72599846,
                        "answer_post": "In Kotlin API interface:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63145875,
                        "answer_post": "using kotlin function as\n\nusing from  your data\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63493144,
                        "answer_post": "Here is how to do it with Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57637304,
                        "answer_post": "Here how can you use that in Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63789514,
                        "answer_post": "Kotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65085597,
                        "answer_post": "In kotlin\n\nIn Java\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "When you write var  arrFirstLetter = charArrayOf() you are creating an empty array.\nThen when you write arrFirstLetter[x] = firstWord[0], you are trying to assign to the element at index x of an empty array. Because the array is empty, this is generating ArrayIndexOutOfBoundsException.\nIn general it's better to avoid trying to loop over collections by using their index and instead use a for loop or the map extension function.\nYou can print out the first letters of each word like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Since Kotlin 1.2, you can use array literals in annotations. These are not part of the actual Kotlin syntax and only reserved for annotations. This might change in the future but currently you cannot make use of array literals in your actual code.\nRead about annotations here.\n\nFor other arguments that have an array type, you need to use the array\n  literal syntax (since Kotlin 1.2) or arrayOf(...):\n// Java\n\n// Kotlin 1.2+:\n\n// Older Kotlin versions:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This happens because in Kotlin Array<Char> is equal to Character[] in Java, not to char[] in Java. \nTo use the spread operator on an array of characters and pass it to a vararg Char parameter, you need to use CharArray which is equal to char[] in Java.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Frame challenge: what you're doing is splitting the string into individual characters \u2014 and there are several existing methods which can do that to a string, such as:\n\nasSequence() gives a Sequence of characters.\nasIterable() gives an Iterable of characters.\u2002(You can do most things to an Iterable that you can to a List.)\ntoCharArray() gives a CharArray.\u2002(Though iterables are generally preferred in Kotlin as they're more flexible and better-supported.)\nforEach() performs a given action on each character.\u2002(This means you can do e.g. for (c in myString) { \u2026 }.)\n\nUsing one of these will be simpler than splitting, and probably more efficient; it'll also make the intent of the code easier to anyone reading it.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "try this\n\nOutput:\n\nYou should avoid Special character in Api\nURL encoding is often required to convert special characters (such as \"/\", \"&\", \"#\", ...), because special characters: \n\nFor instance, the \"#\" character needs to be encoded because it has a special meaning of that of an HTML anchor. \nThe  character needs to be encoded because it is not a valid URL character. Also, some characters, such as \"~\" might not transport properly across the internet. Instead of proceeding with the complex process you should focus on correcting the old one.\nMore you can read here.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "In C#, you try and use UTF-8 encoding to turn your bytes into a string. However, this is a very bad idea -- there are many sequences of bytes which aren't valid in a UTF-8-encoded string, and further sequences which will result in unprintable characters. If the encoder encounters a sequence of bytes which don't form a valid UTF-8-encoded character (and it will do, because you're not doing anything to ensure that your sequence of bytes is a valid UTF-8-encoded string), it will insert a replacement character.\nIn Kotlin, you use new String(byte[]) which uses your system's encoding. You've got a similar problem here: although most bytes will result in a valid character, some of those characters will be unprintable.\nSo you're using two different encodings for C# and Kotlin (hence different results), but you're also doing something which will probably give you unprintable characters, or might replace sequences of bytes with a replacement character (so different MD5 hashes will look the same).\n(Note that \"unprintable characters\" might just not be visible, but they might do strange things like reverse the direction of text on that page, or start joining together the characters around them!)\nYou'd be better off turning your bytes into a base64 string, or a sequence of hex characters. Both of these make sure that every possible sequence of bytes gets turned into printable characters, in a way which is consistent across different languages.\nFor C#, use Convert.ToBase64String(data) to get a base64-encoded string, and BitConverter.ToString(data).Replace(\"-\",\"\") to get a hex-encoded string (although there are many way to do this).\nFor Kotlin, use Base64.getEncoder().encodeToString(data) to get a base64-encoded string, and data.joinToString(\"\") { \"%02x\".format(it) } to get a hex-encoded string.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Starting from the version 1.3.50 Kotlin has guaranteed sequential array initialization order in its API documentation: https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-array/-init-.html\n\nThe function init is called for each array element sequentially starting from the first one. It should return the value for an array element given its index.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Just like in Java, ' is for character literals, and \" is for String literals. \nYou want \"commons-net:commons-net:3.6\". \nAnd compile() is deprecated. Use implementation().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The equivalent in Java and Kotlin is simply to store an index into the array (or String).\nRemember that the JVM has very powerful dynamic compilation and optimisation, so while in C that would be less efficient, on the JVM it generally won't be.  (The difference generally wouldn't be significant in most applications, anyway.)\nAlso note that Kotlin uses Unicode, so a character is not the same as a byte.  A Character is an unsigned two-byte number.  (Characters outside the Basic Multilingual Plane are stored as a surrogate pair.)\nSo the equivalent would be:\n\nor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can maintain the character mapping and replace required characters by iterating over each character in the word.\n\nIf you want to do it for multiple words, you can create an extension function for better readability\n\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "pattern": {
                "finetuned_dpr": [
                    {
                        "id": 57515320,
                        "answer_post": "You'll have to convert your Char to a String in order to convert it to a Digit. Otherwise, you will get the integer used to represent the Char internally.\nUPDATE: If you are using Kotlin 1.5 or higher\nKotlin 1.5 introduced Char.digitToInt(), which does this conversion for you. You can even specify the radix, but it conveniently defaults to base 10.\n\nBefore Kotlin 1.5\n\nAnd you could define an extension function to make this cleaner:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63402531,
                        "answer_post": "If I understand correctly, you want this for loop to result in a true or false based on whether any inner array has the same sequence and number of chars as the key String.\nFirst of all, the inner array should be a CharArray instead of an Array<Char>, to avoid boxing.\n\nThen you can use all and contentEquals to check if any of the inner CharArrays are a match for the key.\n\nIf you want to skip the step of converting the key to a CharArray, you can manually check it like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65944604,
                        "answer_post": "There are many ways to initialize arrays in Kotlin.  The easiest, if all values are the same (here I'm using blanks), is this:\n\nIf you have a specific set of characters (here I made it a constant), I found this to be an easy way:\n\nIf you want to copy one to another (clone), you can do this:\n\nIn the example you gave above, you're trying to initialize an array of CharArray.  Not sure if that's what you really want, but you can do it this way (I have an array of 25 items, each of which is an array with 5 blanks):\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75910340,
                        "answer_post": "In Kotlin you can get Char input by using read() method of the System class.\n\nHere, System.in.read() returns ASCII value (Integer) of the Character entered by the user.\nThen toChar() method converts the Integer value to Char.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75110171,
                        "answer_post": "A Kotlin Char is, basically, just a regular number that represents a Unicode character (What are Unicode, UTF-8, and UTF-16?). Each number is assigned to a character, which we can look up in a unicode table. In this we can see that the letter a has a decimal representation of 97.\n\nYou could also get the decimal value using Char.code\n\n\nRun in Kotlin Playground\nTherefore, in decimal, 97 + 25 = 122.\nLooking up 122 in the Unicode table reveals that this is the decimal representation of z. You can again use Char.code to get the decimal representation.\n\n\nRun in Kotlin Playground\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56825391,
                        "answer_post": "Which char do you want?\nThis will return the first char of the String, since a String is essentially a CharArray.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54874814,
                        "answer_post": "The issue isn't disambiguation but rather an incorrect type. In Kotlin, an Array<Char> is equivalent to a Java Character[]. That means that when you use *delim, you're actually creating a vararg Character (instead of vararg Char). \nInstead, you should prefer the primitive-specific CharArray:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76792619,
                        "answer_post": "Kotlin does not have an array syntax (varray = {1,2,3,4,5}). To create an array in Kotlin, you must use a function such as arrayOf or intArrayOf.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55908561,
                        "answer_post": "You have declared a variable of type CharArray, but haven't assigned it with any instance. \nBefore you can set elements of that CharArray, you have to create an instance of CharArray. It looks like you know the size of that array in advance, then you can use the following array constructor:\n\nBonus point: if you have a function that can provide an array element value given its index you can use the similar constructor to create instance and initialized its elements at once:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 69815786,
                        "answer_post": "I am theorizing from looking at this old issue that the Kotlin developers at one time accidentally treated CharBuffer.charAt() and CharBuffer.get() as equivalent and hid the charAt() method in Kotlin and mapped it to get(). They might have done this in an effort to promote the use of array-access syntax (brackets) and avoid supposed redundancy.\nAnd perhaps later when the above issue was fixed, they missed unhiding the method.\nbuffer.charAt(i) would be buffer[buffer.position() + i] in Kotlin. You could write an extension function so you can continue to use it:\n\nThe error message if you choose an out-of-bounds index will be slightly less informative than the one in the original method.\nMaybe someone should open an issue on YouTrack for this...\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 68317723,
                        "answer_post": "CharBuffer is pretty low-level and really meant for I/O stuff, so it may seem illogical at first. In your example it actually returned a string containing remaining 8 bytes that you didn't set. To make it return your data you need to invoke flip() like this:\n\nYou can find more in the docs of the Buffer\nFor more typical use cases it is much easier to use StringBuilder:\n\nOr even use a Kotlin util that wraps StringBuilder:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76792619,
                        "answer_post": "Kotlin does not have an array syntax (varray = {1,2,3,4,5}). To create an array in Kotlin, you must use a function such as arrayOf or intArrayOf.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70419158,
                        "answer_post": "Replace org.mockito.Mockito with org.mockito.kotlin.*\nand you can code like this\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54854295,
                        "answer_post": "Kotlin has two sets of collection interfaces, the regular List, Set, etc. which are read-only, and the same ones with the Mutable prefix, which can be modified.\nlistOf will give you a List instance, while mutableListOf gives you a MutableList instance. If you use the latter for creating your nested lists, you can use the exact syntax you've asked about:\n\n(I've added the explicit type for myList for clarity's sake, it can be omitted from the left side of the assignment.)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60034694,
                        "answer_post": "xor (being an infix function-docs) in Kotlin has lower precedence than the arithmetic operators(*, /, %,+, -) and has higher precedence than Comparison(<, >, <=, >=),Equality(==, !==) & Assignment(=, +=, -=, *=, /=, %=) operators.(check for full reference for precedence here).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65743882,
                        "answer_post": "Kotlin has a split function too. It will return a List<String>. If you you need an array in the end, call toTypedArray():\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59557972,
                        "answer_post": "In Java/Kotlin, a String is a sequence of characters, each character has a given index, the index is starting from 0, for example:\n\nFrom substring Kotlin documentation:\n\nReturns the substring of this string starting at the startIndex and\n  ending right before the endIndex.\n\n\nBack to your example:\n\npass.substring(0,3) will returns a substring at the startIndex (0) and ending right before the endIndex (endIndex - 1 = 3 - 1 = 2). But 2 is an invalid index, so the program throws IndexOutOfBoundsException and make your app crash.\nYou can check the length of editText before calling substring() on it.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62005375,
                        "answer_post": "$ is a special kotlin metacharacter for string templates. You can use the string templating mechanism itself to insert a literal $:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56166743,
                        "answer_post": "arrayListOf is a function, that has optional variable length arguments\nIn case of using it without arguments, there is no difference\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60876779,
                        "answer_post": "Kotlin provides a Char.isDefined() extension method that seems to do just what you want (or at least, the direct opposite).\nSo you can do e.g.:\n\n(This function is available in Kotlin/JVM and Kotlin/Native, but not in Kotlin/JS yet.)\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 61137291,
                        "answer_post": "example for Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66396834,
                        "answer_post": "Xml:\n\nKotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59944261,
                        "answer_post": "if use kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62829880,
                        "answer_post": "Here is the kotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63145875,
                        "answer_post": "using kotlin function as\n\nusing from  your data\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65085597,
                        "answer_post": "In kotlin\n\nIn Java\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72599846,
                        "answer_post": "In Kotlin API interface:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63789514,
                        "answer_post": "Kotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57637304,
                        "answer_post": "Here how can you use that in Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57622602,
                        "answer_post": "Try this \n\nFor kotlin \n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "When you write var  arrFirstLetter = charArrayOf() you are creating an empty array.\nThen when you write arrFirstLetter[x] = firstWord[0], you are trying to assign to the element at index x of an empty array. Because the array is empty, this is generating ArrayIndexOutOfBoundsException.\nIn general it's better to avoid trying to loop over collections by using their index and instead use a for loop or the map extension function.\nYou can print out the first letters of each word like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Since Kotlin 1.2, you can use array literals in annotations. These are not part of the actual Kotlin syntax and only reserved for annotations. This might change in the future but currently you cannot make use of array literals in your actual code.\nRead about annotations here.\n\nFor other arguments that have an array type, you need to use the array\n  literal syntax (since Kotlin 1.2) or arrayOf(...):\n// Java\n\n// Kotlin 1.2+:\n\n// Older Kotlin versions:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This happens because in Kotlin Array<Char> is equal to Character[] in Java, not to char[] in Java. \nTo use the spread operator on an array of characters and pass it to a vararg Char parameter, you need to use CharArray which is equal to char[] in Java.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Frame challenge: what you're doing is splitting the string into individual characters \u2014 and there are several existing methods which can do that to a string, such as:\n\nasSequence() gives a Sequence of characters.\nasIterable() gives an Iterable of characters.\u2002(You can do most things to an Iterable that you can to a List.)\ntoCharArray() gives a CharArray.\u2002(Though iterables are generally preferred in Kotlin as they're more flexible and better-supported.)\nforEach() performs a given action on each character.\u2002(This means you can do e.g. for (c in myString) { \u2026 }.)\n\nUsing one of these will be simpler than splitting, and probably more efficient; it'll also make the intent of the code easier to anyone reading it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "try this\n\nOutput:\n\nYou should avoid Special character in Api\nURL encoding is often required to convert special characters (such as \"/\", \"&\", \"#\", ...), because special characters: \n\nFor instance, the \"#\" character needs to be encoded because it has a special meaning of that of an HTML anchor. \nThe  character needs to be encoded because it is not a valid URL character. Also, some characters, such as \"~\" might not transport properly across the internet. Instead of proceeding with the complex process you should focus on correcting the old one.\nMore you can read here.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Starting from the version 1.3.50 Kotlin has guaranteed sequential array initialization order in its API documentation: https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-array/-init-.html\n\nThe function init is called for each array element sequentially starting from the first one. It should return the value for an array element given its index.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Just like in Java, ' is for character literals, and \" is for String literals. \nYou want \"commons-net:commons-net:3.6\". \nAnd compile() is deprecated. Use implementation().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The equivalent in Java and Kotlin is simply to store an index into the array (or String).\nRemember that the JVM has very powerful dynamic compilation and optimisation, so while in C that would be less efficient, on the JVM it generally won't be.  (The difference generally wouldn't be significant in most applications, anyway.)\nAlso note that Kotlin uses Unicode, so a character is not the same as a byte.  A Character is an unsigned two-byte number.  (Characters outside the Basic Multilingual Plane are stored as a surrogate pair.)\nSo the equivalent would be:\n\nor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can maintain the character mapping and replace required characters by iterating over each character in the word.\n\nIf you want to do it for multiple words, you can create an extension function for better readability\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Well first, that is not how to define a list in Kotlin. Since there are no list literals in Kotlin.\nInstead, it's like listOf(1, 2, 3, 4,) for a normal list, and mutableListOf(1, 2, 3, 4,) for a mutable (editable) list.\nMutableList is basically an ArrayList in Kotlin. But there is still arrayListOf() in Kotlin.\nThere is also toMutableList() extension to most Collection subclasses in Kotlin\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "environment": {
                "finetuned_dpr": [
                    {
                        "id": 57515320,
                        "answer_post": "You'll have to convert your Char to a String in order to convert it to a Digit. Otherwise, you will get the integer used to represent the Char internally.\nUPDATE: If you are using Kotlin 1.5 or higher\nKotlin 1.5 introduced Char.digitToInt(), which does this conversion for you. You can even specify the radix, but it conveniently defaults to base 10.\n\nBefore Kotlin 1.5\n\nAnd you could define an extension function to make this cleaner:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75910340,
                        "answer_post": "In Kotlin you can get Char input by using read() method of the System class.\n\nHere, System.in.read() returns ASCII value (Integer) of the Character entered by the user.\nThen toChar() method converts the Integer value to Char.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62418607,
                        "answer_post": "(Updated) I am not an expert in Kotlin but you can do something like this :\n\nOutput:\n\nI hope now it makes sense you just need to pass the class to the method and it returns an object.\nAs you will be using Animal as a parent class so you can replace Any => Animal \n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63402531,
                        "answer_post": "If I understand correctly, you want this for loop to result in a true or false based on whether any inner array has the same sequence and number of chars as the key String.\nFirst of all, the inner array should be a CharArray instead of an Array<Char>, to avoid boxing.\n\nThen you can use all and contentEquals to check if any of the inner CharArrays are a match for the key.\n\nIf you want to skip the step of converting the key to a CharArray, you can manually check it like this:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69815786,
                        "answer_post": "I am theorizing from looking at this old issue that the Kotlin developers at one time accidentally treated CharBuffer.charAt() and CharBuffer.get() as equivalent and hid the charAt() method in Kotlin and mapped it to get(). They might have done this in an effort to promote the use of array-access syntax (brackets) and avoid supposed redundancy.\nAnd perhaps later when the above issue was fixed, they missed unhiding the method.\nbuffer.charAt(i) would be buffer[buffer.position() + i] in Kotlin. You could write an extension function so you can continue to use it:\n\nThe error message if you choose an out-of-bounds index will be slightly less informative than the one in the original method.\nMaybe someone should open an issue on YouTrack for this...\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65944604,
                        "answer_post": "There are many ways to initialize arrays in Kotlin.  The easiest, if all values are the same (here I'm using blanks), is this:\n\nIf you have a specific set of characters (here I made it a constant), I found this to be an easy way:\n\nIf you want to copy one to another (clone), you can do this:\n\nIn the example you gave above, you're trying to initialize an array of CharArray.  Not sure if that's what you really want, but you can do it this way (I have an array of 25 items, each of which is an array with 5 blanks):\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54874814,
                        "answer_post": "The issue isn't disambiguation but rather an incorrect type. In Kotlin, an Array<Char> is equivalent to a Java Character[]. That means that when you use *delim, you're actually creating a vararg Character (instead of vararg Char). \nInstead, you should prefer the primitive-specific CharArray:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75110171,
                        "answer_post": "A Kotlin Char is, basically, just a regular number that represents a Unicode character (What are Unicode, UTF-8, and UTF-16?). Each number is assigned to a character, which we can look up in a unicode table. In this we can see that the letter a has a decimal representation of 97.\n\nYou could also get the decimal value using Char.code\n\n\nRun in Kotlin Playground\nTherefore, in decimal, 97 + 25 = 122.\nLooking up 122 in the Unicode table reveals that this is the decimal representation of z. You can again use Char.code to get the decimal representation.\n\n\nRun in Kotlin Playground\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76792619,
                        "answer_post": "Kotlin does not have an array syntax (varray = {1,2,3,4,5}). To create an array in Kotlin, you must use a function such as arrayOf or intArrayOf.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55275484,
                        "answer_post": "Since Kotlin 1.2, you can use array literals in annotations. These are not part of the actual Kotlin syntax and only reserved for annotations. This might change in the future but currently you cannot make use of array literals in your actual code.\nRead about annotations here.\n\nFor other arguments that have an array type, you need to use the array\n  literal syntax (since Kotlin 1.2) or arrayOf(...):\n// Java\n\n// Kotlin 1.2+:\n\n// Older Kotlin versions:\n\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 68317723,
                        "answer_post": "CharBuffer is pretty low-level and really meant for I/O stuff, so it may seem illogical at first. In your example it actually returned a string containing remaining 8 bytes that you didn't set. To make it return your data you need to invoke flip() like this:\n\nYou can find more in the docs of the Buffer\nFor more typical use cases it is much easier to use StringBuilder:\n\nOr even use a Kotlin util that wraps StringBuilder:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76792619,
                        "answer_post": "Kotlin does not have an array syntax (varray = {1,2,3,4,5}). To create an array in Kotlin, you must use a function such as arrayOf or intArrayOf.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70419158,
                        "answer_post": "Replace org.mockito.Mockito with org.mockito.kotlin.*\nand you can code like this\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54854295,
                        "answer_post": "Kotlin has two sets of collection interfaces, the regular List, Set, etc. which are read-only, and the same ones with the Mutable prefix, which can be modified.\nlistOf will give you a List instance, while mutableListOf gives you a MutableList instance. If you use the latter for creating your nested lists, you can use the exact syntax you've asked about:\n\n(I've added the explicit type for myList for clarity's sake, it can be omitted from the left side of the assignment.)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59557972,
                        "answer_post": "In Java/Kotlin, a String is a sequence of characters, each character has a given index, the index is starting from 0, for example:\n\nFrom substring Kotlin documentation:\n\nReturns the substring of this string starting at the startIndex and\n  ending right before the endIndex.\n\n\nBack to your example:\n\npass.substring(0,3) will returns a substring at the startIndex (0) and ending right before the endIndex (endIndex - 1 = 3 - 1 = 2). But 2 is an invalid index, so the program throws IndexOutOfBoundsException and make your app crash.\nYou can check the length of editText before calling substring() on it.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60876779,
                        "answer_post": "Kotlin provides a Char.isDefined() extension method that seems to do just what you want (or at least, the direct opposite).\nSo you can do e.g.:\n\n(This function is available in Kotlin/JVM and Kotlin/Native, but not in Kotlin/JS yet.)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62005375,
                        "answer_post": "$ is a special kotlin metacharacter for string templates. You can use the string templating mechanism itself to insert a literal $:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65743882,
                        "answer_post": "Kotlin has a split function too. It will return a List<String>. If you you need an array in the end, call toTypedArray():\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55073098,
                        "answer_post": "arrayOf and mutableListOf are not in \"global scope\" (that's not even something that exists). They're in the kotlin and kotlin.collections packages, respectively.\nIt just so happens that kotlin.* and kotlin.collections.* are default imports of any kotlin file, so you don't have to make that import yourself. See Default Imports.\nThis is similar to Java where java.lang.* is imported by default and you don't need to specify it.\nAlso, you can't \"construct\" arrayOf and mutableListOf because they're not types; they're methods - and the fact the they start with a lowercase letter is the standard way to indicate that - types start with uppercase letters.\nKotlin allows methods at package level outside a class (although when compiled for the JVM, they will be inside a class), but that's not very different from an import static in Java with which you can access a static method from a class without the classname as a prefix.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57705139,
                        "answer_post": "Kotlin 1.3 provides Extension Function to ease the task.\nUsage:\n\nIn Kotlin 1.4 appendln() is deprecated and appendLine() is introduced.\nUsage:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 61137291,
                        "answer_post": "example for Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66396834,
                        "answer_post": "Xml:\n\nKotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62829880,
                        "answer_post": "Here is the kotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59944261,
                        "answer_post": "if use kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72599846,
                        "answer_post": "In Kotlin API interface:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57622602,
                        "answer_post": "Try this \n\nFor kotlin \n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65085597,
                        "answer_post": "In kotlin\n\nIn Java\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74960577,
                        "answer_post": "Try this in Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63789514,
                        "answer_post": "Kotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57637304,
                        "answer_post": "Here how can you use that in Kotlin\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "When you write var  arrFirstLetter = charArrayOf() you are creating an empty array.\nThen when you write arrFirstLetter[x] = firstWord[0], you are trying to assign to the element at index x of an empty array. Because the array is empty, this is generating ArrayIndexOutOfBoundsException.\nIn general it's better to avoid trying to loop over collections by using their index and instead use a for loop or the map extension function.\nYou can print out the first letters of each word like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Since Kotlin 1.2, you can use array literals in annotations. These are not part of the actual Kotlin syntax and only reserved for annotations. This might change in the future but currently you cannot make use of array literals in your actual code.\nRead about annotations here.\n\nFor other arguments that have an array type, you need to use the array\n  literal syntax (since Kotlin 1.2) or arrayOf(...):\n// Java\n\n// Kotlin 1.2+:\n\n// Older Kotlin versions:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This happens because in Kotlin Array<Char> is equal to Character[] in Java, not to char[] in Java. \nTo use the spread operator on an array of characters and pass it to a vararg Char parameter, you need to use CharArray which is equal to char[] in Java.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "What I wanted was not possible. When reading teamcity environment variables in kotlin, during compilation time, they are read as literals.\nThat is why \"%env.VAR%\".uppercase() was returning %ENV.VAR%.\nDuring the execution time, the expression \"%env.VAR%\" is read as environment variable, and %ENV.VAR% fails to return anything.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Frame challenge: what you're doing is splitting the string into individual characters \u2014 and there are several existing methods which can do that to a string, such as:\n\nasSequence() gives a Sequence of characters.\nasIterable() gives an Iterable of characters.\u2002(You can do most things to an Iterable that you can to a List.)\ntoCharArray() gives a CharArray.\u2002(Though iterables are generally preferred in Kotlin as they're more flexible and better-supported.)\nforEach() performs a given action on each character.\u2002(This means you can do e.g. for (c in myString) { \u2026 }.)\n\nUsing one of these will be simpler than splitting, and probably more efficient; it'll also make the intent of the code easier to anyone reading it.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "try this\n\nOutput:\n\nYou should avoid Special character in Api\nURL encoding is often required to convert special characters (such as \"/\", \"&\", \"#\", ...), because special characters: \n\nFor instance, the \"#\" character needs to be encoded because it has a special meaning of that of an HTML anchor. \nThe  character needs to be encoded because it is not a valid URL character. Also, some characters, such as \"~\" might not transport properly across the internet. Instead of proceeding with the complex process you should focus on correcting the old one.\nMore you can read here.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Starting from the version 1.3.50 Kotlin has guaranteed sequential array initialization order in its API documentation: https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-array/-init-.html\n\nThe function init is called for each array element sequentially starting from the first one. It should return the value for an array element given its index.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Just like in Java, ' is for character literals, and \" is for String literals. \nYou want \"commons-net:commons-net:3.6\". \nAnd compile() is deprecated. Use implementation().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The equivalent in Java and Kotlin is simply to store an index into the array (or String).\nRemember that the JVM has very powerful dynamic compilation and optimisation, so while in C that would be less efficient, on the JVM it generally won't be.  (The difference generally wouldn't be significant in most applications, anyway.)\nAlso note that Kotlin uses Unicode, so a character is not the same as a byte.  A Character is an unsigned two-byte number.  (Characters outside the Basic Multilingual Plane are stored as a surrogate pair.)\nSo the equivalent would be:\n\nor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can maintain the character mapping and replace required characters by iterating over each character in the word.\n\nIf you want to do it for multiple words, you can create an extension function for better readability\n\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "alternative": {
                "finetuned_dpr": [
                    {
                        "id": 57515320,
                        "answer_post": "You'll have to convert your Char to a String in order to convert it to a Digit. Otherwise, you will get the integer used to represent the Char internally.\nUPDATE: If you are using Kotlin 1.5 or higher\nKotlin 1.5 introduced Char.digitToInt(), which does this conversion for you. You can even specify the radix, but it conveniently defaults to base 10.\n\nBefore Kotlin 1.5\n\nAnd you could define an extension function to make this cleaner:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54874814,
                        "answer_post": "The issue isn't disambiguation but rather an incorrect type. In Kotlin, an Array<Char> is equivalent to a Java Character[]. That means that when you use *delim, you're actually creating a vararg Character (instead of vararg Char). \nInstead, you should prefer the primitive-specific CharArray:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63402531,
                        "answer_post": "If I understand correctly, you want this for loop to result in a true or false based on whether any inner array has the same sequence and number of chars as the key String.\nFirst of all, the inner array should be a CharArray instead of an Array<Char>, to avoid boxing.\n\nThen you can use all and contentEquals to check if any of the inner CharArrays are a match for the key.\n\nIf you want to skip the step of converting the key to a CharArray, you can manually check it like this:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69815786,
                        "answer_post": "I am theorizing from looking at this old issue that the Kotlin developers at one time accidentally treated CharBuffer.charAt() and CharBuffer.get() as equivalent and hid the charAt() method in Kotlin and mapped it to get(). They might have done this in an effort to promote the use of array-access syntax (brackets) and avoid supposed redundancy.\nAnd perhaps later when the above issue was fixed, they missed unhiding the method.\nbuffer.charAt(i) would be buffer[buffer.position() + i] in Kotlin. You could write an extension function so you can continue to use it:\n\nThe error message if you choose an out-of-bounds index will be slightly less informative than the one in the original method.\nMaybe someone should open an issue on YouTrack for this...\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75910340,
                        "answer_post": "In Kotlin you can get Char input by using read() method of the System class.\n\nHere, System.in.read() returns ASCII value (Integer) of the Character entered by the user.\nThen toChar() method converts the Integer value to Char.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65944604,
                        "answer_post": "There are many ways to initialize arrays in Kotlin.  The easiest, if all values are the same (here I'm using blanks), is this:\n\nIf you have a specific set of characters (here I made it a constant), I found this to be an easy way:\n\nIf you want to copy one to another (clone), you can do this:\n\nIn the example you gave above, you're trying to initialize an array of CharArray.  Not sure if that's what you really want, but you can do it this way (I have an array of 25 items, each of which is an array with 5 blanks):\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75110171,
                        "answer_post": "A Kotlin Char is, basically, just a regular number that represents a Unicode character (What are Unicode, UTF-8, and UTF-16?). Each number is assigned to a character, which we can look up in a unicode table. In this we can see that the letter a has a decimal representation of 97.\n\nYou could also get the decimal value using Char.code\n\n\nRun in Kotlin Playground\nTherefore, in decimal, 97 + 25 = 122.\nLooking up 122 in the Unicode table reveals that this is the decimal representation of z. You can again use Char.code to get the decimal representation.\n\n\nRun in Kotlin Playground\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55362492,
                        "answer_post": "If you just want to replace all of the instances of one Char in a String with another Char, you can use the String.replace() extension, which is part of the Kotlin standard library:\n\nThere shouldn't be a need to do any conversions to Strings, CharArrays, or anything else. I wouldn't even define a function to encapsulate this, you can probably drop replaceSpace entirely.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55275484,
                        "answer_post": "Since Kotlin 1.2, you can use array literals in annotations. These are not part of the actual Kotlin syntax and only reserved for annotations. This might change in the future but currently you cannot make use of array literals in your actual code.\nRead about annotations here.\n\nFor other arguments that have an array type, you need to use the array\n  literal syntax (since Kotlin 1.2) or arrayOf(...):\n// Java\n\n// Kotlin 1.2+:\n\n// Older Kotlin versions:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76792619,
                        "answer_post": "Kotlin does not have an array syntax (varray = {1,2,3,4,5}). To create an array in Kotlin, you must use a function such as arrayOf or intArrayOf.\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 68317723,
                        "answer_post": "CharBuffer is pretty low-level and really meant for I/O stuff, so it may seem illogical at first. In your example it actually returned a string containing remaining 8 bytes that you didn't set. To make it return your data you need to invoke flip() like this:\n\nYou can find more in the docs of the Buffer\nFor more typical use cases it is much easier to use StringBuilder:\n\nOr even use a Kotlin util that wraps StringBuilder:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70419158,
                        "answer_post": "Replace org.mockito.Mockito with org.mockito.kotlin.*\nand you can code like this\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76792619,
                        "answer_post": "Kotlin does not have an array syntax (varray = {1,2,3,4,5}). To create an array in Kotlin, you must use a function such as arrayOf or intArrayOf.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54854295,
                        "answer_post": "Kotlin has two sets of collection interfaces, the regular List, Set, etc. which are read-only, and the same ones with the Mutable prefix, which can be modified.\nlistOf will give you a List instance, while mutableListOf gives you a MutableList instance. If you use the latter for creating your nested lists, you can use the exact syntax you've asked about:\n\n(I've added the explicit type for myList for clarity's sake, it can be omitted from the left side of the assignment.)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70596209,
                        "answer_post": "Use CacheDataSource.Factory() instead of CacheDataSourceFactory and StandaloneDatabaseProvider instead of ExoDatabaseProvider.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54874814,
                        "answer_post": "The issue isn't disambiguation but rather an incorrect type. In Kotlin, an Array<Char> is equivalent to a Java Character[]. That means that when you use *delim, you're actually creating a vararg Character (instead of vararg Char). \nInstead, you should prefer the primitive-specific CharArray:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 60034694,
                        "answer_post": "xor (being an infix function-docs) in Kotlin has lower precedence than the arithmetic operators(*, /, %,+, -) and has higher precedence than Comparison(<, >, <=, >=),Equality(==, !==) & Assignment(=, +=, -=, *=, /=, %=) operators.(check for full reference for precedence here).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60876779,
                        "answer_post": "Kotlin provides a Char.isDefined() extension method that seems to do just what you want (or at least, the direct opposite).\nSo you can do e.g.:\n\n(This function is available in Kotlin/JVM and Kotlin/Native, but not in Kotlin/JS yet.)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55073098,
                        "answer_post": "arrayOf and mutableListOf are not in \"global scope\" (that's not even something that exists). They're in the kotlin and kotlin.collections packages, respectively.\nIt just so happens that kotlin.* and kotlin.collections.* are default imports of any kotlin file, so you don't have to make that import yourself. See Default Imports.\nThis is similar to Java where java.lang.* is imported by default and you don't need to specify it.\nAlso, you can't \"construct\" arrayOf and mutableListOf because they're not types; they're methods - and the fact the they start with a lowercase letter is the standard way to indicate that - types start with uppercase letters.\nKotlin allows methods at package level outside a class (although when compiled for the JVM, they will be inside a class), but that's not very different from an import static in Java with which you can access a static method from a class without the classname as a prefix.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65743882,
                        "answer_post": "Kotlin has a split function too. It will return a List<String>. If you you need an array in the end, call toTypedArray():\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 61137291,
                        "answer_post": "example for Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66396834,
                        "answer_post": "Xml:\n\nKotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62829880,
                        "answer_post": "Here is the kotlin code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59944261,
                        "answer_post": "if use kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63789514,
                        "answer_post": "Kotlin:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57622602,
                        "answer_post": "Try this \n\nFor kotlin \n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74960577,
                        "answer_post": "Try this in Kotlin\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65085597,
                        "answer_post": "In kotlin\n\nIn Java\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72599846,
                        "answer_post": "In Kotlin API interface:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57637304,
                        "answer_post": "Here how can you use that in Kotlin\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "When you write var  arrFirstLetter = charArrayOf() you are creating an empty array.\nThen when you write arrFirstLetter[x] = firstWord[0], you are trying to assign to the element at index x of an empty array. Because the array is empty, this is generating ArrayIndexOutOfBoundsException.\nIn general it's better to avoid trying to loop over collections by using their index and instead use a for loop or the map extension function.\nYou can print out the first letters of each word like this:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Since Kotlin 1.2, you can use array literals in annotations. These are not part of the actual Kotlin syntax and only reserved for annotations. This might change in the future but currently you cannot make use of array literals in your actual code.\nRead about annotations here.\n\nFor other arguments that have an array type, you need to use the array\n  literal syntax (since Kotlin 1.2) or arrayOf(...):\n// Java\n\n// Kotlin 1.2+:\n\n// Older Kotlin versions:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This happens because in Kotlin Array<Char> is equal to Character[] in Java, not to char[] in Java. \nTo use the spread operator on an array of characters and pass it to a vararg Char parameter, you need to use CharArray which is equal to char[] in Java.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Frame challenge: what you're doing is splitting the string into individual characters \u2014 and there are several existing methods which can do that to a string, such as:\n\nasSequence() gives a Sequence of characters.\nasIterable() gives an Iterable of characters.\u2002(You can do most things to an Iterable that you can to a List.)\ntoCharArray() gives a CharArray.\u2002(Though iterables are generally preferred in Kotlin as they're more flexible and better-supported.)\nforEach() performs a given action on each character.\u2002(This means you can do e.g. for (c in myString) { \u2026 }.)\n\nUsing one of these will be simpler than splitting, and probably more efficient; it'll also make the intent of the code easier to anyone reading it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "try this\n\nOutput:\n\nYou should avoid Special character in Api\nURL encoding is often required to convert special characters (such as \"/\", \"&\", \"#\", ...), because special characters: \n\nFor instance, the \"#\" character needs to be encoded because it has a special meaning of that of an HTML anchor. \nThe  character needs to be encoded because it is not a valid URL character. Also, some characters, such as \"~\" might not transport properly across the internet. Instead of proceeding with the complex process you should focus on correcting the old one.\nMore you can read here.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Starting from the version 1.3.50 Kotlin has guaranteed sequential array initialization order in its API documentation: https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-array/-init-.html\n\nThe function init is called for each array element sequentially starting from the first one. It should return the value for an array element given its index.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Just like in Java, ' is for character literals, and \" is for String literals. \nYou want \"commons-net:commons-net:3.6\". \nAnd compile() is deprecated. Use implementation().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The equivalent in Java and Kotlin is simply to store an index into the array (or String).\nRemember that the JVM has very powerful dynamic compilation and optimisation, so while in C that would be less efficient, on the JVM it generally won't be.  (The difference generally wouldn't be significant in most applications, anyway.)\nAlso note that Kotlin uses Unicode, so a character is not the same as a byte.  A Character is an unsigned two-byte number.  (Characters outside the Basic Multilingual Plane are stored as a surrogate pair.)\nSo the equivalent would be:\n\nor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can maintain the character mapping and replace required characters by iterating over each character in the word.\n\nIf you want to do it for multiple words, you can create an extension function for better readability\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Well first, that is not how to define a list in Kotlin. Since there are no list literals in Kotlin.\nInstead, it's like listOf(1, 2, 3, 4,) for a normal list, and mutableListOf(1, 2, 3, 4,) for a mutable (editable) list.\nMutableList is basically an ArrayList in Kotlin. But there is still arrayListOf() in Kotlin.\nThere is also toMutableList() extension to most Collection subclasses in Kotlin\n",
                        "contain_knowledge": 0
                    }
                ]
            }
        }
    },
    {
        "name": "NotificationManager",
        "language": "android",
        "popularity": "high",
        "label_result": {
            "functionality": {
                "finetuned_dpr": 0.7,
                "dpr": 0.3,
                "e5": 0.0,
                "bm25": 0.4
            },
            "concept": {
                "finetuned_dpr": 0.8,
                "dpr": 0.2,
                "e5": 0.1,
                "bm25": 0.6
            },
            "performance": {
                "finetuned_dpr": 0.7,
                "dpr": 0.4,
                "e5": 0.0,
                "bm25": 0.8
            },
            "directive": {
                "finetuned_dpr": 0.5,
                "dpr": 0.4,
                "e5": 0.0,
                "bm25": 0.6
            },
            "pattern": {
                "finetuned_dpr": 0.9,
                "dpr": 0.7,
                "e5": 0.2,
                "bm25": 1.0
            },
            "environment": {
                "finetuned_dpr": 0.7,
                "dpr": 0.2,
                "e5": 0.0,
                "bm25": 0.5
            },
            "alternative": {
                "finetuned_dpr": 0.9,
                "dpr": 0.5,
                "e5": 0.1,
                "bm25": 0.5
            },
            "total": {
                "finetuned_dpr": 0.7428571428571429,
                "dpr": 0.38571428571428573,
                "e5": 0.05714285714285715,
                "bm25": 0.6285714285714287
            }
        },
        "retrieve_result": {
            "functionality": {
                "finetuned_dpr": [
                    {
                        "id": 76992601,
                        "answer_post": "\nmy question is how an Android app's internal notification settings is synced with the Android OS to manage which notifications to show and which ones to block (mute)?\n\nAndroid itself does not have a concept of \"internal notification settings\".\nAll notifications from an app are created by the app and handed to the OS via NotificationManager. The OS then applies system rules for how they should be handled, such as those configured by the user via the system Settings app.\nIf an app also has its own concept of \"internal notification settings\", that would control when the app actually invokes NotificationManager.\n\nIs it like the OS will pass the received notification to the intended app and then it decides - based on its internal settings- which one to show? Or the app will give the user-defined notification settings to the OS (by some API or ...) and then OS filters the notifications and decides what to show or not?\n\nNeither of those are correct.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70612654,
                        "answer_post": "Notifications on Android TV OS are significantly different than mobile Android. There is an area to display notifications within the launcher, but it is limited to system-level notifications that are important for the user (e.g., issues with your account or info about OS updates). General app notifications do not show up, which means you need to display any kind of notification within your own app UI and not with the regular NotificationManager and related APIs.\n\nCan we use Notification Manager. / Can we set the Notification priority\n\nYes, but it won't result in a notification being visible to the user and shouldn't be done on Android TV OS.\n\nProper method to implementation Android TV notification.\n\nThis should be handled within app UI. Most apps have a reserved space to show these on the main screen so that users see them as soon as they open the app.\n\nPossible way to find out whether the user has seen/interacted with notification or not\n\nSince you'll have to display it in your own UI, you can use regular View methods. For example, if you want to know if the user clicked the message, you can add that code to the OnClickListener.\n\nHandling list of notification messages by Local Database or any other method.\n\nThis is a bit vague to give a specific answer, so you may want to post a separate question with more details about what you're trying to accomplish. One general way to go about it is that you have a server endpoint that understands the state of notifications for a given user and you sync that with your local database (easiest is probably Sqlite using Room). Your UI needs to be told if there's a relevant notification to display within the app, but the details of that depend on your app architecture.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62486856,
                        "answer_post": "It seems like you haven't setup the notification channel that you are trying to add the notification to. As a test can you add this code before the NotificationCompat.Builder setup?\n\nNotification must be assigned to Channels in Android 8.0 (API level 26). Please see the NotificationChannel documentation found here\nThis is most likely the reason the Notification is not showing on your device, however the Worker is definitely still working. You can see some logs of what your Workers have done in both the Debug output and Logcat windows. Some examples of my own tests can be seen below:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72461463,
                        "answer_post": "In your scenario, you'll need to use addNotificationReceivedListener, this listener will be triggered after the user clicks on the notification, inside that listener you can access the notification response data and navigate to another screen.\nYou can read more about it here https://docs.expo.dev/push-notifications/receiving-notifications/\nExample of the notification listener function\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62196033,
                        "answer_post": "I don't think you have that level of control over how Android displays/plays incoming notification messages.\nThe only approach I can think of is taking full control of the display of the messages in your own application code, by using data messages instead of notification messages.\nReminder: Firebase Cloud Messaging has two message types: notification messages, and data messages. Notifications messages are automatically handled/displayed by the OS when your app is not active, while data messages are always delivered to your application code.\nFrom within your application code, you can then use the Android notification API to build the exact display of the message that you want, and display it exactly when you want it (within the notification settings of the user of course).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65329139,
                        "answer_post": "Unfortunately there is no official API to open notifications settings directly.\nInstead what you can do is to open the settings via intent Intent(Settings.ACTION_APPLICATION_DETAILS_SETTINGS this will not open the notification settings but it may help take user a step closer to the notification settings.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61330071,
                        "answer_post": "To access notifications, you can use the NotificationListenerService. The documents on this is located at: https://developer.android.com/reference/android/service/notification/NotificationListenerService\nFor the implementation of this class, there has already been discussed within this link: NotificationListenerService Implementation (See the accepted answer for a link to an example)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66118410,
                        "answer_post": "Basically notifications provide short, timely information about events in your app while it's not in use. For an introduction to how notifications appear on Android, see the Notifications Overview. For sample code that uses notifications.The code on this uses the NotificationCompat APIs from the Android support library. These APIs allow you to add features available only on newer versions of Android while still providing compatibility back to Android 4.0 (API level 14). However, some new features such as the inline reply action result in a no-op on older versions.\nAdd the support library\nAlthough most projects created with Android Studio include the necessary dependencies to use NotificationCompat, you should verify that your module-level build.gradle file includes the following dependency:\ndependencies {\nimplementation \"com.android.support:support-c\ncompat:28.0.0\"\n}\nYou can see more info here:\nhttps://developer.android.com/training/notify-user/channels\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64227477,
                        "answer_post": "From Android 8.0 if you want to show a notification, you should associate it to a Notification Channel.\nFirst you should create a new notification Channel then show your notification.\nYou can find more detailed information here: https://developer.android.com/training/notify-user/channels\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62561442,
                        "answer_post": "\nHow can I create the foreground notification only once or at least how not to play notification sound on successive startForegroundService() calls?\n\nYou can check if the notification is already visible and show it only if it's not visible. You need to have a reference to the notification PendingIntent and notificationId.\n\n\nhow can I go back to my application when I click the foreground notification?\n\nYou need a PendingIntent to open the app from a notification. To open the last activity shown you can remember this using Preferences in the onResume() method of each activity and route the notification into a routing activity that starts the right activity according to the value saved into the preferences.\n\nAnother way to do this is to update the notification PendingIntent if it's already visible with the last activity shown. In this case you don't have to store any value on Preferences and you don't need a route activity.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 61462891,
                        "answer_post": "the notification on android is displayed by calling the mNotificationManager.notify method (NOTIFICATION_ID, mNotification);  .  Try displaying your code to see\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72608305,
                        "answer_post": "notificationManager must also be declared only once\n\nthen use the same variable notification_Manager.notify() and notificationBuilder for every notification update you make.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66249808,
                        "answer_post": "The Notification Composer is an online tool hosted by Firebase.\nTherefore it already knows the Server Key (required to send messages) associated to each of your projects.\nBy design (and for obvious security reasons), the Server Key is implicitely linked to a single app, and you can't use it to send a message to different apps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66090712,
                        "answer_post": "You can use WorkManager to schedule tasks.\n\nWorkManager is an API that makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or the device restarts. The WorkManager API is a suitable and recommended replacement for all previous Android background scheduling APIs, including FirebaseJobDispatcher, GcmNetworkManager, and Job Scheduler.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73559384,
                        "answer_post": "WindowManager interface can be an alternative to the toast after the Android 11 limitations.\nhttps://developer.android.com/reference/android/view/WindowManager\nBut you just need user permission to display custom messages over the apps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70918520,
                        "answer_post": "It's important to note that your viewModel and the method getRandomWordForNotification() will be called while your view is active. In your case that does not help you with getting a random word while your app is in the background/killed.\nYou should modify your AlarmReceiver to start a Service where you will call your repository, get your new random word and construct your notification.\n\n\nIn addition to this, register the service in your AndroidManifest file.\n\nA few disclaimers:\n\nIntentService was deprecated in API level 30.\n\nAlarmManager is often replaced with WorkManager: https://developer.android.com/reference/androidx/work/WorkManager\nand\nhttps://developer.android.com/topic/libraries/architecture/workmanager\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61330071,
                        "answer_post": "To access notifications, you can use the NotificationListenerService. The documents on this is located at: https://developer.android.com/reference/android/service/notification/NotificationListenerService\nFor the implementation of this class, there has already been discussed within this link: NotificationListenerService Implementation (See the accepted answer for a link to an example)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64745632,
                        "answer_post": "A notification message is directly displayed, and therefore the onMessageReceived method will not be called.\nThe method is called only when a data message is received. For details, please refer to Receiving Data Messages. However, a data message cannot reach your app after the process of your app is killed. To display a notification message after the process of your app is killed, or receive a data message through onMessageReceived when your app is running, please refer to Notification Message Display on UI.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72231120,
                        "answer_post": "\nWorkManager 2.3.0-alpha02 adds built-in support for long running\nworkers. In such cases, WorkManager can provide a signal to the OS\nthat the process should be kept alive if possible while this work is\nexecuting. These Workers can run longer than 10 minutes. Example\nuse-cases for this new feature include bulk uploads or downloads (that\ncannot be chunked), crunching on an ML model locally, or a task that's\nimportant to the user of the app.\n\nUnder the hood, WorkManager manages and runs a foreground service on your behalf to execute the WorkRequest, while also showing a configurable notification.\nListenableWorker now supports the setForegroundAsync() API, and CoroutineWorker supports a suspending setForeground() API. These APIs allow developers to specify that this WorkRequest is important (from a user perspective) or long-running.\nStarting with 2.3.0-alpha03, WorkManager also allows you to create a PendingIntent, which can be used to cancel workers without having to register a new Android component using the createCancelPendingIntent() API. This approach is especially useful when used with the setForegroundAsync() or setForeground() APIs, which can be used to add a notification action to cancel the Worker.\nLink to the resource: https://developer.android.com/topic/libraries/architecture/workmanager/advanced/long-running\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61718464,
                        "answer_post": "First of all you have to create the notification channel:\n\nChange the NotificationManager to be:\nNotificationManagerCompat manager;\nthen modify your notify() function like this:\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 62486136,
                        "answer_post": "Use notification manager like below to support all android versions\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77423309,
                        "answer_post": "\"notification\": {\n\n}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71956233,
                        "answer_post": "This should help you, Firebase Notification Scheduler\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68093503,
                        "answer_post": "You can achieve this via NotificationListenerService\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67946567,
                        "answer_post": "Try with custom vibration on getting notification\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61555994,
                        "answer_post": "Try Notifications\nYour best bet is to use Notifications in Android to show your message on the status bar\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68319855,
                        "answer_post": "use this :\n\nbefore putting into NotificationManager.notify\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66090712,
                        "answer_post": "You can use WorkManager to schedule tasks.\n\nWorkManager is an API that makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or the device restarts. The WorkManager API is a suitable and recommended replacement for all previous Android background scheduling APIs, including FirebaseJobDispatcher, GcmNetworkManager, and Job Scheduler.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67242315,
                        "answer_post": "Define RegisterActivity to your Manifest\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61713440,
                        "answer_post": "Add app:layout_behavior here\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "you can get getSystemService from context\nchange your code\nfrom:\n\nval notificationManager: NotificationManager =\ngetSystemService(context.NOTIFICATION_SERVICE) as NotificationManager\n\nto:\n\nval notificationManager: NotificationManager =\ncontext.getSystemService(context.NOTIFICATION_SERVICE) as\nNotificationManager\n\nwhere context is context = flutterPluginBinding.getApplicationContext();\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "If you are working on the android versions above oreo, then you have to use a notification channel for notifications from the notificationManager. I think it will work, as it did in mine.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "In Android using Kotlin, notifications from a particular channel can be removed using \"NotificationManager\" and the channel id of the channel you want to delete. Although this can only be achieved in android oreo and above.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "the problem wasa the phone for some reason couldnt create all the notifications.\nthe code that fixed it was the .apply{} on the notificationManager\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nmy question is how an Android app's internal notification settings is synced with the Android OS to manage which notifications to show and which ones to block (mute)?\n\nAndroid itself does not have a concept of \"internal notification settings\".\nAll notifications from an app are created by the app and handed to the OS via NotificationManager. The OS then applies system rules for how they should be handled, such as those configured by the user via the system Settings app.\nIf an app also has its own concept of \"internal notification settings\", that would control when the app actually invokes NotificationManager.\n\nIs it like the OS will pass the received notification to the intended app and then it decides - based on its internal settings- which one to show? Or the app will give the user-defined notification settings to the OS (by some API or ...) and then OS filters the notifications and decides what to show or not?\n\nNeither of those are correct.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "notificationManager must also be declared only once\n\nthen use the same variable notification_Manager.notify() and notificationBuilder for every notification update you make.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Do you want to let the gps location icon on the notifications go away?\nAfter run the stopLocationUpdates(), is the new location callback received, and let you notifications update ? Did you use NotificationManager to show notifications?\nIf there is no new location callback and after that, you can dismiss the notifications directly.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You will need to use WorkManager & NotificationManager to achieve what you expecting here.\nFor Kotlin, this is a good start.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First of all you have to create the notification channel:\n\nChange the NotificationManager to be:\nNotificationManagerCompat manager;\nthen modify your notify() function like this:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nNever create an instance of an activity yourself. Move checkNotifications() into the service or into some utility class (where you provide a Context as a parameter to checkNotifications() for the purposes of obtaining a NotificationManager).\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "concept": {
                "finetuned_dpr": [
                    {
                        "id": 76992601,
                        "answer_post": "\nmy question is how an Android app's internal notification settings is synced with the Android OS to manage which notifications to show and which ones to block (mute)?\n\nAndroid itself does not have a concept of \"internal notification settings\".\nAll notifications from an app are created by the app and handed to the OS via NotificationManager. The OS then applies system rules for how they should be handled, such as those configured by the user via the system Settings app.\nIf an app also has its own concept of \"internal notification settings\", that would control when the app actually invokes NotificationManager.\n\nIs it like the OS will pass the received notification to the intended app and then it decides - based on its internal settings- which one to show? Or the app will give the user-defined notification settings to the OS (by some API or ...) and then OS filters the notifications and decides what to show or not?\n\nNeither of those are correct.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70612654,
                        "answer_post": "Notifications on Android TV OS are significantly different than mobile Android. There is an area to display notifications within the launcher, but it is limited to system-level notifications that are important for the user (e.g., issues with your account or info about OS updates). General app notifications do not show up, which means you need to display any kind of notification within your own app UI and not with the regular NotificationManager and related APIs.\n\nCan we use Notification Manager. / Can we set the Notification priority\n\nYes, but it won't result in a notification being visible to the user and shouldn't be done on Android TV OS.\n\nProper method to implementation Android TV notification.\n\nThis should be handled within app UI. Most apps have a reserved space to show these on the main screen so that users see them as soon as they open the app.\n\nPossible way to find out whether the user has seen/interacted with notification or not\n\nSince you'll have to display it in your own UI, you can use regular View methods. For example, if you want to know if the user clicked the message, you can add that code to the OnClickListener.\n\nHandling list of notification messages by Local Database or any other method.\n\nThis is a bit vague to give a specific answer, so you may want to post a separate question with more details about what you're trying to accomplish. One general way to go about it is that you have a server endpoint that understands the state of notifications for a given user and you sync that with your local database (easiest is probably Sqlite using Room). Your UI needs to be told if there's a relevant notification to display within the app, but the details of that depend on your app architecture.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65329139,
                        "answer_post": "Unfortunately there is no official API to open notifications settings directly.\nInstead what you can do is to open the settings via intent Intent(Settings.ACTION_APPLICATION_DETAILS_SETTINGS this will not open the notification settings but it may help take user a step closer to the notification settings.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61330071,
                        "answer_post": "To access notifications, you can use the NotificationListenerService. The documents on this is located at: https://developer.android.com/reference/android/service/notification/NotificationListenerService\nFor the implementation of this class, there has already been discussed within this link: NotificationListenerService Implementation (See the accepted answer for a link to an example)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62486856,
                        "answer_post": "It seems like you haven't setup the notification channel that you are trying to add the notification to. As a test can you add this code before the NotificationCompat.Builder setup?\n\nNotification must be assigned to Channels in Android 8.0 (API level 26). Please see the NotificationChannel documentation found here\nThis is most likely the reason the Notification is not showing on your device, however the Worker is definitely still working. You can see some logs of what your Workers have done in both the Debug output and Logcat windows. Some examples of my own tests can be seen below:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62196033,
                        "answer_post": "I don't think you have that level of control over how Android displays/plays incoming notification messages.\nThe only approach I can think of is taking full control of the display of the messages in your own application code, by using data messages instead of notification messages.\nReminder: Firebase Cloud Messaging has two message types: notification messages, and data messages. Notifications messages are automatically handled/displayed by the OS when your app is not active, while data messages are always delivered to your application code.\nFrom within your application code, you can then use the Android notification API to build the exact display of the message that you want, and display it exactly when you want it (within the notification settings of the user of course).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63112379,
                        "answer_post": "Following are the notification styles available :\n\nNotification.BigPictureStyle, Notification.BigTextStyle,\nNotification.DecoratedCustomViewStyle, Notification.InboxStyle,\nNotification.MediaStyle, Notification.MessagingStyle\n\nYou can get more info on this link.\nJust for information purposes, to create a notification without hustle and get all predefined formatting in one place, just do the following :\n\nGo to the Project Tab of android studio and right click.\nClick on New -> UI Component -> Notification\nEnter the required notification name\n\nTo call this notification just enter the following :\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72461463,
                        "answer_post": "In your scenario, you'll need to use addNotificationReceivedListener, this listener will be triggered after the user clicks on the notification, inside that listener you can access the notification response data and navigate to another screen.\nYou can read more about it here https://docs.expo.dev/push-notifications/receiving-notifications/\nExample of the notification listener function\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64227477,
                        "answer_post": "From Android 8.0 if you want to show a notification, you should associate it to a Notification Channel.\nFirst you should create a new notification Channel then show your notification.\nYou can find more detailed information here: https://developer.android.com/training/notify-user/channels\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66118410,
                        "answer_post": "Basically notifications provide short, timely information about events in your app while it's not in use. For an introduction to how notifications appear on Android, see the Notifications Overview. For sample code that uses notifications.The code on this uses the NotificationCompat APIs from the Android support library. These APIs allow you to add features available only on newer versions of Android while still providing compatibility back to Android 4.0 (API level 14). However, some new features such as the inline reply action result in a no-op on older versions.\nAdd the support library\nAlthough most projects created with Android Studio include the necessary dependencies to use NotificationCompat, you should verify that your module-level build.gradle file includes the following dependency:\ndependencies {\nimplementation \"com.android.support:support-c\ncompat:28.0.0\"\n}\nYou can see more info here:\nhttps://developer.android.com/training/notify-user/channels\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 72608305,
                        "answer_post": "notificationManager must also be declared only once\n\nthen use the same variable notification_Manager.notify() and notificationBuilder for every notification update you make.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61462891,
                        "answer_post": "the notification on android is displayed by calling the mNotificationManager.notify method (NOTIFICATION_ID, mNotification);  .  Try displaying your code to see\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66249808,
                        "answer_post": "The Notification Composer is an online tool hosted by Firebase.\nTherefore it already knows the Server Key (required to send messages) associated to each of your projects.\nBy design (and for obvious security reasons), the Server Key is implicitely linked to a single app, and you can't use it to send a message to different apps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66090712,
                        "answer_post": "You can use WorkManager to schedule tasks.\n\nWorkManager is an API that makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or the device restarts. The WorkManager API is a suitable and recommended replacement for all previous Android background scheduling APIs, including FirebaseJobDispatcher, GcmNetworkManager, and Job Scheduler.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73559384,
                        "answer_post": "WindowManager interface can be an alternative to the toast after the Android 11 limitations.\nhttps://developer.android.com/reference/android/view/WindowManager\nBut you just need user permission to display custom messages over the apps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70918520,
                        "answer_post": "It's important to note that your viewModel and the method getRandomWordForNotification() will be called while your view is active. In your case that does not help you with getting a random word while your app is in the background/killed.\nYou should modify your AlarmReceiver to start a Service where you will call your repository, get your new random word and construct your notification.\n\n\nIn addition to this, register the service in your AndroidManifest file.\n\nA few disclaimers:\n\nIntentService was deprecated in API level 30.\n\nAlarmManager is often replaced with WorkManager: https://developer.android.com/reference/androidx/work/WorkManager\nand\nhttps://developer.android.com/topic/libraries/architecture/workmanager\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61330071,
                        "answer_post": "To access notifications, you can use the NotificationListenerService. The documents on this is located at: https://developer.android.com/reference/android/service/notification/NotificationListenerService\nFor the implementation of this class, there has already been discussed within this link: NotificationListenerService Implementation (See the accepted answer for a link to an example)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76487483,
                        "answer_post": "AlarmManager works, but it's an older, less capable API.  It also doesn't save state around reboot.  Newer APIs include JobScheduler and WorkManager.  The first is used to be notified at a specific time and/or when conditions occur (such as gaining network connectivity).  It's meant for 1 time or repeated alarms.  WorkManager is for background work like a database sync that is low priority and meant to be done when the device has spare capacity.  Use whichever is appropriate for your usecase.  If you were just using an alarm, it's probably JobScheduler.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61429229,
                        "answer_post": "WorkManager is a \"new\" Jetpack library that supports Android versions as old as API 14. It is much more flexible than Sync Manager as it allows to set constraints, chain workers, have one time or periodic workers.\nWhich one is better for your use case? it really depends from the use case. For sure WorkManager is more flexible.\nYou can find more information on WorkManager's documentation and on this series of blogs.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72231120,
                        "answer_post": "\nWorkManager 2.3.0-alpha02 adds built-in support for long running\nworkers. In such cases, WorkManager can provide a signal to the OS\nthat the process should be kept alive if possible while this work is\nexecuting. These Workers can run longer than 10 minutes. Example\nuse-cases for this new feature include bulk uploads or downloads (that\ncannot be chunked), crunching on an ML model locally, or a task that's\nimportant to the user of the app.\n\nUnder the hood, WorkManager manages and runs a foreground service on your behalf to execute the WorkRequest, while also showing a configurable notification.\nListenableWorker now supports the setForegroundAsync() API, and CoroutineWorker supports a suspending setForeground() API. These APIs allow developers to specify that this WorkRequest is important (from a user perspective) or long-running.\nStarting with 2.3.0-alpha03, WorkManager also allows you to create a PendingIntent, which can be used to cancel workers without having to register a new Android component using the createCancelPendingIntent() API. This approach is especially useful when used with the setForegroundAsync() or setForeground() APIs, which can be used to add a notification action to cancel the Worker.\nLink to the resource: https://developer.android.com/topic/libraries/architecture/workmanager/advanced/long-running\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 77423309,
                        "answer_post": "\"notification\": {\n\n}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62486136,
                        "answer_post": "Use notification manager like below to support all android versions\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71956233,
                        "answer_post": "This should help you, Firebase Notification Scheduler\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68093503,
                        "answer_post": "You can achieve this via NotificationListenerService\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61555994,
                        "answer_post": "Try Notifications\nYour best bet is to use Notifications in Android to show your message on the status bar\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 68319855,
                        "answer_post": "use this :\n\nbefore putting into NotificationManager.notify\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71500018,
                        "answer_post": "in AndroidManifest.xml\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66090712,
                        "answer_post": "You can use WorkManager to schedule tasks.\n\nWorkManager is an API that makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or the device restarts. The WorkManager API is a suitable and recommended replacement for all previous Android background scheduling APIs, including FirebaseJobDispatcher, GcmNetworkManager, and Job Scheduler.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61843790,
                        "answer_post": "The Notification IDs should be different\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61713440,
                        "answer_post": "Add app:layout_behavior here\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "you can get getSystemService from context\nchange your code\nfrom:\n\nval notificationManager: NotificationManager =\ngetSystemService(context.NOTIFICATION_SERVICE) as NotificationManager\n\nto:\n\nval notificationManager: NotificationManager =\ncontext.getSystemService(context.NOTIFICATION_SERVICE) as\nNotificationManager\n\nwhere context is context = flutterPluginBinding.getApplicationContext();\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "If you are working on the android versions above oreo, then you have to use a notification channel for notifications from the notificationManager. I think it will work, as it did in mine.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "In Android using Kotlin, notifications from a particular channel can be removed using \"NotificationManager\" and the channel id of the channel you want to delete. Although this can only be achieved in android oreo and above.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "the problem wasa the phone for some reason couldnt create all the notifications.\nthe code that fixed it was the .apply{} on the notificationManager\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nmy question is how an Android app's internal notification settings is synced with the Android OS to manage which notifications to show and which ones to block (mute)?\n\nAndroid itself does not have a concept of \"internal notification settings\".\nAll notifications from an app are created by the app and handed to the OS via NotificationManager. The OS then applies system rules for how they should be handled, such as those configured by the user via the system Settings app.\nIf an app also has its own concept of \"internal notification settings\", that would control when the app actually invokes NotificationManager.\n\nIs it like the OS will pass the received notification to the intended app and then it decides - based on its internal settings- which one to show? Or the app will give the user-defined notification settings to the OS (by some API or ...) and then OS filters the notifications and decides what to show or not?\n\nNeither of those are correct.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "notificationManager must also be declared only once\n\nthen use the same variable notification_Manager.notify() and notificationBuilder for every notification update you make.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Do you want to let the gps location icon on the notifications go away?\nAfter run the stopLocationUpdates(), is the new location callback received, and let you notifications update ? Did you use NotificationManager to show notifications?\nIf there is no new location callback and after that, you can dismiss the notifications directly.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You will need to use WorkManager & NotificationManager to achieve what you expecting here.\nFor Kotlin, this is a good start.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First of all you have to create the notification channel:\n\nChange the NotificationManager to be:\nNotificationManagerCompat manager;\nthen modify your notify() function like this:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nNever create an instance of an activity yourself. Move checkNotifications() into the service or into some utility class (where you provide a Context as a parameter to checkNotifications() for the purposes of obtaining a NotificationManager).\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "performance": {
                "finetuned_dpr": [
                    {
                        "id": 76992601,
                        "answer_post": "\nmy question is how an Android app's internal notification settings is synced with the Android OS to manage which notifications to show and which ones to block (mute)?\n\nAndroid itself does not have a concept of \"internal notification settings\".\nAll notifications from an app are created by the app and handed to the OS via NotificationManager. The OS then applies system rules for how they should be handled, such as those configured by the user via the system Settings app.\nIf an app also has its own concept of \"internal notification settings\", that would control when the app actually invokes NotificationManager.\n\nIs it like the OS will pass the received notification to the intended app and then it decides - based on its internal settings- which one to show? Or the app will give the user-defined notification settings to the OS (by some API or ...) and then OS filters the notifications and decides what to show or not?\n\nNeither of those are correct.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70612654,
                        "answer_post": "Notifications on Android TV OS are significantly different than mobile Android. There is an area to display notifications within the launcher, but it is limited to system-level notifications that are important for the user (e.g., issues with your account or info about OS updates). General app notifications do not show up, which means you need to display any kind of notification within your own app UI and not with the regular NotificationManager and related APIs.\n\nCan we use Notification Manager. / Can we set the Notification priority\n\nYes, but it won't result in a notification being visible to the user and shouldn't be done on Android TV OS.\n\nProper method to implementation Android TV notification.\n\nThis should be handled within app UI. Most apps have a reserved space to show these on the main screen so that users see them as soon as they open the app.\n\nPossible way to find out whether the user has seen/interacted with notification or not\n\nSince you'll have to display it in your own UI, you can use regular View methods. For example, if you want to know if the user clicked the message, you can add that code to the OnClickListener.\n\nHandling list of notification messages by Local Database or any other method.\n\nThis is a bit vague to give a specific answer, so you may want to post a separate question with more details about what you're trying to accomplish. One general way to go about it is that you have a server endpoint that understands the state of notifications for a given user and you sync that with your local database (easiest is probably Sqlite using Room). Your UI needs to be told if there's a relevant notification to display within the app, but the details of that depend on your app architecture.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62486856,
                        "answer_post": "It seems like you haven't setup the notification channel that you are trying to add the notification to. As a test can you add this code before the NotificationCompat.Builder setup?\n\nNotification must be assigned to Channels in Android 8.0 (API level 26). Please see the NotificationChannel documentation found here\nThis is most likely the reason the Notification is not showing on your device, however the Worker is definitely still working. You can see some logs of what your Workers have done in both the Debug output and Logcat windows. Some examples of my own tests can be seen below:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62196033,
                        "answer_post": "I don't think you have that level of control over how Android displays/plays incoming notification messages.\nThe only approach I can think of is taking full control of the display of the messages in your own application code, by using data messages instead of notification messages.\nReminder: Firebase Cloud Messaging has two message types: notification messages, and data messages. Notifications messages are automatically handled/displayed by the OS when your app is not active, while data messages are always delivered to your application code.\nFrom within your application code, you can then use the Android notification API to build the exact display of the message that you want, and display it exactly when you want it (within the notification settings of the user of course).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64227477,
                        "answer_post": "From Android 8.0 if you want to show a notification, you should associate it to a Notification Channel.\nFirst you should create a new notification Channel then show your notification.\nYou can find more detailed information here: https://developer.android.com/training/notify-user/channels\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65329139,
                        "answer_post": "Unfortunately there is no official API to open notifications settings directly.\nInstead what you can do is to open the settings via intent Intent(Settings.ACTION_APPLICATION_DETAILS_SETTINGS this will not open the notification settings but it may help take user a step closer to the notification settings.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72461463,
                        "answer_post": "In your scenario, you'll need to use addNotificationReceivedListener, this listener will be triggered after the user clicks on the notification, inside that listener you can access the notification response data and navigate to another screen.\nYou can read more about it here https://docs.expo.dev/push-notifications/receiving-notifications/\nExample of the notification listener function\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62561442,
                        "answer_post": "\nHow can I create the foreground notification only once or at least how not to play notification sound on successive startForegroundService() calls?\n\nYou can check if the notification is already visible and show it only if it's not visible. You need to have a reference to the notification PendingIntent and notificationId.\n\n\nhow can I go back to my application when I click the foreground notification?\n\nYou need a PendingIntent to open the app from a notification. To open the last activity shown you can remember this using Preferences in the onResume() method of each activity and route the notification into a routing activity that starts the right activity according to the value saved into the preferences.\n\nAnother way to do this is to update the notification PendingIntent if it's already visible with the last activity shown. In this case you don't have to store any value on Preferences and you don't need a route activity.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65473701,
                        "answer_post": "You can follow below Notification Builder. I am setting small icons like this:\n\nUPDATE:\nI am posting my full code for showing notification.\n\nYou can change it as per you need. Hope this will help. :)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67208591,
                        "answer_post": "First of all, create a background worker with work manager which is one of the jetpack components in android world. In that worker, if you got new feeds you can show local notifications to the user. Here, use this library to firing the notifications: https://github.com/theozgurr/NotificationMan\nAnd you can see usage of the work manager in it.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 61462891,
                        "answer_post": "the notification on android is displayed by calling the mNotificationManager.notify method (NOTIFICATION_ID, mNotification);  .  Try displaying your code to see\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72608305,
                        "answer_post": "notificationManager must also be declared only once\n\nthen use the same variable notification_Manager.notify() and notificationBuilder for every notification update you make.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66090712,
                        "answer_post": "You can use WorkManager to schedule tasks.\n\nWorkManager is an API that makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or the device restarts. The WorkManager API is a suitable and recommended replacement for all previous Android background scheduling APIs, including FirebaseJobDispatcher, GcmNetworkManager, and Job Scheduler.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73559384,
                        "answer_post": "WindowManager interface can be an alternative to the toast after the Android 11 limitations.\nhttps://developer.android.com/reference/android/view/WindowManager\nBut you just need user permission to display custom messages over the apps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70918520,
                        "answer_post": "It's important to note that your viewModel and the method getRandomWordForNotification() will be called while your view is active. In your case that does not help you with getting a random word while your app is in the background/killed.\nYou should modify your AlarmReceiver to start a Service where you will call your repository, get your new random word and construct your notification.\n\n\nIn addition to this, register the service in your AndroidManifest file.\n\nA few disclaimers:\n\nIntentService was deprecated in API level 30.\n\nAlarmManager is often replaced with WorkManager: https://developer.android.com/reference/androidx/work/WorkManager\nand\nhttps://developer.android.com/topic/libraries/architecture/workmanager\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72231120,
                        "answer_post": "\nWorkManager 2.3.0-alpha02 adds built-in support for long running\nworkers. In such cases, WorkManager can provide a signal to the OS\nthat the process should be kept alive if possible while this work is\nexecuting. These Workers can run longer than 10 minutes. Example\nuse-cases for this new feature include bulk uploads or downloads (that\ncannot be chunked), crunching on an ML model locally, or a task that's\nimportant to the user of the app.\n\nUnder the hood, WorkManager manages and runs a foreground service on your behalf to execute the WorkRequest, while also showing a configurable notification.\nListenableWorker now supports the setForegroundAsync() API, and CoroutineWorker supports a suspending setForeground() API. These APIs allow developers to specify that this WorkRequest is important (from a user perspective) or long-running.\nStarting with 2.3.0-alpha03, WorkManager also allows you to create a PendingIntent, which can be used to cancel workers without having to register a new Android component using the createCancelPendingIntent() API. This approach is especially useful when used with the setForegroundAsync() or setForeground() APIs, which can be used to add a notification action to cancel the Worker.\nLink to the resource: https://developer.android.com/topic/libraries/architecture/workmanager/advanced/long-running\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66249808,
                        "answer_post": "The Notification Composer is an online tool hosted by Firebase.\nTherefore it already knows the Server Key (required to send messages) associated to each of your projects.\nBy design (and for obvious security reasons), the Server Key is implicitely linked to a single app, and you can't use it to send a message to different apps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64745632,
                        "answer_post": "A notification message is directly displayed, and therefore the onMessageReceived method will not be called.\nThe method is called only when a data message is received. For details, please refer to Receiving Data Messages. However, a data message cannot reach your app after the process of your app is killed. To display a notification message after the process of your app is killed, or receive a data message through onMessageReceived when your app is running, please refer to Notification Message Display on UI.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61429229,
                        "answer_post": "WorkManager is a \"new\" Jetpack library that supports Android versions as old as API 14. It is much more flexible than Sync Manager as it allows to set constraints, chain workers, have one time or periodic workers.\nWhich one is better for your use case? it really depends from the use case. For sure WorkManager is more flexible.\nYou can find more information on WorkManager's documentation and on this series of blogs.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61560734,
                        "answer_post": "you can use WorkManger to schedule tasks.\nThe WorkManager API makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or device restarts.\ncheck Google documentation here.\nfor notifications, you can send a notification in your work manager class. learn more here.\nthese hints should be enough. let me know if you need more clarifications. \n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 77423309,
                        "answer_post": "\"notification\": {\n\n}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62486136,
                        "answer_post": "Use notification manager like below to support all android versions\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71956233,
                        "answer_post": "This should help you, Firebase Notification Scheduler\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68093503,
                        "answer_post": "You can achieve this via NotificationListenerService\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68319855,
                        "answer_post": "use this :\n\nbefore putting into NotificationManager.notify\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61555994,
                        "answer_post": "Try Notifications\nYour best bet is to use Notifications in Android to show your message on the status bar\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67242315,
                        "answer_post": "Define RegisterActivity to your Manifest\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67946567,
                        "answer_post": "Try with custom vibration on getting notification\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66090712,
                        "answer_post": "You can use WorkManager to schedule tasks.\n\nWorkManager is an API that makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or the device restarts. The WorkManager API is a suitable and recommended replacement for all previous Android background scheduling APIs, including FirebaseJobDispatcher, GcmNetworkManager, and Job Scheduler.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61843790,
                        "answer_post": "The Notification IDs should be different\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "you can get getSystemService from context\nchange your code\nfrom:\n\nval notificationManager: NotificationManager =\ngetSystemService(context.NOTIFICATION_SERVICE) as NotificationManager\n\nto:\n\nval notificationManager: NotificationManager =\ncontext.getSystemService(context.NOTIFICATION_SERVICE) as\nNotificationManager\n\nwhere context is context = flutterPluginBinding.getApplicationContext();\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "If you are working on the android versions above oreo, then you have to use a notification channel for notifications from the notificationManager. I think it will work, as it did in mine.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "In Android using Kotlin, notifications from a particular channel can be removed using \"NotificationManager\" and the channel id of the channel you want to delete. Although this can only be achieved in android oreo and above.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "the problem wasa the phone for some reason couldnt create all the notifications.\nthe code that fixed it was the .apply{} on the notificationManager\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "\nmy question is how an Android app's internal notification settings is synced with the Android OS to manage which notifications to show and which ones to block (mute)?\n\nAndroid itself does not have a concept of \"internal notification settings\".\nAll notifications from an app are created by the app and handed to the OS via NotificationManager. The OS then applies system rules for how they should be handled, such as those configured by the user via the system Settings app.\nIf an app also has its own concept of \"internal notification settings\", that would control when the app actually invokes NotificationManager.\n\nIs it like the OS will pass the received notification to the intended app and then it decides - based on its internal settings- which one to show? Or the app will give the user-defined notification settings to the OS (by some API or ...) and then OS filters the notifications and decides what to show or not?\n\nNeither of those are correct.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "notificationManager must also be declared only once\n\nthen use the same variable notification_Manager.notify() and notificationBuilder for every notification update you make.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Do you want to let the gps location icon on the notifications go away?\nAfter run the stopLocationUpdates(), is the new location callback received, and let you notifications update ? Did you use NotificationManager to show notifications?\nIf there is no new location callback and after that, you can dismiss the notifications directly.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You will need to use WorkManager & NotificationManager to achieve what you expecting here.\nFor Kotlin, this is a good start.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First of all you have to create the notification channel:\n\nChange the NotificationManager to be:\nNotificationManagerCompat manager;\nthen modify your notify() function like this:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nNever create an instance of an activity yourself. Move checkNotifications() into the service or into some utility class (where you provide a Context as a parameter to checkNotifications() for the purposes of obtaining a NotificationManager).\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "directive": {
                "finetuned_dpr": [
                    {
                        "id": 76992601,
                        "answer_post": "\nmy question is how an Android app's internal notification settings is synced with the Android OS to manage which notifications to show and which ones to block (mute)?\n\nAndroid itself does not have a concept of \"internal notification settings\".\nAll notifications from an app are created by the app and handed to the OS via NotificationManager. The OS then applies system rules for how they should be handled, such as those configured by the user via the system Settings app.\nIf an app also has its own concept of \"internal notification settings\", that would control when the app actually invokes NotificationManager.\n\nIs it like the OS will pass the received notification to the intended app and then it decides - based on its internal settings- which one to show? Or the app will give the user-defined notification settings to the OS (by some API or ...) and then OS filters the notifications and decides what to show or not?\n\nNeither of those are correct.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70612654,
                        "answer_post": "Notifications on Android TV OS are significantly different than mobile Android. There is an area to display notifications within the launcher, but it is limited to system-level notifications that are important for the user (e.g., issues with your account or info about OS updates). General app notifications do not show up, which means you need to display any kind of notification within your own app UI and not with the regular NotificationManager and related APIs.\n\nCan we use Notification Manager. / Can we set the Notification priority\n\nYes, but it won't result in a notification being visible to the user and shouldn't be done on Android TV OS.\n\nProper method to implementation Android TV notification.\n\nThis should be handled within app UI. Most apps have a reserved space to show these on the main screen so that users see them as soon as they open the app.\n\nPossible way to find out whether the user has seen/interacted with notification or not\n\nSince you'll have to display it in your own UI, you can use regular View methods. For example, if you want to know if the user clicked the message, you can add that code to the OnClickListener.\n\nHandling list of notification messages by Local Database or any other method.\n\nThis is a bit vague to give a specific answer, so you may want to post a separate question with more details about what you're trying to accomplish. One general way to go about it is that you have a server endpoint that understands the state of notifications for a given user and you sync that with your local database (easiest is probably Sqlite using Room). Your UI needs to be told if there's a relevant notification to display within the app, but the details of that depend on your app architecture.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65329139,
                        "answer_post": "Unfortunately there is no official API to open notifications settings directly.\nInstead what you can do is to open the settings via intent Intent(Settings.ACTION_APPLICATION_DETAILS_SETTINGS this will not open the notification settings but it may help take user a step closer to the notification settings.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62486856,
                        "answer_post": "It seems like you haven't setup the notification channel that you are trying to add the notification to. As a test can you add this code before the NotificationCompat.Builder setup?\n\nNotification must be assigned to Channels in Android 8.0 (API level 26). Please see the NotificationChannel documentation found here\nThis is most likely the reason the Notification is not showing on your device, however the Worker is definitely still working. You can see some logs of what your Workers have done in both the Debug output and Logcat windows. Some examples of my own tests can be seen below:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62196033,
                        "answer_post": "I don't think you have that level of control over how Android displays/plays incoming notification messages.\nThe only approach I can think of is taking full control of the display of the messages in your own application code, by using data messages instead of notification messages.\nReminder: Firebase Cloud Messaging has two message types: notification messages, and data messages. Notifications messages are automatically handled/displayed by the OS when your app is not active, while data messages are always delivered to your application code.\nFrom within your application code, you can then use the Android notification API to build the exact display of the message that you want, and display it exactly when you want it (within the notification settings of the user of course).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62561442,
                        "answer_post": "\nHow can I create the foreground notification only once or at least how not to play notification sound on successive startForegroundService() calls?\n\nYou can check if the notification is already visible and show it only if it's not visible. You need to have a reference to the notification PendingIntent and notificationId.\n\n\nhow can I go back to my application when I click the foreground notification?\n\nYou need a PendingIntent to open the app from a notification. To open the last activity shown you can remember this using Preferences in the onResume() method of each activity and route the notification into a routing activity that starts the right activity according to the value saved into the preferences.\n\nAnother way to do this is to update the notification PendingIntent if it's already visible with the last activity shown. In this case you don't have to store any value on Preferences and you don't need a route activity.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64227477,
                        "answer_post": "From Android 8.0 if you want to show a notification, you should associate it to a Notification Channel.\nFirst you should create a new notification Channel then show your notification.\nYou can find more detailed information here: https://developer.android.com/training/notify-user/channels\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61330071,
                        "answer_post": "To access notifications, you can use the NotificationListenerService. The documents on this is located at: https://developer.android.com/reference/android/service/notification/NotificationListenerService\nFor the implementation of this class, there has already been discussed within this link: NotificationListenerService Implementation (See the accepted answer for a link to an example)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72461463,
                        "answer_post": "In your scenario, you'll need to use addNotificationReceivedListener, this listener will be triggered after the user clicks on the notification, inside that listener you can access the notification response data and navigate to another screen.\nYou can read more about it here https://docs.expo.dev/push-notifications/receiving-notifications/\nExample of the notification listener function\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66118410,
                        "answer_post": "Basically notifications provide short, timely information about events in your app while it's not in use. For an introduction to how notifications appear on Android, see the Notifications Overview. For sample code that uses notifications.The code on this uses the NotificationCompat APIs from the Android support library. These APIs allow you to add features available only on newer versions of Android while still providing compatibility back to Android 4.0 (API level 14). However, some new features such as the inline reply action result in a no-op on older versions.\nAdd the support library\nAlthough most projects created with Android Studio include the necessary dependencies to use NotificationCompat, you should verify that your module-level build.gradle file includes the following dependency:\ndependencies {\nimplementation \"com.android.support:support-c\ncompat:28.0.0\"\n}\nYou can see more info here:\nhttps://developer.android.com/training/notify-user/channels\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 72608305,
                        "answer_post": "notificationManager must also be declared only once\n\nthen use the same variable notification_Manager.notify() and notificationBuilder for every notification update you make.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61462891,
                        "answer_post": "the notification on android is displayed by calling the mNotificationManager.notify method (NOTIFICATION_ID, mNotification);  .  Try displaying your code to see\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73559384,
                        "answer_post": "WindowManager interface can be an alternative to the toast after the Android 11 limitations.\nhttps://developer.android.com/reference/android/view/WindowManager\nBut you just need user permission to display custom messages over the apps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66090712,
                        "answer_post": "You can use WorkManager to schedule tasks.\n\nWorkManager is an API that makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or the device restarts. The WorkManager API is a suitable and recommended replacement for all previous Android background scheduling APIs, including FirebaseJobDispatcher, GcmNetworkManager, and Job Scheduler.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76487483,
                        "answer_post": "AlarmManager works, but it's an older, less capable API.  It also doesn't save state around reboot.  Newer APIs include JobScheduler and WorkManager.  The first is used to be notified at a specific time and/or when conditions occur (such as gaining network connectivity).  It's meant for 1 time or repeated alarms.  WorkManager is for background work like a database sync that is low priority and meant to be done when the device has spare capacity.  Use whichever is appropriate for your usecase.  If you were just using an alarm, it's probably JobScheduler.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66249808,
                        "answer_post": "The Notification Composer is an online tool hosted by Firebase.\nTherefore it already knows the Server Key (required to send messages) associated to each of your projects.\nBy design (and for obvious security reasons), the Server Key is implicitely linked to a single app, and you can't use it to send a message to different apps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70918520,
                        "answer_post": "It's important to note that your viewModel and the method getRandomWordForNotification() will be called while your view is active. In your case that does not help you with getting a random word while your app is in the background/killed.\nYou should modify your AlarmReceiver to start a Service where you will call your repository, get your new random word and construct your notification.\n\n\nIn addition to this, register the service in your AndroidManifest file.\n\nA few disclaimers:\n\nIntentService was deprecated in API level 30.\n\nAlarmManager is often replaced with WorkManager: https://developer.android.com/reference/androidx/work/WorkManager\nand\nhttps://developer.android.com/topic/libraries/architecture/workmanager\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64745632,
                        "answer_post": "A notification message is directly displayed, and therefore the onMessageReceived method will not be called.\nThe method is called only when a data message is received. For details, please refer to Receiving Data Messages. However, a data message cannot reach your app after the process of your app is killed. To display a notification message after the process of your app is killed, or receive a data message through onMessageReceived when your app is running, please refer to Notification Message Display on UI.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61718464,
                        "answer_post": "First of all you have to create the notification channel:\n\nChange the NotificationManager to be:\nNotificationManagerCompat manager;\nthen modify your notify() function like this:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61330071,
                        "answer_post": "To access notifications, you can use the NotificationListenerService. The documents on this is located at: https://developer.android.com/reference/android/service/notification/NotificationListenerService\nFor the implementation of this class, there has already been discussed within this link: NotificationListenerService Implementation (See the accepted answer for a link to an example)\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 77423309,
                        "answer_post": "\"notification\": {\n\n}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62486136,
                        "answer_post": "Use notification manager like below to support all android versions\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71956233,
                        "answer_post": "This should help you, Firebase Notification Scheduler\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68319855,
                        "answer_post": "use this :\n\nbefore putting into NotificationManager.notify\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61555994,
                        "answer_post": "Try Notifications\nYour best bet is to use Notifications in Android to show your message on the status bar\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68093503,
                        "answer_post": "You can achieve this via NotificationListenerService\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63159183,
                        "answer_post": "Use alarm manager, for this :\n\nFor full guidance visit this developer android page\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66090712,
                        "answer_post": "You can use WorkManager to schedule tasks.\n\nWorkManager is an API that makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or the device restarts. The WorkManager API is a suitable and recommended replacement for all previous Android background scheduling APIs, including FirebaseJobDispatcher, GcmNetworkManager, and Job Scheduler.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61713440,
                        "answer_post": "Add app:layout_behavior here\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67242315,
                        "answer_post": "Define RegisterActivity to your Manifest\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "you can get getSystemService from context\nchange your code\nfrom:\n\nval notificationManager: NotificationManager =\ngetSystemService(context.NOTIFICATION_SERVICE) as NotificationManager\n\nto:\n\nval notificationManager: NotificationManager =\ncontext.getSystemService(context.NOTIFICATION_SERVICE) as\nNotificationManager\n\nwhere context is context = flutterPluginBinding.getApplicationContext();\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "If you are working on the android versions above oreo, then you have to use a notification channel for notifications from the notificationManager. I think it will work, as it did in mine.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "In Android using Kotlin, notifications from a particular channel can be removed using \"NotificationManager\" and the channel id of the channel you want to delete. Although this can only be achieved in android oreo and above.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "the problem wasa the phone for some reason couldnt create all the notifications.\nthe code that fixed it was the .apply{} on the notificationManager\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nmy question is how an Android app's internal notification settings is synced with the Android OS to manage which notifications to show and which ones to block (mute)?\n\nAndroid itself does not have a concept of \"internal notification settings\".\nAll notifications from an app are created by the app and handed to the OS via NotificationManager. The OS then applies system rules for how they should be handled, such as those configured by the user via the system Settings app.\nIf an app also has its own concept of \"internal notification settings\", that would control when the app actually invokes NotificationManager.\n\nIs it like the OS will pass the received notification to the intended app and then it decides - based on its internal settings- which one to show? Or the app will give the user-defined notification settings to the OS (by some API or ...) and then OS filters the notifications and decides what to show or not?\n\nNeither of those are correct.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "notificationManager must also be declared only once\n\nthen use the same variable notification_Manager.notify() and notificationBuilder for every notification update you make.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Do you want to let the gps location icon on the notifications go away?\nAfter run the stopLocationUpdates(), is the new location callback received, and let you notifications update ? Did you use NotificationManager to show notifications?\nIf there is no new location callback and after that, you can dismiss the notifications directly.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You will need to use WorkManager & NotificationManager to achieve what you expecting here.\nFor Kotlin, this is a good start.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First of all you have to create the notification channel:\n\nChange the NotificationManager to be:\nNotificationManagerCompat manager;\nthen modify your notify() function like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "\nNever create an instance of an activity yourself. Move checkNotifications() into the service or into some utility class (where you provide a Context as a parameter to checkNotifications() for the purposes of obtaining a NotificationManager).\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "pattern": {
                "finetuned_dpr": [
                    {
                        "id": 76992601,
                        "answer_post": "\nmy question is how an Android app's internal notification settings is synced with the Android OS to manage which notifications to show and which ones to block (mute)?\n\nAndroid itself does not have a concept of \"internal notification settings\".\nAll notifications from an app are created by the app and handed to the OS via NotificationManager. The OS then applies system rules for how they should be handled, such as those configured by the user via the system Settings app.\nIf an app also has its own concept of \"internal notification settings\", that would control when the app actually invokes NotificationManager.\n\nIs it like the OS will pass the received notification to the intended app and then it decides - based on its internal settings- which one to show? Or the app will give the user-defined notification settings to the OS (by some API or ...) and then OS filters the notifications and decides what to show or not?\n\nNeither of those are correct.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70612654,
                        "answer_post": "Notifications on Android TV OS are significantly different than mobile Android. There is an area to display notifications within the launcher, but it is limited to system-level notifications that are important for the user (e.g., issues with your account or info about OS updates). General app notifications do not show up, which means you need to display any kind of notification within your own app UI and not with the regular NotificationManager and related APIs.\n\nCan we use Notification Manager. / Can we set the Notification priority\n\nYes, but it won't result in a notification being visible to the user and shouldn't be done on Android TV OS.\n\nProper method to implementation Android TV notification.\n\nThis should be handled within app UI. Most apps have a reserved space to show these on the main screen so that users see them as soon as they open the app.\n\nPossible way to find out whether the user has seen/interacted with notification or not\n\nSince you'll have to display it in your own UI, you can use regular View methods. For example, if you want to know if the user clicked the message, you can add that code to the OnClickListener.\n\nHandling list of notification messages by Local Database or any other method.\n\nThis is a bit vague to give a specific answer, so you may want to post a separate question with more details about what you're trying to accomplish. One general way to go about it is that you have a server endpoint that understands the state of notifications for a given user and you sync that with your local database (easiest is probably Sqlite using Room). Your UI needs to be told if there's a relevant notification to display within the app, but the details of that depend on your app architecture.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65329139,
                        "answer_post": "Unfortunately there is no official API to open notifications settings directly.\nInstead what you can do is to open the settings via intent Intent(Settings.ACTION_APPLICATION_DETAILS_SETTINGS this will not open the notification settings but it may help take user a step closer to the notification settings.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62486856,
                        "answer_post": "It seems like you haven't setup the notification channel that you are trying to add the notification to. As a test can you add this code before the NotificationCompat.Builder setup?\n\nNotification must be assigned to Channels in Android 8.0 (API level 26). Please see the NotificationChannel documentation found here\nThis is most likely the reason the Notification is not showing on your device, however the Worker is definitely still working. You can see some logs of what your Workers have done in both the Debug output and Logcat windows. Some examples of my own tests can be seen below:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61330071,
                        "answer_post": "To access notifications, you can use the NotificationListenerService. The documents on this is located at: https://developer.android.com/reference/android/service/notification/NotificationListenerService\nFor the implementation of this class, there has already been discussed within this link: NotificationListenerService Implementation (See the accepted answer for a link to an example)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72461463,
                        "answer_post": "In your scenario, you'll need to use addNotificationReceivedListener, this listener will be triggered after the user clicks on the notification, inside that listener you can access the notification response data and navigate to another screen.\nYou can read more about it here https://docs.expo.dev/push-notifications/receiving-notifications/\nExample of the notification listener function\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62561442,
                        "answer_post": "\nHow can I create the foreground notification only once or at least how not to play notification sound on successive startForegroundService() calls?\n\nYou can check if the notification is already visible and show it only if it's not visible. You need to have a reference to the notification PendingIntent and notificationId.\n\n\nhow can I go back to my application when I click the foreground notification?\n\nYou need a PendingIntent to open the app from a notification. To open the last activity shown you can remember this using Preferences in the onResume() method of each activity and route the notification into a routing activity that starts the right activity according to the value saved into the preferences.\n\nAnother way to do this is to update the notification PendingIntent if it's already visible with the last activity shown. In this case you don't have to store any value on Preferences and you don't need a route activity.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62196033,
                        "answer_post": "I don't think you have that level of control over how Android displays/plays incoming notification messages.\nThe only approach I can think of is taking full control of the display of the messages in your own application code, by using data messages instead of notification messages.\nReminder: Firebase Cloud Messaging has two message types: notification messages, and data messages. Notifications messages are automatically handled/displayed by the OS when your app is not active, while data messages are always delivered to your application code.\nFrom within your application code, you can then use the Android notification API to build the exact display of the message that you want, and display it exactly when you want it (within the notification settings of the user of course).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63112379,
                        "answer_post": "Following are the notification styles available :\n\nNotification.BigPictureStyle, Notification.BigTextStyle,\nNotification.DecoratedCustomViewStyle, Notification.InboxStyle,\nNotification.MediaStyle, Notification.MessagingStyle\n\nYou can get more info on this link.\nJust for information purposes, to create a notification without hustle and get all predefined formatting in one place, just do the following :\n\nGo to the Project Tab of android studio and right click.\nClick on New -> UI Component -> Notification\nEnter the required notification name\n\nTo call this notification just enter the following :\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66118410,
                        "answer_post": "Basically notifications provide short, timely information about events in your app while it's not in use. For an introduction to how notifications appear on Android, see the Notifications Overview. For sample code that uses notifications.The code on this uses the NotificationCompat APIs from the Android support library. These APIs allow you to add features available only on newer versions of Android while still providing compatibility back to Android 4.0 (API level 14). However, some new features such as the inline reply action result in a no-op on older versions.\nAdd the support library\nAlthough most projects created with Android Studio include the necessary dependencies to use NotificationCompat, you should verify that your module-level build.gradle file includes the following dependency:\ndependencies {\nimplementation \"com.android.support:support-c\ncompat:28.0.0\"\n}\nYou can see more info here:\nhttps://developer.android.com/training/notify-user/channels\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 61462891,
                        "answer_post": "the notification on android is displayed by calling the mNotificationManager.notify method (NOTIFICATION_ID, mNotification);  .  Try displaying your code to see\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72608305,
                        "answer_post": "notificationManager must also be declared only once\n\nthen use the same variable notification_Manager.notify() and notificationBuilder for every notification update you make.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66249808,
                        "answer_post": "The Notification Composer is an online tool hosted by Firebase.\nTherefore it already knows the Server Key (required to send messages) associated to each of your projects.\nBy design (and for obvious security reasons), the Server Key is implicitely linked to a single app, and you can't use it to send a message to different apps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70918520,
                        "answer_post": "It's important to note that your viewModel and the method getRandomWordForNotification() will be called while your view is active. In your case that does not help you with getting a random word while your app is in the background/killed.\nYou should modify your AlarmReceiver to start a Service where you will call your repository, get your new random word and construct your notification.\n\n\nIn addition to this, register the service in your AndroidManifest file.\n\nA few disclaimers:\n\nIntentService was deprecated in API level 30.\n\nAlarmManager is often replaced with WorkManager: https://developer.android.com/reference/androidx/work/WorkManager\nand\nhttps://developer.android.com/topic/libraries/architecture/workmanager\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61330071,
                        "answer_post": "To access notifications, you can use the NotificationListenerService. The documents on this is located at: https://developer.android.com/reference/android/service/notification/NotificationListenerService\nFor the implementation of this class, there has already been discussed within this link: NotificationListenerService Implementation (See the accepted answer for a link to an example)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64745632,
                        "answer_post": "A notification message is directly displayed, and therefore the onMessageReceived method will not be called.\nThe method is called only when a data message is received. For details, please refer to Receiving Data Messages. However, a data message cannot reach your app after the process of your app is killed. To display a notification message after the process of your app is killed, or receive a data message through onMessageReceived when your app is running, please refer to Notification Message Display on UI.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73559384,
                        "answer_post": "WindowManager interface can be an alternative to the toast after the Android 11 limitations.\nhttps://developer.android.com/reference/android/view/WindowManager\nBut you just need user permission to display custom messages over the apps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66090712,
                        "answer_post": "You can use WorkManager to schedule tasks.\n\nWorkManager is an API that makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or the device restarts. The WorkManager API is a suitable and recommended replacement for all previous Android background scheduling APIs, including FirebaseJobDispatcher, GcmNetworkManager, and Job Scheduler.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61718464,
                        "answer_post": "First of all you have to create the notification channel:\n\nChange the NotificationManager to be:\nNotificationManagerCompat manager;\nthen modify your notify() function like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75195627,
                        "answer_post": "In version 10 the following callback has been reworked flutter_local_notifications changelog 10.0.0\nFor using onSelectNotification callback use flutter_local_notifications below 10.0.0.\nThis callback (onSelectNotification) is guaranteed to work in version 9.3.1.\nAlso, in version 10.0.0 and higher, the following callback can be used instead:\nonDidReceiveNotificationResponse:\ninvoked only when the app is running. This works when a user has selected a notification or notification action. This replaces the onSelectNotification\nonDidReceiveBackgroundNotificationResponse: invoked on a background isolate when a user has selected a notification action. This replaces the onSelectNotificationAction callback\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 77423309,
                        "answer_post": "\"notification\": {\n\n}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62486136,
                        "answer_post": "Use notification manager like below to support all android versions\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61555994,
                        "answer_post": "Try Notifications\nYour best bet is to use Notifications in Android to show your message on the status bar\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68319855,
                        "answer_post": "use this :\n\nbefore putting into NotificationManager.notify\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71956233,
                        "answer_post": "This should help you, Firebase Notification Scheduler\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68093503,
                        "answer_post": "You can achieve this via NotificationListenerService\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63159183,
                        "answer_post": "Use alarm manager, for this :\n\nFor full guidance visit this developer android page\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61843790,
                        "answer_post": "The Notification IDs should be different\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66090712,
                        "answer_post": "You can use WorkManager to schedule tasks.\n\nWorkManager is an API that makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or the device restarts. The WorkManager API is a suitable and recommended replacement for all previous Android background scheduling APIs, including FirebaseJobDispatcher, GcmNetworkManager, and Job Scheduler.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67242315,
                        "answer_post": "Define RegisterActivity to your Manifest\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "you can get getSystemService from context\nchange your code\nfrom:\n\nval notificationManager: NotificationManager =\ngetSystemService(context.NOTIFICATION_SERVICE) as NotificationManager\n\nto:\n\nval notificationManager: NotificationManager =\ncontext.getSystemService(context.NOTIFICATION_SERVICE) as\nNotificationManager\n\nwhere context is context = flutterPluginBinding.getApplicationContext();\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "If you are working on the android versions above oreo, then you have to use a notification channel for notifications from the notificationManager. I think it will work, as it did in mine.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "In Android using Kotlin, notifications from a particular channel can be removed using \"NotificationManager\" and the channel id of the channel you want to delete. Although this can only be achieved in android oreo and above.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "the problem wasa the phone for some reason couldnt create all the notifications.\nthe code that fixed it was the .apply{} on the notificationManager\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "\nmy question is how an Android app's internal notification settings is synced with the Android OS to manage which notifications to show and which ones to block (mute)?\n\nAndroid itself does not have a concept of \"internal notification settings\".\nAll notifications from an app are created by the app and handed to the OS via NotificationManager. The OS then applies system rules for how they should be handled, such as those configured by the user via the system Settings app.\nIf an app also has its own concept of \"internal notification settings\", that would control when the app actually invokes NotificationManager.\n\nIs it like the OS will pass the received notification to the intended app and then it decides - based on its internal settings- which one to show? Or the app will give the user-defined notification settings to the OS (by some API or ...) and then OS filters the notifications and decides what to show or not?\n\nNeither of those are correct.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "notificationManager must also be declared only once\n\nthen use the same variable notification_Manager.notify() and notificationBuilder for every notification update you make.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Do you want to let the gps location icon on the notifications go away?\nAfter run the stopLocationUpdates(), is the new location callback received, and let you notifications update ? Did you use NotificationManager to show notifications?\nIf there is no new location callback and after that, you can dismiss the notifications directly.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You will need to use WorkManager & NotificationManager to achieve what you expecting here.\nFor Kotlin, this is a good start.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "First of all you have to create the notification channel:\n\nChange the NotificationManager to be:\nNotificationManagerCompat manager;\nthen modify your notify() function like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "\nNever create an instance of an activity yourself. Move checkNotifications() into the service or into some utility class (where you provide a Context as a parameter to checkNotifications() for the purposes of obtaining a NotificationManager).\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "environment": {
                "finetuned_dpr": [
                    {
                        "id": 76992601,
                        "answer_post": "\nmy question is how an Android app's internal notification settings is synced with the Android OS to manage which notifications to show and which ones to block (mute)?\n\nAndroid itself does not have a concept of \"internal notification settings\".\nAll notifications from an app are created by the app and handed to the OS via NotificationManager. The OS then applies system rules for how they should be handled, such as those configured by the user via the system Settings app.\nIf an app also has its own concept of \"internal notification settings\", that would control when the app actually invokes NotificationManager.\n\nIs it like the OS will pass the received notification to the intended app and then it decides - based on its internal settings- which one to show? Or the app will give the user-defined notification settings to the OS (by some API or ...) and then OS filters the notifications and decides what to show or not?\n\nNeither of those are correct.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70612654,
                        "answer_post": "Notifications on Android TV OS are significantly different than mobile Android. There is an area to display notifications within the launcher, but it is limited to system-level notifications that are important for the user (e.g., issues with your account or info about OS updates). General app notifications do not show up, which means you need to display any kind of notification within your own app UI and not with the regular NotificationManager and related APIs.\n\nCan we use Notification Manager. / Can we set the Notification priority\n\nYes, but it won't result in a notification being visible to the user and shouldn't be done on Android TV OS.\n\nProper method to implementation Android TV notification.\n\nThis should be handled within app UI. Most apps have a reserved space to show these on the main screen so that users see them as soon as they open the app.\n\nPossible way to find out whether the user has seen/interacted with notification or not\n\nSince you'll have to display it in your own UI, you can use regular View methods. For example, if you want to know if the user clicked the message, you can add that code to the OnClickListener.\n\nHandling list of notification messages by Local Database or any other method.\n\nThis is a bit vague to give a specific answer, so you may want to post a separate question with more details about what you're trying to accomplish. One general way to go about it is that you have a server endpoint that understands the state of notifications for a given user and you sync that with your local database (easiest is probably Sqlite using Room). Your UI needs to be told if there's a relevant notification to display within the app, but the details of that depend on your app architecture.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65329139,
                        "answer_post": "Unfortunately there is no official API to open notifications settings directly.\nInstead what you can do is to open the settings via intent Intent(Settings.ACTION_APPLICATION_DETAILS_SETTINGS this will not open the notification settings but it may help take user a step closer to the notification settings.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62196033,
                        "answer_post": "I don't think you have that level of control over how Android displays/plays incoming notification messages.\nThe only approach I can think of is taking full control of the display of the messages in your own application code, by using data messages instead of notification messages.\nReminder: Firebase Cloud Messaging has two message types: notification messages, and data messages. Notifications messages are automatically handled/displayed by the OS when your app is not active, while data messages are always delivered to your application code.\nFrom within your application code, you can then use the Android notification API to build the exact display of the message that you want, and display it exactly when you want it (within the notification settings of the user of course).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62561442,
                        "answer_post": "\nHow can I create the foreground notification only once or at least how not to play notification sound on successive startForegroundService() calls?\n\nYou can check if the notification is already visible and show it only if it's not visible. You need to have a reference to the notification PendingIntent and notificationId.\n\n\nhow can I go back to my application when I click the foreground notification?\n\nYou need a PendingIntent to open the app from a notification. To open the last activity shown you can remember this using Preferences in the onResume() method of each activity and route the notification into a routing activity that starts the right activity according to the value saved into the preferences.\n\nAnother way to do this is to update the notification PendingIntent if it's already visible with the last activity shown. In this case you don't have to store any value on Preferences and you don't need a route activity.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62486856,
                        "answer_post": "It seems like you haven't setup the notification channel that you are trying to add the notification to. As a test can you add this code before the NotificationCompat.Builder setup?\n\nNotification must be assigned to Channels in Android 8.0 (API level 26). Please see the NotificationChannel documentation found here\nThis is most likely the reason the Notification is not showing on your device, however the Worker is definitely still working. You can see some logs of what your Workers have done in both the Debug output and Logcat windows. Some examples of my own tests can be seen below:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61330071,
                        "answer_post": "To access notifications, you can use the NotificationListenerService. The documents on this is located at: https://developer.android.com/reference/android/service/notification/NotificationListenerService\nFor the implementation of this class, there has already been discussed within this link: NotificationListenerService Implementation (See the accepted answer for a link to an example)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63112379,
                        "answer_post": "Following are the notification styles available :\n\nNotification.BigPictureStyle, Notification.BigTextStyle,\nNotification.DecoratedCustomViewStyle, Notification.InboxStyle,\nNotification.MediaStyle, Notification.MessagingStyle\n\nYou can get more info on this link.\nJust for information purposes, to create a notification without hustle and get all predefined formatting in one place, just do the following :\n\nGo to the Project Tab of android studio and right click.\nClick on New -> UI Component -> Notification\nEnter the required notification name\n\nTo call this notification just enter the following :\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66089790,
                        "answer_post": "1- If your implementation can be handled in local, you can use Notification Manager for this, not remote push notifications. Basically set alarms for your desired times, create notifications in OnReceive method of Alarm manager and notify the system\nhttps://developer.android.com/reference/android/app/AlarmManager\nhttps://developer.android.com/training/notify-user/build-notification\n2- If you want to have more control over your notification system and dynamically manage your remote notifications, you can make it via Firebase Admin SDK.\nhttps://firebase.google.com/docs/admin/setup\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72461463,
                        "answer_post": "In your scenario, you'll need to use addNotificationReceivedListener, this listener will be triggered after the user clicks on the notification, inside that listener you can access the notification response data and navigate to another screen.\nYou can read more about it here https://docs.expo.dev/push-notifications/receiving-notifications/\nExample of the notification listener function\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 61462891,
                        "answer_post": "the notification on android is displayed by calling the mNotificationManager.notify method (NOTIFICATION_ID, mNotification);  .  Try displaying your code to see\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66090712,
                        "answer_post": "You can use WorkManager to schedule tasks.\n\nWorkManager is an API that makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or the device restarts. The WorkManager API is a suitable and recommended replacement for all previous Android background scheduling APIs, including FirebaseJobDispatcher, GcmNetworkManager, and Job Scheduler.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73559384,
                        "answer_post": "WindowManager interface can be an alternative to the toast after the Android 11 limitations.\nhttps://developer.android.com/reference/android/view/WindowManager\nBut you just need user permission to display custom messages over the apps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66249808,
                        "answer_post": "The Notification Composer is an online tool hosted by Firebase.\nTherefore it already knows the Server Key (required to send messages) associated to each of your projects.\nBy design (and for obvious security reasons), the Server Key is implicitely linked to a single app, and you can't use it to send a message to different apps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72231120,
                        "answer_post": "\nWorkManager 2.3.0-alpha02 adds built-in support for long running\nworkers. In such cases, WorkManager can provide a signal to the OS\nthat the process should be kept alive if possible while this work is\nexecuting. These Workers can run longer than 10 minutes. Example\nuse-cases for this new feature include bulk uploads or downloads (that\ncannot be chunked), crunching on an ML model locally, or a task that's\nimportant to the user of the app.\n\nUnder the hood, WorkManager manages and runs a foreground service on your behalf to execute the WorkRequest, while also showing a configurable notification.\nListenableWorker now supports the setForegroundAsync() API, and CoroutineWorker supports a suspending setForeground() API. These APIs allow developers to specify that this WorkRequest is important (from a user perspective) or long-running.\nStarting with 2.3.0-alpha03, WorkManager also allows you to create a PendingIntent, which can be used to cancel workers without having to register a new Android component using the createCancelPendingIntent() API. This approach is especially useful when used with the setForegroundAsync() or setForeground() APIs, which can be used to add a notification action to cancel the Worker.\nLink to the resource: https://developer.android.com/topic/libraries/architecture/workmanager/advanced/long-running\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61330071,
                        "answer_post": "To access notifications, you can use the NotificationListenerService. The documents on this is located at: https://developer.android.com/reference/android/service/notification/NotificationListenerService\nFor the implementation of this class, there has already been discussed within this link: NotificationListenerService Implementation (See the accepted answer for a link to an example)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70918520,
                        "answer_post": "It's important to note that your viewModel and the method getRandomWordForNotification() will be called while your view is active. In your case that does not help you with getting a random word while your app is in the background/killed.\nYou should modify your AlarmReceiver to start a Service where you will call your repository, get your new random word and construct your notification.\n\n\nIn addition to this, register the service in your AndroidManifest file.\n\nA few disclaimers:\n\nIntentService was deprecated in API level 30.\n\nAlarmManager is often replaced with WorkManager: https://developer.android.com/reference/androidx/work/WorkManager\nand\nhttps://developer.android.com/topic/libraries/architecture/workmanager\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64745632,
                        "answer_post": "A notification message is directly displayed, and therefore the onMessageReceived method will not be called.\nThe method is called only when a data message is received. For details, please refer to Receiving Data Messages. However, a data message cannot reach your app after the process of your app is killed. To display a notification message after the process of your app is killed, or receive a data message through onMessageReceived when your app is running, please refer to Notification Message Display on UI.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62088749,
                        "answer_post": "Firebase Cloud Messaging has two distinct types of messages:\n\nNotification messages that are handled and displayed by the OS when the app is not active, and handled by your application code when the app is active.\nData messages that are always handled by your application code, which can then choose to display or update UI notifications as needed.\n\nWhat you're describing sounds like you want to use data messages only, and then use Android's notification UI/API to display, update, or hide a notification.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76487483,
                        "answer_post": "AlarmManager works, but it's an older, less capable API.  It also doesn't save state around reboot.  Newer APIs include JobScheduler and WorkManager.  The first is used to be notified at a specific time and/or when conditions occur (such as gaining network connectivity).  It's meant for 1 time or repeated alarms.  WorkManager is for background work like a database sync that is low priority and meant to be done when the device has spare capacity.  Use whichever is appropriate for your usecase.  If you were just using an alarm, it's probably JobScheduler.\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 77423309,
                        "answer_post": "\"notification\": {\n\n}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62486136,
                        "answer_post": "Use notification manager like below to support all android versions\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71956233,
                        "answer_post": "This should help you, Firebase Notification Scheduler\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66090712,
                        "answer_post": "You can use WorkManager to schedule tasks.\n\nWorkManager is an API that makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or the device restarts. The WorkManager API is a suitable and recommended replacement for all previous Android background scheduling APIs, including FirebaseJobDispatcher, GcmNetworkManager, and Job Scheduler.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61555994,
                        "answer_post": "Try Notifications\nYour best bet is to use Notifications in Android to show your message on the status bar\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68319855,
                        "answer_post": "use this :\n\nbefore putting into NotificationManager.notify\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61713440,
                        "answer_post": "Add app:layout_behavior here\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68093503,
                        "answer_post": "You can achieve this via NotificationListenerService\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67242315,
                        "answer_post": "Define RegisterActivity to your Manifest\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71500018,
                        "answer_post": "in AndroidManifest.xml\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "you can get getSystemService from context\nchange your code\nfrom:\n\nval notificationManager: NotificationManager =\ngetSystemService(context.NOTIFICATION_SERVICE) as NotificationManager\n\nto:\n\nval notificationManager: NotificationManager =\ncontext.getSystemService(context.NOTIFICATION_SERVICE) as\nNotificationManager\n\nwhere context is context = flutterPluginBinding.getApplicationContext();\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "If you are working on the android versions above oreo, then you have to use a notification channel for notifications from the notificationManager. I think it will work, as it did in mine.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "In Android using Kotlin, notifications from a particular channel can be removed using \"NotificationManager\" and the channel id of the channel you want to delete. Although this can only be achieved in android oreo and above.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "the problem wasa the phone for some reason couldnt create all the notifications.\nthe code that fixed it was the .apply{} on the notificationManager\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nmy question is how an Android app's internal notification settings is synced with the Android OS to manage which notifications to show and which ones to block (mute)?\n\nAndroid itself does not have a concept of \"internal notification settings\".\nAll notifications from an app are created by the app and handed to the OS via NotificationManager. The OS then applies system rules for how they should be handled, such as those configured by the user via the system Settings app.\nIf an app also has its own concept of \"internal notification settings\", that would control when the app actually invokes NotificationManager.\n\nIs it like the OS will pass the received notification to the intended app and then it decides - based on its internal settings- which one to show? Or the app will give the user-defined notification settings to the OS (by some API or ...) and then OS filters the notifications and decides what to show or not?\n\nNeither of those are correct.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "notificationManager must also be declared only once\n\nthen use the same variable notification_Manager.notify() and notificationBuilder for every notification update you make.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Do you want to let the gps location icon on the notifications go away?\nAfter run the stopLocationUpdates(), is the new location callback received, and let you notifications update ? Did you use NotificationManager to show notifications?\nIf there is no new location callback and after that, you can dismiss the notifications directly.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You will need to use WorkManager & NotificationManager to achieve what you expecting here.\nFor Kotlin, this is a good start.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First of all you have to create the notification channel:\n\nChange the NotificationManager to be:\nNotificationManagerCompat manager;\nthen modify your notify() function like this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "\nNever create an instance of an activity yourself. Move checkNotifications() into the service or into some utility class (where you provide a Context as a parameter to checkNotifications() for the purposes of obtaining a NotificationManager).\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "alternative": {
                "finetuned_dpr": [
                    {
                        "id": 76992601,
                        "answer_post": "\nmy question is how an Android app's internal notification settings is synced with the Android OS to manage which notifications to show and which ones to block (mute)?\n\nAndroid itself does not have a concept of \"internal notification settings\".\nAll notifications from an app are created by the app and handed to the OS via NotificationManager. The OS then applies system rules for how they should be handled, such as those configured by the user via the system Settings app.\nIf an app also has its own concept of \"internal notification settings\", that would control when the app actually invokes NotificationManager.\n\nIs it like the OS will pass the received notification to the intended app and then it decides - based on its internal settings- which one to show? Or the app will give the user-defined notification settings to the OS (by some API or ...) and then OS filters the notifications and decides what to show or not?\n\nNeither of those are correct.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70612654,
                        "answer_post": "Notifications on Android TV OS are significantly different than mobile Android. There is an area to display notifications within the launcher, but it is limited to system-level notifications that are important for the user (e.g., issues with your account or info about OS updates). General app notifications do not show up, which means you need to display any kind of notification within your own app UI and not with the regular NotificationManager and related APIs.\n\nCan we use Notification Manager. / Can we set the Notification priority\n\nYes, but it won't result in a notification being visible to the user and shouldn't be done on Android TV OS.\n\nProper method to implementation Android TV notification.\n\nThis should be handled within app UI. Most apps have a reserved space to show these on the main screen so that users see them as soon as they open the app.\n\nPossible way to find out whether the user has seen/interacted with notification or not\n\nSince you'll have to display it in your own UI, you can use regular View methods. For example, if you want to know if the user clicked the message, you can add that code to the OnClickListener.\n\nHandling list of notification messages by Local Database or any other method.\n\nThis is a bit vague to give a specific answer, so you may want to post a separate question with more details about what you're trying to accomplish. One general way to go about it is that you have a server endpoint that understands the state of notifications for a given user and you sync that with your local database (easiest is probably Sqlite using Room). Your UI needs to be told if there's a relevant notification to display within the app, but the details of that depend on your app architecture.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65329139,
                        "answer_post": "Unfortunately there is no official API to open notifications settings directly.\nInstead what you can do is to open the settings via intent Intent(Settings.ACTION_APPLICATION_DETAILS_SETTINGS this will not open the notification settings but it may help take user a step closer to the notification settings.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62486856,
                        "answer_post": "It seems like you haven't setup the notification channel that you are trying to add the notification to. As a test can you add this code before the NotificationCompat.Builder setup?\n\nNotification must be assigned to Channels in Android 8.0 (API level 26). Please see the NotificationChannel documentation found here\nThis is most likely the reason the Notification is not showing on your device, however the Worker is definitely still working. You can see some logs of what your Workers have done in both the Debug output and Logcat windows. Some examples of my own tests can be seen below:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61330071,
                        "answer_post": "To access notifications, you can use the NotificationListenerService. The documents on this is located at: https://developer.android.com/reference/android/service/notification/NotificationListenerService\nFor the implementation of this class, there has already been discussed within this link: NotificationListenerService Implementation (See the accepted answer for a link to an example)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72461463,
                        "answer_post": "In your scenario, you'll need to use addNotificationReceivedListener, this listener will be triggered after the user clicks on the notification, inside that listener you can access the notification response data and navigate to another screen.\nYou can read more about it here https://docs.expo.dev/push-notifications/receiving-notifications/\nExample of the notification listener function\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62561442,
                        "answer_post": "\nHow can I create the foreground notification only once or at least how not to play notification sound on successive startForegroundService() calls?\n\nYou can check if the notification is already visible and show it only if it's not visible. You need to have a reference to the notification PendingIntent and notificationId.\n\n\nhow can I go back to my application when I click the foreground notification?\n\nYou need a PendingIntent to open the app from a notification. To open the last activity shown you can remember this using Preferences in the onResume() method of each activity and route the notification into a routing activity that starts the right activity according to the value saved into the preferences.\n\nAnother way to do this is to update the notification PendingIntent if it's already visible with the last activity shown. In this case you don't have to store any value on Preferences and you don't need a route activity.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64227477,
                        "answer_post": "From Android 8.0 if you want to show a notification, you should associate it to a Notification Channel.\nFirst you should create a new notification Channel then show your notification.\nYou can find more detailed information here: https://developer.android.com/training/notify-user/channels\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62196033,
                        "answer_post": "I don't think you have that level of control over how Android displays/plays incoming notification messages.\nThe only approach I can think of is taking full control of the display of the messages in your own application code, by using data messages instead of notification messages.\nReminder: Firebase Cloud Messaging has two message types: notification messages, and data messages. Notifications messages are automatically handled/displayed by the OS when your app is not active, while data messages are always delivered to your application code.\nFrom within your application code, you can then use the Android notification API to build the exact display of the message that you want, and display it exactly when you want it (within the notification settings of the user of course).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63112379,
                        "answer_post": "Following are the notification styles available :\n\nNotification.BigPictureStyle, Notification.BigTextStyle,\nNotification.DecoratedCustomViewStyle, Notification.InboxStyle,\nNotification.MediaStyle, Notification.MessagingStyle\n\nYou can get more info on this link.\nJust for information purposes, to create a notification without hustle and get all predefined formatting in one place, just do the following :\n\nGo to the Project Tab of android studio and right click.\nClick on New -> UI Component -> Notification\nEnter the required notification name\n\nTo call this notification just enter the following :\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 72608305,
                        "answer_post": "notificationManager must also be declared only once\n\nthen use the same variable notification_Manager.notify() and notificationBuilder for every notification update you make.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61462891,
                        "answer_post": "the notification on android is displayed by calling the mNotificationManager.notify method (NOTIFICATION_ID, mNotification);  .  Try displaying your code to see\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73559384,
                        "answer_post": "WindowManager interface can be an alternative to the toast after the Android 11 limitations.\nhttps://developer.android.com/reference/android/view/WindowManager\nBut you just need user permission to display custom messages over the apps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66090712,
                        "answer_post": "You can use WorkManager to schedule tasks.\n\nWorkManager is an API that makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or the device restarts. The WorkManager API is a suitable and recommended replacement for all previous Android background scheduling APIs, including FirebaseJobDispatcher, GcmNetworkManager, and Job Scheduler.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70918520,
                        "answer_post": "It's important to note that your viewModel and the method getRandomWordForNotification() will be called while your view is active. In your case that does not help you with getting a random word while your app is in the background/killed.\nYou should modify your AlarmReceiver to start a Service where you will call your repository, get your new random word and construct your notification.\n\n\nIn addition to this, register the service in your AndroidManifest file.\n\nA few disclaimers:\n\nIntentService was deprecated in API level 30.\n\nAlarmManager is often replaced with WorkManager: https://developer.android.com/reference/androidx/work/WorkManager\nand\nhttps://developer.android.com/topic/libraries/architecture/workmanager\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64745632,
                        "answer_post": "A notification message is directly displayed, and therefore the onMessageReceived method will not be called.\nThe method is called only when a data message is received. For details, please refer to Receiving Data Messages. However, a data message cannot reach your app after the process of your app is killed. To display a notification message after the process of your app is killed, or receive a data message through onMessageReceived when your app is running, please refer to Notification Message Display on UI.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61330071,
                        "answer_post": "To access notifications, you can use the NotificationListenerService. The documents on this is located at: https://developer.android.com/reference/android/service/notification/NotificationListenerService\nFor the implementation of this class, there has already been discussed within this link: NotificationListenerService Implementation (See the accepted answer for a link to an example)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72231120,
                        "answer_post": "\nWorkManager 2.3.0-alpha02 adds built-in support for long running\nworkers. In such cases, WorkManager can provide a signal to the OS\nthat the process should be kept alive if possible while this work is\nexecuting. These Workers can run longer than 10 minutes. Example\nuse-cases for this new feature include bulk uploads or downloads (that\ncannot be chunked), crunching on an ML model locally, or a task that's\nimportant to the user of the app.\n\nUnder the hood, WorkManager manages and runs a foreground service on your behalf to execute the WorkRequest, while also showing a configurable notification.\nListenableWorker now supports the setForegroundAsync() API, and CoroutineWorker supports a suspending setForeground() API. These APIs allow developers to specify that this WorkRequest is important (from a user perspective) or long-running.\nStarting with 2.3.0-alpha03, WorkManager also allows you to create a PendingIntent, which can be used to cancel workers without having to register a new Android component using the createCancelPendingIntent() API. This approach is especially useful when used with the setForegroundAsync() or setForeground() APIs, which can be used to add a notification action to cancel the Worker.\nLink to the resource: https://developer.android.com/topic/libraries/architecture/workmanager/advanced/long-running\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75195627,
                        "answer_post": "In version 10 the following callback has been reworked flutter_local_notifications changelog 10.0.0\nFor using onSelectNotification callback use flutter_local_notifications below 10.0.0.\nThis callback (onSelectNotification) is guaranteed to work in version 9.3.1.\nAlso, in version 10.0.0 and higher, the following callback can be used instead:\nonDidReceiveNotificationResponse:\ninvoked only when the app is running. This works when a user has selected a notification or notification action. This replaces the onSelectNotification\nonDidReceiveBackgroundNotificationResponse: invoked on a background isolate when a user has selected a notification action. This replaces the onSelectNotificationAction callback\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61560734,
                        "answer_post": "you can use WorkManger to schedule tasks.\nThe WorkManager API makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or device restarts.\ncheck Google documentation here.\nfor notifications, you can send a notification in your work manager class. learn more here.\nthese hints should be enough. let me know if you need more clarifications. \n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 77423309,
                        "answer_post": "\"notification\": {\n\n}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61843790,
                        "answer_post": "The Notification IDs should be different\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62486136,
                        "answer_post": "Use notification manager like below to support all android versions\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68319855,
                        "answer_post": "use this :\n\nbefore putting into NotificationManager.notify\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68093503,
                        "answer_post": "You can achieve this via NotificationListenerService\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71956233,
                        "answer_post": "This should help you, Firebase Notification Scheduler\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61555994,
                        "answer_post": "Try Notifications\nYour best bet is to use Notifications in Android to show your message on the status bar\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74928441,
                        "answer_post": "for android:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66090712,
                        "answer_post": "You can use WorkManager to schedule tasks.\n\nWorkManager is an API that makes it easy to schedule deferrable, asynchronous tasks that are expected to run even if the app exits or the device restarts. The WorkManager API is a suitable and recommended replacement for all previous Android background scheduling APIs, including FirebaseJobDispatcher, GcmNetworkManager, and Job Scheduler.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67946567,
                        "answer_post": "Try with custom vibration on getting notification\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "you can get getSystemService from context\nchange your code\nfrom:\n\nval notificationManager: NotificationManager =\ngetSystemService(context.NOTIFICATION_SERVICE) as NotificationManager\n\nto:\n\nval notificationManager: NotificationManager =\ncontext.getSystemService(context.NOTIFICATION_SERVICE) as\nNotificationManager\n\nwhere context is context = flutterPluginBinding.getApplicationContext();\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "If you are working on the android versions above oreo, then you have to use a notification channel for notifications from the notificationManager. I think it will work, as it did in mine.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "In Android using Kotlin, notifications from a particular channel can be removed using \"NotificationManager\" and the channel id of the channel you want to delete. Although this can only be achieved in android oreo and above.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "the problem wasa the phone for some reason couldnt create all the notifications.\nthe code that fixed it was the .apply{} on the notificationManager\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nmy question is how an Android app's internal notification settings is synced with the Android OS to manage which notifications to show and which ones to block (mute)?\n\nAndroid itself does not have a concept of \"internal notification settings\".\nAll notifications from an app are created by the app and handed to the OS via NotificationManager. The OS then applies system rules for how they should be handled, such as those configured by the user via the system Settings app.\nIf an app also has its own concept of \"internal notification settings\", that would control when the app actually invokes NotificationManager.\n\nIs it like the OS will pass the received notification to the intended app and then it decides - based on its internal settings- which one to show? Or the app will give the user-defined notification settings to the OS (by some API or ...) and then OS filters the notifications and decides what to show or not?\n\nNeither of those are correct.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "notificationManager must also be declared only once\n\nthen use the same variable notification_Manager.notify() and notificationBuilder for every notification update you make.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Do you want to let the gps location icon on the notifications go away?\nAfter run the stopLocationUpdates(), is the new location callback received, and let you notifications update ? Did you use NotificationManager to show notifications?\nIf there is no new location callback and after that, you can dismiss the notifications directly.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You will need to use WorkManager & NotificationManager to achieve what you expecting here.\nFor Kotlin, this is a good start.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "First of all you have to create the notification channel:\n\nChange the NotificationManager to be:\nNotificationManagerCompat manager;\nthen modify your notify() function like this:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nNever create an instance of an activity yourself. Move checkNotifications() into the service or into some utility class (where you provide a Context as a parameter to checkNotifications() for the purposes of obtaining a NotificationManager).\n",
                        "contain_knowledge": 1
                    }
                ]
            }
        }
    },
    {
        "name": "Attributes2Impl",
        "language": "android",
        "popularity": "low",
        "label_result": {
            "functionality": {
                "finetuned_dpr": 0.0,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.0
            },
            "concept": {
                "finetuned_dpr": 0.3,
                "dpr": 0.2,
                "e5": 0.2,
                "bm25": 0.0
            },
            "performance": {
                "finetuned_dpr": 0.0,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.0
            },
            "directive": {
                "finetuned_dpr": 0.0,
                "dpr": 0.1,
                "e5": 0.1,
                "bm25": 0.0
            },
            "pattern": {
                "finetuned_dpr": 0.1,
                "dpr": 0.1,
                "e5": 0.1,
                "bm25": 0.0
            },
            "environment": {
                "finetuned_dpr": 0.2,
                "dpr": 0.4,
                "e5": 0.1,
                "bm25": 0.1
            },
            "alternative": {
                "finetuned_dpr": 0.2,
                "dpr": 0.3,
                "e5": 0.1,
                "bm25": 0.0
            },
            "total": {
                "finetuned_dpr": 0.1142857142857143,
                "dpr": 0.18571428571428572,
                "e5": 0.08571428571428572,
                "bm25": 0.014285714285714287
            }
        },
        "retrieve_result": {
            "functionality": {
                "finetuned_dpr": [
                    {
                        "id": 63289873,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66623045,
                        "answer_post": "In your attires.xml you should define a theme reference attribute\n\nThen you should define attributes in your style\n\nAfter then, you have to direct this style to a reference in your theme.\n\nIn your custom view's class, you need to define these attributes\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74900089,
                        "answer_post": "According to https://developer.android.com/develop/ui/views/layout/custom-views/create-view#addprop you can't programmatically set attributes, but instead you should define fields/getters/setters for your attributes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77701916,
                        "answer_post": "You can't add a custom attribute to the android namespace.  That namespace is pre-defined and consists of only the built in Android attributes.  Adding a custom attribute adds it to the application namespace, by convention that's the app:XXX attributes (although that's a convention, you can call it anything you want).  Please note that custom attributes must be defined in attrs.xml, you can't just make one up in the layout xml.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77534449,
                        "answer_post": "They're used to define attributes.  They specify the file to look for the attribute definitions in.  http://schemas.android.com/apk/res/android is the Android SDK's built in definitions.  \"http://schemas.android.com/apk/res-auto\" is the list of attribute defined by your application (including libraries you depend on). You can define any others you want, but typically an app only uses these two.\nThe namespace is used to qualify what attribute you're using.  Let's say you have namespace A and B.  Both define an attribute \"foo\".  If you were to specify foo without a namespace, it would be impossible to know what foo to use.  Using namespaces avoids that problem.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62919282,
                        "answer_post": "If you are able to add them from the xml file, you can add these attributes in your views (needed ones):\n\n\nTry to invalidate the cached and restart Android Studio, also make sure sure that you click on the views for the attributes to show in the design section.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71583809,
                        "answer_post": "In the StickerView file:\n\nRemove the StickerView(Context context) constructor\nPut the initialization code also in the StickerView(Context context, AttributeSet attributeSet) constructor (creating a dedicated method is a good approach) and\nChange this(context, attributeSet, 0) to super(context, attributeSet)\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62007162,
                        "answer_post": "Android studio does not work that way. You cannot set the positions of views(items) by dragging them and placing them. You will have to set the constraints on the attribute tab. You can find the attribute tab at the top left corner. It is visible in the picture you uploaded. Click on that and the attributes window will open. \nThen, when you click on a view, there is a square that appears in the attribute window. That square has 4 + signs around it. You have to click on one of the left or right + signs and enter a number. That would determine the horizontal position (distance from left or right margin) of the view. \nSimilarly, set the vertical position by clicking on to our bottom +.\nThis is the method used to set the position of views graphically. There is a way to set them in the xml code. I guess you are not familiar with it. You will get to know how to do it inxml as you go on with Android development.\nYou can also set the position of a view with reference to other views instead of the margins. Please watch this video to know more about constraints.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65432045,
                        "answer_post": "\nA theme is a collection of attributes that's applied to an entire app, activity, or view hierarchy\u2014not just an individual view. When you apply a theme, every view in the app or activity applies each of the theme's attributes that it supports. Themes can also apply styles to non-view elements, such as the status bar and window background.\n\nThis is a documentation quote which describes that themes are inheritable by default to all view or non-view elements in your app, unless you hard-coded your own theme.\nIf you notice that in manifest, your <activity> tag is a child of <application> tag, and yet the activity inherits the theme set in the <application> this way and cascade this inheritance all the way down.\nThis is an advantage as it keeps the coherence of your app elements and the user experience accordingly.\nYou can check the documentation for further info.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62098444,
                        "answer_post": "I don't think there is something wrong but something that might help is just using one namespace for all your custom attributes.\nIn your parent container you are using the app namespace\n\nSo, you need to use that namespace in the cardview attributes. Just replace card_view with app and remove the namespace in your CardView.\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 63138341,
                        "answer_post": "To use auto attributes, add the tools namespace to the root element of each XML file where you'd like to use them, as shown here:\n<app xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\">  \n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63289873,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71978976,
                        "answer_post": "Like most Android SDK classes, ExifInterface has documentation. In particular, that documentation contains a list of public constructors.\nThe first such constructor takes a File as its sole constructor parameter.\nYou appear to be looking to get this information from a File, identified by a variable named path.\nSo, use new ExifInterface(path).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77242197,
                        "answer_post": "Starting from Android 12 (API level 31), you are required to specify an explicit value for the android:exported attribute in your AndroidManifest.xml file for all components (activities, services, broadcast receivers, and content providers) that can be accessed by other apps.\nYou should explicitly specify whether a component can be accessed by other apps or not by setting the android:exported attribute to either true or false. Here's how you can do it for different components:\n\nSet android:exported to true if you want other apps to be able to start this activity otherwise false.\n\nYou need to add this attribute to all of your activities, services, broadcast receivers, and content providers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71250037,
                        "answer_post": "You can add the appAuthRedirectScheme attributes to the manifestPlaceholders instead of replacing the whole array, by using += instead of =\nExample :\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67556222,
                        "answer_post": "Attribute android:editable=\"false\" is deprecated. You can instead use android:enabled=\"false\" in the XML. If you want to programmatically do it, use:\n\nFor making other views dynamically appear as per values entered to your textview, you can use something like:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66194262,
                        "answer_post": "The android:name attribute used to add a default Fragment in the container.\nIt\n\nCreates a new instance of the Fragment\nCalls Fragment.onInflate(Context, AttributeSet, Bundle)\nExecutes a FragmentTransaction to add the Fragment to the appropriate FragmentManager\n\nFor more insight on this head to: Official Doc\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66413944,
                        "answer_post": "The problem is here:\n\n\n\nThe attribute android.R.attr.contextPopupMenuStyle was not added until API level 24, so you must target at least 24 for the Material Components library to access that attribute.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71583809,
                        "answer_post": "In the StickerView file:\n\nRemove the StickerView(Context context) constructor\nPut the initialization code also in the StickerView(Context context, AttributeSet attributeSet) constructor (creating a dedicated method is a good approach) and\nChange this(context, attributeSet, 0) to super(context, attributeSet)\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77701916,
                        "answer_post": "You can't add a custom attribute to the android namespace.  That namespace is pre-defined and consists of only the built in Android attributes.  Adding a custom attribute adds it to the application namespace, by convention that's the app:XXX attributes (although that's a convention, you can call it anything you want).  Please note that custom attributes must be defined in attrs.xml, you can't just make one up in the layout xml.\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 76048454,
                        "answer_post": "android.R.attr.fingerprintAuthDrawable\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71723371,
                        "answer_post": "\nhere how it works with fragment\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71500018,
                        "answer_post": "in AndroidManifest.xml\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62237887,
                        "answer_post": "Use ItemTouchHelper class\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64107142,
                        "answer_post": "in activity\n\nin XML\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67242315,
                        "answer_post": "Define RegisterActivity to your Manifest\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65356178,
                        "answer_post": "Try\n\nMainActivity\n\n\n\nViewModel\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77768833,
                        "answer_post": "XML File\n\nAPI Function\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76200241,
                        "answer_post": "\nReference- How do i display 2 interfaces on the same app based on different credentials?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70766989,
                        "answer_post": "use package device_info\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "After doing thorough analysis what I confirmed is there is no way to set the SHIFT state of GBOARD unless google provides the API in future android release.\nI was able to achieve this in LatinIME keyboard, Android's default keyboard, through changes in the keyboard (LatinIME) application itself.\nThanks\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Use of Device Admin have been deprecated and Android provides very limited functionality starting from Android 10.\nApplication management permissions are part of Device Owner and Profile Owner deployment models in Android. You need to set your app as Device Owner, use below API :\nFor blocking Application uninstallation:\nhttps://developer.android.com/reference/android/app/admin/DevicePolicyManager#setUninstallBlocked(android.content.ComponentName,%20java.lang.String,%20boolean)\nTo prevent Factory Reset :\nhttps://developer.android.com/reference/android/os/UserManager#DISALLOW_FACTORY_RESET\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Try adding the following attributes into the RadioButton, it should work.\n\nRemember to set supportsRtl property to true in your application manifest.\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Shared Preferences Vs Flutter Secure Storage\nBasically, Why you should use flutter_secure_storage because it provides another secure layer rather than the shared preferences. In shared preferences, the data is stored as the key-value pairs as it is.\nRather than that flutter_Secure_Storage provides another secure layer above storing the data by encrypting the key values. It uses the IOS Keychain which is the mechanism to store small bits of user data in an encrypted database in the IOS operating system. Also, for the Android OS, the Android Keystore mechanism. So if you wish to store some serious data in your mobile application, definitely you should choose flutter_secure_storage. Here you can see how to work with flutter_secure_storage and Shared_Preferences.\nShared Preferences ---> Shared_Preferences_Implementation\nFlutter Secure Storage ---> Flutter_Secure_Storage_Implementation\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Shared Preferences Vs Flutter Secure Storage\nBasically, Why you should use flutter_secure_storage because it provides another secure layer rather than the shared preferences. In shared preferences, the data is stored as the key-value pairs as it is.\nRather than that flutter_Secure_Storage provides another secure layer above storing the data by encrypting the key values. It uses the IOS Keychain which is the mechanism to store small bits of user data in an encrypted database in the IOS operating system. Also, for the Android OS, the Android Keystore mechanism. So if you wish to store some serious data in your mobile application, definitely you should choose flutter_secure_storage. Here you can see how to work with flutter_secure_storage and Shared_Preferences.\nShared Preferences ---> Shared_Preferences_Implementation\nFlutter Secure Storage ---> Flutter_Secure_Storage_Implementation\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "If you're using the Androidx Compat Library make sure you're using the attributes without the android tag.\nFor example:\nThis will work fine\n\nThis will give you a \"require API 31\" error\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "In Android 10 and 11, you've to use Scoped Storage to access files. But, if you set android:requestLegacyExternalStorage to true, then you can work with the previous methods of accessing storage in Android 10.\nFor Android 11, you've to set targetSDKVersion as 29, not 30 to make android:requestLegacyExternalStorage work as mentioned in the below image, Reference - Storage updates in Android 11.\n\nSo, in your build.gradle (app), set targetSdkVersion 29 or go with Scoped Storage.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First of all, your app will be accpeted by the Goolge Play Store because your target sdk is heigher than Api 31. And then about the minSDKVersion, the official document's explain:\n\nAn integer designating the minimum API Level required for the application to run. The Android system will prevent the user from installing the application if the system's API Level is lower than the value specified in this attribute. You should always declare this attribute.\n\nGoogle doesn't have a request for this attribute. And the android official document said:\n\nIf you do not declare this attribute, the system assumes a default value of \"1\", which indicates that your application is compatible with all versions of Android.\n\nSo if your application is compatible with the lower versions, such as it can run well on the Android 10 or lower, you can set it as 29.\nFor more information, you can check the official document about the uses-sdk attributes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Some time ago I switched my AOSP environment from Android 10 to 11. Google made quite a few changes to the Overlay mechanism. To my big surprise these changes fixed the problems I had when trying to \"overlay\" custom attributes.\nWith the Android 10 environment I observed while debugging that the Android XML parser returns \"null\" when trying to read the mentioned attributes. With idmap I was able to confirm that the attributes were present in the overlay and the target app, and that they were properly mapped.\nAlso all the linker errors were gone.\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "concept": {
                "finetuned_dpr": [
                    {
                        "id": 63289873,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66623045,
                        "answer_post": "In your attires.xml you should define a theme reference attribute\n\nThen you should define attributes in your style\n\nAfter then, you have to direct this style to a reference in your theme.\n\nIn your custom view's class, you need to define these attributes\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74900089,
                        "answer_post": "According to https://developer.android.com/develop/ui/views/layout/custom-views/create-view#addprop you can't programmatically set attributes, but instead you should define fields/getters/setters for your attributes.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77701916,
                        "answer_post": "You can't add a custom attribute to the android namespace.  That namespace is pre-defined and consists of only the built in Android attributes.  Adding a custom attribute adds it to the application namespace, by convention that's the app:XXX attributes (although that's a convention, you can call it anything you want).  Please note that custom attributes must be defined in attrs.xml, you can't just make one up in the layout xml.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77534449,
                        "answer_post": "They're used to define attributes.  They specify the file to look for the attribute definitions in.  http://schemas.android.com/apk/res/android is the Android SDK's built in definitions.  \"http://schemas.android.com/apk/res-auto\" is the list of attribute defined by your application (including libraries you depend on). You can define any others you want, but typically an app only uses these two.\nThe namespace is used to qualify what attribute you're using.  Let's say you have namespace A and B.  Both define an attribute \"foo\".  If you were to specify foo without a namespace, it would be impossible to know what foo to use.  Using namespaces avoids that problem.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65432045,
                        "answer_post": "\nA theme is a collection of attributes that's applied to an entire app, activity, or view hierarchy\u2014not just an individual view. When you apply a theme, every view in the app or activity applies each of the theme's attributes that it supports. Themes can also apply styles to non-view elements, such as the status bar and window background.\n\nThis is a documentation quote which describes that themes are inheritable by default to all view or non-view elements in your app, unless you hard-coded your own theme.\nIf you notice that in manifest, your <activity> tag is a child of <application> tag, and yet the activity inherits the theme set in the <application> this way and cascade this inheritance all the way down.\nThis is an advantage as it keeps the coherence of your app elements and the user experience accordingly.\nYou can check the documentation for further info.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71583809,
                        "answer_post": "In the StickerView file:\n\nRemove the StickerView(Context context) constructor\nPut the initialization code also in the StickerView(Context context, AttributeSet attributeSet) constructor (creating a dedicated method is a good approach) and\nChange this(context, attributeSet, 0) to super(context, attributeSet)\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62919282,
                        "answer_post": "If you are able to add them from the xml file, you can add these attributes in your views (needed ones):\n\n\nTry to invalidate the cached and restart Android Studio, also make sure sure that you click on the views for the attributes to show in the design section.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67218323,
                        "answer_post": "I think it's a good idea to check out the design of the Composables provided by the framework.\nFor example:\n\nSo in short, yes it is a good idea, and I'd use it for grouping attributes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62007162,
                        "answer_post": "Android studio does not work that way. You cannot set the positions of views(items) by dragging them and placing them. You will have to set the constraints on the attribute tab. You can find the attribute tab at the top left corner. It is visible in the picture you uploaded. Click on that and the attributes window will open. \nThen, when you click on a view, there is a square that appears in the attribute window. That square has 4 + signs around it. You have to click on one of the left or right + signs and enter a number. That would determine the horizontal position (distance from left or right margin) of the view. \nSimilarly, set the vertical position by clicking on to our bottom +.\nThis is the method used to set the position of views graphically. There is a way to set them in the xml code. I guess you are not familiar with it. You will get to know how to do it inxml as you go on with Android development.\nYou can also set the position of a view with reference to other views instead of the margins. Please watch this video to know more about constraints.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 63138341,
                        "answer_post": "To use auto attributes, add the tools namespace to the root element of each XML file where you'd like to use them, as shown here:\n<app xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\">  \n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63289873,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71978976,
                        "answer_post": "Like most Android SDK classes, ExifInterface has documentation. In particular, that documentation contains a list of public constructors.\nThe first such constructor takes a File as its sole constructor parameter.\nYou appear to be looking to get this information from a File, identified by a variable named path.\nSo, use new ExifInterface(path).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71250037,
                        "answer_post": "You can add the appAuthRedirectScheme attributes to the manifestPlaceholders instead of replacing the whole array, by using += instead of =\nExample :\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67556222,
                        "answer_post": "Attribute android:editable=\"false\" is deprecated. You can instead use android:enabled=\"false\" in the XML. If you want to programmatically do it, use:\n\nFor making other views dynamically appear as per values entered to your textview, you can use something like:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77242197,
                        "answer_post": "Starting from Android 12 (API level 31), you are required to specify an explicit value for the android:exported attribute in your AndroidManifest.xml file for all components (activities, services, broadcast receivers, and content providers) that can be accessed by other apps.\nYou should explicitly specify whether a component can be accessed by other apps or not by setting the android:exported attribute to either true or false. Here's how you can do it for different components:\n\nSet android:exported to true if you want other apps to be able to start this activity otherwise false.\n\nYou need to add this attribute to all of your activities, services, broadcast receivers, and content providers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66194262,
                        "answer_post": "The android:name attribute used to add a default Fragment in the container.\nIt\n\nCreates a new instance of the Fragment\nCalls Fragment.onInflate(Context, AttributeSet, Bundle)\nExecutes a FragmentTransaction to add the Fragment to the appropriate FragmentManager\n\nFor more insight on this head to: Official Doc\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66413944,
                        "answer_post": "The problem is here:\n\n\n\nThe attribute android.R.attr.contextPopupMenuStyle was not added until API level 24, so you must target at least 24 for the Material Components library to access that attribute.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71583809,
                        "answer_post": "In the StickerView file:\n\nRemove the StickerView(Context context) constructor\nPut the initialization code also in the StickerView(Context context, AttributeSet attributeSet) constructor (creating a dedicated method is a good approach) and\nChange this(context, attributeSet, 0) to super(context, attributeSet)\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67549349,
                        "answer_post": "Can you try\n\nThe entire name of the attribute needs to match, so either include app: in code or remove app: in xml\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 76048454,
                        "answer_post": "android.R.attr.fingerprintAuthDrawable\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71500018,
                        "answer_post": "in AndroidManifest.xml\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72187445,
                        "answer_post": "Add this attribute\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76200241,
                        "answer_post": "\nReference- How do i display 2 interfaces on the same app based on different credentials?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67242315,
                        "answer_post": "Define RegisterActivity to your Manifest\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64107142,
                        "answer_post": "in activity\n\nin XML\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65356178,
                        "answer_post": "Try\n\nMainActivity\n\n\n\nViewModel\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67239641,
                        "answer_post": "This is how you can display height and width of the screen\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61578234,
                        "answer_post": "In the XML define this attribute: android:inputType=\"numberSigned\"\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62237887,
                        "answer_post": "Use ItemTouchHelper class\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "After doing thorough analysis what I confirmed is there is no way to set the SHIFT state of GBOARD unless google provides the API in future android release.\nI was able to achieve this in LatinIME keyboard, Android's default keyboard, through changes in the keyboard (LatinIME) application itself.\nThanks\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Use of Device Admin have been deprecated and Android provides very limited functionality starting from Android 10.\nApplication management permissions are part of Device Owner and Profile Owner deployment models in Android. You need to set your app as Device Owner, use below API :\nFor blocking Application uninstallation:\nhttps://developer.android.com/reference/android/app/admin/DevicePolicyManager#setUninstallBlocked(android.content.ComponentName,%20java.lang.String,%20boolean)\nTo prevent Factory Reset :\nhttps://developer.android.com/reference/android/os/UserManager#DISALLOW_FACTORY_RESET\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This is explained partly in the Concepts section of the Android NDK documentation.\nIn brief: every Android user application needs to run the Android event loop in some capacity to receive events, participate in the application lifecycle, and display stuff on the screen.\nWhat people call \"native\" c++ applications are actually running a \"hollow\" Java Android application/activity on top of ART (the Android \"Java\" runtime). The native part is expected to do everything that you get for free from normal Java-based activities: pump events and update the screen regularly.\nNow, to answer your final question: for some aspects they can use the Android kernel directly. However, this is a very limited set of operations and more interesting operations either require some of the native APIs (which use an RPC mechanism called Binder to talk to system services) or use JNI to talk to a Java implementation (that in turn probably still uses Binder).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This is explained partly in the Concepts section of the Android NDK documentation.\nIn brief: every Android user application needs to run the Android event loop in some capacity to receive events, participate in the application lifecycle, and display stuff on the screen.\nWhat people call \"native\" c++ applications are actually running a \"hollow\" Java Android application/activity on top of ART (the Android \"Java\" runtime). The native part is expected to do everything that you get for free from normal Java-based activities: pump events and update the screen regularly.\nNow, to answer your final question: for some aspects they can use the Android kernel directly. However, this is a very limited set of operations and more interesting operations either require some of the native APIs (which use an RPC mechanism called Binder to talk to system services) or use JNI to talk to a Java implementation (that in turn probably still uses Binder).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First of all, your app will be accpeted by the Goolge Play Store because your target sdk is heigher than Api 31. And then about the minSDKVersion, the official document's explain:\n\nAn integer designating the minimum API Level required for the application to run. The Android system will prevent the user from installing the application if the system's API Level is lower than the value specified in this attribute. You should always declare this attribute.\n\nGoogle doesn't have a request for this attribute. And the android official document said:\n\nIf you do not declare this attribute, the system assumes a default value of \"1\", which indicates that your application is compatible with all versions of Android.\n\nSo if your application is compatible with the lower versions, such as it can run well on the Android 10 or lower, you can set it as 29.\nFor more information, you can check the official document about the uses-sdk attributes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Some time ago I switched my AOSP environment from Android 10 to 11. Google made quite a few changes to the Overlay mechanism. To my big surprise these changes fixed the problems I had when trying to \"overlay\" custom attributes.\nWith the Android 10 environment I observed while debugging that the Android XML parser returns \"null\" when trying to read the mentioned attributes. With idmap I was able to confirm that the attributes were present in the overlay and the target app, and that they were properly mapped.\nAlso all the linker errors were gone.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Accessing REST API is given in the Android developers guide. Try the example given here: https://developers.google.com/android/guides/http-auth\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Shared Preferences Vs Flutter Secure Storage\nBasically, Why you should use flutter_secure_storage because it provides another secure layer rather than the shared preferences. In shared preferences, the data is stored as the key-value pairs as it is.\nRather than that flutter_Secure_Storage provides another secure layer above storing the data by encrypting the key values. It uses the IOS Keychain which is the mechanism to store small bits of user data in an encrypted database in the IOS operating system. Also, for the Android OS, the Android Keystore mechanism. So if you wish to store some serious data in your mobile application, definitely you should choose flutter_secure_storage. Here you can see how to work with flutter_secure_storage and Shared_Preferences.\nShared Preferences ---> Shared_Preferences_Implementation\nFlutter Secure Storage ---> Flutter_Secure_Storage_Implementation\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Shared Preferences Vs Flutter Secure Storage\nBasically, Why you should use flutter_secure_storage because it provides another secure layer rather than the shared preferences. In shared preferences, the data is stored as the key-value pairs as it is.\nRather than that flutter_Secure_Storage provides another secure layer above storing the data by encrypting the key values. It uses the IOS Keychain which is the mechanism to store small bits of user data in an encrypted database in the IOS operating system. Also, for the Android OS, the Android Keystore mechanism. So if you wish to store some serious data in your mobile application, definitely you should choose flutter_secure_storage. Here you can see how to work with flutter_secure_storage and Shared_Preferences.\nShared Preferences ---> Shared_Preferences_Implementation\nFlutter Secure Storage ---> Flutter_Secure_Storage_Implementation\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "performance": {
                "finetuned_dpr": [
                    {
                        "id": 63289873,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66623045,
                        "answer_post": "In your attires.xml you should define a theme reference attribute\n\nThen you should define attributes in your style\n\nAfter then, you have to direct this style to a reference in your theme.\n\nIn your custom view's class, you need to define these attributes\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74900089,
                        "answer_post": "According to https://developer.android.com/develop/ui/views/layout/custom-views/create-view#addprop you can't programmatically set attributes, but instead you should define fields/getters/setters for your attributes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62919282,
                        "answer_post": "If you are able to add them from the xml file, you can add these attributes in your views (needed ones):\n\n\nTry to invalidate the cached and restart Android Studio, also make sure sure that you click on the views for the attributes to show in the design section.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77534449,
                        "answer_post": "They're used to define attributes.  They specify the file to look for the attribute definitions in.  http://schemas.android.com/apk/res/android is the Android SDK's built in definitions.  \"http://schemas.android.com/apk/res-auto\" is the list of attribute defined by your application (including libraries you depend on). You can define any others you want, but typically an app only uses these two.\nThe namespace is used to qualify what attribute you're using.  Let's say you have namespace A and B.  Both define an attribute \"foo\".  If you were to specify foo without a namespace, it would be impossible to know what foo to use.  Using namespaces avoids that problem.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77701916,
                        "answer_post": "You can't add a custom attribute to the android namespace.  That namespace is pre-defined and consists of only the built in Android attributes.  Adding a custom attribute adds it to the application namespace, by convention that's the app:XXX attributes (although that's a convention, you can call it anything you want).  Please note that custom attributes must be defined in attrs.xml, you can't just make one up in the layout xml.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62007162,
                        "answer_post": "Android studio does not work that way. You cannot set the positions of views(items) by dragging them and placing them. You will have to set the constraints on the attribute tab. You can find the attribute tab at the top left corner. It is visible in the picture you uploaded. Click on that and the attributes window will open. \nThen, when you click on a view, there is a square that appears in the attribute window. That square has 4 + signs around it. You have to click on one of the left or right + signs and enter a number. That would determine the horizontal position (distance from left or right margin) of the view. \nSimilarly, set the vertical position by clicking on to our bottom +.\nThis is the method used to set the position of views graphically. There is a way to set them in the xml code. I guess you are not familiar with it. You will get to know how to do it inxml as you go on with Android development.\nYou can also set the position of a view with reference to other views instead of the margins. Please watch this video to know more about constraints.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71583809,
                        "answer_post": "In the StickerView file:\n\nRemove the StickerView(Context context) constructor\nPut the initialization code also in the StickerView(Context context, AttributeSet attributeSet) constructor (creating a dedicated method is a good approach) and\nChange this(context, attributeSet, 0) to super(context, attributeSet)\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68519916,
                        "answer_post": "You can go through this document for more details.\nhttps://developer.android.com/work/managed-profiles\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67949230,
                        "answer_post": "I answer myself, platform attributes works, but they start with \"android:...\".\nSo, using \"android:background\" it works.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 63138341,
                        "answer_post": "To use auto attributes, add the tools namespace to the root element of each XML file where you'd like to use them, as shown here:\n<app xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\">  \n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67556222,
                        "answer_post": "Attribute android:editable=\"false\" is deprecated. You can instead use android:enabled=\"false\" in the XML. If you want to programmatically do it, use:\n\nFor making other views dynamically appear as per values entered to your textview, you can use something like:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77242197,
                        "answer_post": "Starting from Android 12 (API level 31), you are required to specify an explicit value for the android:exported attribute in your AndroidManifest.xml file for all components (activities, services, broadcast receivers, and content providers) that can be accessed by other apps.\nYou should explicitly specify whether a component can be accessed by other apps or not by setting the android:exported attribute to either true or false. Here's how you can do it for different components:\n\nSet android:exported to true if you want other apps to be able to start this activity otherwise false.\n\nYou need to add this attribute to all of your activities, services, broadcast receivers, and content providers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66413944,
                        "answer_post": "The problem is here:\n\n\n\nThe attribute android.R.attr.contextPopupMenuStyle was not added until API level 24, so you must target at least 24 for the Material Components library to access that attribute.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63289873,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71978976,
                        "answer_post": "Like most Android SDK classes, ExifInterface has documentation. In particular, that documentation contains a list of public constructors.\nThe first such constructor takes a File as its sole constructor parameter.\nYou appear to be looking to get this information from a File, identified by a variable named path.\nSo, use new ExifInterface(path).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71250037,
                        "answer_post": "You can add the appAuthRedirectScheme attributes to the manifestPlaceholders instead of replacing the whole array, by using += instead of =\nExample :\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63788718,
                        "answer_post": "Your AppModule can create the implementation with a specific Scope (@Singleton in this case) and you can have 2 provides methods which return this implementation instance.\nNOTE: Untested\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67549349,
                        "answer_post": "Can you try\n\nThe entire name of the attribute needs to match, so either include app: in code or remove app: in xml\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66194262,
                        "answer_post": "The android:name attribute used to add a default Fragment in the container.\nIt\n\nCreates a new instance of the Fragment\nCalls Fragment.onInflate(Context, AttributeSet, Bundle)\nExecutes a FragmentTransaction to add the Fragment to the appropriate FragmentManager\n\nFor more insight on this head to: Official Doc\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 76048454,
                        "answer_post": "android.R.attr.fingerprintAuthDrawable\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67242315,
                        "answer_post": "Define RegisterActivity to your Manifest\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67239641,
                        "answer_post": "This is how you can display height and width of the screen\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71500018,
                        "answer_post": "in AndroidManifest.xml\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64107142,
                        "answer_post": "in activity\n\nin XML\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62237887,
                        "answer_post": "Use ItemTouchHelper class\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76200241,
                        "answer_post": "\nReference- How do i display 2 interfaces on the same app based on different credentials?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65356178,
                        "answer_post": "Try\n\nMainActivity\n\n\n\nViewModel\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70766989,
                        "answer_post": "use package device_info\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73043885,
                        "answer_post": "The attribute is modifier.\nUse\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "After doing thorough analysis what I confirmed is there is no way to set the SHIFT state of GBOARD unless google provides the API in future android release.\nI was able to achieve this in LatinIME keyboard, Android's default keyboard, through changes in the keyboard (LatinIME) application itself.\nThanks\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Use of Device Admin have been deprecated and Android provides very limited functionality starting from Android 10.\nApplication management permissions are part of Device Owner and Profile Owner deployment models in Android. You need to set your app as Device Owner, use below API :\nFor blocking Application uninstallation:\nhttps://developer.android.com/reference/android/app/admin/DevicePolicyManager#setUninstallBlocked(android.content.ComponentName,%20java.lang.String,%20boolean)\nTo prevent Factory Reset :\nhttps://developer.android.com/reference/android/os/UserManager#DISALLOW_FACTORY_RESET\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First of all, your app will be accpeted by the Goolge Play Store because your target sdk is heigher than Api 31. And then about the minSDKVersion, the official document's explain:\n\nAn integer designating the minimum API Level required for the application to run. The Android system will prevent the user from installing the application if the system's API Level is lower than the value specified in this attribute. You should always declare this attribute.\n\nGoogle doesn't have a request for this attribute. And the android official document said:\n\nIf you do not declare this attribute, the system assumes a default value of \"1\", which indicates that your application is compatible with all versions of Android.\n\nSo if your application is compatible with the lower versions, such as it can run well on the Android 10 or lower, you can set it as 29.\nFor more information, you can check the official document about the uses-sdk attributes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Some time ago I switched my AOSP environment from Android 10 to 11. Google made quite a few changes to the Overlay mechanism. To my big surprise these changes fixed the problems I had when trying to \"overlay\" custom attributes.\nWith the Android 10 environment I observed while debugging that the Android XML parser returns \"null\" when trying to read the mentioned attributes. With idmap I was able to confirm that the attributes were present in the overlay and the target app, and that they were properly mapped.\nAlso all the linker errors were gone.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "JMeter script doesn't run on the \"device\" and isn't connected to Android OS by any means.\nGiven you were able to record your application network activity it seems that your application uses at least HTTP protocol to speak with the backend, see Performance Testing for Native Mobile Apps webcast for more comprehensive information if needed.\nJMeter replays the recorded requests absolutely independently. So given there are no changes in API contract - you should be able to re-use the same script.\nAlso be aware that with JMeter you can only load test the backend, Android application performance per se can be assessed using i.e. Android Profiler\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "if you use theme on application tag, It's automatically will apply for all activities.\nIf you have to apply different themes for different activities , you can set theme on activity tag.\nso there no different on performance.\nFinally android:theme on application is universal and android:theme on activity is specific or individual.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Accessing REST API is given in the Android developers guide. Try the example given here: https://developers.google.com/android/guides/http-auth\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Shared Preferences Vs Flutter Secure Storage\nBasically, Why you should use flutter_secure_storage because it provides another secure layer rather than the shared preferences. In shared preferences, the data is stored as the key-value pairs as it is.\nRather than that flutter_Secure_Storage provides another secure layer above storing the data by encrypting the key values. It uses the IOS Keychain which is the mechanism to store small bits of user data in an encrypted database in the IOS operating system. Also, for the Android OS, the Android Keystore mechanism. So if you wish to store some serious data in your mobile application, definitely you should choose flutter_secure_storage. Here you can see how to work with flutter_secure_storage and Shared_Preferences.\nShared Preferences ---> Shared_Preferences_Implementation\nFlutter Secure Storage ---> Flutter_Secure_Storage_Implementation\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Shared Preferences Vs Flutter Secure Storage\nBasically, Why you should use flutter_secure_storage because it provides another secure layer rather than the shared preferences. In shared preferences, the data is stored as the key-value pairs as it is.\nRather than that flutter_Secure_Storage provides another secure layer above storing the data by encrypting the key values. It uses the IOS Keychain which is the mechanism to store small bits of user data in an encrypted database in the IOS operating system. Also, for the Android OS, the Android Keystore mechanism. So if you wish to store some serious data in your mobile application, definitely you should choose flutter_secure_storage. Here you can see how to work with flutter_secure_storage and Shared_Preferences.\nShared Preferences ---> Shared_Preferences_Implementation\nFlutter Secure Storage ---> Flutter_Secure_Storage_Implementation\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "directive": {
                "finetuned_dpr": [
                    {
                        "id": 63289873,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66623045,
                        "answer_post": "In your attires.xml you should define a theme reference attribute\n\nThen you should define attributes in your style\n\nAfter then, you have to direct this style to a reference in your theme.\n\nIn your custom view's class, you need to define these attributes\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74900089,
                        "answer_post": "According to https://developer.android.com/develop/ui/views/layout/custom-views/create-view#addprop you can't programmatically set attributes, but instead you should define fields/getters/setters for your attributes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77701916,
                        "answer_post": "You can't add a custom attribute to the android namespace.  That namespace is pre-defined and consists of only the built in Android attributes.  Adding a custom attribute adds it to the application namespace, by convention that's the app:XXX attributes (although that's a convention, you can call it anything you want).  Please note that custom attributes must be defined in attrs.xml, you can't just make one up in the layout xml.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77534449,
                        "answer_post": "They're used to define attributes.  They specify the file to look for the attribute definitions in.  http://schemas.android.com/apk/res/android is the Android SDK's built in definitions.  \"http://schemas.android.com/apk/res-auto\" is the list of attribute defined by your application (including libraries you depend on). You can define any others you want, but typically an app only uses these two.\nThe namespace is used to qualify what attribute you're using.  Let's say you have namespace A and B.  Both define an attribute \"foo\".  If you were to specify foo without a namespace, it would be impossible to know what foo to use.  Using namespaces avoids that problem.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65432045,
                        "answer_post": "\nA theme is a collection of attributes that's applied to an entire app, activity, or view hierarchy\u2014not just an individual view. When you apply a theme, every view in the app or activity applies each of the theme's attributes that it supports. Themes can also apply styles to non-view elements, such as the status bar and window background.\n\nThis is a documentation quote which describes that themes are inheritable by default to all view or non-view elements in your app, unless you hard-coded your own theme.\nIf you notice that in manifest, your <activity> tag is a child of <application> tag, and yet the activity inherits the theme set in the <application> this way and cascade this inheritance all the way down.\nThis is an advantage as it keeps the coherence of your app elements and the user experience accordingly.\nYou can check the documentation for further info.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62919282,
                        "answer_post": "If you are able to add them from the xml file, you can add these attributes in your views (needed ones):\n\n\nTry to invalidate the cached and restart Android Studio, also make sure sure that you click on the views for the attributes to show in the design section.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71583809,
                        "answer_post": "In the StickerView file:\n\nRemove the StickerView(Context context) constructor\nPut the initialization code also in the StickerView(Context context, AttributeSet attributeSet) constructor (creating a dedicated method is a good approach) and\nChange this(context, attributeSet, 0) to super(context, attributeSet)\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62007162,
                        "answer_post": "Android studio does not work that way. You cannot set the positions of views(items) by dragging them and placing them. You will have to set the constraints on the attribute tab. You can find the attribute tab at the top left corner. It is visible in the picture you uploaded. Click on that and the attributes window will open. \nThen, when you click on a view, there is a square that appears in the attribute window. That square has 4 + signs around it. You have to click on one of the left or right + signs and enter a number. That would determine the horizontal position (distance from left or right margin) of the view. \nSimilarly, set the vertical position by clicking on to our bottom +.\nThis is the method used to set the position of views graphically. There is a way to set them in the xml code. I guess you are not familiar with it. You will get to know how to do it inxml as you go on with Android development.\nYou can also set the position of a view with reference to other views instead of the margins. Please watch this video to know more about constraints.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67218323,
                        "answer_post": "I think it's a good idea to check out the design of the Composables provided by the framework.\nFor example:\n\nSo in short, yes it is a good idea, and I'd use it for grouping attributes.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 63138341,
                        "answer_post": "To use auto attributes, add the tools namespace to the root element of each XML file where you'd like to use them, as shown here:\n<app xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\">  \n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67556222,
                        "answer_post": "Attribute android:editable=\"false\" is deprecated. You can instead use android:enabled=\"false\" in the XML. If you want to programmatically do it, use:\n\nFor making other views dynamically appear as per values entered to your textview, you can use something like:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71978976,
                        "answer_post": "Like most Android SDK classes, ExifInterface has documentation. In particular, that documentation contains a list of public constructors.\nThe first such constructor takes a File as its sole constructor parameter.\nYou appear to be looking to get this information from a File, identified by a variable named path.\nSo, use new ExifInterface(path).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77242197,
                        "answer_post": "Starting from Android 12 (API level 31), you are required to specify an explicit value for the android:exported attribute in your AndroidManifest.xml file for all components (activities, services, broadcast receivers, and content providers) that can be accessed by other apps.\nYou should explicitly specify whether a component can be accessed by other apps or not by setting the android:exported attribute to either true or false. Here's how you can do it for different components:\n\nSet android:exported to true if you want other apps to be able to start this activity otherwise false.\n\nYou need to add this attribute to all of your activities, services, broadcast receivers, and content providers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63289873,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66413944,
                        "answer_post": "The problem is here:\n\n\n\nThe attribute android.R.attr.contextPopupMenuStyle was not added until API level 24, so you must target at least 24 for the Material Components library to access that attribute.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71250037,
                        "answer_post": "You can add the appAuthRedirectScheme attributes to the manifestPlaceholders instead of replacing the whole array, by using += instead of =\nExample :\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66194262,
                        "answer_post": "The android:name attribute used to add a default Fragment in the container.\nIt\n\nCreates a new instance of the Fragment\nCalls Fragment.onInflate(Context, AttributeSet, Bundle)\nExecutes a FragmentTransaction to add the Fragment to the appropriate FragmentManager\n\nFor more insight on this head to: Official Doc\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77701916,
                        "answer_post": "You can't add a custom attribute to the android namespace.  That namespace is pre-defined and consists of only the built in Android attributes.  Adding a custom attribute adds it to the application namespace, by convention that's the app:XXX attributes (although that's a convention, you can call it anything you want).  Please note that custom attributes must be defined in attrs.xml, you can't just make one up in the layout xml.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63788718,
                        "answer_post": "Your AppModule can create the implementation with a specific Scope (@Singleton in this case) and you can have 2 provides methods which return this implementation instance.\nNOTE: Untested\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 76048454,
                        "answer_post": "android.R.attr.fingerprintAuthDrawable\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71500018,
                        "answer_post": "in AndroidManifest.xml\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62237887,
                        "answer_post": "Use ItemTouchHelper class\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62549435,
                        "answer_post": "In your xml use\n\nOr in code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70766989,
                        "answer_post": "use package device_info\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76200241,
                        "answer_post": "\nReference- How do i display 2 interfaces on the same app based on different credentials?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73043885,
                        "answer_post": "The attribute is modifier.\nUse\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67242315,
                        "answer_post": "Define RegisterActivity to your Manifest\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64107142,
                        "answer_post": "in activity\n\nin XML\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65356178,
                        "answer_post": "Try\n\nMainActivity\n\n\n\nViewModel\n\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "After doing thorough analysis what I confirmed is there is no way to set the SHIFT state of GBOARD unless google provides the API in future android release.\nI was able to achieve this in LatinIME keyboard, Android's default keyboard, through changes in the keyboard (LatinIME) application itself.\nThanks\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Use of Device Admin have been deprecated and Android provides very limited functionality starting from Android 10.\nApplication management permissions are part of Device Owner and Profile Owner deployment models in Android. You need to set your app as Device Owner, use below API :\nFor blocking Application uninstallation:\nhttps://developer.android.com/reference/android/app/admin/DevicePolicyManager#setUninstallBlocked(android.content.ComponentName,%20java.lang.String,%20boolean)\nTo prevent Factory Reset :\nhttps://developer.android.com/reference/android/os/UserManager#DISALLOW_FACTORY_RESET\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes, you can achieve this in Android by using a combination of android:gravity and android:padding attributes. You can set the android:gravity attribute to center for the hint in the EditText to center it, and then set the android:gravity attribute to left for the input text to make it left-aligned. Additionally, you may need to adjust the android:padding attribute to ensure proper spacing.\nHere's an example:\n\nThis might help you if want to do this with edit text in xml.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First of all, your app will be accpeted by the Goolge Play Store because your target sdk is heigher than Api 31. And then about the minSDKVersion, the official document's explain:\n\nAn integer designating the minimum API Level required for the application to run. The Android system will prevent the user from installing the application if the system's API Level is lower than the value specified in this attribute. You should always declare this attribute.\n\nGoogle doesn't have a request for this attribute. And the android official document said:\n\nIf you do not declare this attribute, the system assumes a default value of \"1\", which indicates that your application is compatible with all versions of Android.\n\nSo if your application is compatible with the lower versions, such as it can run well on the Android 10 or lower, you can set it as 29.\nFor more information, you can check the official document about the uses-sdk attributes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Some time ago I switched my AOSP environment from Android 10 to 11. Google made quite a few changes to the Overlay mechanism. To my big surprise these changes fixed the problems I had when trying to \"overlay\" custom attributes.\nWith the Android 10 environment I observed while debugging that the Android XML parser returns \"null\" when trying to read the mentioned attributes. With idmap I was able to confirm that the attributes were present in the overlay and the target app, and that they were properly mapped.\nAlso all the linker errors were gone.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Ensure that the manifest entries representing the entry points of your application contain an explicit value for the android:exported attribute. It requires from API level 31+.\n\nFor more: https://developer.android.com/topic/security/risks/android-exported\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot set whether a device is 12-hour or 24-hour format, nor can you set that in your TextView. Hence, you'll have to use both format12Hour and format24Hour attributes to ensure that in both cases, the format will be hh:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Accessing REST API is given in the Android developers guide. Try the example given here: https://developers.google.com/android/guides/http-auth\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Shared Preferences Vs Flutter Secure Storage\nBasically, Why you should use flutter_secure_storage because it provides another secure layer rather than the shared preferences. In shared preferences, the data is stored as the key-value pairs as it is.\nRather than that flutter_Secure_Storage provides another secure layer above storing the data by encrypting the key values. It uses the IOS Keychain which is the mechanism to store small bits of user data in an encrypted database in the IOS operating system. Also, for the Android OS, the Android Keystore mechanism. So if you wish to store some serious data in your mobile application, definitely you should choose flutter_secure_storage. Here you can see how to work with flutter_secure_storage and Shared_Preferences.\nShared Preferences ---> Shared_Preferences_Implementation\nFlutter Secure Storage ---> Flutter_Secure_Storage_Implementation\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "pattern": {
                "finetuned_dpr": [
                    {
                        "id": 63289873,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66623045,
                        "answer_post": "In your attires.xml you should define a theme reference attribute\n\nThen you should define attributes in your style\n\nAfter then, you have to direct this style to a reference in your theme.\n\nIn your custom view's class, you need to define these attributes\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77701916,
                        "answer_post": "You can't add a custom attribute to the android namespace.  That namespace is pre-defined and consists of only the built in Android attributes.  Adding a custom attribute adds it to the application namespace, by convention that's the app:XXX attributes (although that's a convention, you can call it anything you want).  Please note that custom attributes must be defined in attrs.xml, you can't just make one up in the layout xml.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74900089,
                        "answer_post": "According to https://developer.android.com/develop/ui/views/layout/custom-views/create-view#addprop you can't programmatically set attributes, but instead you should define fields/getters/setters for your attributes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77534449,
                        "answer_post": "They're used to define attributes.  They specify the file to look for the attribute definitions in.  http://schemas.android.com/apk/res/android is the Android SDK's built in definitions.  \"http://schemas.android.com/apk/res-auto\" is the list of attribute defined by your application (including libraries you depend on). You can define any others you want, but typically an app only uses these two.\nThe namespace is used to qualify what attribute you're using.  Let's say you have namespace A and B.  Both define an attribute \"foo\".  If you were to specify foo without a namespace, it would be impossible to know what foo to use.  Using namespaces avoids that problem.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62919282,
                        "answer_post": "If you are able to add them from the xml file, you can add these attributes in your views (needed ones):\n\n\nTry to invalidate the cached and restart Android Studio, also make sure sure that you click on the views for the attributes to show in the design section.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65432045,
                        "answer_post": "\nA theme is a collection of attributes that's applied to an entire app, activity, or view hierarchy\u2014not just an individual view. When you apply a theme, every view in the app or activity applies each of the theme's attributes that it supports. Themes can also apply styles to non-view elements, such as the status bar and window background.\n\nThis is a documentation quote which describes that themes are inheritable by default to all view or non-view elements in your app, unless you hard-coded your own theme.\nIf you notice that in manifest, your <activity> tag is a child of <application> tag, and yet the activity inherits the theme set in the <application> this way and cascade this inheritance all the way down.\nThis is an advantage as it keeps the coherence of your app elements and the user experience accordingly.\nYou can check the documentation for further info.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62007162,
                        "answer_post": "Android studio does not work that way. You cannot set the positions of views(items) by dragging them and placing them. You will have to set the constraints on the attribute tab. You can find the attribute tab at the top left corner. It is visible in the picture you uploaded. Click on that and the attributes window will open. \nThen, when you click on a view, there is a square that appears in the attribute window. That square has 4 + signs around it. You have to click on one of the left or right + signs and enter a number. That would determine the horizontal position (distance from left or right margin) of the view. \nSimilarly, set the vertical position by clicking on to our bottom +.\nThis is the method used to set the position of views graphically. There is a way to set them in the xml code. I guess you are not familiar with it. You will get to know how to do it inxml as you go on with Android development.\nYou can also set the position of a view with reference to other views instead of the margins. Please watch this video to know more about constraints.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71583809,
                        "answer_post": "In the StickerView file:\n\nRemove the StickerView(Context context) constructor\nPut the initialization code also in the StickerView(Context context, AttributeSet attributeSet) constructor (creating a dedicated method is a good approach) and\nChange this(context, attributeSet, 0) to super(context, attributeSet)\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66973829,
                        "answer_post": "That way should work. You use a Popup Window, so that's how to define the attributes:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 63138341,
                        "answer_post": "To use auto attributes, add the tools namespace to the root element of each XML file where you'd like to use them, as shown here:\n<app xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\">  \n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63289873,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77242197,
                        "answer_post": "Starting from Android 12 (API level 31), you are required to specify an explicit value for the android:exported attribute in your AndroidManifest.xml file for all components (activities, services, broadcast receivers, and content providers) that can be accessed by other apps.\nYou should explicitly specify whether a component can be accessed by other apps or not by setting the android:exported attribute to either true or false. Here's how you can do it for different components:\n\nSet android:exported to true if you want other apps to be able to start this activity otherwise false.\n\nYou need to add this attribute to all of your activities, services, broadcast receivers, and content providers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71978976,
                        "answer_post": "Like most Android SDK classes, ExifInterface has documentation. In particular, that documentation contains a list of public constructors.\nThe first such constructor takes a File as its sole constructor parameter.\nYou appear to be looking to get this information from a File, identified by a variable named path.\nSo, use new ExifInterface(path).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67556222,
                        "answer_post": "Attribute android:editable=\"false\" is deprecated. You can instead use android:enabled=\"false\" in the XML. If you want to programmatically do it, use:\n\nFor making other views dynamically appear as per values entered to your textview, you can use something like:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71250037,
                        "answer_post": "You can add the appAuthRedirectScheme attributes to the manifestPlaceholders instead of replacing the whole array, by using += instead of =\nExample :\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66194262,
                        "answer_post": "The android:name attribute used to add a default Fragment in the container.\nIt\n\nCreates a new instance of the Fragment\nCalls Fragment.onInflate(Context, AttributeSet, Bundle)\nExecutes a FragmentTransaction to add the Fragment to the appropriate FragmentManager\n\nFor more insight on this head to: Official Doc\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66413944,
                        "answer_post": "The problem is here:\n\n\n\nThe attribute android.R.attr.contextPopupMenuStyle was not added until API level 24, so you must target at least 24 for the Material Components library to access that attribute.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77701916,
                        "answer_post": "You can't add a custom attribute to the android namespace.  That namespace is pre-defined and consists of only the built in Android attributes.  Adding a custom attribute adds it to the application namespace, by convention that's the app:XXX attributes (although that's a convention, you can call it anything you want).  Please note that custom attributes must be defined in attrs.xml, you can't just make one up in the layout xml.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63788718,
                        "answer_post": "Your AppModule can create the implementation with a specific Scope (@Singleton in this case) and you can have 2 provides methods which return this implementation instance.\nNOTE: Untested\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 76048454,
                        "answer_post": "android.R.attr.fingerprintAuthDrawable\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62549435,
                        "answer_post": "In your xml use\n\nOr in code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73043885,
                        "answer_post": "The attribute is modifier.\nUse\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62237887,
                        "answer_post": "Use ItemTouchHelper class\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70766989,
                        "answer_post": "use package device_info\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64107142,
                        "answer_post": "in activity\n\nin XML\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71500018,
                        "answer_post": "in AndroidManifest.xml\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65356178,
                        "answer_post": "Try\n\nMainActivity\n\n\n\nViewModel\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67239641,
                        "answer_post": "This is how you can display height and width of the screen\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62774739,
                        "answer_post": "use this in yout application class\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "After doing thorough analysis what I confirmed is there is no way to set the SHIFT state of GBOARD unless google provides the API in future android release.\nI was able to achieve this in LatinIME keyboard, Android's default keyboard, through changes in the keyboard (LatinIME) application itself.\nThanks\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Use of Device Admin have been deprecated and Android provides very limited functionality starting from Android 10.\nApplication management permissions are part of Device Owner and Profile Owner deployment models in Android. You need to set your app as Device Owner, use below API :\nFor blocking Application uninstallation:\nhttps://developer.android.com/reference/android/app/admin/DevicePolicyManager#setUninstallBlocked(android.content.ComponentName,%20java.lang.String,%20boolean)\nTo prevent Factory Reset :\nhttps://developer.android.com/reference/android/os/UserManager#DISALLOW_FACTORY_RESET\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First of all, your app will be accpeted by the Goolge Play Store because your target sdk is heigher than Api 31. And then about the minSDKVersion, the official document's explain:\n\nAn integer designating the minimum API Level required for the application to run. The Android system will prevent the user from installing the application if the system's API Level is lower than the value specified in this attribute. You should always declare this attribute.\n\nGoogle doesn't have a request for this attribute. And the android official document said:\n\nIf you do not declare this attribute, the system assumes a default value of \"1\", which indicates that your application is compatible with all versions of Android.\n\nSo if your application is compatible with the lower versions, such as it can run well on the Android 10 or lower, you can set it as 29.\nFor more information, you can check the official document about the uses-sdk attributes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Some time ago I switched my AOSP environment from Android 10 to 11. Google made quite a few changes to the Overlay mechanism. To my big surprise these changes fixed the problems I had when trying to \"overlay\" custom attributes.\nWith the Android 10 environment I observed while debugging that the Android XML parser returns \"null\" when trying to read the mentioned attributes. With idmap I was able to confirm that the attributes were present in the overlay and the target app, and that they were properly mapped.\nAlso all the linker errors were gone.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Accessing REST API is given in the Android developers guide. Try the example given here: https://developers.google.com/android/guides/http-auth\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Shared Preferences Vs Flutter Secure Storage\nBasically, Why you should use flutter_secure_storage because it provides another secure layer rather than the shared preferences. In shared preferences, the data is stored as the key-value pairs as it is.\nRather than that flutter_Secure_Storage provides another secure layer above storing the data by encrypting the key values. It uses the IOS Keychain which is the mechanism to store small bits of user data in an encrypted database in the IOS operating system. Also, for the Android OS, the Android Keystore mechanism. So if you wish to store some serious data in your mobile application, definitely you should choose flutter_secure_storage. Here you can see how to work with flutter_secure_storage and Shared_Preferences.\nShared Preferences ---> Shared_Preferences_Implementation\nFlutter Secure Storage ---> Flutter_Secure_Storage_Implementation\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Shared Preferences Vs Flutter Secure Storage\nBasically, Why you should use flutter_secure_storage because it provides another secure layer rather than the shared preferences. In shared preferences, the data is stored as the key-value pairs as it is.\nRather than that flutter_Secure_Storage provides another secure layer above storing the data by encrypting the key values. It uses the IOS Keychain which is the mechanism to store small bits of user data in an encrypted database in the IOS operating system. Also, for the Android OS, the Android Keystore mechanism. So if you wish to store some serious data in your mobile application, definitely you should choose flutter_secure_storage. Here you can see how to work with flutter_secure_storage and Shared_Preferences.\nShared Preferences ---> Shared_Preferences_Implementation\nFlutter Secure Storage ---> Flutter_Secure_Storage_Implementation\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The issue on Android 10, because you set in In the AndroidManifest : android:maxSdkVersion=\"29\".\nAndroid 10 is API level 29.\nadd in AndroidMainfest\nin application node\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can't add a custom attribute to the android namespace.  That namespace is pre-defined and consists of only the built in Android attributes.  Adding a custom attribute adds it to the application namespace, by convention that's the app:XXX attributes (although that's a convention, you can call it anything you want).  Please note that custom attributes must be defined in attrs.xml, you can't just make one up in the layout xml.\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "environment": {
                "finetuned_dpr": [
                    {
                        "id": 63289873,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66623045,
                        "answer_post": "In your attires.xml you should define a theme reference attribute\n\nThen you should define attributes in your style\n\nAfter then, you have to direct this style to a reference in your theme.\n\nIn your custom view's class, you need to define these attributes\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74900089,
                        "answer_post": "According to https://developer.android.com/develop/ui/views/layout/custom-views/create-view#addprop you can't programmatically set attributes, but instead you should define fields/getters/setters for your attributes.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77701916,
                        "answer_post": "You can't add a custom attribute to the android namespace.  That namespace is pre-defined and consists of only the built in Android attributes.  Adding a custom attribute adds it to the application namespace, by convention that's the app:XXX attributes (although that's a convention, you can call it anything you want).  Please note that custom attributes must be defined in attrs.xml, you can't just make one up in the layout xml.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77534449,
                        "answer_post": "They're used to define attributes.  They specify the file to look for the attribute definitions in.  http://schemas.android.com/apk/res/android is the Android SDK's built in definitions.  \"http://schemas.android.com/apk/res-auto\" is the list of attribute defined by your application (including libraries you depend on). You can define any others you want, but typically an app only uses these two.\nThe namespace is used to qualify what attribute you're using.  Let's say you have namespace A and B.  Both define an attribute \"foo\".  If you were to specify foo without a namespace, it would be impossible to know what foo to use.  Using namespaces avoids that problem.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65432045,
                        "answer_post": "\nA theme is a collection of attributes that's applied to an entire app, activity, or view hierarchy\u2014not just an individual view. When you apply a theme, every view in the app or activity applies each of the theme's attributes that it supports. Themes can also apply styles to non-view elements, such as the status bar and window background.\n\nThis is a documentation quote which describes that themes are inheritable by default to all view or non-view elements in your app, unless you hard-coded your own theme.\nIf you notice that in manifest, your <activity> tag is a child of <application> tag, and yet the activity inherits the theme set in the <application> this way and cascade this inheritance all the way down.\nThis is an advantage as it keeps the coherence of your app elements and the user experience accordingly.\nYou can check the documentation for further info.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62919282,
                        "answer_post": "If you are able to add them from the xml file, you can add these attributes in your views (needed ones):\n\n\nTry to invalidate the cached and restart Android Studio, also make sure sure that you click on the views for the attributes to show in the design section.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62007162,
                        "answer_post": "Android studio does not work that way. You cannot set the positions of views(items) by dragging them and placing them. You will have to set the constraints on the attribute tab. You can find the attribute tab at the top left corner. It is visible in the picture you uploaded. Click on that and the attributes window will open. \nThen, when you click on a view, there is a square that appears in the attribute window. That square has 4 + signs around it. You have to click on one of the left or right + signs and enter a number. That would determine the horizontal position (distance from left or right margin) of the view. \nSimilarly, set the vertical position by clicking on to our bottom +.\nThis is the method used to set the position of views graphically. There is a way to set them in the xml code. I guess you are not familiar with it. You will get to know how to do it inxml as you go on with Android development.\nYou can also set the position of a view with reference to other views instead of the margins. Please watch this video to know more about constraints.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71583809,
                        "answer_post": "In the StickerView file:\n\nRemove the StickerView(Context context) constructor\nPut the initialization code also in the StickerView(Context context, AttributeSet attributeSet) constructor (creating a dedicated method is a good approach) and\nChange this(context, attributeSet, 0) to super(context, attributeSet)\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77208184,
                        "answer_post": "You can use Themes. Themes are used to style every view of the app at once.\nCreate a themes.xml file inside your /res/values folder, if it doesn't exist already.\nInside it define your theme and define the styling properties you want to apply to all views.\n\nApply this theme to your complete app by defining in AndroidManifest.xml file inside application tag.\n\nSample Output:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 63138341,
                        "answer_post": "To use auto attributes, add the tools namespace to the root element of each XML file where you'd like to use them, as shown here:\n<app xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\">  \n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63289873,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77242197,
                        "answer_post": "Starting from Android 12 (API level 31), you are required to specify an explicit value for the android:exported attribute in your AndroidManifest.xml file for all components (activities, services, broadcast receivers, and content providers) that can be accessed by other apps.\nYou should explicitly specify whether a component can be accessed by other apps or not by setting the android:exported attribute to either true or false. Here's how you can do it for different components:\n\nSet android:exported to true if you want other apps to be able to start this activity otherwise false.\n\nYou need to add this attribute to all of your activities, services, broadcast receivers, and content providers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71978976,
                        "answer_post": "Like most Android SDK classes, ExifInterface has documentation. In particular, that documentation contains a list of public constructors.\nThe first such constructor takes a File as its sole constructor parameter.\nYou appear to be looking to get this information from a File, identified by a variable named path.\nSo, use new ExifInterface(path).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66413944,
                        "answer_post": "The problem is here:\n\n\n\nThe attribute android.R.attr.contextPopupMenuStyle was not added until API level 24, so you must target at least 24 for the Material Components library to access that attribute.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67556222,
                        "answer_post": "Attribute android:editable=\"false\" is deprecated. You can instead use android:enabled=\"false\" in the XML. If you want to programmatically do it, use:\n\nFor making other views dynamically appear as per values entered to your textview, you can use something like:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71250037,
                        "answer_post": "You can add the appAuthRedirectScheme attributes to the manifestPlaceholders instead of replacing the whole array, by using += instead of =\nExample :\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66194262,
                        "answer_post": "The android:name attribute used to add a default Fragment in the container.\nIt\n\nCreates a new instance of the Fragment\nCalls Fragment.onInflate(Context, AttributeSet, Bundle)\nExecutes a FragmentTransaction to add the Fragment to the appropriate FragmentManager\n\nFor more insight on this head to: Official Doc\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77701916,
                        "answer_post": "You can't add a custom attribute to the android namespace.  That namespace is pre-defined and consists of only the built in Android attributes.  Adding a custom attribute adds it to the application namespace, by convention that's the app:XXX attributes (although that's a convention, you can call it anything you want).  Please note that custom attributes must be defined in attrs.xml, you can't just make one up in the layout xml.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63176164,
                        "answer_post": "Application manifest can refer to both the build.gradle declaration or a definition in an android manifest (https://developer.android.com/studio/publish/versioning#appversioning):\n\nNote: If your app defines the app version directly in the  element, the version values in the Gradle build file will override the settings in the manifest. Additionally, defining these settings in the Gradle build files allows you to specify different values for different versions of your app. For greater flexibility and to avoid potential overwriting when the manifest is merged, you should remove these attributes from the  element and define your version settings in the Gradle build files instead.\n\nIt looks like ARCore can't find the metadata in your APK. It's possible that the minSdkVersion is placed in the wrong place; it's hard to tell without the entire build file.\nYou can use Android Studio's APK Analyzer to find out which metadata is present in your generated AndroidManifest.xml.\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 76048454,
                        "answer_post": "android.R.attr.fingerprintAuthDrawable\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64107142,
                        "answer_post": "in activity\n\nin XML\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71500018,
                        "answer_post": "in AndroidManifest.xml\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67242315,
                        "answer_post": "Define RegisterActivity to your Manifest\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62549435,
                        "answer_post": "In your xml use\n\nOr in code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65356178,
                        "answer_post": "Try\n\nMainActivity\n\n\n\nViewModel\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76252771,
                        "answer_post": "xml code\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61713440,
                        "answer_post": "Add app:layout_behavior here\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77768833,
                        "answer_post": "XML File\n\nAPI Function\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77545041,
                        "answer_post": "need permissions\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "Some time ago I switched my AOSP environment from Android 10 to 11. Google made quite a few changes to the Overlay mechanism. To my big surprise these changes fixed the problems I had when trying to \"overlay\" custom attributes.\nWith the Android 10 environment I observed while debugging that the Android XML parser returns \"null\" when trying to read the mentioned attributes. With idmap I was able to confirm that the attributes were present in the overlay and the target app, and that they were properly mapped.\nAlso all the linker errors were gone.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "After doing thorough analysis what I confirmed is there is no way to set the SHIFT state of GBOARD unless google provides the API in future android release.\nI was able to achieve this in LatinIME keyboard, Android's default keyboard, through changes in the keyboard (LatinIME) application itself.\nThanks\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Use of Device Admin have been deprecated and Android provides very limited functionality starting from Android 10.\nApplication management permissions are part of Device Owner and Profile Owner deployment models in Android. You need to set your app as Device Owner, use below API :\nFor blocking Application uninstallation:\nhttps://developer.android.com/reference/android/app/admin/DevicePolicyManager#setUninstallBlocked(android.content.ComponentName,%20java.lang.String,%20boolean)\nTo prevent Factory Reset :\nhttps://developer.android.com/reference/android/os/UserManager#DISALLOW_FACTORY_RESET\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First of all, your app will be accpeted by the Goolge Play Store because your target sdk is heigher than Api 31. And then about the minSDKVersion, the official document's explain:\n\nAn integer designating the minimum API Level required for the application to run. The Android system will prevent the user from installing the application if the system's API Level is lower than the value specified in this attribute. You should always declare this attribute.\n\nGoogle doesn't have a request for this attribute. And the android official document said:\n\nIf you do not declare this attribute, the system assumes a default value of \"1\", which indicates that your application is compatible with all versions of Android.\n\nSo if your application is compatible with the lower versions, such as it can run well on the Android 10 or lower, you can set it as 29.\nFor more information, you can check the official document about the uses-sdk attributes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "This is due to the nature of android studio. If you do not want to set the RAM requirements android studio can live with the recommended requirements. Also android studio is working with different versions of HAXM as per user. The dialog is in place to ensure backwards compatibility.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Accessing REST API is given in the Android developers guide. Try the example given here: https://developers.google.com/android/guides/http-auth\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The Windows API is what you should use if you write a C++ application for Windows. That will be the best supported option. If you happen to find some library that also does BLE it will probably just be a wrapper around the Windows API.\nUnfortunately these APIs use the WinRT architecture which is not the easiest to set up but should work fine once you've managed to set up the environment.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Shared Preferences Vs Flutter Secure Storage\nBasically, Why you should use flutter_secure_storage because it provides another secure layer rather than the shared preferences. In shared preferences, the data is stored as the key-value pairs as it is.\nRather than that flutter_Secure_Storage provides another secure layer above storing the data by encrypting the key values. It uses the IOS Keychain which is the mechanism to store small bits of user data in an encrypted database in the IOS operating system. Also, for the Android OS, the Android Keystore mechanism. So if you wish to store some serious data in your mobile application, definitely you should choose flutter_secure_storage. Here you can see how to work with flutter_secure_storage and Shared_Preferences.\nShared Preferences ---> Shared_Preferences_Implementation\nFlutter Secure Storage ---> Flutter_Secure_Storage_Implementation\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Shared Preferences Vs Flutter Secure Storage\nBasically, Why you should use flutter_secure_storage because it provides another secure layer rather than the shared preferences. In shared preferences, the data is stored as the key-value pairs as it is.\nRather than that flutter_Secure_Storage provides another secure layer above storing the data by encrypting the key values. It uses the IOS Keychain which is the mechanism to store small bits of user data in an encrypted database in the IOS operating system. Also, for the Android OS, the Android Keystore mechanism. So if you wish to store some serious data in your mobile application, definitely you should choose flutter_secure_storage. Here you can see how to work with flutter_secure_storage and Shared_Preferences.\nShared Preferences ---> Shared_Preferences_Implementation\nFlutter Secure Storage ---> Flutter_Secure_Storage_Implementation\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "alternative": {
                "finetuned_dpr": [
                    {
                        "id": 63289873,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66623045,
                        "answer_post": "In your attires.xml you should define a theme reference attribute\n\nThen you should define attributes in your style\n\nAfter then, you have to direct this style to a reference in your theme.\n\nIn your custom view's class, you need to define these attributes\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74900089,
                        "answer_post": "According to https://developer.android.com/develop/ui/views/layout/custom-views/create-view#addprop you can't programmatically set attributes, but instead you should define fields/getters/setters for your attributes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77701916,
                        "answer_post": "You can't add a custom attribute to the android namespace.  That namespace is pre-defined and consists of only the built in Android attributes.  Adding a custom attribute adds it to the application namespace, by convention that's the app:XXX attributes (although that's a convention, you can call it anything you want).  Please note that custom attributes must be defined in attrs.xml, you can't just make one up in the layout xml.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77534449,
                        "answer_post": "They're used to define attributes.  They specify the file to look for the attribute definitions in.  http://schemas.android.com/apk/res/android is the Android SDK's built in definitions.  \"http://schemas.android.com/apk/res-auto\" is the list of attribute defined by your application (including libraries you depend on). You can define any others you want, but typically an app only uses these two.\nThe namespace is used to qualify what attribute you're using.  Let's say you have namespace A and B.  Both define an attribute \"foo\".  If you were to specify foo without a namespace, it would be impossible to know what foo to use.  Using namespaces avoids that problem.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62919282,
                        "answer_post": "If you are able to add them from the xml file, you can add these attributes in your views (needed ones):\n\n\nTry to invalidate the cached and restart Android Studio, also make sure sure that you click on the views for the attributes to show in the design section.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71583809,
                        "answer_post": "In the StickerView file:\n\nRemove the StickerView(Context context) constructor\nPut the initialization code also in the StickerView(Context context, AttributeSet attributeSet) constructor (creating a dedicated method is a good approach) and\nChange this(context, attributeSet, 0) to super(context, attributeSet)\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65432045,
                        "answer_post": "\nA theme is a collection of attributes that's applied to an entire app, activity, or view hierarchy\u2014not just an individual view. When you apply a theme, every view in the app or activity applies each of the theme's attributes that it supports. Themes can also apply styles to non-view elements, such as the status bar and window background.\n\nThis is a documentation quote which describes that themes are inheritable by default to all view or non-view elements in your app, unless you hard-coded your own theme.\nIf you notice that in manifest, your <activity> tag is a child of <application> tag, and yet the activity inherits the theme set in the <application> this way and cascade this inheritance all the way down.\nThis is an advantage as it keeps the coherence of your app elements and the user experience accordingly.\nYou can check the documentation for further info.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62007162,
                        "answer_post": "Android studio does not work that way. You cannot set the positions of views(items) by dragging them and placing them. You will have to set the constraints on the attribute tab. You can find the attribute tab at the top left corner. It is visible in the picture you uploaded. Click on that and the attributes window will open. \nThen, when you click on a view, there is a square that appears in the attribute window. That square has 4 + signs around it. You have to click on one of the left or right + signs and enter a number. That would determine the horizontal position (distance from left or right margin) of the view. \nSimilarly, set the vertical position by clicking on to our bottom +.\nThis is the method used to set the position of views graphically. There is a way to set them in the xml code. I guess you are not familiar with it. You will get to know how to do it inxml as you go on with Android development.\nYou can also set the position of a view with reference to other views instead of the margins. Please watch this video to know more about constraints.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62098444,
                        "answer_post": "I don't think there is something wrong but something that might help is just using one namespace for all your custom attributes.\nIn your parent container you are using the app namespace\n\nSo, you need to use that namespace in the cardview attributes. Just replace card_view with app and remove the namespace in your CardView.\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 63138341,
                        "answer_post": "To use auto attributes, add the tools namespace to the root element of each XML file where you'd like to use them, as shown here:\n<app xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\">  \n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67556222,
                        "answer_post": "Attribute android:editable=\"false\" is deprecated. You can instead use android:enabled=\"false\" in the XML. If you want to programmatically do it, use:\n\nFor making other views dynamically appear as per values entered to your textview, you can use something like:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71978976,
                        "answer_post": "Like most Android SDK classes, ExifInterface has documentation. In particular, that documentation contains a list of public constructors.\nThe first such constructor takes a File as its sole constructor parameter.\nYou appear to be looking to get this information from a File, identified by a variable named path.\nSo, use new ExifInterface(path).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71250037,
                        "answer_post": "You can add the appAuthRedirectScheme attributes to the manifestPlaceholders instead of replacing the whole array, by using += instead of =\nExample :\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66194262,
                        "answer_post": "The android:name attribute used to add a default Fragment in the container.\nIt\n\nCreates a new instance of the Fragment\nCalls Fragment.onInflate(Context, AttributeSet, Bundle)\nExecutes a FragmentTransaction to add the Fragment to the appropriate FragmentManager\n\nFor more insight on this head to: Official Doc\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63289873,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66413944,
                        "answer_post": "The problem is here:\n\n\n\nThe attribute android.R.attr.contextPopupMenuStyle was not added until API level 24, so you must target at least 24 for the Material Components library to access that attribute.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77242197,
                        "answer_post": "Starting from Android 12 (API level 31), you are required to specify an explicit value for the android:exported attribute in your AndroidManifest.xml file for all components (activities, services, broadcast receivers, and content providers) that can be accessed by other apps.\nYou should explicitly specify whether a component can be accessed by other apps or not by setting the android:exported attribute to either true or false. Here's how you can do it for different components:\n\nSet android:exported to true if you want other apps to be able to start this activity otherwise false.\n\nYou need to add this attribute to all of your activities, services, broadcast receivers, and content providers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71583809,
                        "answer_post": "In the StickerView file:\n\nRemove the StickerView(Context context) constructor\nPut the initialization code also in the StickerView(Context context, AttributeSet attributeSet) constructor (creating a dedicated method is a good approach) and\nChange this(context, attributeSet, 0) to super(context, attributeSet)\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63788718,
                        "answer_post": "Your AppModule can create the implementation with a specific Scope (@Singleton in this case) and you can have 2 provides methods which return this implementation instance.\nNOTE: Untested\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 76048454,
                        "answer_post": "android.R.attr.fingerprintAuthDrawable\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76200241,
                        "answer_post": "\nReference- How do i display 2 interfaces on the same app based on different credentials?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65356178,
                        "answer_post": "Try\n\nMainActivity\n\n\n\nViewModel\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64107142,
                        "answer_post": "in activity\n\nin XML\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71500018,
                        "answer_post": "in AndroidManifest.xml\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67242315,
                        "answer_post": "Define RegisterActivity to your Manifest\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72187445,
                        "answer_post": "Add this attribute\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70766989,
                        "answer_post": "use package device_info\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64249323,
                        "answer_post": "\nXML:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77405681,
                        "answer_post": "XML:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "After doing thorough analysis what I confirmed is there is no way to set the SHIFT state of GBOARD unless google provides the API in future android release.\nI was able to achieve this in LatinIME keyboard, Android's default keyboard, through changes in the keyboard (LatinIME) application itself.\nThanks\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Use of Device Admin have been deprecated and Android provides very limited functionality starting from Android 10.\nApplication management permissions are part of Device Owner and Profile Owner deployment models in Android. You need to set your app as Device Owner, use below API :\nFor blocking Application uninstallation:\nhttps://developer.android.com/reference/android/app/admin/DevicePolicyManager#setUninstallBlocked(android.content.ComponentName,%20java.lang.String,%20boolean)\nTo prevent Factory Reset :\nhttps://developer.android.com/reference/android/os/UserManager#DISALLOW_FACTORY_RESET\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First of all, your app will be accpeted by the Goolge Play Store because your target sdk is heigher than Api 31. And then about the minSDKVersion, the official document's explain:\n\nAn integer designating the minimum API Level required for the application to run. The Android system will prevent the user from installing the application if the system's API Level is lower than the value specified in this attribute. You should always declare this attribute.\n\nGoogle doesn't have a request for this attribute. And the android official document said:\n\nIf you do not declare this attribute, the system assumes a default value of \"1\", which indicates that your application is compatible with all versions of Android.\n\nSo if your application is compatible with the lower versions, such as it can run well on the Android 10 or lower, you can set it as 29.\nFor more information, you can check the official document about the uses-sdk attributes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "android namespace is used in order to access and use the attributes which are provided by the Android platform.\napp namespace is used to access the custom attributes which are defined in the application scope.\nThe app namespace is not specific to a library, but it is used for all attributes defined in your app, whether by your code or by libraries you import, effectively making a single global namespace for custom attributes - i.e., attributes not defined by the android system.\nBased on this\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Some time ago I switched my AOSP environment from Android 10 to 11. Google made quite a few changes to the Overlay mechanism. To my big surprise these changes fixed the problems I had when trying to \"overlay\" custom attributes.\nWith the Android 10 environment I observed while debugging that the Android XML parser returns \"null\" when trying to read the mentioned attributes. With idmap I was able to confirm that the attributes were present in the overlay and the target app, and that they were properly mapped.\nAlso all the linker errors were gone.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Accessing the child fragment's view in parent fragment is not a good idea. If you want to trigger any action from the fragment. You can follow these steps:\n\nAlternatives\n\nIf you know about EventBus, then you can use EventBus.\nThe android's default way is to use BroadcastReceiver.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Accessing REST API is given in the Android developers guide. Try the example given here: https://developers.google.com/android/guides/http-auth\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Shared Preferences Vs Flutter Secure Storage\nBasically, Why you should use flutter_secure_storage because it provides another secure layer rather than the shared preferences. In shared preferences, the data is stored as the key-value pairs as it is.\nRather than that flutter_Secure_Storage provides another secure layer above storing the data by encrypting the key values. It uses the IOS Keychain which is the mechanism to store small bits of user data in an encrypted database in the IOS operating system. Also, for the Android OS, the Android Keystore mechanism. So if you wish to store some serious data in your mobile application, definitely you should choose flutter_secure_storage. Here you can see how to work with flutter_secure_storage and Shared_Preferences.\nShared Preferences ---> Shared_Preferences_Implementation\nFlutter Secure Storage ---> Flutter_Secure_Storage_Implementation\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Shared Preferences Vs Flutter Secure Storage\nBasically, Why you should use flutter_secure_storage because it provides another secure layer rather than the shared preferences. In shared preferences, the data is stored as the key-value pairs as it is.\nRather than that flutter_Secure_Storage provides another secure layer above storing the data by encrypting the key values. It uses the IOS Keychain which is the mechanism to store small bits of user data in an encrypted database in the IOS operating system. Also, for the Android OS, the Android Keystore mechanism. So if you wish to store some serious data in your mobile application, definitely you should choose flutter_secure_storage. Here you can see how to work with flutter_secure_storage and Shared_Preferences.\nShared Preferences ---> Shared_Preferences_Implementation\nFlutter Secure Storage ---> Flutter_Secure_Storage_Implementation\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The issue on Android 10, because you set in In the AndroidManifest : android:maxSdkVersion=\"29\".\nAndroid 10 is API level 29.\nadd in AndroidMainfest\nin application node\n\n",
                        "contain_knowledge": 0
                    }
                ]
            }
        }
    },
    {
        "name": "GradientTape",
        "language": "tf",
        "popularity": "high",
        "label_result": {
            "functionality": {
                "finetuned_dpr": 0.8,
                "dpr": 0.8,
                "e5": 0.4,
                "bm25": 0.9
            },
            "concept": {
                "finetuned_dpr": 0.9,
                "dpr": 0.8,
                "e5": 0.5,
                "bm25": 1.0
            },
            "performance": {
                "finetuned_dpr": 0.9,
                "dpr": 0.8,
                "e5": 0.2,
                "bm25": 0.9
            },
            "directive": {
                "finetuned_dpr": 0.9,
                "dpr": 0.9,
                "e5": 0.5,
                "bm25": 0.9
            },
            "pattern": {
                "finetuned_dpr": 1.0,
                "dpr": 1.0,
                "e5": 0.5,
                "bm25": 0.9
            },
            "environment": {
                "finetuned_dpr": 0.9,
                "dpr": 0.6,
                "e5": 0.4,
                "bm25": 0.9
            },
            "alternative": {
                "finetuned_dpr": 0.9,
                "dpr": 0.7,
                "e5": 0.4,
                "bm25": 0.8
            },
            "total": {
                "finetuned_dpr": 0.9000000000000001,
                "dpr": 0.8,
                "e5": 0.41428571428571426,
                "bm25": 0.9
            }
        },
        "retrieve_result": {
            "functionality": {
                "finetuned_dpr": [
                    {
                        "id": 69000523,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64012068,
                        "answer_post": "Supposing you are working with Tensorflow 2.x, If you are trying to create a custom training step, to track the model gradients, you have to invoke the model under the tf.GradientTape context manager.\nHere you have your code updated to correctly work with the GradientTape:\n\nAlso note that instead of using model.predict I am using the call method which is the one you should be using when training\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70597883,
                        "answer_post": "You have 2 problems in your code which prevents you from getting the result you want.\n\nIf you want to compute higher-order derivatives you have to create nested GradientTape objects\nGradientTape automatically track variables in its context, if you want to track tensors (as in your case, you want to track z and t) you have to call tape.watch(<my_tensor>) otherwise you will not have gradients for it.\n\nFixed code:\n\nMore on gradient tape can be found in the official documentation: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 57336013,
                        "answer_post": "Look at @tf.custom_gradient for writing your own gradient calculation function. \nhttps://www.tensorflow.org/api_docs/python/tf/custom_gradient\nIf you're using eager execution, you can monitor the gradients using Gradient Tape.\nhttps://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61748035,
                        "answer_post": "loss.backward() equivalent in tensorflow is tf.GradientTape(). TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\noptimizer.step() equivalent in tensorflow is minimize(). Minimizes the loss by updating the variable list. Calling minimize() takes care of both computing the gradients and applying them to the variables.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76753084,
                        "answer_post": "After trying different things out and reading more about automatic differentation and especially about GradientTape I came across the batch_jacobian function which does exactly what I was looking for.\nMight be useful for other people that are also not that familiar with GradientTape.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 70983654,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 60544413,
                        "answer_post": "Yes you can use GradientTape. The purpose of tf.GradientTape is to record operations for automatic differentiation or for\u00a0computing the gradient of an operation or computation with respect to its input variables.\nAccording to What's New in TensorFlow 2.0, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. This ensures that all of the computations will be recorded on the gradient tape.\nThen, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient\u00a0clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.\u00a0Take a look at the following example:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71240068,
                        "answer_post": "According to https://www.tensorflow.org/api_docs/python/tf/GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon\nas GradientTape.gradient() method is called. To compute multiple\ngradients over the same computation, create a persistent gradient\ntape. This allows multiple calls to the gradient() method as resources\nare released when the tape object is garbage collected.\n\nAfter train step, as long as no other object has a reference to that tape, the garbage collector will collect it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62197631,
                        "answer_post": "As you have correctly mentioned, you have to handle Loss when its 0 else there is nothing for optimizer to minimize. Thus weights of the model also won't update. So ideal way in this case is to keep track of training loss at step level using custom training.\nYou will have more control with custom training. If you want lower-level over your training and evaluation loops than what fit() and evaluate() provide, you should write your own training loop. It's actually pretty simple. But you should be ready to have a lot more debugging to do on your own.\nCalling a model inside a GradientTape scope enables you to retrieve the gradients of the trainable weights of the layer with respect to a loss value. Using an optimizer instance, you can use these gradients to update these variables (which you can retrieve using model.trainable_weights).\nTensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of a computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHere is a simple example for mnist data. The comments are present in the code to explain better.\nCode-\n\nOutput -\n\nYou can find more about tf.GradientTape here. The example used here is taken from here.\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 70983654,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 58227549,
                        "answer_post": "In tensorflow 2.0, you need use the tf.GradientTape context to calculate the gradients, and then apply gradients on your model's variables. \n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61297910,
                        "answer_post": "You need to call g.watch for each of these variables:\nRefer: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61748035,
                        "answer_post": "loss.backward() equivalent in tensorflow is tf.GradientTape(). TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\noptimizer.step() equivalent in tensorflow is minimize(). Minimizes the loss by updating the variable list. Calling minimize() takes care of both computing the gradients and applying them to the variables.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55799378,
                        "answer_post": "There is no built-in mechanism in TensorFlow 2.0 to override all gradients for a built-in operator within a scope. However, if you are able to modify the call-site for each call to the built-in operator, you can use the tf.custom_gradient decorator as follows:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69000523,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71240068,
                        "answer_post": "According to https://www.tensorflow.org/api_docs/python/tf/GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon\nas GradientTape.gradient() method is called. To compute multiple\ngradients over the same computation, create a persistent gradient\ntape. This allows multiple calls to the gradient() method as resources\nare released when the tape object is garbage collected.\n\nAfter train step, as long as no other object has a reference to that tape, the garbage collector will collect it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61262458,
                        "answer_post": "As far as I understood from my previous experience, Tensorflow needs to use GradientTape in order to record the activity of a certain variable and so to compute its gradients. In your case should be something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65125515,
                        "answer_post": "In TensorFlow 2, you can use GradientTape with batch_jacobian. From the official website:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56073840,
                        "answer_post": "From the documentation of GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon as GradientTape.gradient() method is called. To compute multiple gradients over the same computation, create a persistent gradient tape. This allows multiple calls to the gradient() method as resources are released when the tape object is garbage collected.\n\nA persistent gradient can be created with with tf.GradientTape(persistent=True) as tape and can/should be manually deleted with del tape (credits for this @zwep, @Crispy13).\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 72733574,
                        "answer_post": "Don\u2019t worry, using tf.GradientTape is the most case way to get an auto differential with theoretical value. You can always use tf.GradientTape for your training codes. Just like:\n\nand outputs:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66221955,
                        "answer_post": "you might want to take a look at tf.GradientTape in tensorflow. Gradient tape is very simple way to auto-differentiate your computation. And the link has some basic example.\nHowever your model is already quite big. If you have n parameters, your jacobian will have n*n values. I believe your model probably already has more than 10000 parameters. You might need to make it smaller.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62854550,
                        "answer_post": "Yes, you are right. Layers has two variables. The one you mentioned is called kernel. And the other one is called bias. The example below explains it in details:\n\nThe output will be something like:\n\ntf.GradientTape() is used to record the operations on the trainable weights (variables) in its context for automatic differentiation. So later we can get the derivative of the variables.\nSuppose you have two weight variables as weight1 and weight2. First you need to change you loss function to use both variables (see the code below). Then in each step you need to get the derivative of loss function wrt. the variables and update them to optimize the loss. Please see the code below.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55279458,
                        "answer_post": "The tf.GradientTape is recording every operation that happens inside its scope.\nYou don't want to record in the tape the gradient calculation, you only want to compute the loss forward.\n\nMore importantly, I don't see the loop on the training set, therefore I suppose the complete code looks like:\n\nMoreover, the usage of the metrics is wrong.\nYou want to accumulate, thus update the internal state of the accuracy operation, at every training step and measure the overall accuracy at the end of every epoch.\nThus you have to:\n\nAnd call accuracy.result() only at the end of the epoch, when all the accuracy value have been saved into the metric.\nRemember to call to the .reset_states() method to clears the variable states, resetting it to zero at the end of every epoch.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71420697,
                        "answer_post": "You could start off with a custom training loop using tf.GradientTape:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 57281952,
                        "answer_post": "Using tensorflow API\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76808704,
                        "answer_post": "Use tf.pad function\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66946641,
                        "answer_post": "\nAs described in the figure above, tf.GradientTape.gradient simply calculates the gradient dy/dx. In your case with multiple variables, tf seems to calculate the derivative of the corresponding tensor instead of automatically summing them.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73957756,
                        "answer_post": "\n@tf.function uses the graph execution,\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60860555,
                        "answer_post": "You can load and perform the inference of your TRT Model using this snippet of code.\nThis is executed in Tensorflow 2.1.0 and Google Colab Environment.\n\noutput_saved_model_dir is the location of your TensorRT Optimized model in SavedModel format.\nFrom here, you can add your testing methods to determine the performance of your pre and post-processed model. \nEDIT:\n\nHere are the codes used for Converting and Saving the Tensorflow RT Optimized model.\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "After trying different things out and reading more about automatic differentation and especially about GradientTape I came across the batch_jacobian function which does exactly what I was looking for.\nMight be useful for other people that are also not that familiar with GradientTape.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "For a gradient to get on the tape, there has to be operations in the forward function (i.e. in the with GradientTape context). There are no operations with x and y (or no operations at all), so no gradient is recorded and the tape returns None.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You need to run (i.e. forward pass) the computation graph or model within the context of GradientTape so that all the operations in the model could be recorded:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You are using numpy operations in several places inside the scope of GradientTape, for example in the line\n\nReplace all numpy functions inside GradientTape's scope with their tensorflow equivalents. For example, the above line becomes:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Optimization process needs to iterate over and over for better result.\nWrap computation inside a GradientTape for automatic differentiation.\n\nCompute gradients.\n\nUpdate W and b following gradients.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Supposing you are working with Tensorflow 2.x, If you are trying to create a custom training step, to track the model gradients, you have to invoke the model under the tf.GradientTape context manager.\nHere you have your code updated to correctly work with the GradientTape:\n\nAlso note that instead of using model.predict I am using the call method which is the one you should be using when training\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Have you tried putting code from predictions = model.predict(img) onwards into the GradientTape context manager?\nThe thing is, if you did not record the gradients going from last_conv_layer.output to model.output, the backprop chain is effectively broken. \n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes you can use GradientTape. The purpose of tf.GradientTape is to record operations for automatic differentiation or for\u00a0computing the gradient of an operation or computation with respect to its input variables.\nAccording to What's New in TensorFlow 2.0, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. This ensures that all of the computations will be recorded on the gradient tape.\nThen, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient\u00a0clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.\u00a0Take a look at the following example:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "concept": {
                "finetuned_dpr": [
                    {
                        "id": 69000523,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64012068,
                        "answer_post": "Supposing you are working with Tensorflow 2.x, If you are trying to create a custom training step, to track the model gradients, you have to invoke the model under the tf.GradientTape context manager.\nHere you have your code updated to correctly work with the GradientTape:\n\nAlso note that instead of using model.predict I am using the call method which is the one you should be using when training\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70597883,
                        "answer_post": "You have 2 problems in your code which prevents you from getting the result you want.\n\nIf you want to compute higher-order derivatives you have to create nested GradientTape objects\nGradientTape automatically track variables in its context, if you want to track tensors (as in your case, you want to track z and t) you have to call tape.watch(<my_tensor>) otherwise you will not have gradients for it.\n\nFixed code:\n\nMore on gradient tape can be found in the official documentation: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76753084,
                        "answer_post": "After trying different things out and reading more about automatic differentation and especially about GradientTape I came across the batch_jacobian function which does exactly what I was looking for.\nMight be useful for other people that are also not that familiar with GradientTape.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57336013,
                        "answer_post": "Look at @tf.custom_gradient for writing your own gradient calculation function. \nhttps://www.tensorflow.org/api_docs/python/tf/custom_gradient\nIf you're using eager execution, you can monitor the gradients using Gradient Tape.\nhttps://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61748035,
                        "answer_post": "loss.backward() equivalent in tensorflow is tf.GradientTape(). TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\noptimizer.step() equivalent in tensorflow is minimize(). Minimizes the loss by updating the variable list. Calling minimize() takes care of both computing the gradients and applying them to the variables.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 60544413,
                        "answer_post": "Yes you can use GradientTape. The purpose of tf.GradientTape is to record operations for automatic differentiation or for\u00a0computing the gradient of an operation or computation with respect to its input variables.\nAccording to What's New in TensorFlow 2.0, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. This ensures that all of the computations will be recorded on the gradient tape.\nThen, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient\u00a0clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.\u00a0Take a look at the following example:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70983654,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71240068,
                        "answer_post": "According to https://www.tensorflow.org/api_docs/python/tf/GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon\nas GradientTape.gradient() method is called. To compute multiple\ngradients over the same computation, create a persistent gradient\ntape. This allows multiple calls to the gradient() method as resources\nare released when the tape object is garbage collected.\n\nAfter train step, as long as no other object has a reference to that tape, the garbage collector will collect it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61262458,
                        "answer_post": "As far as I understood from my previous experience, Tensorflow needs to use GradientTape in order to record the activity of a certain variable and so to compute its gradients. In your case should be something like that:\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 70983654,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 58227549,
                        "answer_post": "In tensorflow 2.0, you need use the tf.GradientTape context to calculate the gradients, and then apply gradients on your model's variables. \n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61297910,
                        "answer_post": "You need to call g.watch for each of these variables:\nRefer: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61748035,
                        "answer_post": "loss.backward() equivalent in tensorflow is tf.GradientTape(). TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\noptimizer.step() equivalent in tensorflow is minimize(). Minimizes the loss by updating the variable list. Calling minimize() takes care of both computing the gradients and applying them to the variables.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 69000523,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61262458,
                        "answer_post": "As far as I understood from my previous experience, Tensorflow needs to use GradientTape in order to record the activity of a certain variable and so to compute its gradients. In your case should be something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55799378,
                        "answer_post": "There is no built-in mechanism in TensorFlow 2.0 to override all gradients for a built-in operator within a scope. However, if you are able to modify the call-site for each call to the built-in operator, you can use the tf.custom_gradient decorator as follows:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71240068,
                        "answer_post": "According to https://www.tensorflow.org/api_docs/python/tf/GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon\nas GradientTape.gradient() method is called. To compute multiple\ngradients over the same computation, create a persistent gradient\ntape. This allows multiple calls to the gradient() method as resources\nare released when the tape object is garbage collected.\n\nAfter train step, as long as no other object has a reference to that tape, the garbage collector will collect it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65125515,
                        "answer_post": "In TensorFlow 2, you can use GradientTape with batch_jacobian. From the official website:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56073840,
                        "answer_post": "From the documentation of GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon as GradientTape.gradient() method is called. To compute multiple gradients over the same computation, create a persistent gradient tape. This allows multiple calls to the gradient() method as resources are released when the tape object is garbage collected.\n\nA persistent gradient can be created with with tf.GradientTape(persistent=True) as tape and can/should be manually deleted with del tape (credits for this @zwep, @Crispy13).\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 72733574,
                        "answer_post": "Don\u2019t worry, using tf.GradientTape is the most case way to get an auto differential with theoretical value. You can always use tf.GradientTape for your training codes. Just like:\n\nand outputs:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66221955,
                        "answer_post": "you might want to take a look at tf.GradientTape in tensorflow. Gradient tape is very simple way to auto-differentiate your computation. And the link has some basic example.\nHowever your model is already quite big. If you have n parameters, your jacobian will have n*n values. I believe your model probably already has more than 10000 parameters. You might need to make it smaller.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62854550,
                        "answer_post": "Yes, you are right. Layers has two variables. The one you mentioned is called kernel. And the other one is called bias. The example below explains it in details:\n\nThe output will be something like:\n\ntf.GradientTape() is used to record the operations on the trainable weights (variables) in its context for automatic differentiation. So later we can get the derivative of the variables.\nSuppose you have two weight variables as weight1 and weight2. First you need to change you loss function to use both variables (see the code below). Then in each step you need to get the derivative of loss function wrt. the variables and update them to optimize the loss. Please see the code below.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55279458,
                        "answer_post": "The tf.GradientTape is recording every operation that happens inside its scope.\nYou don't want to record in the tape the gradient calculation, you only want to compute the loss forward.\n\nMore importantly, I don't see the loop on the training set, therefore I suppose the complete code looks like:\n\nMoreover, the usage of the metrics is wrong.\nYou want to accumulate, thus update the internal state of the accuracy operation, at every training step and measure the overall accuracy at the end of every epoch.\nThus you have to:\n\nAnd call accuracy.result() only at the end of the epoch, when all the accuracy value have been saved into the metric.\nRemember to call to the .reset_states() method to clears the variable states, resetting it to zero at the end of every epoch.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66946641,
                        "answer_post": "\nAs described in the figure above, tf.GradientTape.gradient simply calculates the gradient dy/dx. In your case with multiple variables, tf seems to calculate the derivative of the corresponding tensor instead of automatically summing them.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71420697,
                        "answer_post": "You could start off with a custom training loop using tf.GradientTape:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57281952,
                        "answer_post": "Using tensorflow API\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60860555,
                        "answer_post": "You can load and perform the inference of your TRT Model using this snippet of code.\nThis is executed in Tensorflow 2.1.0 and Google Colab Environment.\n\noutput_saved_model_dir is the location of your TensorRT Optimized model in SavedModel format.\nFrom here, you can add your testing methods to determine the performance of your pre and post-processed model. \nEDIT:\n\nHere are the codes used for Converting and Saving the Tensorflow RT Optimized model.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62117706,
                        "answer_post": "According to this keras document\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61262458,
                        "answer_post": "As far as I understood from my previous experience, Tensorflow needs to use GradientTape in order to record the activity of a certain variable and so to compute its gradients. In your case should be something like that:\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "After trying different things out and reading more about automatic differentation and especially about GradientTape I came across the batch_jacobian function which does exactly what I was looking for.\nMight be useful for other people that are also not that familiar with GradientTape.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "For a gradient to get on the tape, there has to be operations in the forward function (i.e. in the with GradientTape context). There are no operations with x and y (or no operations at all), so no gradient is recorded and the tape returns None.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You need to run (i.e. forward pass) the computation graph or model within the context of GradientTape so that all the operations in the model could be recorded:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You are using numpy operations in several places inside the scope of GradientTape, for example in the line\n\nReplace all numpy functions inside GradientTape's scope with their tensorflow equivalents. For example, the above line becomes:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Optimization process needs to iterate over and over for better result.\nWrap computation inside a GradientTape for automatic differentiation.\n\nCompute gradients.\n\nUpdate W and b following gradients.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Have you tried putting code from predictions = model.predict(img) onwards into the GradientTape context manager?\nThe thing is, if you did not record the gradients going from last_conv_layer.output to model.output, the backprop chain is effectively broken. \n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes you can use GradientTape. The purpose of tf.GradientTape is to record operations for automatic differentiation or for\u00a0computing the gradient of an operation or computation with respect to its input variables.\nAccording to What's New in TensorFlow 2.0, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. This ensures that all of the computations will be recorded on the gradient tape.\nThen, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient\u00a0clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.\u00a0Take a look at the following example:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Supposing you are working with Tensorflow 2.x, If you are trying to create a custom training step, to track the model gradients, you have to invoke the model under the tf.GradientTape context manager.\nHere you have your code updated to correctly work with the GradientTape:\n\nAlso note that instead of using model.predict I am using the call method which is the one you should be using when training\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "performance": {
                "finetuned_dpr": [
                    {
                        "id": 64012068,
                        "answer_post": "Supposing you are working with Tensorflow 2.x, If you are trying to create a custom training step, to track the model gradients, you have to invoke the model under the tf.GradientTape context manager.\nHere you have your code updated to correctly work with the GradientTape:\n\nAlso note that instead of using model.predict I am using the call method which is the one you should be using when training\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 69000523,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70597883,
                        "answer_post": "You have 2 problems in your code which prevents you from getting the result you want.\n\nIf you want to compute higher-order derivatives you have to create nested GradientTape objects\nGradientTape automatically track variables in its context, if you want to track tensors (as in your case, you want to track z and t) you have to call tape.watch(<my_tensor>) otherwise you will not have gradients for it.\n\nFixed code:\n\nMore on gradient tape can be found in the official documentation: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 57336013,
                        "answer_post": "Look at @tf.custom_gradient for writing your own gradient calculation function. \nhttps://www.tensorflow.org/api_docs/python/tf/custom_gradient\nIf you're using eager execution, you can monitor the gradients using Gradient Tape.\nhttps://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76753084,
                        "answer_post": "After trying different things out and reading more about automatic differentation and especially about GradientTape I came across the batch_jacobian function which does exactly what I was looking for.\nMight be useful for other people that are also not that familiar with GradientTape.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61748035,
                        "answer_post": "loss.backward() equivalent in tensorflow is tf.GradientTape(). TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\noptimizer.step() equivalent in tensorflow is minimize(). Minimizes the loss by updating the variable list. Calling minimize() takes care of both computing the gradients and applying them to the variables.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 60544413,
                        "answer_post": "Yes you can use GradientTape. The purpose of tf.GradientTape is to record operations for automatic differentiation or for\u00a0computing the gradient of an operation or computation with respect to its input variables.\nAccording to What's New in TensorFlow 2.0, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. This ensures that all of the computations will be recorded on the gradient tape.\nThen, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient\u00a0clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.\u00a0Take a look at the following example:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70983654,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71240068,
                        "answer_post": "According to https://www.tensorflow.org/api_docs/python/tf/GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon\nas GradientTape.gradient() method is called. To compute multiple\ngradients over the same computation, create a persistent gradient\ntape. This allows multiple calls to the gradient() method as resources\nare released when the tape object is garbage collected.\n\nAfter train step, as long as no other object has a reference to that tape, the garbage collector will collect it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62197631,
                        "answer_post": "As you have correctly mentioned, you have to handle Loss when its 0 else there is nothing for optimizer to minimize. Thus weights of the model also won't update. So ideal way in this case is to keep track of training loss at step level using custom training.\nYou will have more control with custom training. If you want lower-level over your training and evaluation loops than what fit() and evaluate() provide, you should write your own training loop. It's actually pretty simple. But you should be ready to have a lot more debugging to do on your own.\nCalling a model inside a GradientTape scope enables you to retrieve the gradients of the trainable weights of the layer with respect to a loss value. Using an optimizer instance, you can use these gradients to update these variables (which you can retrieve using model.trainable_weights).\nTensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of a computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHere is a simple example for mnist data. The comments are present in the code to explain better.\nCode-\n\nOutput -\n\nYou can find more about tf.GradientTape here. The example used here is taken from here.\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 70983654,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61297910,
                        "answer_post": "You need to call g.watch for each of these variables:\nRefer: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 58227549,
                        "answer_post": "In tensorflow 2.0, you need use the tf.GradientTape context to calculate the gradients, and then apply gradients on your model's variables. \n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61748035,
                        "answer_post": "loss.backward() equivalent in tensorflow is tf.GradientTape(). TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\noptimizer.step() equivalent in tensorflow is minimize(). Minimizes the loss by updating the variable list. Calling minimize() takes care of both computing the gradients and applying them to the variables.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71240068,
                        "answer_post": "According to https://www.tensorflow.org/api_docs/python/tf/GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon\nas GradientTape.gradient() method is called. To compute multiple\ngradients over the same computation, create a persistent gradient\ntape. This allows multiple calls to the gradient() method as resources\nare released when the tape object is garbage collected.\n\nAfter train step, as long as no other object has a reference to that tape, the garbage collector will collect it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55799378,
                        "answer_post": "There is no built-in mechanism in TensorFlow 2.0 to override all gradients for a built-in operator within a scope. However, if you are able to modify the call-site for each call to the built-in operator, you can use the tf.custom_gradient decorator as follows:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 69000523,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65125515,
                        "answer_post": "In TensorFlow 2, you can use GradientTape with batch_jacobian. From the official website:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61262458,
                        "answer_post": "As far as I understood from my previous experience, Tensorflow needs to use GradientTape in order to record the activity of a certain variable and so to compute its gradients. In your case should be something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 56073840,
                        "answer_post": "From the documentation of GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon as GradientTape.gradient() method is called. To compute multiple gradients over the same computation, create a persistent gradient tape. This allows multiple calls to the gradient() method as resources are released when the tape object is garbage collected.\n\nA persistent gradient can be created with with tf.GradientTape(persistent=True) as tape and can/should be manually deleted with del tape (credits for this @zwep, @Crispy13).\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 72733574,
                        "answer_post": "Don\u2019t worry, using tf.GradientTape is the most case way to get an auto differential with theoretical value. You can always use tf.GradientTape for your training codes. Just like:\n\nand outputs:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66221955,
                        "answer_post": "you might want to take a look at tf.GradientTape in tensorflow. Gradient tape is very simple way to auto-differentiate your computation. And the link has some basic example.\nHowever your model is already quite big. If you have n parameters, your jacobian will have n*n values. I believe your model probably already has more than 10000 parameters. You might need to make it smaller.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62854550,
                        "answer_post": "Yes, you are right. Layers has two variables. The one you mentioned is called kernel. And the other one is called bias. The example below explains it in details:\n\nThe output will be something like:\n\ntf.GradientTape() is used to record the operations on the trainable weights (variables) in its context for automatic differentiation. So later we can get the derivative of the variables.\nSuppose you have two weight variables as weight1 and weight2. First you need to change you loss function to use both variables (see the code below). Then in each step you need to get the derivative of loss function wrt. the variables and update them to optimize the loss. Please see the code below.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55279458,
                        "answer_post": "The tf.GradientTape is recording every operation that happens inside its scope.\nYou don't want to record in the tape the gradient calculation, you only want to compute the loss forward.\n\nMore importantly, I don't see the loop on the training set, therefore I suppose the complete code looks like:\n\nMoreover, the usage of the metrics is wrong.\nYou want to accumulate, thus update the internal state of the accuracy operation, at every training step and measure the overall accuracy at the end of every epoch.\nThus you have to:\n\nAnd call accuracy.result() only at the end of the epoch, when all the accuracy value have been saved into the metric.\nRemember to call to the .reset_states() method to clears the variable states, resetting it to zero at the end of every epoch.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 57281952,
                        "answer_post": "Using tensorflow API\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71420697,
                        "answer_post": "You could start off with a custom training loop using tf.GradientTape:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60860555,
                        "answer_post": "You can load and perform the inference of your TRT Model using this snippet of code.\nThis is executed in Tensorflow 2.1.0 and Google Colab Environment.\n\noutput_saved_model_dir is the location of your TensorRT Optimized model in SavedModel format.\nFrom here, you can add your testing methods to determine the performance of your pre and post-processed model. \nEDIT:\n\nHere are the codes used for Converting and Saving the Tensorflow RT Optimized model.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66946641,
                        "answer_post": "\nAs described in the figure above, tf.GradientTape.gradient simply calculates the gradient dy/dx. In your case with multiple variables, tf seems to calculate the derivative of the corresponding tensor instead of automatically summing them.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73957756,
                        "answer_post": "\n@tf.function uses the graph execution,\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62117706,
                        "answer_post": "According to this keras document\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "After trying different things out and reading more about automatic differentation and especially about GradientTape I came across the batch_jacobian function which does exactly what I was looking for.\nMight be useful for other people that are also not that familiar with GradientTape.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "For a gradient to get on the tape, there has to be operations in the forward function (i.e. in the with GradientTape context). There are no operations with x and y (or no operations at all), so no gradient is recorded and the tape returns None.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You need to run (i.e. forward pass) the computation graph or model within the context of GradientTape so that all the operations in the model could be recorded:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You are using numpy operations in several places inside the scope of GradientTape, for example in the line\n\nReplace all numpy functions inside GradientTape's scope with their tensorflow equivalents. For example, the above line becomes:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Optimization process needs to iterate over and over for better result.\nWrap computation inside a GradientTape for automatic differentiation.\n\nCompute gradients.\n\nUpdate W and b following gradients.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Have you tried putting code from predictions = model.predict(img) onwards into the GradientTape context manager?\nThe thing is, if you did not record the gradients going from last_conv_layer.output to model.output, the backprop chain is effectively broken. \n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes you can use GradientTape. The purpose of tf.GradientTape is to record operations for automatic differentiation or for\u00a0computing the gradient of an operation or computation with respect to its input variables.\nAccording to What's New in TensorFlow 2.0, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. This ensures that all of the computations will be recorded on the gradient tape.\nThen, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient\u00a0clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.\u00a0Take a look at the following example:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Supposing you are working with Tensorflow 2.x, If you are trying to create a custom training step, to track the model gradients, you have to invoke the model under the tf.GradientTape context manager.\nHere you have your code updated to correctly work with the GradientTape:\n\nAlso note that instead of using model.predict I am using the call method which is the one you should be using when training\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "directive": {
                "finetuned_dpr": [
                    {
                        "id": 69000523,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64012068,
                        "answer_post": "Supposing you are working with Tensorflow 2.x, If you are trying to create a custom training step, to track the model gradients, you have to invoke the model under the tf.GradientTape context manager.\nHere you have your code updated to correctly work with the GradientTape:\n\nAlso note that instead of using model.predict I am using the call method which is the one you should be using when training\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70597883,
                        "answer_post": "You have 2 problems in your code which prevents you from getting the result you want.\n\nIf you want to compute higher-order derivatives you have to create nested GradientTape objects\nGradientTape automatically track variables in its context, if you want to track tensors (as in your case, you want to track z and t) you have to call tape.watch(<my_tensor>) otherwise you will not have gradients for it.\n\nFixed code:\n\nMore on gradient tape can be found in the official documentation: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76753084,
                        "answer_post": "After trying different things out and reading more about automatic differentation and especially about GradientTape I came across the batch_jacobian function which does exactly what I was looking for.\nMight be useful for other people that are also not that familiar with GradientTape.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61748035,
                        "answer_post": "loss.backward() equivalent in tensorflow is tf.GradientTape(). TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\noptimizer.step() equivalent in tensorflow is minimize(). Minimizes the loss by updating the variable list. Calling minimize() takes care of both computing the gradients and applying them to the variables.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 57336013,
                        "answer_post": "Look at @tf.custom_gradient for writing your own gradient calculation function. \nhttps://www.tensorflow.org/api_docs/python/tf/custom_gradient\nIf you're using eager execution, you can monitor the gradients using Gradient Tape.\nhttps://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 60544413,
                        "answer_post": "Yes you can use GradientTape. The purpose of tf.GradientTape is to record operations for automatic differentiation or for\u00a0computing the gradient of an operation or computation with respect to its input variables.\nAccording to What's New in TensorFlow 2.0, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. This ensures that all of the computations will be recorded on the gradient tape.\nThen, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient\u00a0clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.\u00a0Take a look at the following example:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71240068,
                        "answer_post": "According to https://www.tensorflow.org/api_docs/python/tf/GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon\nas GradientTape.gradient() method is called. To compute multiple\ngradients over the same computation, create a persistent gradient\ntape. This allows multiple calls to the gradient() method as resources\nare released when the tape object is garbage collected.\n\nAfter train step, as long as no other object has a reference to that tape, the garbage collector will collect it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70983654,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62197631,
                        "answer_post": "As you have correctly mentioned, you have to handle Loss when its 0 else there is nothing for optimizer to minimize. Thus weights of the model also won't update. So ideal way in this case is to keep track of training loss at step level using custom training.\nYou will have more control with custom training. If you want lower-level over your training and evaluation loops than what fit() and evaluate() provide, you should write your own training loop. It's actually pretty simple. But you should be ready to have a lot more debugging to do on your own.\nCalling a model inside a GradientTape scope enables you to retrieve the gradients of the trainable weights of the layer with respect to a loss value. Using an optimizer instance, you can use these gradients to update these variables (which you can retrieve using model.trainable_weights).\nTensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of a computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHere is a simple example for mnist data. The comments are present in the code to explain better.\nCode-\n\nOutput -\n\nYou can find more about tf.GradientTape here. The example used here is taken from here.\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 70983654,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61297910,
                        "answer_post": "You need to call g.watch for each of these variables:\nRefer: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61748035,
                        "answer_post": "loss.backward() equivalent in tensorflow is tf.GradientTape(). TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\noptimizer.step() equivalent in tensorflow is minimize(). Minimizes the loss by updating the variable list. Calling minimize() takes care of both computing the gradients and applying them to the variables.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55799378,
                        "answer_post": "There is no built-in mechanism in TensorFlow 2.0 to override all gradients for a built-in operator within a scope. However, if you are able to modify the call-site for each call to the built-in operator, you can use the tf.custom_gradient decorator as follows:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 58227549,
                        "answer_post": "In tensorflow 2.0, you need use the tf.GradientTape context to calculate the gradients, and then apply gradients on your model's variables. \n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71240068,
                        "answer_post": "According to https://www.tensorflow.org/api_docs/python/tf/GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon\nas GradientTape.gradient() method is called. To compute multiple\ngradients over the same computation, create a persistent gradient\ntape. This allows multiple calls to the gradient() method as resources\nare released when the tape object is garbage collected.\n\nAfter train step, as long as no other object has a reference to that tape, the garbage collector will collect it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 69000523,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 56073840,
                        "answer_post": "From the documentation of GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon as GradientTape.gradient() method is called. To compute multiple gradients over the same computation, create a persistent gradient tape. This allows multiple calls to the gradient() method as resources are released when the tape object is garbage collected.\n\nA persistent gradient can be created with with tf.GradientTape(persistent=True) as tape and can/should be manually deleted with del tape (credits for this @zwep, @Crispy13).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61262458,
                        "answer_post": "As far as I understood from my previous experience, Tensorflow needs to use GradientTape in order to record the activity of a certain variable and so to compute its gradients. In your case should be something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65125515,
                        "answer_post": "In TensorFlow 2, you can use GradientTape with batch_jacobian. From the official website:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72733574,
                        "answer_post": "Don\u2019t worry, using tf.GradientTape is the most case way to get an auto differential with theoretical value. You can always use tf.GradientTape for your training codes. Just like:\n\nand outputs:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66221955,
                        "answer_post": "you might want to take a look at tf.GradientTape in tensorflow. Gradient tape is very simple way to auto-differentiate your computation. And the link has some basic example.\nHowever your model is already quite big. If you have n parameters, your jacobian will have n*n values. I believe your model probably already has more than 10000 parameters. You might need to make it smaller.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62854550,
                        "answer_post": "Yes, you are right. Layers has two variables. The one you mentioned is called kernel. And the other one is called bias. The example below explains it in details:\n\nThe output will be something like:\n\ntf.GradientTape() is used to record the operations on the trainable weights (variables) in its context for automatic differentiation. So later we can get the derivative of the variables.\nSuppose you have two weight variables as weight1 and weight2. First you need to change you loss function to use both variables (see the code below). Then in each step you need to get the derivative of loss function wrt. the variables and update them to optimize the loss. Please see the code below.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55279458,
                        "answer_post": "The tf.GradientTape is recording every operation that happens inside its scope.\nYou don't want to record in the tape the gradient calculation, you only want to compute the loss forward.\n\nMore importantly, I don't see the loop on the training set, therefore I suppose the complete code looks like:\n\nMoreover, the usage of the metrics is wrong.\nYou want to accumulate, thus update the internal state of the accuracy operation, at every training step and measure the overall accuracy at the end of every epoch.\nThus you have to:\n\nAnd call accuracy.result() only at the end of the epoch, when all the accuracy value have been saved into the metric.\nRemember to call to the .reset_states() method to clears the variable states, resetting it to zero at the end of every epoch.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61262458,
                        "answer_post": "As far as I understood from my previous experience, Tensorflow needs to use GradientTape in order to record the activity of a certain variable and so to compute its gradients. In your case should be something like that:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71420697,
                        "answer_post": "You could start off with a custom training loop using tf.GradientTape:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 57281952,
                        "answer_post": "Using tensorflow API\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66946641,
                        "answer_post": "\nAs described in the figure above, tf.GradientTape.gradient simply calculates the gradient dy/dx. In your case with multiple variables, tf seems to calculate the derivative of the corresponding tensor instead of automatically summing them.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 60860555,
                        "answer_post": "You can load and perform the inference of your TRT Model using this snippet of code.\nThis is executed in Tensorflow 2.1.0 and Google Colab Environment.\n\noutput_saved_model_dir is the location of your TensorRT Optimized model in SavedModel format.\nFrom here, you can add your testing methods to determine the performance of your pre and post-processed model. \nEDIT:\n\nHere are the codes used for Converting and Saving the Tensorflow RT Optimized model.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68184521,
                        "answer_post": "Use tf.where\n\n\n\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "After trying different things out and reading more about automatic differentation and especially about GradientTape I came across the batch_jacobian function which does exactly what I was looking for.\nMight be useful for other people that are also not that familiar with GradientTape.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "For a gradient to get on the tape, there has to be operations in the forward function (i.e. in the with GradientTape context). There are no operations with x and y (or no operations at all), so no gradient is recorded and the tape returns None.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You need to run (i.e. forward pass) the computation graph or model within the context of GradientTape so that all the operations in the model could be recorded:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You are using numpy operations in several places inside the scope of GradientTape, for example in the line\n\nReplace all numpy functions inside GradientTape's scope with their tensorflow equivalents. For example, the above line becomes:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Optimization process needs to iterate over and over for better result.\nWrap computation inside a GradientTape for automatic differentiation.\n\nCompute gradients.\n\nUpdate W and b following gradients.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Have you tried putting code from predictions = model.predict(img) onwards into the GradientTape context manager?\nThe thing is, if you did not record the gradients going from last_conv_layer.output to model.output, the backprop chain is effectively broken. \n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes you can use GradientTape. The purpose of tf.GradientTape is to record operations for automatic differentiation or for\u00a0computing the gradient of an operation or computation with respect to its input variables.\nAccording to What's New in TensorFlow 2.0, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. This ensures that all of the computations will be recorded on the gradient tape.\nThen, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient\u00a0clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.\u00a0Take a look at the following example:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Supposing you are working with Tensorflow 2.x, If you are trying to create a custom training step, to track the model gradients, you have to invoke the model under the tf.GradientTape context manager.\nHere you have your code updated to correctly work with the GradientTape:\n\nAlso note that instead of using model.predict I am using the call method which is the one you should be using when training\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "pattern": {
                "finetuned_dpr": [
                    {
                        "id": 69000523,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70597883,
                        "answer_post": "You have 2 problems in your code which prevents you from getting the result you want.\n\nIf you want to compute higher-order derivatives you have to create nested GradientTape objects\nGradientTape automatically track variables in its context, if you want to track tensors (as in your case, you want to track z and t) you have to call tape.watch(<my_tensor>) otherwise you will not have gradients for it.\n\nFixed code:\n\nMore on gradient tape can be found in the official documentation: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64012068,
                        "answer_post": "Supposing you are working with Tensorflow 2.x, If you are trying to create a custom training step, to track the model gradients, you have to invoke the model under the tf.GradientTape context manager.\nHere you have your code updated to correctly work with the GradientTape:\n\nAlso note that instead of using model.predict I am using the call method which is the one you should be using when training\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61748035,
                        "answer_post": "loss.backward() equivalent in tensorflow is tf.GradientTape(). TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\noptimizer.step() equivalent in tensorflow is minimize(). Minimizes the loss by updating the variable list. Calling minimize() takes care of both computing the gradients and applying them to the variables.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 57336013,
                        "answer_post": "Look at @tf.custom_gradient for writing your own gradient calculation function. \nhttps://www.tensorflow.org/api_docs/python/tf/custom_gradient\nIf you're using eager execution, you can monitor the gradients using Gradient Tape.\nhttps://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76753084,
                        "answer_post": "After trying different things out and reading more about automatic differentation and especially about GradientTape I came across the batch_jacobian function which does exactly what I was looking for.\nMight be useful for other people that are also not that familiar with GradientTape.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71240068,
                        "answer_post": "According to https://www.tensorflow.org/api_docs/python/tf/GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon\nas GradientTape.gradient() method is called. To compute multiple\ngradients over the same computation, create a persistent gradient\ntape. This allows multiple calls to the gradient() method as resources\nare released when the tape object is garbage collected.\n\nAfter train step, as long as no other object has a reference to that tape, the garbage collector will collect it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70983654,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 60544413,
                        "answer_post": "Yes you can use GradientTape. The purpose of tf.GradientTape is to record operations for automatic differentiation or for\u00a0computing the gradient of an operation or computation with respect to its input variables.\nAccording to What's New in TensorFlow 2.0, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. This ensures that all of the computations will be recorded on the gradient tape.\nThen, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient\u00a0clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.\u00a0Take a look at the following example:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62197631,
                        "answer_post": "As you have correctly mentioned, you have to handle Loss when its 0 else there is nothing for optimizer to minimize. Thus weights of the model also won't update. So ideal way in this case is to keep track of training loss at step level using custom training.\nYou will have more control with custom training. If you want lower-level over your training and evaluation loops than what fit() and evaluate() provide, you should write your own training loop. It's actually pretty simple. But you should be ready to have a lot more debugging to do on your own.\nCalling a model inside a GradientTape scope enables you to retrieve the gradients of the trainable weights of the layer with respect to a loss value. Using an optimizer instance, you can use these gradients to update these variables (which you can retrieve using model.trainable_weights).\nTensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of a computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHere is a simple example for mnist data. The comments are present in the code to explain better.\nCode-\n\nOutput -\n\nYou can find more about tf.GradientTape here. The example used here is taken from here.\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 70983654,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61297910,
                        "answer_post": "You need to call g.watch for each of these variables:\nRefer: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71240068,
                        "answer_post": "According to https://www.tensorflow.org/api_docs/python/tf/GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon\nas GradientTape.gradient() method is called. To compute multiple\ngradients over the same computation, create a persistent gradient\ntape. This allows multiple calls to the gradient() method as resources\nare released when the tape object is garbage collected.\n\nAfter train step, as long as no other object has a reference to that tape, the garbage collector will collect it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 58227549,
                        "answer_post": "In tensorflow 2.0, you need use the tf.GradientTape context to calculate the gradients, and then apply gradients on your model's variables. \n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61748035,
                        "answer_post": "loss.backward() equivalent in tensorflow is tf.GradientTape(). TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\noptimizer.step() equivalent in tensorflow is minimize(). Minimizes the loss by updating the variable list. Calling minimize() takes care of both computing the gradients and applying them to the variables.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 56073840,
                        "answer_post": "From the documentation of GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon as GradientTape.gradient() method is called. To compute multiple gradients over the same computation, create a persistent gradient tape. This allows multiple calls to the gradient() method as resources are released when the tape object is garbage collected.\n\nA persistent gradient can be created with with tf.GradientTape(persistent=True) as tape and can/should be manually deleted with del tape (credits for this @zwep, @Crispy13).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 69000523,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55799378,
                        "answer_post": "There is no built-in mechanism in TensorFlow 2.0 to override all gradients for a built-in operator within a scope. However, if you are able to modify the call-site for each call to the built-in operator, you can use the tf.custom_gradient decorator as follows:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61262458,
                        "answer_post": "As far as I understood from my previous experience, Tensorflow needs to use GradientTape in order to record the activity of a certain variable and so to compute its gradients. In your case should be something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65125515,
                        "answer_post": "In TensorFlow 2, you can use GradientTape with batch_jacobian. From the official website:\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 72733574,
                        "answer_post": "Don\u2019t worry, using tf.GradientTape is the most case way to get an auto differential with theoretical value. You can always use tf.GradientTape for your training codes. Just like:\n\nand outputs:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66221955,
                        "answer_post": "you might want to take a look at tf.GradientTape in tensorflow. Gradient tape is very simple way to auto-differentiate your computation. And the link has some basic example.\nHowever your model is already quite big. If you have n parameters, your jacobian will have n*n values. I believe your model probably already has more than 10000 parameters. You might need to make it smaller.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62854550,
                        "answer_post": "Yes, you are right. Layers has two variables. The one you mentioned is called kernel. And the other one is called bias. The example below explains it in details:\n\nThe output will be something like:\n\ntf.GradientTape() is used to record the operations on the trainable weights (variables) in its context for automatic differentiation. So later we can get the derivative of the variables.\nSuppose you have two weight variables as weight1 and weight2. First you need to change you loss function to use both variables (see the code below). Then in each step you need to get the derivative of loss function wrt. the variables and update them to optimize the loss. Please see the code below.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55279458,
                        "answer_post": "The tf.GradientTape is recording every operation that happens inside its scope.\nYou don't want to record in the tape the gradient calculation, you only want to compute the loss forward.\n\nMore importantly, I don't see the loop on the training set, therefore I suppose the complete code looks like:\n\nMoreover, the usage of the metrics is wrong.\nYou want to accumulate, thus update the internal state of the accuracy operation, at every training step and measure the overall accuracy at the end of every epoch.\nThus you have to:\n\nAnd call accuracy.result() only at the end of the epoch, when all the accuracy value have been saved into the metric.\nRemember to call to the .reset_states() method to clears the variable states, resetting it to zero at the end of every epoch.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71420697,
                        "answer_post": "You could start off with a custom training loop using tf.GradientTape:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61262458,
                        "answer_post": "As far as I understood from my previous experience, Tensorflow needs to use GradientTape in order to record the activity of a certain variable and so to compute its gradients. In your case should be something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 57281952,
                        "answer_post": "Using tensorflow API\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66946641,
                        "answer_post": "\nAs described in the figure above, tf.GradientTape.gradient simply calculates the gradient dy/dx. In your case with multiple variables, tf seems to calculate the derivative of the corresponding tensor instead of automatically summing them.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73957756,
                        "answer_post": "\n@tf.function uses the graph execution,\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68184521,
                        "answer_post": "Use tf.where\n\n\n\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "After trying different things out and reading more about automatic differentation and especially about GradientTape I came across the batch_jacobian function which does exactly what I was looking for.\nMight be useful for other people that are also not that familiar with GradientTape.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "For a gradient to get on the tape, there has to be operations in the forward function (i.e. in the with GradientTape context). There are no operations with x and y (or no operations at all), so no gradient is recorded and the tape returns None.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You need to run (i.e. forward pass) the computation graph or model within the context of GradientTape so that all the operations in the model could be recorded:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You are using numpy operations in several places inside the scope of GradientTape, for example in the line\n\nReplace all numpy functions inside GradientTape's scope with their tensorflow equivalents. For example, the above line becomes:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Optimization process needs to iterate over and over for better result.\nWrap computation inside a GradientTape for automatic differentiation.\n\nCompute gradients.\n\nUpdate W and b following gradients.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Have you tried putting code from predictions = model.predict(img) onwards into the GradientTape context manager?\nThe thing is, if you did not record the gradients going from last_conv_layer.output to model.output, the backprop chain is effectively broken. \n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes you can use GradientTape. The purpose of tf.GradientTape is to record operations for automatic differentiation or for\u00a0computing the gradient of an operation or computation with respect to its input variables.\nAccording to What's New in TensorFlow 2.0, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. This ensures that all of the computations will be recorded on the gradient tape.\nThen, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient\u00a0clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.\u00a0Take a look at the following example:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Supposing you are working with Tensorflow 2.x, If you are trying to create a custom training step, to track the model gradients, you have to invoke the model under the tf.GradientTape context manager.\nHere you have your code updated to correctly work with the GradientTape:\n\nAlso note that instead of using model.predict I am using the call method which is the one you should be using when training\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "environment": {
                "finetuned_dpr": [
                    {
                        "id": 64012068,
                        "answer_post": "Supposing you are working with Tensorflow 2.x, If you are trying to create a custom training step, to track the model gradients, you have to invoke the model under the tf.GradientTape context manager.\nHere you have your code updated to correctly work with the GradientTape:\n\nAlso note that instead of using model.predict I am using the call method which is the one you should be using when training\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 69000523,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70597883,
                        "answer_post": "You have 2 problems in your code which prevents you from getting the result you want.\n\nIf you want to compute higher-order derivatives you have to create nested GradientTape objects\nGradientTape automatically track variables in its context, if you want to track tensors (as in your case, you want to track z and t) you have to call tape.watch(<my_tensor>) otherwise you will not have gradients for it.\n\nFixed code:\n\nMore on gradient tape can be found in the official documentation: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76753084,
                        "answer_post": "After trying different things out and reading more about automatic differentation and especially about GradientTape I came across the batch_jacobian function which does exactly what I was looking for.\nMight be useful for other people that are also not that familiar with GradientTape.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57336013,
                        "answer_post": "Look at @tf.custom_gradient for writing your own gradient calculation function. \nhttps://www.tensorflow.org/api_docs/python/tf/custom_gradient\nIf you're using eager execution, you can monitor the gradients using Gradient Tape.\nhttps://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61748035,
                        "answer_post": "loss.backward() equivalent in tensorflow is tf.GradientTape(). TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\noptimizer.step() equivalent in tensorflow is minimize(). Minimizes the loss by updating the variable list. Calling minimize() takes care of both computing the gradients and applying them to the variables.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70983654,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71240068,
                        "answer_post": "According to https://www.tensorflow.org/api_docs/python/tf/GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon\nas GradientTape.gradient() method is called. To compute multiple\ngradients over the same computation, create a persistent gradient\ntape. This allows multiple calls to the gradient() method as resources\nare released when the tape object is garbage collected.\n\nAfter train step, as long as no other object has a reference to that tape, the garbage collector will collect it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 60544413,
                        "answer_post": "Yes you can use GradientTape. The purpose of tf.GradientTape is to record operations for automatic differentiation or for\u00a0computing the gradient of an operation or computation with respect to its input variables.\nAccording to What's New in TensorFlow 2.0, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. This ensures that all of the computations will be recorded on the gradient tape.\nThen, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient\u00a0clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.\u00a0Take a look at the following example:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62197631,
                        "answer_post": "As you have correctly mentioned, you have to handle Loss when its 0 else there is nothing for optimizer to minimize. Thus weights of the model also won't update. So ideal way in this case is to keep track of training loss at step level using custom training.\nYou will have more control with custom training. If you want lower-level over your training and evaluation loops than what fit() and evaluate() provide, you should write your own training loop. It's actually pretty simple. But you should be ready to have a lot more debugging to do on your own.\nCalling a model inside a GradientTape scope enables you to retrieve the gradients of the trainable weights of the layer with respect to a loss value. Using an optimizer instance, you can use these gradients to update these variables (which you can retrieve using model.trainable_weights).\nTensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of a computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHere is a simple example for mnist data. The comments are present in the code to explain better.\nCode-\n\nOutput -\n\nYou can find more about tf.GradientTape here. The example used here is taken from here.\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 70983654,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61297910,
                        "answer_post": "You need to call g.watch for each of these variables:\nRefer: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55799378,
                        "answer_post": "There is no built-in mechanism in TensorFlow 2.0 to override all gradients for a built-in operator within a scope. However, if you are able to modify the call-site for each call to the built-in operator, you can use the tf.custom_gradient decorator as follows:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 58227549,
                        "answer_post": "In tensorflow 2.0, you need use the tf.GradientTape context to calculate the gradients, and then apply gradients on your model's variables. \n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71240068,
                        "answer_post": "According to https://www.tensorflow.org/api_docs/python/tf/GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon\nas GradientTape.gradient() method is called. To compute multiple\ngradients over the same computation, create a persistent gradient\ntape. This allows multiple calls to the gradient() method as resources\nare released when the tape object is garbage collected.\n\nAfter train step, as long as no other object has a reference to that tape, the garbage collector will collect it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61748035,
                        "answer_post": "loss.backward() equivalent in tensorflow is tf.GradientTape(). TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\noptimizer.step() equivalent in tensorflow is minimize(). Minimizes the loss by updating the variable list. Calling minimize() takes care of both computing the gradients and applying them to the variables.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 56073840,
                        "answer_post": "From the documentation of GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon as GradientTape.gradient() method is called. To compute multiple gradients over the same computation, create a persistent gradient tape. This allows multiple calls to the gradient() method as resources are released when the tape object is garbage collected.\n\nA persistent gradient can be created with with tf.GradientTape(persistent=True) as tape and can/should be manually deleted with del tape (credits for this @zwep, @Crispy13).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71079495,
                        "answer_post": "If you have any environment about tensorflow, uninstall it and install tensorflow to the base(root)\n\nconda activate base\nconda install -c anaconda pip\npip install tensorflow\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69000523,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65125515,
                        "answer_post": "In TensorFlow 2, you can use GradientTape with batch_jacobian. From the official website:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72733574,
                        "answer_post": "Don\u2019t worry, using tf.GradientTape is the most case way to get an auto differential with theoretical value. You can always use tf.GradientTape for your training codes. Just like:\n\nand outputs:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66221955,
                        "answer_post": "you might want to take a look at tf.GradientTape in tensorflow. Gradient tape is very simple way to auto-differentiate your computation. And the link has some basic example.\nHowever your model is already quite big. If you have n parameters, your jacobian will have n*n values. I believe your model probably already has more than 10000 parameters. You might need to make it smaller.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55279458,
                        "answer_post": "The tf.GradientTape is recording every operation that happens inside its scope.\nYou don't want to record in the tape the gradient calculation, you only want to compute the loss forward.\n\nMore importantly, I don't see the loop on the training set, therefore I suppose the complete code looks like:\n\nMoreover, the usage of the metrics is wrong.\nYou want to accumulate, thus update the internal state of the accuracy operation, at every training step and measure the overall accuracy at the end of every epoch.\nThus you have to:\n\nAnd call accuracy.result() only at the end of the epoch, when all the accuracy value have been saved into the metric.\nRemember to call to the .reset_states() method to clears the variable states, resetting it to zero at the end of every epoch.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62854550,
                        "answer_post": "Yes, you are right. Layers has two variables. The one you mentioned is called kernel. And the other one is called bias. The example below explains it in details:\n\nThe output will be something like:\n\ntf.GradientTape() is used to record the operations on the trainable weights (variables) in its context for automatic differentiation. So later we can get the derivative of the variables.\nSuppose you have two weight variables as weight1 and weight2. First you need to change you loss function to use both variables (see the code below). Then in each step you need to get the derivative of loss function wrt. the variables and update them to optimize the loss. Please see the code below.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 57281952,
                        "answer_post": "Using tensorflow API\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61262458,
                        "answer_post": "As far as I understood from my previous experience, Tensorflow needs to use GradientTape in order to record the activity of a certain variable and so to compute its gradients. In your case should be something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71420697,
                        "answer_post": "You could start off with a custom training loop using tf.GradientTape:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60860555,
                        "answer_post": "You can load and perform the inference of your TRT Model using this snippet of code.\nThis is executed in Tensorflow 2.1.0 and Google Colab Environment.\n\noutput_saved_model_dir is the location of your TensorRT Optimized model in SavedModel format.\nFrom here, you can add your testing methods to determine the performance of your pre and post-processed model. \nEDIT:\n\nHere are the codes used for Converting and Saving the Tensorflow RT Optimized model.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68184521,
                        "answer_post": "Use tf.where\n\n\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62117706,
                        "answer_post": "According to this keras document\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "After trying different things out and reading more about automatic differentation and especially about GradientTape I came across the batch_jacobian function which does exactly what I was looking for.\nMight be useful for other people that are also not that familiar with GradientTape.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "For a gradient to get on the tape, there has to be operations in the forward function (i.e. in the with GradientTape context). There are no operations with x and y (or no operations at all), so no gradient is recorded and the tape returns None.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You need to run (i.e. forward pass) the computation graph or model within the context of GradientTape so that all the operations in the model could be recorded:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You are using numpy operations in several places inside the scope of GradientTape, for example in the line\n\nReplace all numpy functions inside GradientTape's scope with their tensorflow equivalents. For example, the above line becomes:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Optimization process needs to iterate over and over for better result.\nWrap computation inside a GradientTape for automatic differentiation.\n\nCompute gradients.\n\nUpdate W and b following gradients.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Have you tried putting code from predictions = model.predict(img) onwards into the GradientTape context manager?\nThe thing is, if you did not record the gradients going from last_conv_layer.output to model.output, the backprop chain is effectively broken. \n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes you can use GradientTape. The purpose of tf.GradientTape is to record operations for automatic differentiation or for\u00a0computing the gradient of an operation or computation with respect to its input variables.\nAccording to What's New in TensorFlow 2.0, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. This ensures that all of the computations will be recorded on the gradient tape.\nThen, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient\u00a0clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.\u00a0Take a look at the following example:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Supposing you are working with Tensorflow 2.x, If you are trying to create a custom training step, to track the model gradients, you have to invoke the model under the tf.GradientTape context manager.\nHere you have your code updated to correctly work with the GradientTape:\n\nAlso note that instead of using model.predict I am using the call method which is the one you should be using when training\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "alternative": {
                "finetuned_dpr": [
                    {
                        "id": 64012068,
                        "answer_post": "Supposing you are working with Tensorflow 2.x, If you are trying to create a custom training step, to track the model gradients, you have to invoke the model under the tf.GradientTape context manager.\nHere you have your code updated to correctly work with the GradientTape:\n\nAlso note that instead of using model.predict I am using the call method which is the one you should be using when training\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 69000523,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70597883,
                        "answer_post": "You have 2 problems in your code which prevents you from getting the result you want.\n\nIf you want to compute higher-order derivatives you have to create nested GradientTape objects\nGradientTape automatically track variables in its context, if you want to track tensors (as in your case, you want to track z and t) you have to call tape.watch(<my_tensor>) otherwise you will not have gradients for it.\n\nFixed code:\n\nMore on gradient tape can be found in the official documentation: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76753084,
                        "answer_post": "After trying different things out and reading more about automatic differentation and especially about GradientTape I came across the batch_jacobian function which does exactly what I was looking for.\nMight be useful for other people that are also not that familiar with GradientTape.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 57336013,
                        "answer_post": "Look at @tf.custom_gradient for writing your own gradient calculation function. \nhttps://www.tensorflow.org/api_docs/python/tf/custom_gradient\nIf you're using eager execution, you can monitor the gradients using Gradient Tape.\nhttps://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61748035,
                        "answer_post": "loss.backward() equivalent in tensorflow is tf.GradientTape(). TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\noptimizer.step() equivalent in tensorflow is minimize(). Minimizes the loss by updating the variable list. Calling minimize() takes care of both computing the gradients and applying them to the variables.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71240068,
                        "answer_post": "According to https://www.tensorflow.org/api_docs/python/tf/GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon\nas GradientTape.gradient() method is called. To compute multiple\ngradients over the same computation, create a persistent gradient\ntape. This allows multiple calls to the gradient() method as resources\nare released when the tape object is garbage collected.\n\nAfter train step, as long as no other object has a reference to that tape, the garbage collector will collect it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 70983654,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 60544413,
                        "answer_post": "Yes you can use GradientTape. The purpose of tf.GradientTape is to record operations for automatic differentiation or for\u00a0computing the gradient of an operation or computation with respect to its input variables.\nAccording to What's New in TensorFlow 2.0, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. This ensures that all of the computations will be recorded on the gradient tape.\nThen, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient\u00a0clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.\u00a0Take a look at the following example:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62197631,
                        "answer_post": "As you have correctly mentioned, you have to handle Loss when its 0 else there is nothing for optimizer to minimize. Thus weights of the model also won't update. So ideal way in this case is to keep track of training loss at step level using custom training.\nYou will have more control with custom training. If you want lower-level over your training and evaluation loops than what fit() and evaluate() provide, you should write your own training loop. It's actually pretty simple. But you should be ready to have a lot more debugging to do on your own.\nCalling a model inside a GradientTape scope enables you to retrieve the gradients of the trainable weights of the layer with respect to a loss value. Using an optimizer instance, you can use these gradients to update these variables (which you can retrieve using model.trainable_weights).\nTensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of a computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHere is a simple example for mnist data. The comments are present in the code to explain better.\nCode-\n\nOutput -\n\nYou can find more about tf.GradientTape here. The example used here is taken from here.\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 70983654,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61748035,
                        "answer_post": "loss.backward() equivalent in tensorflow is tf.GradientTape(). TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\noptimizer.step() equivalent in tensorflow is minimize(). Minimizes the loss by updating the variable list. Calling minimize() takes care of both computing the gradients and applying them to the variables.\nIf you want to process the gradients before applying them you can instead use the optimizer in three steps:\n\nCompute the gradients with tf.GradientTape.\nProcess the gradients as you wish.\nApply the processed gradients with apply_gradients().\n\nHope this answers your question. Happy Learning.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 58227549,
                        "answer_post": "In tensorflow 2.0, you need use the tf.GradientTape context to calculate the gradients, and then apply gradients on your model's variables. \n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55799378,
                        "answer_post": "There is no built-in mechanism in TensorFlow 2.0 to override all gradients for a built-in operator within a scope. However, if you are able to modify the call-site for each call to the built-in operator, you can use the tf.custom_gradient decorator as follows:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 56073840,
                        "answer_post": "From the documentation of GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon as GradientTape.gradient() method is called. To compute multiple gradients over the same computation, create a persistent gradient tape. This allows multiple calls to the gradient() method as resources are released when the tape object is garbage collected.\n\nA persistent gradient can be created with with tf.GradientTape(persistent=True) as tape and can/should be manually deleted with del tape (credits for this @zwep, @Crispy13).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61297910,
                        "answer_post": "You need to call g.watch for each of these variables:\nRefer: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71240068,
                        "answer_post": "According to https://www.tensorflow.org/api_docs/python/tf/GradientTape:\n\nBy default, the resources held by a GradientTape are released as soon\nas GradientTape.gradient() method is called. To compute multiple\ngradients over the same computation, create a persistent gradient\ntape. This allows multiple calls to the gradient() method as resources\nare released when the tape object is garbage collected.\n\nAfter train step, as long as no other object has a reference to that tape, the garbage collector will collect it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65125515,
                        "answer_post": "In TensorFlow 2, you can use GradientTape with batch_jacobian. From the official website:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69000523,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75046515,
                        "answer_post": "try conda install instead of pip install if you have conda installed\nconda install tensorflow==2.6.0\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72733574,
                        "answer_post": "Don\u2019t worry, using tf.GradientTape is the most case way to get an auto differential with theoretical value. You can always use tf.GradientTape for your training codes. Just like:\n\nand outputs:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66221955,
                        "answer_post": "you might want to take a look at tf.GradientTape in tensorflow. Gradient tape is very simple way to auto-differentiate your computation. And the link has some basic example.\nHowever your model is already quite big. If you have n parameters, your jacobian will have n*n values. I believe your model probably already has more than 10000 parameters. You might need to make it smaller.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62854550,
                        "answer_post": "Yes, you are right. Layers has two variables. The one you mentioned is called kernel. And the other one is called bias. The example below explains it in details:\n\nThe output will be something like:\n\ntf.GradientTape() is used to record the operations on the trainable weights (variables) in its context for automatic differentiation. So later we can get the derivative of the variables.\nSuppose you have two weight variables as weight1 and weight2. First you need to change you loss function to use both variables (see the code below). Then in each step you need to get the derivative of loss function wrt. the variables and update them to optimize the loss. Please see the code below.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71420697,
                        "answer_post": "You could start off with a custom training loop using tf.GradientTape:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55279458,
                        "answer_post": "The tf.GradientTape is recording every operation that happens inside its scope.\nYou don't want to record in the tape the gradient calculation, you only want to compute the loss forward.\n\nMore importantly, I don't see the loop on the training set, therefore I suppose the complete code looks like:\n\nMoreover, the usage of the metrics is wrong.\nYou want to accumulate, thus update the internal state of the accuracy operation, at every training step and measure the overall accuracy at the end of every epoch.\nThus you have to:\n\nAnd call accuracy.result() only at the end of the epoch, when all the accuracy value have been saved into the metric.\nRemember to call to the .reset_states() method to clears the variable states, resetting it to zero at the end of every epoch.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 57281952,
                        "answer_post": "Using tensorflow API\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76808704,
                        "answer_post": "Use tf.pad function\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74938672,
                        "answer_post": "Need to use not linear optimizer\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 59837821,
                        "answer_post": "with TENSORFLOW 2\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66946641,
                        "answer_post": "\nAs described in the figure above, tf.GradientTape.gradient simply calculates the gradient dy/dx. In your case with multiple variables, tf seems to calculate the derivative of the corresponding tensor instead of automatically summing them.\n",
                        "contain_knowledge": 1
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You need to understand how the GradientTape operates. For that, you can follow the guide: Introduction to gradients and automatic differentiation. Here is an excerpt:\n\nTensorFlow provides the tf.GradientTape API for automatic\ndifferentiation; that is, computing the gradient of a computation with\nrespect to some inputs, usually tf.Variables. TensorFlow \"records\"\nrelevant operations executed inside the context of a tf.GradientTape\nonto a \"tape\". TensorFlow then uses that tape to compute the gradients\nof a \"recorded\" computation using reverse mode differentiation.\n\nTo compute a gradient (or a jacobian), the tape needs to record the operations that are executed in its context. Then, outside its context, once the forward pass has been executed, its possible to use the tape to compute the gradient/jacobian.\nYou could use something like that:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "After trying different things out and reading more about automatic differentation and especially about GradientTape I came across the batch_jacobian function which does exactly what I was looking for.\nMight be useful for other people that are also not that familiar with GradientTape.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "For a gradient to get on the tape, there has to be operations in the forward function (i.e. in the with GradientTape context). There are no operations with x and y (or no operations at all), so no gradient is recorded and the tape returns None.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You need to run (i.e. forward pass) the computation graph or model within the context of GradientTape so that all the operations in the model could be recorded:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You are using numpy operations in several places inside the scope of GradientTape, for example in the line\n\nReplace all numpy functions inside GradientTape's scope with their tensorflow equivalents. For example, the above line becomes:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Optimization process needs to iterate over and over for better result.\nWrap computation inside a GradientTape for automatic differentiation.\n\nCompute gradients.\n\nUpdate W and b following gradients.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Have you tried putting code from predictions = model.predict(img) onwards into the GradientTape context manager?\nThe thing is, if you did not record the gradients going from last_conv_layer.output to model.output, the backprop chain is effectively broken. \n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes you can use GradientTape. The purpose of tf.GradientTape is to record operations for automatic differentiation or for\u00a0computing the gradient of an operation or computation with respect to its input variables.\nAccording to What's New in TensorFlow 2.0, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. This ensures that all of the computations will be recorded on the gradient tape.\nThen, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient\u00a0clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.\u00a0Take a look at the following example:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "TF.gradients\ntf.gradients is only valid in a graph context. In particular, it is valid in the context of a tf.function wrapper, where code is executing as a graph.\n\ntf.GradientTape\nTensorFlow provides the tf.GradientTape API for automatic differentiation. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation. tf.GradientTape not really required tf.function wrapper. It automatically runs in Graph mode.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Supposing you are working with Tensorflow 2.x, If you are trying to create a custom training step, to track the model gradients, you have to invoke the model under the tf.GradientTape context manager.\nHere you have your code updated to correctly work with the GradientTape:\n\nAlso note that instead of using model.predict I am using the call method which is the one you should be using when training\n",
                        "contain_knowledge": 1
                    }
                ]
            }
        }
    },
    {
        "name": "SAXParser",
        "language": "java",
        "popularity": "middle",
        "label_result": {
            "functionality": {
                "finetuned_dpr": 0.6,
                "dpr": 0.3,
                "e5": 0.2,
                "bm25": 0.5
            },
            "concept": {
                "finetuned_dpr": 0.7,
                "dpr": 0.4,
                "e5": 0.2,
                "bm25": 0.5
            },
            "performance": {
                "finetuned_dpr": 0.5,
                "dpr": 0.4,
                "e5": 0.0,
                "bm25": 0.6
            },
            "directive": {
                "finetuned_dpr": 0.4,
                "dpr": 0.3,
                "e5": 0.1,
                "bm25": 0.5
            },
            "pattern": {
                "finetuned_dpr": 0.5,
                "dpr": 0.4,
                "e5": 0.1,
                "bm25": 0.5
            },
            "environment": {
                "finetuned_dpr": 0.6,
                "dpr": 0.4,
                "e5": 0.0,
                "bm25": 0.5
            },
            "alternative": {
                "finetuned_dpr": 0.6,
                "dpr": 0.5,
                "e5": 0.1,
                "bm25": 0.6
            },
            "total": {
                "finetuned_dpr": 0.5571428571428572,
                "dpr": 0.38571428571428573,
                "e5": 0.09999999999999999,
                "bm25": 0.5285714285714286
            }
        },
        "retrieve_result": {
            "functionality": {
                "finetuned_dpr": [
                    {
                        "id": 73384382,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74745279,
                        "answer_post": "I have resolved this issue, it was due to another bug in my own code.\nSo it had nothing to do with the SAXParser. Thanks for all the help!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73064025,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77003634,
                        "answer_post": "\nOne way could be to maintain a boolean variable var insideA=false, (\u2026)\n\nYes, that looks like the usual way to address your goal using SAX.\n\nAny suggestions for an alternative approach?\n\nSAX is a bit complex to setup, but \"better\" than DOM / XPath regarding memory usage. Anyway:\nIf your XML document fits in RAM,\nyou can also try using XPath (internally based on the DOM model), which is simpler to use.\nAs you tagged your question with java, here is a nice tutorial for evaluating XPath expressions in Java, see also the official W3C spec. (a.k.a. recommendation), and this online XPath tester.\nIf your XML is huge and you find SAX a bit annoying to use,\nyou can try using StAX, which combines the performance of streaming-based parsing and the usability of \"pull parsing\" (roughly, no callback anymore).\nSee also this example tutorial in Java.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73398356,
                        "answer_post": "Ideally you should use a library like SAX parser to Deserialize an input stream like XML.\nBut if you want to do this using no libraries maybe the method below can help:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72434146,
                        "answer_post": "I managed to implement a solution based on Schema.newValidatorHandler(). I lost most time with the fact that SaxParser.parse() only accepts a DefaultHandler. To insert a custom ContentHandler, one has to use SaxParser.getXMLReader().setContentHandler().\nI am aware that this proof of concept is not very robust, because it is parsing the validation error message to extract the maxLength schema information. So this solution is relying on a very specific SAX implementation.\nI looked at schema aware XSLT transformation, but could not find any indication that the schema information can be accessed in the transformation expressions.\nWriting my own specialized schema parser is still not completely off the table.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76292324,
                        "answer_post": "cts.documentQuery(cts.uriMatch(\"/directory/*/folder/*.xml\"))\nIs this what you are expecting? This is the server side javascript (XQuery) equivalent of what you have asked.\nIf you want to pass a serialized query, you should first execute cts:uri-match(\"/directory/*/folder/*.xml\") and then enclose the results into cts:document-query as shown below\n\nBest approach is to create a MarkLogic module server-side (in XQuery or JS) and invoke it from JAVA client API (by passing the uri-match string)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77085031,
                        "answer_post": "Obviously, you need to parse the whole document, and the fastest way way to arrive at a solution is to not include the \"filtered out\" elements in the document building process. Both DOM4J and JDOM are good alternatives for this, since they allow custom document builders that can defer or allow the tree construction based on previously obtained conditions. SAX/StAX is of course also an alternative, but at a lower level and require more infrastructure code to get a result.\nSearch this site for DOM4J/JDOM and builder, I may already have given the answer ;)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 78820176,
                        "answer_post": "SXSSF library is mainly for writing the large (xlsx) files with 2^20 (1,048,576) rows per sheet, but not for reading the data from excel file. To read the data from excel, Apache poi provides SAX parsing based event handling. Please refer to this: https://poi.apache.org/components/spreadsheet/how-to.html#xssf_sax_api\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77193930,
                        "answer_post": "SchemaParser is deprecated in favor of SchemaRepository.\nFirst, create the repository:\n\nThen use it in the ValidationHandlerBuilder:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73064025,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72809808,
                        "answer_post": "Instead of doing an invocationBuilder.method(\"GET\", ...), use invocationBuilder.post(entity), as described here. This will allow you to POST your transaction String to the endpoint.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 78820176,
                        "answer_post": "SXSSF library is mainly for writing the large (xlsx) files with 2^20 (1,048,576) rows per sheet, but not for reading the data from excel file. To read the data from excel, Apache poi provides SAX parsing based event handling. Please refer to this: https://poi.apache.org/components/spreadsheet/how-to.html#xssf_sax_api\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74224422,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73259387,
                        "answer_post": "To parse XML use XML parser. One of easier but yet powerful ones is Jsoup which allows us to write code like\n\nOutput: {1=0, 2=7, 3=22, 4=2, 5=1}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72520904,
                        "answer_post": "Typically this is done with the Apache Commons library's trim method. This library is so commonplace that it's basically part of Java. It will return null for null Strings. E.g. StringUtils.trim(\"myString \"); would return \"myString\"\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76798793,
                        "answer_post": "In Java, primitive types, including boolean, are passed by value, meaning they cannot be modified by other methods. Class types, including List, are passed by reference, which means that they can be modified by other methods. (As pointed out by @WJS, the list cannot be modified directly, only its contents, so this is sometimes called \"call by sharing\", but it is very similar)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72394099,
                        "answer_post": "You can use JAXB parser instead of SAX, It converts each element tag into a Java objects and easily configurable too. But we need to create classes for each element tag in the XML file as mentioned in this article https://www.javatpoint.com/jaxb-tutorial\nAs per your data your root class will be like below:\n\nFollowing method helps to convert XML into JavaObject:\nRequired parameters are:\n\nInputStream (Inputstream of the XML file)\nClass (Class name of the root element in the XML com.a.b.c.DtecBs)\n\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72888526,
                        "answer_post": "\nUse the Character API\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76095804,
                        "answer_post": "See this please\nfor Java\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73398356,
                        "answer_post": "Ideally you should use a library like SAX parser to Deserialize an input stream like XML.\nBut if you want to do this using no libraries maybe the method below can help:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74738107,
                        "answer_post": "what is //fullname mock here?\nits working\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74960566,
                        "answer_post": "Use DataNode\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77198249,
                        "answer_post": "Using java.time\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72773754,
                        "answer_post": "Your interpretation is wrong. SAX is firing the events other than you expect.\n\nWhen the SAX parser reads this document, it will fire\n\nstartElement for <QuotaCode>\ncharacters for the linefeed (invisible)\nstartElement for <null/>\nendElement for <null/>\ncharacters for the linefeed (invisible)\nendElement for </QuotaCode>\n\nMaybe you expected <null/> to be the element text? Then you need to escape that data like so:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77499417,
                        "answer_post": "Use the DecimalFormat class.\n\nOutput\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75052469,
                        "answer_post": "Use loadStrings or loadBytes\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I have resolved this issue, it was due to another bug in my own code.\nSo it had nothing to do with the SAXParser. Thanks for all the help!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Check for these problems:\n\nIf there are characters before the XML declaration (<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>), delete them.\n\nIf you're parsing a non-XML file, change to parsing an actual XML file.\n\nIf you're passing the filename to a call that expects a string of XML, change to passing a string of XML.\n\nIf you're receiving Base64-encoded, compressed, or otherwise represented XML, decode/decompress/convert it before parsing.\n\n\nSee also\n\nError: The processing instruction target matching \"[xX][mM][lL]\" is not allowed\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "There are a few ways to read the XML file and extract the information you need without using a lot of if statements. One approach is to use an XML parsing library such as JAXB or SAX, and create Java classes to represent the XML elements.\nIn JAXB, you can use the javax.xml.bind.Unmarshaller class to unmarshal the XML file into a Java object, which you can then traverse to extract the information you need.\nYou should start creating a Java classes based on the XML structure, like FlowMonitor, Menu1, Item, Connection etc. , and use annotation to map the xml elements to the fields.\nThen, you can use the unmarshaller.unmarshal() method to parse the XML file and create an instance of the FlowMonitor class, which will contain all the information from the XML file.\nOnce you have the FlowMonitor object you can loop through the items, and get the description and filename by calling getDescriptionValue() and getFilenameValue() of the item object....\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You're getting the error since your @XmlRootElement misses the XML namespace (xmlns) but since your XML documents contains a lot of child elements with different namespaces I doubt adding this would be enough. Usually you would start with the XML schema of BPMN and generate Java classes out of it.\nI think another option in this special case would be not to use JAXB but the Camunda Model API.\nAnother thing: Do yourself a favor and never convert between XML documents, which come as byte array usually, and String using new String() or String.getBytes(). If you do this without watching the character set within the XML declaration of your document, or UTF-8 if its missing, you'll get mangled characters sooner or later. Every conversion between byte [] and String either assumes a character set or encoding (default platform encoding) or expects it as a parameter.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can use JAXB parser instead of SAX, It converts each element tag into a Java objects and easily configurable too. But we need to create classes for each element tag in the XML file as mentioned in this article https://www.javatpoint.com/jaxb-tutorial\nAs per your data your root class will be like below:\n\nFollowing method helps to convert XML into JavaObject:\nRequired parameters are:\n\nInputStream (Inputstream of the XML file)\nClass (Class name of the root element in the XML com.a.b.c.DtecBs)\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "tag <064E> is illegal:\nRead up on the rules for XML tag names :\nhttps://www.w3schools.com/xml/xml_elements.asp\nAs a workaround you could use an _ before the number character or write your custom xml parser  :\nBest method to parse various custom XML documents in Java\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "concept": {
                "finetuned_dpr": [
                    {
                        "id": 73384382,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74745279,
                        "answer_post": "I have resolved this issue, it was due to another bug in my own code.\nSo it had nothing to do with the SAXParser. Thanks for all the help!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73064025,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73398356,
                        "answer_post": "Ideally you should use a library like SAX parser to Deserialize an input stream like XML.\nBut if you want to do this using no libraries maybe the method below can help:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77003634,
                        "answer_post": "\nOne way could be to maintain a boolean variable var insideA=false, (\u2026)\n\nYes, that looks like the usual way to address your goal using SAX.\n\nAny suggestions for an alternative approach?\n\nSAX is a bit complex to setup, but \"better\" than DOM / XPath regarding memory usage. Anyway:\nIf your XML document fits in RAM,\nyou can also try using XPath (internally based on the DOM model), which is simpler to use.\nAs you tagged your question with java, here is a nice tutorial for evaluating XPath expressions in Java, see also the official W3C spec. (a.k.a. recommendation), and this online XPath tester.\nIf your XML is huge and you find SAX a bit annoying to use,\nyou can try using StAX, which combines the performance of streaming-based parsing and the usability of \"pull parsing\" (roughly, no callback anymore).\nSee also this example tutorial in Java.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72434146,
                        "answer_post": "I managed to implement a solution based on Schema.newValidatorHandler(). I lost most time with the fact that SaxParser.parse() only accepts a DefaultHandler. To insert a custom ContentHandler, one has to use SaxParser.getXMLReader().setContentHandler().\nI am aware that this proof of concept is not very robust, because it is parsing the validation error message to extract the maxLength schema information. So this solution is relying on a very specific SAX implementation.\nI looked at schema aware XSLT transformation, but could not find any indication that the schema information can be accessed in the transformation expressions.\nWriting my own specialized schema parser is still not completely off the table.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77085031,
                        "answer_post": "Obviously, you need to parse the whole document, and the fastest way way to arrive at a solution is to not include the \"filtered out\" elements in the document building process. Both DOM4J and JDOM are good alternatives for this, since they allow custom document builders that can defer or allow the tree construction based on previously obtained conditions. SAX/StAX is of course also an alternative, but at a lower level and require more infrastructure code to get a result.\nSearch this site for DOM4J/JDOM and builder, I may already have given the answer ;)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 78820176,
                        "answer_post": "SXSSF library is mainly for writing the large (xlsx) files with 2^20 (1,048,576) rows per sheet, but not for reading the data from excel file. To read the data from excel, Apache poi provides SAX parsing based event handling. Please refer to this: https://poi.apache.org/components/spreadsheet/how-to.html#xssf_sax_api\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76292324,
                        "answer_post": "cts.documentQuery(cts.uriMatch(\"/directory/*/folder/*.xml\"))\nIs this what you are expecting? This is the server side javascript (XQuery) equivalent of what you have asked.\nIf you want to pass a serialized query, you should first execute cts:uri-match(\"/directory/*/folder/*.xml\") and then enclose the results into cts:document-query as shown below\n\nBest approach is to create a MarkLogic module server-side (in XQuery or JS) and invoke it from JAVA client API (by passing the uri-match string)\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73064025,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77193930,
                        "answer_post": "SchemaParser is deprecated in favor of SchemaRepository.\nFirst, create the repository:\n\nThen use it in the ValidationHandlerBuilder:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 78820176,
                        "answer_post": "SXSSF library is mainly for writing the large (xlsx) files with 2^20 (1,048,576) rows per sheet, but not for reading the data from excel file. To read the data from excel, Apache poi provides SAX parsing based event handling. Please refer to this: https://poi.apache.org/components/spreadsheet/how-to.html#xssf_sax_api\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72809808,
                        "answer_post": "Instead of doing an invocationBuilder.method(\"GET\", ...), use invocationBuilder.post(entity), as described here. This will allow you to POST your transaction String to the endpoint.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74224422,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73259387,
                        "answer_post": "To parse XML use XML parser. One of easier but yet powerful ones is Jsoup which allows us to write code like\n\nOutput: {1=0, 2=7, 3=22, 4=2, 5=1}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72520904,
                        "answer_post": "Typically this is done with the Apache Commons library's trim method. This library is so commonplace that it's basically part of Java. It will return null for null Strings. E.g. StringUtils.trim(\"myString \"); would return \"myString\"\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72394099,
                        "answer_post": "You can use JAXB parser instead of SAX, It converts each element tag into a Java objects and easily configurable too. But we need to create classes for each element tag in the XML file as mentioned in this article https://www.javatpoint.com/jaxb-tutorial\nAs per your data your root class will be like below:\n\nFollowing method helps to convert XML into JavaObject:\nRequired parameters are:\n\nInputStream (Inputstream of the XML file)\nClass (Class name of the root element in the XML com.a.b.c.DtecBs)\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76798793,
                        "answer_post": "In Java, primitive types, including boolean, are passed by value, meaning they cannot be modified by other methods. Class types, including List, are passed by reference, which means that they can be modified by other methods. (As pointed out by @WJS, the list cannot be modified directly, only its contents, so this is sometimes called \"call by sharing\", but it is very similar)\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 76095804,
                        "answer_post": "See this please\nfor Java\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72888526,
                        "answer_post": "\nUse the Character API\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73398356,
                        "answer_post": "Ideally you should use a library like SAX parser to Deserialize an input stream like XML.\nBut if you want to do this using no libraries maybe the method below can help:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73489047,
                        "answer_post": "java version:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74960566,
                        "answer_post": "Use DataNode\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 78852629,
                        "answer_post": "Defining a RestTemplate bean:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77198249,
                        "answer_post": "Using java.time\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77075486,
                        "answer_post": "pom.xml\n\napplication.properties\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I have resolved this issue, it was due to another bug in my own code.\nSo it had nothing to do with the SAXParser. Thanks for all the help!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Check for these problems:\n\nIf there are characters before the XML declaration (<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>), delete them.\n\nIf you're parsing a non-XML file, change to parsing an actual XML file.\n\nIf you're passing the filename to a call that expects a string of XML, change to passing a string of XML.\n\nIf you're receiving Base64-encoded, compressed, or otherwise represented XML, decode/decompress/convert it before parsing.\n\n\nSee also\n\nError: The processing instruction target matching \"[xX][mM][lL]\" is not allowed\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "There are a few ways to read the XML file and extract the information you need without using a lot of if statements. One approach is to use an XML parsing library such as JAXB or SAX, and create Java classes to represent the XML elements.\nIn JAXB, you can use the javax.xml.bind.Unmarshaller class to unmarshal the XML file into a Java object, which you can then traverse to extract the information you need.\nYou should start creating a Java classes based on the XML structure, like FlowMonitor, Menu1, Item, Connection etc. , and use annotation to map the xml elements to the fields.\nThen, you can use the unmarshaller.unmarshal() method to parse the XML file and create an instance of the FlowMonitor class, which will contain all the information from the XML file.\nOnce you have the FlowMonitor object you can loop through the items, and get the description and filename by calling getDescriptionValue() and getFilenameValue() of the item object....\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You're getting the error since your @XmlRootElement misses the XML namespace (xmlns) but since your XML documents contains a lot of child elements with different namespaces I doubt adding this would be enough. Usually you would start with the XML schema of BPMN and generate Java classes out of it.\nI think another option in this special case would be not to use JAXB but the Camunda Model API.\nAnother thing: Do yourself a favor and never convert between XML documents, which come as byte array usually, and String using new String() or String.getBytes(). If you do this without watching the character set within the XML declaration of your document, or UTF-8 if its missing, you'll get mangled characters sooner or later. Every conversion between byte [] and String either assumes a character set or encoding (default platform encoding) or expects it as a parameter.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can use JAXB parser instead of SAX, It converts each element tag into a Java objects and easily configurable too. But we need to create classes for each element tag in the XML file as mentioned in this article https://www.javatpoint.com/jaxb-tutorial\nAs per your data your root class will be like below:\n\nFollowing method helps to convert XML into JavaObject:\nRequired parameters are:\n\nInputStream (Inputstream of the XML file)\nClass (Class name of the root element in the XML com.a.b.c.DtecBs)\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "tag <064E> is illegal:\nRead up on the rules for XML tag names :\nhttps://www.w3schools.com/xml/xml_elements.asp\nAs a workaround you could use an _ before the number character or write your custom xml parser  :\nBest method to parse various custom XML documents in Java\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "performance": {
                "finetuned_dpr": [
                    {
                        "id": 73384382,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74745279,
                        "answer_post": "I have resolved this issue, it was due to another bug in my own code.\nSo it had nothing to do with the SAXParser. Thanks for all the help!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73064025,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77003634,
                        "answer_post": "\nOne way could be to maintain a boolean variable var insideA=false, (\u2026)\n\nYes, that looks like the usual way to address your goal using SAX.\n\nAny suggestions for an alternative approach?\n\nSAX is a bit complex to setup, but \"better\" than DOM / XPath regarding memory usage. Anyway:\nIf your XML document fits in RAM,\nyou can also try using XPath (internally based on the DOM model), which is simpler to use.\nAs you tagged your question with java, here is a nice tutorial for evaluating XPath expressions in Java, see also the official W3C spec. (a.k.a. recommendation), and this online XPath tester.\nIf your XML is huge and you find SAX a bit annoying to use,\nyou can try using StAX, which combines the performance of streaming-based parsing and the usability of \"pull parsing\" (roughly, no callback anymore).\nSee also this example tutorial in Java.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73398356,
                        "answer_post": "Ideally you should use a library like SAX parser to Deserialize an input stream like XML.\nBut if you want to do this using no libraries maybe the method below can help:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72434146,
                        "answer_post": "I managed to implement a solution based on Schema.newValidatorHandler(). I lost most time with the fact that SaxParser.parse() only accepts a DefaultHandler. To insert a custom ContentHandler, one has to use SaxParser.getXMLReader().setContentHandler().\nI am aware that this proof of concept is not very robust, because it is parsing the validation error message to extract the maxLength schema information. So this solution is relying on a very specific SAX implementation.\nI looked at schema aware XSLT transformation, but could not find any indication that the schema information can be accessed in the transformation expressions.\nWriting my own specialized schema parser is still not completely off the table.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 78820176,
                        "answer_post": "SXSSF library is mainly for writing the large (xlsx) files with 2^20 (1,048,576) rows per sheet, but not for reading the data from excel file. To read the data from excel, Apache poi provides SAX parsing based event handling. Please refer to this: https://poi.apache.org/components/spreadsheet/how-to.html#xssf_sax_api\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77085031,
                        "answer_post": "Obviously, you need to parse the whole document, and the fastest way way to arrive at a solution is to not include the \"filtered out\" elements in the document building process. Both DOM4J and JDOM are good alternatives for this, since they allow custom document builders that can defer or allow the tree construction based on previously obtained conditions. SAX/StAX is of course also an alternative, but at a lower level and require more infrastructure code to get a result.\nSearch this site for DOM4J/JDOM and builder, I may already have given the answer ;)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76292324,
                        "answer_post": "cts.documentQuery(cts.uriMatch(\"/directory/*/folder/*.xml\"))\nIs this what you are expecting? This is the server side javascript (XQuery) equivalent of what you have asked.\nIf you want to pass a serialized query, you should first execute cts:uri-match(\"/directory/*/folder/*.xml\") and then enclose the results into cts:document-query as shown below\n\nBest approach is to create a MarkLogic module server-side (in XQuery or JS) and invoke it from JAVA client API (by passing the uri-match string)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73064025,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77193930,
                        "answer_post": "SchemaParser is deprecated in favor of SchemaRepository.\nFirst, create the repository:\n\nThen use it in the ValidationHandlerBuilder:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 78820176,
                        "answer_post": "SXSSF library is mainly for writing the large (xlsx) files with 2^20 (1,048,576) rows per sheet, but not for reading the data from excel file. To read the data from excel, Apache poi provides SAX parsing based event handling. Please refer to this: https://poi.apache.org/components/spreadsheet/how-to.html#xssf_sax_api\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74224422,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72809808,
                        "answer_post": "Instead of doing an invocationBuilder.method(\"GET\", ...), use invocationBuilder.post(entity), as described here. This will allow you to POST your transaction String to the endpoint.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73259387,
                        "answer_post": "To parse XML use XML parser. One of easier but yet powerful ones is Jsoup which allows us to write code like\n\nOutput: {1=0, 2=7, 3=22, 4=2, 5=1}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72520904,
                        "answer_post": "Typically this is done with the Apache Commons library's trim method. This library is so commonplace that it's basically part of Java. It will return null for null Strings. E.g. StringUtils.trim(\"myString \"); would return \"myString\"\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72680413,
                        "answer_post": "JsonUnit with AssertJ style is probably the best option:\n\nHowever, I would have expected the AssertJ recursive comparison to work as well:\n\nbut this is not the case.\nI created #2672 to track this potential improvement.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72394099,
                        "answer_post": "You can use JAXB parser instead of SAX, It converts each element tag into a Java objects and easily configurable too. But we need to create classes for each element tag in the XML file as mentioned in this article https://www.javatpoint.com/jaxb-tutorial\nAs per your data your root class will be like below:\n\nFollowing method helps to convert XML into JavaObject:\nRequired parameters are:\n\nInputStream (Inputstream of the XML file)\nClass (Class name of the root element in the XML com.a.b.c.DtecBs)\n\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72888526,
                        "answer_post": "\nUse the Character API\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76095804,
                        "answer_post": "See this please\nfor Java\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73398356,
                        "answer_post": "Ideally you should use a library like SAX parser to Deserialize an input stream like XML.\nBut if you want to do this using no libraries maybe the method below can help:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73489047,
                        "answer_post": "java version:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75052469,
                        "answer_post": "Use loadStrings or loadBytes\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74960566,
                        "answer_post": "Use DataNode\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77198249,
                        "answer_post": "Using java.time\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72711160,
                        "answer_post": "use this data class\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77499417,
                        "answer_post": "Use the DecimalFormat class.\n\nOutput\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I have resolved this issue, it was due to another bug in my own code.\nSo it had nothing to do with the SAXParser. Thanks for all the help!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Check for these problems:\n\nIf there are characters before the XML declaration (<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>), delete them.\n\nIf you're parsing a non-XML file, change to parsing an actual XML file.\n\nIf you're passing the filename to a call that expects a string of XML, change to passing a string of XML.\n\nIf you're receiving Base64-encoded, compressed, or otherwise represented XML, decode/decompress/convert it before parsing.\n\n\nSee also\n\nError: The processing instruction target matching \"[xX][mM][lL]\" is not allowed\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "There are a few ways to read the XML file and extract the information you need without using a lot of if statements. One approach is to use an XML parsing library such as JAXB or SAX, and create Java classes to represent the XML elements.\nIn JAXB, you can use the javax.xml.bind.Unmarshaller class to unmarshal the XML file into a Java object, which you can then traverse to extract the information you need.\nYou should start creating a Java classes based on the XML structure, like FlowMonitor, Menu1, Item, Connection etc. , and use annotation to map the xml elements to the fields.\nThen, you can use the unmarshaller.unmarshal() method to parse the XML file and create an instance of the FlowMonitor class, which will contain all the information from the XML file.\nOnce you have the FlowMonitor object you can loop through the items, and get the description and filename by calling getDescriptionValue() and getFilenameValue() of the item object....\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You're getting the error since your @XmlRootElement misses the XML namespace (xmlns) but since your XML documents contains a lot of child elements with different namespaces I doubt adding this would be enough. Usually you would start with the XML schema of BPMN and generate Java classes out of it.\nI think another option in this special case would be not to use JAXB but the Camunda Model API.\nAnother thing: Do yourself a favor and never convert between XML documents, which come as byte array usually, and String using new String() or String.getBytes(). If you do this without watching the character set within the XML declaration of your document, or UTF-8 if its missing, you'll get mangled characters sooner or later. Every conversion between byte [] and String either assumes a character set or encoding (default platform encoding) or expects it as a parameter.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nOne way could be to maintain a boolean variable var insideA=false, (\u2026)\n\nYes, that looks like the usual way to address your goal using SAX.\n\nAny suggestions for an alternative approach?\n\nSAX is a bit complex to setup, but \"better\" than DOM / XPath regarding memory usage. Anyway:\nIf your XML document fits in RAM,\nyou can also try using XPath (internally based on the DOM model), which is simpler to use.\nAs you tagged your question with java, here is a nice tutorial for evaluating XPath expressions in Java, see also the official W3C spec. (a.k.a. recommendation), and this online XPath tester.\nIf your XML is huge and you find SAX a bit annoying to use,\nyou can try using StAX, which combines the performance of streaming-based parsing and the usability of \"pull parsing\" (roughly, no callback anymore).\nSee also this example tutorial in Java.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You can use JAXB parser instead of SAX, It converts each element tag into a Java objects and easily configurable too. But we need to create classes for each element tag in the XML file as mentioned in this article https://www.javatpoint.com/jaxb-tutorial\nAs per your data your root class will be like below:\n\nFollowing method helps to convert XML into JavaObject:\nRequired parameters are:\n\nInputStream (Inputstream of the XML file)\nClass (Class name of the root element in the XML com.a.b.c.DtecBs)\n\n\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "directive": {
                "finetuned_dpr": [
                    {
                        "id": 73384382,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74745279,
                        "answer_post": "I have resolved this issue, it was due to another bug in my own code.\nSo it had nothing to do with the SAXParser. Thanks for all the help!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73064025,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73398356,
                        "answer_post": "Ideally you should use a library like SAX parser to Deserialize an input stream like XML.\nBut if you want to do this using no libraries maybe the method below can help:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77003634,
                        "answer_post": "\nOne way could be to maintain a boolean variable var insideA=false, (\u2026)\n\nYes, that looks like the usual way to address your goal using SAX.\n\nAny suggestions for an alternative approach?\n\nSAX is a bit complex to setup, but \"better\" than DOM / XPath regarding memory usage. Anyway:\nIf your XML document fits in RAM,\nyou can also try using XPath (internally based on the DOM model), which is simpler to use.\nAs you tagged your question with java, here is a nice tutorial for evaluating XPath expressions in Java, see also the official W3C spec. (a.k.a. recommendation), and this online XPath tester.\nIf your XML is huge and you find SAX a bit annoying to use,\nyou can try using StAX, which combines the performance of streaming-based parsing and the usability of \"pull parsing\" (roughly, no callback anymore).\nSee also this example tutorial in Java.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72434146,
                        "answer_post": "I managed to implement a solution based on Schema.newValidatorHandler(). I lost most time with the fact that SaxParser.parse() only accepts a DefaultHandler. To insert a custom ContentHandler, one has to use SaxParser.getXMLReader().setContentHandler().\nI am aware that this proof of concept is not very robust, because it is parsing the validation error message to extract the maxLength schema information. So this solution is relying on a very specific SAX implementation.\nI looked at schema aware XSLT transformation, but could not find any indication that the schema information can be accessed in the transformation expressions.\nWriting my own specialized schema parser is still not completely off the table.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76292324,
                        "answer_post": "cts.documentQuery(cts.uriMatch(\"/directory/*/folder/*.xml\"))\nIs this what you are expecting? This is the server side javascript (XQuery) equivalent of what you have asked.\nIf you want to pass a serialized query, you should first execute cts:uri-match(\"/directory/*/folder/*.xml\") and then enclose the results into cts:document-query as shown below\n\nBest approach is to create a MarkLogic module server-side (in XQuery or JS) and invoke it from JAVA client API (by passing the uri-match string)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77085031,
                        "answer_post": "Obviously, you need to parse the whole document, and the fastest way way to arrive at a solution is to not include the \"filtered out\" elements in the document building process. Both DOM4J and JDOM are good alternatives for this, since they allow custom document builders that can defer or allow the tree construction based on previously obtained conditions. SAX/StAX is of course also an alternative, but at a lower level and require more infrastructure code to get a result.\nSearch this site for DOM4J/JDOM and builder, I may already have given the answer ;)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 78820176,
                        "answer_post": "SXSSF library is mainly for writing the large (xlsx) files with 2^20 (1,048,576) rows per sheet, but not for reading the data from excel file. To read the data from excel, Apache poi provides SAX parsing based event handling. Please refer to this: https://poi.apache.org/components/spreadsheet/how-to.html#xssf_sax_api\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73411361,
                        "answer_post": "It's a bit awkward but it seems to do the first part of what I need to do which is get the reflection data\n\nThe follow up question would be given that I have this info, how do I make the call building from JSON input that is to be parsed to a format used by the GRPC server?\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77193930,
                        "answer_post": "SchemaParser is deprecated in favor of SchemaRepository.\nFirst, create the repository:\n\nThen use it in the ValidationHandlerBuilder:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73064025,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72809808,
                        "answer_post": "Instead of doing an invocationBuilder.method(\"GET\", ...), use invocationBuilder.post(entity), as described here. This will allow you to POST your transaction String to the endpoint.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74224422,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 78820176,
                        "answer_post": "SXSSF library is mainly for writing the large (xlsx) files with 2^20 (1,048,576) rows per sheet, but not for reading the data from excel file. To read the data from excel, Apache poi provides SAX parsing based event handling. Please refer to this: https://poi.apache.org/components/spreadsheet/how-to.html#xssf_sax_api\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72520904,
                        "answer_post": "Typically this is done with the Apache Commons library's trim method. This library is so commonplace that it's basically part of Java. It will return null for null Strings. E.g. StringUtils.trim(\"myString \"); would return \"myString\"\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73259387,
                        "answer_post": "To parse XML use XML parser. One of easier but yet powerful ones is Jsoup which allows us to write code like\n\nOutput: {1=0, 2=7, 3=22, 4=2, 5=1}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76200100,
                        "answer_post": "\nWhen running the project, hibernate creates a table named hte_item in oracle.\n\nThe hte_item table is a temporary table used by Hibernate for certain bulk update and delete queries. It is not the name of the table where Items are made persistent.\nSince you've specified @Table(name = \"item\") you must have a table named item in your database. If you want Hibernate to export that table for you, then you need to explicitly enable schema export, by setting a config property:\n\nor whatever.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75938972,
                        "answer_post": "If this works with Postman, likely the issue is in the client part.\nMultipart is not APPLICATION_JSON (\"application/json\"). Try to use \"multipart/form-data\" or \"application/octet-stream\" when you prepare the entity and in request(). Also try to remove .accept(APPLICATION_JSON) completely.\nConsider using higher level http clients. Some references:\nhttps://www.baeldung.com/httpclient-multipart-upload\nhttps://www.baeldung.com/spring-rest-template-multipart-upload\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 73398356,
                        "answer_post": "Ideally you should use a library like SAX parser to Deserialize an input stream like XML.\nBut if you want to do this using no libraries maybe the method below can help:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76095804,
                        "answer_post": "See this please\nfor Java\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72888526,
                        "answer_post": "\nUse the Character API\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73489047,
                        "answer_post": "java version:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74960566,
                        "answer_post": "Use DataNode\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75052469,
                        "answer_post": "Use loadStrings or loadBytes\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77198249,
                        "answer_post": "Using java.time\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77075486,
                        "answer_post": "pom.xml\n\napplication.properties\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I have resolved this issue, it was due to another bug in my own code.\nSo it had nothing to do with the SAXParser. Thanks for all the help!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Check for these problems:\n\nIf there are characters before the XML declaration (<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>), delete them.\n\nIf you're parsing a non-XML file, change to parsing an actual XML file.\n\nIf you're passing the filename to a call that expects a string of XML, change to passing a string of XML.\n\nIf you're receiving Base64-encoded, compressed, or otherwise represented XML, decode/decompress/convert it before parsing.\n\n\nSee also\n\nError: The processing instruction target matching \"[xX][mM][lL]\" is not allowed\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "There are a few ways to read the XML file and extract the information you need without using a lot of if statements. One approach is to use an XML parsing library such as JAXB or SAX, and create Java classes to represent the XML elements.\nIn JAXB, you can use the javax.xml.bind.Unmarshaller class to unmarshal the XML file into a Java object, which you can then traverse to extract the information you need.\nYou should start creating a Java classes based on the XML structure, like FlowMonitor, Menu1, Item, Connection etc. , and use annotation to map the xml elements to the fields.\nThen, you can use the unmarshaller.unmarshal() method to parse the XML file and create an instance of the FlowMonitor class, which will contain all the information from the XML file.\nOnce you have the FlowMonitor object you can loop through the items, and get the description and filename by calling getDescriptionValue() and getFilenameValue() of the item object....\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You're getting the error since your @XmlRootElement misses the XML namespace (xmlns) but since your XML documents contains a lot of child elements with different namespaces I doubt adding this would be enough. Usually you would start with the XML schema of BPMN and generate Java classes out of it.\nI think another option in this special case would be not to use JAXB but the Camunda Model API.\nAnother thing: Do yourself a favor and never convert between XML documents, which come as byte array usually, and String using new String() or String.getBytes(). If you do this without watching the character set within the XML declaration of your document, or UTF-8 if its missing, you'll get mangled characters sooner or later. Every conversion between byte [] and String either assumes a character set or encoding (default platform encoding) or expects it as a parameter.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "In a Spring Boot application using JAXB for XML serialization/deserialization, the @XmlRootElement(name = \"request\") annotation should work as expected to rename the root element of the generated XML. However, if it's not working as expected, there could be a few reasons to investigate...\nFirst of all, you mentioned that there's a dependency on javax.xml.rpc-api. This could potentially cause conflicts or interfere with JAXB annotations. JAXB and javax.xml.rpc are two different Java technologies for handling XML. Ensure that the conflicting dependency doesn't override JAXB annotations or configurations.\nNext I would ensure the JAXB Context Configuration: Make sure that your Spring Boot application has been correctly configured to use JAXB for XML processing. Spring Boot typically configures JAXB automatically, but if you have any custom configurations or if you've disabled auto-configuration, ensure that the JAXB context is properly set up.\nFor example, you can configure the JAXB context explicitly by creating a Jaxb2Marshaller bean in your Spring configuration and specifying the package where your JAXB-annotated classes are located, just like this:\n\n2 more less possible reasons, could be:\n\nCheck the Classpath (correct version of JAXB (jaxb-api and jaxb-impl) is on your classpath. )\nInspect Generated XML (verify that the generated XML indeed contains the  element by examining the output or using a\ntool to pretty-print the XML. This will help confirm whether the\nissue is with JAXB annotations or with the receiving end's\nexpectations.)\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "A fair number of questions there.\n\nThe cert in the keystore validated that the XML is signed by the expected key.  You can't implicitly trust the signature in the XML file.  It's like me providing you a picture ID that consists of a mirror with \"me\" written at the top.  It might be correct but it's not real reliable.\n\nFormatting XML must be done before it is signed.  The canonicalization of XML is meant to ensure that the XML being signed is equivalent.  It processes the XML with rules to ensure that equivalent XML would have the same signature but some formatting and tidying after the signature would break it.  While I do like nicely formatted XML it's meant to be processed by by computers so don't worry too much about it...\n\n\n\nUpdate 1:\n\nThe original xml is well formatted. Currently, only the ds:Signature node is not well formatted.\n\n\nNot much to be done with that in general.  Signing the XML requires the library to create an xml fragment containing a digest for the canonical version of your XML.  The fragment is then signed and the result is another XML fragment.  In general they are independent in that as long as you don't change what makes an equivalent canonical xml but there are enough rules to make it difficult for the library to make it pretty when combined.   You would need to have a combined original XML and Signature in a pretty format and then update the Signature/SignedInfo with the parts that change.  For example insert the new signature value for the SignedInfo into a complete document that you know is well formatted.\n\n\nWhen process the sign with the apache library, How do we know the XML file is already formatted? Because the XML file is now represented\nas Java objects.\n\n\nMost (many? some?) XML libraries have a function that can format the XML as \"pretty\" (or well formatted).  However the nature of Signed XML would mean that the signature could be affected by doing that.\n\n\nUsually, the content between > and <, like in this piece of this is content, this is content is the payload, Does the\nsigning process only sign the payload? or it will contain the ,\n<\\Item>, even more it will include some blank space before the \nlike    and some \\n in the end of <\\Item>?\n\n\nThe rules vary somewhat by canonicalization method.  See https://www.w3.org/TR/xml-c14n/#Terminology for example.  But I would expect that\n\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "pattern": {
                "finetuned_dpr": [
                    {
                        "id": 73384382,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73064025,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74745279,
                        "answer_post": "I have resolved this issue, it was due to another bug in my own code.\nSo it had nothing to do with the SAXParser. Thanks for all the help!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73398356,
                        "answer_post": "Ideally you should use a library like SAX parser to Deserialize an input stream like XML.\nBut if you want to do this using no libraries maybe the method below can help:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77003634,
                        "answer_post": "\nOne way could be to maintain a boolean variable var insideA=false, (\u2026)\n\nYes, that looks like the usual way to address your goal using SAX.\n\nAny suggestions for an alternative approach?\n\nSAX is a bit complex to setup, but \"better\" than DOM / XPath regarding memory usage. Anyway:\nIf your XML document fits in RAM,\nyou can also try using XPath (internally based on the DOM model), which is simpler to use.\nAs you tagged your question with java, here is a nice tutorial for evaluating XPath expressions in Java, see also the official W3C spec. (a.k.a. recommendation), and this online XPath tester.\nIf your XML is huge and you find SAX a bit annoying to use,\nyou can try using StAX, which combines the performance of streaming-based parsing and the usability of \"pull parsing\" (roughly, no callback anymore).\nSee also this example tutorial in Java.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72434146,
                        "answer_post": "I managed to implement a solution based on Schema.newValidatorHandler(). I lost most time with the fact that SaxParser.parse() only accepts a DefaultHandler. To insert a custom ContentHandler, one has to use SaxParser.getXMLReader().setContentHandler().\nI am aware that this proof of concept is not very robust, because it is parsing the validation error message to extract the maxLength schema information. So this solution is relying on a very specific SAX implementation.\nI looked at schema aware XSLT transformation, but could not find any indication that the schema information can be accessed in the transformation expressions.\nWriting my own specialized schema parser is still not completely off the table.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76292324,
                        "answer_post": "cts.documentQuery(cts.uriMatch(\"/directory/*/folder/*.xml\"))\nIs this what you are expecting? This is the server side javascript (XQuery) equivalent of what you have asked.\nIf you want to pass a serialized query, you should first execute cts:uri-match(\"/directory/*/folder/*.xml\") and then enclose the results into cts:document-query as shown below\n\nBest approach is to create a MarkLogic module server-side (in XQuery or JS) and invoke it from JAVA client API (by passing the uri-match string)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76818846,
                        "answer_post": "Here's what I've done. Please tell me why this is wrong. It feels wrong, it smells wrong.\nI added this class\n\nIt now starts up just fine.\nWhy did I even try this? Well, the article Configure and Use Multiple DataSources in Spring Boot implies I need to make one of my existing EMF beans be the primary. I can't find how to do that in XML. I don't really want to pull all the XML into code, and adding @Primary to FirstDAO didn't do the trick. This does.\nBut it smells wrong :-(\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77085031,
                        "answer_post": "Obviously, you need to parse the whole document, and the fastest way way to arrive at a solution is to not include the \"filtered out\" elements in the document building process. Both DOM4J and JDOM are good alternatives for this, since they allow custom document builders that can defer or allow the tree construction based on previously obtained conditions. SAX/StAX is of course also an alternative, but at a lower level and require more infrastructure code to get a result.\nSearch this site for DOM4J/JDOM and builder, I may already have given the answer ;)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 78820176,
                        "answer_post": "SXSSF library is mainly for writing the large (xlsx) files with 2^20 (1,048,576) rows per sheet, but not for reading the data from excel file. To read the data from excel, Apache poi provides SAX parsing based event handling. Please refer to this: https://poi.apache.org/components/spreadsheet/how-to.html#xssf_sax_api\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77193930,
                        "answer_post": "SchemaParser is deprecated in favor of SchemaRepository.\nFirst, create the repository:\n\nThen use it in the ValidationHandlerBuilder:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72809808,
                        "answer_post": "Instead of doing an invocationBuilder.method(\"GET\", ...), use invocationBuilder.post(entity), as described here. This will allow you to POST your transaction String to the endpoint.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73064025,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74224422,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 78820176,
                        "answer_post": "SXSSF library is mainly for writing the large (xlsx) files with 2^20 (1,048,576) rows per sheet, but not for reading the data from excel file. To read the data from excel, Apache poi provides SAX parsing based event handling. Please refer to this: https://poi.apache.org/components/spreadsheet/how-to.html#xssf_sax_api\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73259387,
                        "answer_post": "To parse XML use XML parser. One of easier but yet powerful ones is Jsoup which allows us to write code like\n\nOutput: {1=0, 2=7, 3=22, 4=2, 5=1}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72520904,
                        "answer_post": "Typically this is done with the Apache Commons library's trim method. This library is so commonplace that it's basically part of Java. It will return null for null Strings. E.g. StringUtils.trim(\"myString \"); would return \"myString\"\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76798793,
                        "answer_post": "In Java, primitive types, including boolean, are passed by value, meaning they cannot be modified by other methods. Class types, including List, are passed by reference, which means that they can be modified by other methods. (As pointed out by @WJS, the list cannot be modified directly, only its contents, so this is sometimes called \"call by sharing\", but it is very similar)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74949774,
                        "answer_post": "According to the Java Language Specification:\n\nString contexts apply only to an operand of the binary + operator which is not a String when the other operand is a String.\n\n\nThe target type in these contexts is always String, and a string conversion (\u00a75.1.11) of the non-String operand always occurs.\n\nWhich means that when you do hp + brand, since brand is a String the rule above kicks in, hp gets converted to a String and concatenation occurs, resulting in a String.\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72888526,
                        "answer_post": "\nUse the Character API\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76095804,
                        "answer_post": "See this please\nfor Java\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73398356,
                        "answer_post": "Ideally you should use a library like SAX parser to Deserialize an input stream like XML.\nBut if you want to do this using no libraries maybe the method below can help:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74960566,
                        "answer_post": "Use DataNode\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72711160,
                        "answer_post": "use this data class\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73489047,
                        "answer_post": "java version:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75052469,
                        "answer_post": "Use loadStrings or loadBytes\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74943724,
                        "answer_post": "Call this, below replaceFragment\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77198249,
                        "answer_post": "Using java.time\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I have resolved this issue, it was due to another bug in my own code.\nSo it had nothing to do with the SAXParser. Thanks for all the help!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Check for these problems:\n\nIf there are characters before the XML declaration (<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>), delete them.\n\nIf you're parsing a non-XML file, change to parsing an actual XML file.\n\nIf you're passing the filename to a call that expects a string of XML, change to passing a string of XML.\n\nIf you're receiving Base64-encoded, compressed, or otherwise represented XML, decode/decompress/convert it before parsing.\n\n\nSee also\n\nError: The processing instruction target matching \"[xX][mM][lL]\" is not allowed\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "There are a few ways to read the XML file and extract the information you need without using a lot of if statements. One approach is to use an XML parsing library such as JAXB or SAX, and create Java classes to represent the XML elements.\nIn JAXB, you can use the javax.xml.bind.Unmarshaller class to unmarshal the XML file into a Java object, which you can then traverse to extract the information you need.\nYou should start creating a Java classes based on the XML structure, like FlowMonitor, Menu1, Item, Connection etc. , and use annotation to map the xml elements to the fields.\nThen, you can use the unmarshaller.unmarshal() method to parse the XML file and create an instance of the FlowMonitor class, which will contain all the information from the XML file.\nOnce you have the FlowMonitor object you can loop through the items, and get the description and filename by calling getDescriptionValue() and getFilenameValue() of the item object....\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You're getting the error since your @XmlRootElement misses the XML namespace (xmlns) but since your XML documents contains a lot of child elements with different namespaces I doubt adding this would be enough. Usually you would start with the XML schema of BPMN and generate Java classes out of it.\nI think another option in this special case would be not to use JAXB but the Camunda Model API.\nAnother thing: Do yourself a favor and never convert between XML documents, which come as byte array usually, and String using new String() or String.getBytes(). If you do this without watching the character set within the XML declaration of your document, or UTF-8 if its missing, you'll get mangled characters sooner or later. Every conversion between byte [] and String either assumes a character set or encoding (default platform encoding) or expects it as a parameter.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can use JAXB parser instead of SAX, It converts each element tag into a Java objects and easily configurable too. But we need to create classes for each element tag in the XML file as mentioned in this article https://www.javatpoint.com/jaxb-tutorial\nAs per your data your root class will be like below:\n\nFollowing method helps to convert XML into JavaObject:\nRequired parameters are:\n\nInputStream (Inputstream of the XML file)\nClass (Class name of the root element in the XML com.a.b.c.DtecBs)\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "tag <064E> is illegal:\nRead up on the rules for XML tag names :\nhttps://www.w3schools.com/xml/xml_elements.asp\nAs a workaround you could use an _ before the number character or write your custom xml parser  :\nBest method to parse various custom XML documents in Java\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "environment": {
                "finetuned_dpr": [
                    {
                        "id": 73384382,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74745279,
                        "answer_post": "I have resolved this issue, it was due to another bug in my own code.\nSo it had nothing to do with the SAXParser. Thanks for all the help!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73064025,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73398356,
                        "answer_post": "Ideally you should use a library like SAX parser to Deserialize an input stream like XML.\nBut if you want to do this using no libraries maybe the method below can help:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77003634,
                        "answer_post": "\nOne way could be to maintain a boolean variable var insideA=false, (\u2026)\n\nYes, that looks like the usual way to address your goal using SAX.\n\nAny suggestions for an alternative approach?\n\nSAX is a bit complex to setup, but \"better\" than DOM / XPath regarding memory usage. Anyway:\nIf your XML document fits in RAM,\nyou can also try using XPath (internally based on the DOM model), which is simpler to use.\nAs you tagged your question with java, here is a nice tutorial for evaluating XPath expressions in Java, see also the official W3C spec. (a.k.a. recommendation), and this online XPath tester.\nIf your XML is huge and you find SAX a bit annoying to use,\nyou can try using StAX, which combines the performance of streaming-based parsing and the usability of \"pull parsing\" (roughly, no callback anymore).\nSee also this example tutorial in Java.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72434146,
                        "answer_post": "I managed to implement a solution based on Schema.newValidatorHandler(). I lost most time with the fact that SaxParser.parse() only accepts a DefaultHandler. To insert a custom ContentHandler, one has to use SaxParser.getXMLReader().setContentHandler().\nI am aware that this proof of concept is not very robust, because it is parsing the validation error message to extract the maxLength schema information. So this solution is relying on a very specific SAX implementation.\nI looked at schema aware XSLT transformation, but could not find any indication that the schema information can be accessed in the transformation expressions.\nWriting my own specialized schema parser is still not completely off the table.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76292324,
                        "answer_post": "cts.documentQuery(cts.uriMatch(\"/directory/*/folder/*.xml\"))\nIs this what you are expecting? This is the server side javascript (XQuery) equivalent of what you have asked.\nIf you want to pass a serialized query, you should first execute cts:uri-match(\"/directory/*/folder/*.xml\") and then enclose the results into cts:document-query as shown below\n\nBest approach is to create a MarkLogic module server-side (in XQuery or JS) and invoke it from JAVA client API (by passing the uri-match string)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77085031,
                        "answer_post": "Obviously, you need to parse the whole document, and the fastest way way to arrive at a solution is to not include the \"filtered out\" elements in the document building process. Both DOM4J and JDOM are good alternatives for this, since they allow custom document builders that can defer or allow the tree construction based on previously obtained conditions. SAX/StAX is of course also an alternative, but at a lower level and require more infrastructure code to get a result.\nSearch this site for DOM4J/JDOM and builder, I may already have given the answer ;)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74224422,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 78820176,
                        "answer_post": "SXSSF library is mainly for writing the large (xlsx) files with 2^20 (1,048,576) rows per sheet, but not for reading the data from excel file. To read the data from excel, Apache poi provides SAX parsing based event handling. Please refer to this: https://poi.apache.org/components/spreadsheet/how-to.html#xssf_sax_api\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77193930,
                        "answer_post": "SchemaParser is deprecated in favor of SchemaRepository.\nFirst, create the repository:\n\nThen use it in the ValidationHandlerBuilder:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72809808,
                        "answer_post": "Instead of doing an invocationBuilder.method(\"GET\", ...), use invocationBuilder.post(entity), as described here. This will allow you to POST your transaction String to the endpoint.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 78820176,
                        "answer_post": "SXSSF library is mainly for writing the large (xlsx) files with 2^20 (1,048,576) rows per sheet, but not for reading the data from excel file. To read the data from excel, Apache poi provides SAX parsing based event handling. Please refer to this: https://poi.apache.org/components/spreadsheet/how-to.html#xssf_sax_api\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73064025,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74224422,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73259387,
                        "answer_post": "To parse XML use XML parser. One of easier but yet powerful ones is Jsoup which allows us to write code like\n\nOutput: {1=0, 2=7, 3=22, 4=2, 5=1}\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72520904,
                        "answer_post": "Typically this is done with the Apache Commons library's trim method. This library is so commonplace that it's basically part of Java. It will return null for null Strings. E.g. StringUtils.trim(\"myString \"); would return \"myString\"\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75828396,
                        "answer_post": "You can use a Map to build the Metadata object, which can then be passed to SchemaExport execute method:\n\nSource\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76200100,
                        "answer_post": "\nWhen running the project, hibernate creates a table named hte_item in oracle.\n\nThe hte_item table is a temporary table used by Hibernate for certain bulk update and delete queries. It is not the name of the table where Items are made persistent.\nSince you've specified @Table(name = \"item\") you must have a table named item in your database. If you want Hibernate to export that table for you, then you need to explicitly enable schema export, by setting a config property:\n\nor whatever.\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72888526,
                        "answer_post": "\nUse the Character API\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76095804,
                        "answer_post": "See this please\nfor Java\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73398356,
                        "answer_post": "Ideally you should use a library like SAX parser to Deserialize an input stream like XML.\nBut if you want to do this using no libraries maybe the method below can help:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77075486,
                        "answer_post": "pom.xml\n\napplication.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73489047,
                        "answer_post": "java version:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76883763,
                        "answer_post": "For CORS Configuration\n\nFor Token\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76048454,
                        "answer_post": "android.R.attr.fingerprintAuthDrawable\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 78852629,
                        "answer_post": "Defining a RestTemplate bean:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I have resolved this issue, it was due to another bug in my own code.\nSo it had nothing to do with the SAXParser. Thanks for all the help!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Check for these problems:\n\nIf there are characters before the XML declaration (<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>), delete them.\n\nIf you're parsing a non-XML file, change to parsing an actual XML file.\n\nIf you're passing the filename to a call that expects a string of XML, change to passing a string of XML.\n\nIf you're receiving Base64-encoded, compressed, or otherwise represented XML, decode/decompress/convert it before parsing.\n\n\nSee also\n\nError: The processing instruction target matching \"[xX][mM][lL]\" is not allowed\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "There are a few ways to read the XML file and extract the information you need without using a lot of if statements. One approach is to use an XML parsing library such as JAXB or SAX, and create Java classes to represent the XML elements.\nIn JAXB, you can use the javax.xml.bind.Unmarshaller class to unmarshal the XML file into a Java object, which you can then traverse to extract the information you need.\nYou should start creating a Java classes based on the XML structure, like FlowMonitor, Menu1, Item, Connection etc. , and use annotation to map the xml elements to the fields.\nThen, you can use the unmarshaller.unmarshal() method to parse the XML file and create an instance of the FlowMonitor class, which will contain all the information from the XML file.\nOnce you have the FlowMonitor object you can loop through the items, and get the description and filename by calling getDescriptionValue() and getFilenameValue() of the item object....\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You're getting the error since your @XmlRootElement misses the XML namespace (xmlns) but since your XML documents contains a lot of child elements with different namespaces I doubt adding this would be enough. Usually you would start with the XML schema of BPMN and generate Java classes out of it.\nI think another option in this special case would be not to use JAXB but the Camunda Model API.\nAnother thing: Do yourself a favor and never convert between XML documents, which come as byte array usually, and String using new String() or String.getBytes(). If you do this without watching the character set within the XML declaration of your document, or UTF-8 if its missing, you'll get mangled characters sooner or later. Every conversion between byte [] and String either assumes a character set or encoding (default platform encoding) or expects it as a parameter.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can use JAXB parser instead of SAX, It converts each element tag into a Java objects and easily configurable too. But we need to create classes for each element tag in the XML file as mentioned in this article https://www.javatpoint.com/jaxb-tutorial\nAs per your data your root class will be like below:\n\nFollowing method helps to convert XML into JavaObject:\nRequired parameters are:\n\nInputStream (Inputstream of the XML file)\nClass (Class name of the root element in the XML com.a.b.c.DtecBs)\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "tag <064E> is illegal:\nRead up on the rules for XML tag names :\nhttps://www.w3schools.com/xml/xml_elements.asp\nAs a workaround you could use an _ before the number character or write your custom xml parser  :\nBest method to parse various custom XML documents in Java\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "alternative": {
                "finetuned_dpr": [
                    {
                        "id": 73384382,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73064025,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74745279,
                        "answer_post": "I have resolved this issue, it was due to another bug in my own code.\nSo it had nothing to do with the SAXParser. Thanks for all the help!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73398356,
                        "answer_post": "Ideally you should use a library like SAX parser to Deserialize an input stream like XML.\nBut if you want to do this using no libraries maybe the method below can help:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77003634,
                        "answer_post": "\nOne way could be to maintain a boolean variable var insideA=false, (\u2026)\n\nYes, that looks like the usual way to address your goal using SAX.\n\nAny suggestions for an alternative approach?\n\nSAX is a bit complex to setup, but \"better\" than DOM / XPath regarding memory usage. Anyway:\nIf your XML document fits in RAM,\nyou can also try using XPath (internally based on the DOM model), which is simpler to use.\nAs you tagged your question with java, here is a nice tutorial for evaluating XPath expressions in Java, see also the official W3C spec. (a.k.a. recommendation), and this online XPath tester.\nIf your XML is huge and you find SAX a bit annoying to use,\nyou can try using StAX, which combines the performance of streaming-based parsing and the usability of \"pull parsing\" (roughly, no callback anymore).\nSee also this example tutorial in Java.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72434146,
                        "answer_post": "I managed to implement a solution based on Schema.newValidatorHandler(). I lost most time with the fact that SaxParser.parse() only accepts a DefaultHandler. To insert a custom ContentHandler, one has to use SaxParser.getXMLReader().setContentHandler().\nI am aware that this proof of concept is not very robust, because it is parsing the validation error message to extract the maxLength schema information. So this solution is relying on a very specific SAX implementation.\nI looked at schema aware XSLT transformation, but could not find any indication that the schema information can be accessed in the transformation expressions.\nWriting my own specialized schema parser is still not completely off the table.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77085031,
                        "answer_post": "Obviously, you need to parse the whole document, and the fastest way way to arrive at a solution is to not include the \"filtered out\" elements in the document building process. Both DOM4J and JDOM are good alternatives for this, since they allow custom document builders that can defer or allow the tree construction based on previously obtained conditions. SAX/StAX is of course also an alternative, but at a lower level and require more infrastructure code to get a result.\nSearch this site for DOM4J/JDOM and builder, I may already have given the answer ;)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76292324,
                        "answer_post": "cts.documentQuery(cts.uriMatch(\"/directory/*/folder/*.xml\"))\nIs this what you are expecting? This is the server side javascript (XQuery) equivalent of what you have asked.\nIf you want to pass a serialized query, you should first execute cts:uri-match(\"/directory/*/folder/*.xml\") and then enclose the results into cts:document-query as shown below\n\nBest approach is to create a MarkLogic module server-side (in XQuery or JS) and invoke it from JAVA client API (by passing the uri-match string)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76818846,
                        "answer_post": "Here's what I've done. Please tell me why this is wrong. It feels wrong, it smells wrong.\nI added this class\n\nIt now starts up just fine.\nWhy did I even try this? Well, the article Configure and Use Multiple DataSources in Spring Boot implies I need to make one of my existing EMF beans be the primary. I can't find how to do that in XML. I don't really want to pull all the XML into code, and adding @Primary to FirstDAO didn't do the trick. This does.\nBut it smells wrong :-(\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77193930,
                        "answer_post": "SchemaParser is deprecated in favor of SchemaRepository.\nFirst, create the repository:\n\nThen use it in the ValidationHandlerBuilder:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73064025,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72809808,
                        "answer_post": "Instead of doing an invocationBuilder.method(\"GET\", ...), use invocationBuilder.post(entity), as described here. This will allow you to POST your transaction String to the endpoint.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74224422,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 78820176,
                        "answer_post": "SXSSF library is mainly for writing the large (xlsx) files with 2^20 (1,048,576) rows per sheet, but not for reading the data from excel file. To read the data from excel, Apache poi provides SAX parsing based event handling. Please refer to this: https://poi.apache.org/components/spreadsheet/how-to.html#xssf_sax_api\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73259387,
                        "answer_post": "To parse XML use XML parser. One of easier but yet powerful ones is Jsoup which allows us to write code like\n\nOutput: {1=0, 2=7, 3=22, 4=2, 5=1}\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72520904,
                        "answer_post": "Typically this is done with the Apache Commons library's trim method. This library is so commonplace that it's basically part of Java. It will return null for null Strings. E.g. StringUtils.trim(\"myString \"); would return \"myString\"\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75938972,
                        "answer_post": "If this works with Postman, likely the issue is in the client part.\nMultipart is not APPLICATION_JSON (\"application/json\"). Try to use \"multipart/form-data\" or \"application/octet-stream\" when you prepare the entity and in request(). Also try to remove .accept(APPLICATION_JSON) completely.\nConsider using higher level http clients. Some references:\nhttps://www.baeldung.com/httpclient-multipart-upload\nhttps://www.baeldung.com/spring-rest-template-multipart-upload\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72680413,
                        "answer_post": "JsonUnit with AssertJ style is probably the best option:\n\nHowever, I would have expected the AssertJ recursive comparison to work as well:\n\nbut this is not the case.\nI created #2672 to track this potential improvement.\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 76095804,
                        "answer_post": "See this please\nfor Java\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72888526,
                        "answer_post": "\nUse the Character API\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74943724,
                        "answer_post": "Call this, below replaceFragment\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73489047,
                        "answer_post": "java version:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73398356,
                        "answer_post": "Ideally you should use a library like SAX parser to Deserialize an input stream like XML.\nBut if you want to do this using no libraries maybe the method below can help:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72450577,
                        "answer_post": "You can write a SAX ContentHandler that duplicates each event sending it to two different ContentHandlers, one being your current one, and the other being a JAXP TransformerHandler that serializes the stream of events to a StreamResult.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73263627,
                        "answer_post": "Try java streams:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77198249,
                        "answer_post": "Using java.time\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75052469,
                        "answer_post": "Use loadStrings or loadBytes\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 78852629,
                        "answer_post": "Defining a RestTemplate bean:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "There is no automatic way to split a big xml in several smaller xml.\nAs an extreme simplification a single xml represent a single object with properties.\nSplitting it in different xmls means splitting a single object in multiple objects. This is not something that can be done automatically.\nLet show a simple example. Imagine to have this xml\n\nHow do you split it? Is the following a valid way to split it? (It is a business decision how to split and recombine it).\n\nIf the problem is not related to spliting a big xml to smaller xmls, but to split a single big file to smaller files you can split it as\n\nand\n\nBut if the problem is the size of the file to send it over the internet or to save space when saving it, consider also to compress it. Compressing an xml file results in a very smaller compressed result. Eventually you can split the compressed file.\nIf the problem instead is to hold in memory the whole file simply don't do that.  Use a SAX parser instead of a DOM parser so you can hold in memory just a little portion of the original xml. A Sax parser is:\n\nSAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list.1 SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole\u2014building the full abstract syntax tree of an XML document for convenience of the user\u2014SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making a single pass[clarification needed] through the input stream.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I have resolved this issue, it was due to another bug in my own code.\nSo it had nothing to do with the SAXParser. Thanks for all the help!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "To match a streaming XML parser against a set of simple xpaths, you can use the following steps:\n\nCreate a Map<String, String> to store the xpaths and their corresponding values. Initialize the values to null.\nCreate a Stack<String> to keep track of the current path of the XML elements.\nCreate a SAXParser and a DefaultHandler to parse the XML input.\nIn the startElement method of the handler, push the element name to the stack and append it to the current path. Then, check if the current path matches any of the xpaths in the map. If yes, set a flag to indicate that the value should be extracted.\nIn the endElement method of the handler, pop the element name from the stack and remove it from the current path. Then, reset the flag to indicate that the value should not be extracted.\nIn the characters method of the handler, check if the flag is set. If yes, append the character data to the value of the matching xpath in the map.\nAfter parsing the XML input, return the map with the xpaths and their values.\n\nExplanation\nA streaming XML parser, such as SAXParser, reads the XML input sequentially and triggers events when it encounters different parts of the document, such as start tags, end tags, text, etc. It does not build a tree structure of the document in memory, which makes it more efficient for large XML inputs.\nAn xpath is a syntax for selecting nodes from an XML document. It consists of a series of steps, separated by slashes, that describe the location of the desired node. For example, /bookstore/book/title selects the title element of the book element of the bookstore element.\nA simple xpath involves only tags and attributes, no predicates. For example, /bookstore/book[@lang='en']/title selects the title element of the book element that has an attribute lang with value en.\nTo match a streaming XML parser against a set of simple xpaths, we need to keep track of the current path of the XML elements as we parse the input, and compare it with the xpaths in the set. If we find a match, we need to extract the value of the node and store it in a map. We also need to handle the cases where the node value spans across multiple character events, or where the node has multiple occurrences in the document.\nExample\nSuppose we have the following XML input:\n\nAnd the following set of simple xpaths:\n\n/bookstore/book/title\n/bookstore/book/author\n/bookstore/book[@lang='fr']/price\n\nWe can use the following Java code to match the streaming XML parser against the set of xpaths:\n\nThe output of the code is:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Sadly, I know of no XML parser where you can say \"start parsing XML here and stop when you get to the end of the document\". All parsers that I know of will report an error if there is anything beyond the end of the document, which means that if XML is nested inside some larger text, you have the difficult challenge of locating the end of the document before invoking the parser.\nHowever, if you use a SAX parser, then you can count nested start and end tags, and abort the parse when the final end tag is notified. If you implement your application as a SAX filter, then it can pass everything it's given to the JAXB process, suppressing the error that would otherwise arise because of the unwanted content that follows the XML.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Check for these problems:\n\nIf there are characters before the XML declaration (<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>), delete them.\n\nIf you're parsing a non-XML file, change to parsing an actual XML file.\n\nIf you're passing the filename to a call that expects a string of XML, change to passing a string of XML.\n\nIf you're receiving Base64-encoded, compressed, or otherwise represented XML, decode/decompress/convert it before parsing.\n\n\nSee also\n\nError: The processing instruction target matching \"[xX][mM][lL]\" is not allowed\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "There are a few ways to read the XML file and extract the information you need without using a lot of if statements. One approach is to use an XML parsing library such as JAXB or SAX, and create Java classes to represent the XML elements.\nIn JAXB, you can use the javax.xml.bind.Unmarshaller class to unmarshal the XML file into a Java object, which you can then traverse to extract the information you need.\nYou should start creating a Java classes based on the XML structure, like FlowMonitor, Menu1, Item, Connection etc. , and use annotation to map the xml elements to the fields.\nThen, you can use the unmarshaller.unmarshal() method to parse the XML file and create an instance of the FlowMonitor class, which will contain all the information from the XML file.\nOnce you have the FlowMonitor object you can loop through the items, and get the description and filename by calling getDescriptionValue() and getFilenameValue() of the item object....\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You're getting the error since your @XmlRootElement misses the XML namespace (xmlns) but since your XML documents contains a lot of child elements with different namespaces I doubt adding this would be enough. Usually you would start with the XML schema of BPMN and generate Java classes out of it.\nI think another option in this special case would be not to use JAXB but the Camunda Model API.\nAnother thing: Do yourself a favor and never convert between XML documents, which come as byte array usually, and String using new String() or String.getBytes(). If you do this without watching the character set within the XML declaration of your document, or UTF-8 if its missing, you'll get mangled characters sooner or later. Every conversion between byte [] and String either assumes a character set or encoding (default platform encoding) or expects it as a parameter.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can use JAXB parser instead of SAX, It converts each element tag into a Java objects and easily configurable too. But we need to create classes for each element tag in the XML file as mentioned in this article https://www.javatpoint.com/jaxb-tutorial\nAs per your data your root class will be like below:\n\nFollowing method helps to convert XML into JavaObject:\nRequired parameters are:\n\nInputStream (Inputstream of the XML file)\nClass (Class name of the root element in the XML com.a.b.c.DtecBs)\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "tag <064E> is illegal:\nRead up on the rules for XML tag names :\nhttps://www.w3schools.com/xml/xml_elements.asp\nAs a workaround you could use an _ before the number character or write your custom xml parser  :\nBest method to parse various custom XML documents in Java\n",
                        "contain_knowledge": 0
                    }
                ]
            }
        }
    },
    {
        "name": "AlgorithmConstraints",
        "language": "java",
        "popularity": "high",
        "label_result": {
            "functionality": {
                "finetuned_dpr": 0.1,
                "dpr": 0.0,
                "e5": 0.0,
                "bm25": 0.0
            },
            "concept": {
                "finetuned_dpr": 0.2,
                "dpr": 0.2,
                "e5": 0.0,
                "bm25": 0.1
            },
            "performance": {
                "finetuned_dpr": 0.4,
                "dpr": 0.2,
                "e5": 0.0,
                "bm25": 0.2
            },
            "directive": {
                "finetuned_dpr": 0.2,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.0
            },
            "pattern": {
                "finetuned_dpr": 0.4,
                "dpr": 0.4,
                "e5": 0.0,
                "bm25": 0.3
            },
            "environment": {
                "finetuned_dpr": 0.1,
                "dpr": 0.3,
                "e5": 0.1,
                "bm25": 0.3
            },
            "alternative": {
                "finetuned_dpr": 0.2,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.1
            },
            "total": {
                "finetuned_dpr": 0.22857142857142862,
                "dpr": 0.18571428571428572,
                "e5": 0.014285714285714287,
                "bm25": 0.14285714285714288
            }
        },
        "retrieve_result": {
            "functionality": {
                "finetuned_dpr": [
                    {
                        "id": 74771450,
                        "answer_post": "In your case, your input size n = high - low which is exactly the number of iterations your algorithm is executing. Hence the time complexity is O(n)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72983240,
                        "answer_post": "You will need to change your domain; from Cost, I can see you require the Jobs to be ordered, but Job does not have any problem properties (i.e. non-planning variable fields) that can be used to determine the order (for example, a datetime field).\nTo enforce an order,there are two different models you can use:\n\nthe chained model, where each Job point to the previous Job (and the first Job points to Employee). This is explained by https://www.optaplanner.org/docs/optaplanner/latest/planner-configuration/planner-configuration.html#chainedPlanningVariable and https://www.optaplanner.org/docs/optaplanner/latest/design-patterns/design-patterns.html#chainedThroughTimePattern .\n\nUsing @PlanningListVariable, where each Employee is assigned an ordered List of jobs (and each job goes to exactly one employee). This changes Employee to the @PlanningEntity with a @PlanningListVariable for jobs, and Job to a shadow entity (changing its @PlanningVariable to an @InverseRelationShadowVariable). An example of this is https://github.com/kiegroup/optaplanner-quickstarts/tree/stable/use-cases/vehicle-routing .\n\n\nThe final form of the constraints will vary depending on which model is used.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76762979,
                        "answer_post": "Normally teams use karate.callSingle() for this kind of use-case: https://stackoverflow.com/a/56853597/143475\nIf you insist on using Java, use a singleton as described here: https://stackoverflow.com/a/54571844/143475\nPlease note that tests that depend on each other is not a good practice and not supported by Karate: https://stackoverflow.com/a/46080568/143475\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74864595,
                        "answer_post": "For your scenario, you can use the Template Method pattern.\n\nTemplate method defines the steps to execute an algorithm\nand it can provide a default implementation that might be common for\nall or some of the subclasses\n\nAn Example below\n\n\nUsage:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75887067,
                        "answer_post": "Fine-tuning the solver is an art on its own. Please find out more in benchmarking and tweaking OptaPlanner.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75059735,
                        "answer_post": "Time complexity describes how an algorithm's time grows, as a function of the input, as time approaches infinity.\nIn this case, it is clear that the running time depends only on the size of the input, not on its content. So it is up to you to define a variable that describes your input size.\nIn your code example, the input size is constant 3x3, so if this never changes, then you can just say the algorithm has constant time complexity, O(1).\nIf the input can change, then it is up to you to decide how it can change, and how it makes sense to define it. For example, you can say that it is an n * n quadratic grid. Fine. Then, clearly both your loops run n times, so you get a total complexity of O(n * n) = O(n2).\nIt is also perfectly correct to define n as the total number of elements in your array. Then, we have some n = a * b. One of your loops runs a times, the other b times, so in total the complexity becomes O(a * b) = O(n).\nAs for your second question, yes if you apply this for a board m times, then your complexity would be O(m n2) or O(m n), depending on your chosen definition.\nWhat matters is that you make your definitions clear and define your variables in a way that makes sense for what you are trying to say.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76811028,
                        "answer_post": "You can integrate any Java code into Karate, so if you really want you can go direct to JDBC.\nWhen it comes to APIs I'm pretty sure you can't control transactions, because you are at an outer layer of the architecture. From experience, the strategy I've seen work is that each test creates data that is \"scoped\" to that flow at the start. When you GET data, you can filter by the data you are interested in either by the API parameters, or you can do it in Karate (typically a match contains when arrays are involved).\nYou can see a typical example here.\nAlso see this thread: https://stackoverflow.com/a/60944060/143475\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74686751,
                        "answer_post": "Although the order of insertion is significant as that is generally the order in which OptaPlanner will iterate over the facts and entities, it should have no impact on the quality of the solution.\nWhat does have impact on solution quality is your constraints. In your case, there is no constraint to tell OptaPlanner that SKU1 is preferrable to SKU2, or vice versa. How is OptaPlanner supposed to know to prefer one or the other?\nAsk yourself that question, and turn the answer into a constraint. If that answer is capacity multiplied by price, then there should be a constraint that takes it into account. I do not see one in your problem description.\nIn the absence of such information, OptaPlanner will treat all facts as equivalent in terms of solution quality, and therefore it will pick an arbitrary one. (In this case, one that was inserted earlier.)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77041295,
                        "answer_post": "When optimizing code first analyze the code and determine where the bottleneck is, then address the bottleneck. Optimizing anything else is a waste of time.\nMost applications have issues like slow network calls or unindexed queries, etc, that will be slowing things down. If virtual method lookups really are your bottleneck, then congratulations, you have a super fast program. At some point optimizing won't be cost effective and won't yield significant benefits, it is overwhelmingly likely you will hit that point way before virtual methods become an issue.  Part of optimization is knowing when to quit.\nWhat we try to optimize for in real life is developer time, where we try to write code that is clear and not confusing. The benefit of polymorphism is that the flow of the program doesnt have to care about details of subclasses, which stay out of the way, unlike your if-tests which are mixed into the logic flow. Think of what a hassle it would be to add another subclass in the if-test version, how you would have to search for all the if checks and add another case.\n2 main lessons:\n\nMeasure before performance tuning so you can make an informed decision about whether it's worthwhile, don't make assumptions.\n\nOptimize for your time, it is a lot more costly than a few cpu cycles.\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74978826,
                        "answer_post": "Time complexity is just how long an algorithm will take to run as a function of the size of the input.\nSo for this specific example (and most cases tbh) yes, it\u2019ll run in the same time complexity regardless of programming language.\nThe only exception I can think of are built in functions, for which every language may have their own time complexity\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 72280675,
                        "answer_post": "Try using Environment.getDataDirectory().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77389748,
                        "answer_post": "As Slaw pointed out, Iterator does what you want:\n\nIf you want to keep track of the current index in the list/array, or if you want to be able to navigate both forwards and backwards, you can use a ListIterator:\n\n(This code is identical to the first code block, except for calling listIterator() instead of iterator().)\nThe Iterator, ListIterator, and Arrays classes are all in the java.util package.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73153710,
                        "answer_post": "LinkedBlockingQueue uses synchronization internally, in the form of ReentrantLock -- that's how it implements the 'blocking' part.\nSomething like this should work:\n\nHere threads compete at the busy flag. One of them wins the right to add to the list, others busy-wait until the winning thread clears the flag.\nThe two calls to AtomicBoolean methods establish proper 'happens-before' relationship between list.add() calls done on different threads, so each thread should observe actual state of the list.\nLinkedList can be used for unbounded queues. For bounded ones, maybe ArrayList with initial capacity set.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74664479,
                        "answer_post": "A HashMap makes no guarantees about the internal ordering, other than it being consistent - i.e., if you run the same program twice with the same JDK, you'll get the same order.\nIf you want a HashMap that preserves the order of insertion, you could use a LinkedHashMap.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76808758,
                        "answer_post": "Using Java 9's List.of()-Method you can do:\n\nJust be aware that the resulting List is immutable.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76872017,
                        "answer_post": "\n... the output should be {abc=1, def=1, ghi=1}\n\nThere is no reason to expect this behavior. Every comparison operation yields zero (i.e. \"equal\") for your sample data, and there's no guarantee in the specification (i.e. the Javadoc) that TreeMap preserves insertion order for equal keys.  If you want to preserve insertion order you'll need to use a LinkedHashMap.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72336333,
                        "answer_post": "Iterative or stream based solutions are unnecessarily complicated and slow. Just use System.arraycopy:\n\nSystem.arraycopy is highly optimised: Why is System.arraycopy native in Java?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77672085,
                        "answer_post": "First need to formulate your algorithm in words (or kind od pseudocode). Something like this:\nProblem: remove duplicated chars from string except space.\nSolution (pseudocode):\n\nNow you can implement this in any language you want.\nImplementation in java can be:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72653515,
                        "answer_post": "Try this.\n\noutput:\n\nIf you use class instead of record, you need to override equals() and hashCode() appropriately.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72340560,
                        "answer_post": "According to the JavaDoc of class Process some platforms have a limited buffer for the output:\n\nAll its standard I/O (i.e. stdin, stdout, stderr) operations [..] can be accessed via [..] getOutputStream(), getInputStream(), and getErrorStream().\nBecause some native platforms only provide limited buffer size for standard input and output streams, failure to promptly write the input stream or read the output stream of the subprocess may cause the subprocess to block, or even deadlock.\n\nTry the following, before you call process.waitFor():\n\nget the output-streams from the process using getErrorStream() and getOutputStream() and\nread their contents to flush the buffer\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72605934,
                        "answer_post": "Try with post method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73482220,
                        "answer_post": "use setGravity method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72888526,
                        "answer_post": "\nUse the Character API\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77619571,
                        "answer_post": "Using in your Activity onBackPressed Method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72628261,
                        "answer_post": "Resolved with the following method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75956015,
                        "answer_post": "thy this in the application.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77198249,
                        "answer_post": "Using java.time\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74891193,
                        "answer_post": "You looking for takeWhile() method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72998208,
                        "answer_post": "Solution in Kotlin\n\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "The filter criteria may not be specified correctly: Make sure that the filter criteria you're using is valid and matches the data types and values in the file.\nThe filter criteria may not be compatible with the data type of the column being filtered: Ensure that the data type of the column you're filtering on matches the data type expected by the filter.\nThere may be a bug in the implementation of the filter or in the ParquetFileReader class itself: Check the documentation and known issues for the Parquet library you're using, and try updating to the latest version of the library.\nTo further diagnose the issue, you can try debugging the code and examining the values of the filter criteria and the data being filtered on. You may also want to consider reaching out to the Parquet library community or support team for assistance.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "For cases when it is not possible to edit the classes to add validation annotations to it there are two options:\nSpecifying the constraints via XML\nTo use this approach you'd need to add a META-INF/validation.xml and then inside of it you can define/redefine your constraints:\n\nfor more details you should check this section of the specification.\nProgrammatic constraint definition\nAlternatively, Hibernate Validator provides a way to add constraints programmatically:\n\nFor more details, check this section of the Hibernate Validator documentation.\nIf you do not know which fields will need not empty/blank constraint being applied you can try to iterate through the fields using the reflection and then based on that information define the constraints via programmatic API. once constraints are added to the validator you should be able to just use Validator#validate(..)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This looks tls algorithm is part of your disabledAlgorithms list in jdk which is running in your system.\nWhile link shared by Marc Stroebel might help you but if you want to set this programatically as well, then you can use below in your spring startup :\n\nThis will allow all algorithms while app execution.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nI try without including criteria and its work the processor add my new attribute but why the include doesn't work anything wrong?\n\nI also referred the above documentation demonstrates how to configure an attribute processor with an \"include\" condition to match specific attributes and values, but the processor failed.\nConfigure an ApplicationInsights.xml file to you application check below.\n\n\nThe telemetry processing logic specified in the configuration files is applied to the telemetry data before it's sent to Application Insights.\n\nOnce the new/updated config file is ready try to re-deploy the JAR files or other relevant resources for the changes\n\n\nResult:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "TL;DR\n:: or && are not part of the JPA Criteria API standard. You could use a native SQL query.\n\nIf you want to use specific features or functions unique to a database system like PostgreSQL, it may not be possible to use them directly within the JPA Criteria API.\nSome queries, you can avoid the headache by specifying the escape sequence completely, but for this query; There is no way to simultaneously escape special types such as overlap (&&), double colon (::), and tsrange (cast(string as tsrange)).\nIt would be appropriate to create this query using a native query (@Query) instead of the Criteria API, or alternatively; if you are using Hibernate you can create a FunctionContributor for this statement.\nCreate a FunctionContributor, here we give our function a special name and set our pattern:\n(It is a simple function definition approach, it can be made more usable.)\n\nWe use this function with the Criteria API:\n\nThe class must be then registered via Java ServiceLoader mechanism by adding full name of the class with its packages into the file with name org.hibernate.boot.model.FunctionContributor into the java module\u2019s META-INF/services directory.\nYou use this specification your query will look like this:\n\nIt was prepared with Spring Boot 3.2.1 and Hibernate 6.2.7.Final.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "My assumption is that you shouldn't be keeping the criteria builder around. It's meant to be used in a case-by-case execution, so in this method you would rather run:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Locking with the use of @Lock doesn't work with non select @Query.\nIt looks like a bigger theme since we have this in the Query interface documentation:\n\nThrows: IllegalStateException - if the query is found not to be a Java\nPersistence query language SELECT query or a Criteria API query\n\nhttps://docs.oracle.com/javaee/6/api/javax/persistence/Query.html#setLockMode(javax.persistence.LockModeType)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Admittedly this is only tangenitally related to your question, but depending on what version of java your using, you might not have the full suite of cryptographic algorithms available to you.\nInitially, as strong encryption algorithms could not be shipped everywhere due to various legal restrictions, java was shipped with limited crypto algorithms.  To have the full suite of crypto algorithms (including the 'strong' ones), you'll need to apply the official oracle Java Cryptographic Extension patch to both of your java installations.\nSee https://www.baeldung.com/jce-enable-unlimited-strength for more details.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "See the answer I posted here: Equivalent of Hibernate's Restrictions.sqlRestriction in JPA2 Criteria API?\nWe had very complex queries being dynamically generated and I did not want to have to replace them with criteria based sub queries.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "By using io.netty.bootstrap.Bootstrap and io.netty.bootstrap.ServerBootstrap, it seems that it can meet my needs.\nI would continue to work on it.\n\nAnother solution is this: How to make my Java SpringBoot application to proxy MQTT Broker WebSocket 8083 port?\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "concept": {
                "finetuned_dpr": [
                    {
                        "id": 74771450,
                        "answer_post": "In your case, your input size n = high - low which is exactly the number of iterations your algorithm is executing. Hence the time complexity is O(n)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72983240,
                        "answer_post": "You will need to change your domain; from Cost, I can see you require the Jobs to be ordered, but Job does not have any problem properties (i.e. non-planning variable fields) that can be used to determine the order (for example, a datetime field).\nTo enforce an order,there are two different models you can use:\n\nthe chained model, where each Job point to the previous Job (and the first Job points to Employee). This is explained by https://www.optaplanner.org/docs/optaplanner/latest/planner-configuration/planner-configuration.html#chainedPlanningVariable and https://www.optaplanner.org/docs/optaplanner/latest/design-patterns/design-patterns.html#chainedThroughTimePattern .\n\nUsing @PlanningListVariable, where each Employee is assigned an ordered List of jobs (and each job goes to exactly one employee). This changes Employee to the @PlanningEntity with a @PlanningListVariable for jobs, and Job to a shadow entity (changing its @PlanningVariable to an @InverseRelationShadowVariable). An example of this is https://github.com/kiegroup/optaplanner-quickstarts/tree/stable/use-cases/vehicle-routing .\n\n\nThe final form of the constraints will vary depending on which model is used.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75059735,
                        "answer_post": "Time complexity describes how an algorithm's time grows, as a function of the input, as time approaches infinity.\nIn this case, it is clear that the running time depends only on the size of the input, not on its content. So it is up to you to define a variable that describes your input size.\nIn your code example, the input size is constant 3x3, so if this never changes, then you can just say the algorithm has constant time complexity, O(1).\nIf the input can change, then it is up to you to decide how it can change, and how it makes sense to define it. For example, you can say that it is an n * n quadratic grid. Fine. Then, clearly both your loops run n times, so you get a total complexity of O(n * n) = O(n2).\nIt is also perfectly correct to define n as the total number of elements in your array. Then, we have some n = a * b. One of your loops runs a times, the other b times, so in total the complexity becomes O(a * b) = O(n).\nAs for your second question, yes if you apply this for a board m times, then your complexity would be O(m n2) or O(m n), depending on your chosen definition.\nWhat matters is that you make your definitions clear and define your variables in a way that makes sense for what you are trying to say.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74864595,
                        "answer_post": "For your scenario, you can use the Template Method pattern.\n\nTemplate method defines the steps to execute an algorithm\nand it can provide a default implementation that might be common for\nall or some of the subclasses\n\nAn Example below\n\n\nUsage:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75887067,
                        "answer_post": "Fine-tuning the solver is an art on its own. Please find out more in benchmarking and tweaking OptaPlanner.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77041295,
                        "answer_post": "When optimizing code first analyze the code and determine where the bottleneck is, then address the bottleneck. Optimizing anything else is a waste of time.\nMost applications have issues like slow network calls or unindexed queries, etc, that will be slowing things down. If virtual method lookups really are your bottleneck, then congratulations, you have a super fast program. At some point optimizing won't be cost effective and won't yield significant benefits, it is overwhelmingly likely you will hit that point way before virtual methods become an issue.  Part of optimization is knowing when to quit.\nWhat we try to optimize for in real life is developer time, where we try to write code that is clear and not confusing. The benefit of polymorphism is that the flow of the program doesnt have to care about details of subclasses, which stay out of the way, unlike your if-tests which are mixed into the logic flow. Think of what a hassle it would be to add another subclass in the if-test version, how you would have to search for all the if checks and add another case.\n2 main lessons:\n\nMeasure before performance tuning so you can make an informed decision about whether it's worthwhile, don't make assumptions.\n\nOptimize for your time, it is a lot more costly than a few cpu cycles.\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76762979,
                        "answer_post": "Normally teams use karate.callSingle() for this kind of use-case: https://stackoverflow.com/a/56853597/143475\nIf you insist on using Java, use a singleton as described here: https://stackoverflow.com/a/54571844/143475\nPlease note that tests that depend on each other is not a good practice and not supported by Karate: https://stackoverflow.com/a/46080568/143475\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74686751,
                        "answer_post": "Although the order of insertion is significant as that is generally the order in which OptaPlanner will iterate over the facts and entities, it should have no impact on the quality of the solution.\nWhat does have impact on solution quality is your constraints. In your case, there is no constraint to tell OptaPlanner that SKU1 is preferrable to SKU2, or vice versa. How is OptaPlanner supposed to know to prefer one or the other?\nAsk yourself that question, and turn the answer into a constraint. If that answer is capacity multiplied by price, then there should be a constraint that takes it into account. I do not see one in your problem description.\nIn the absence of such information, OptaPlanner will treat all facts as equivalent in terms of solution quality, and therefore it will pick an arbitrary one. (In this case, one that was inserted earlier.)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76811028,
                        "answer_post": "You can integrate any Java code into Karate, so if you really want you can go direct to JDBC.\nWhen it comes to APIs I'm pretty sure you can't control transactions, because you are at an outer layer of the architecture. From experience, the strategy I've seen work is that each test creates data that is \"scoped\" to that flow at the start. When you GET data, you can filter by the data you are interested in either by the API parameters, or you can do it in Karate (typically a match contains when arrays are involved).\nYou can see a typical example here.\nAlso see this thread: https://stackoverflow.com/a/60944060/143475\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74978826,
                        "answer_post": "Time complexity is just how long an algorithm will take to run as a function of the size of the input.\nSo for this specific example (and most cases tbh) yes, it\u2019ll run in the same time complexity regardless of programming language.\nThe only exception I can think of are built in functions, for which every language may have their own time complexity\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 72280675,
                        "answer_post": "Try using Environment.getDataDirectory().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77389748,
                        "answer_post": "As Slaw pointed out, Iterator does what you want:\n\nIf you want to keep track of the current index in the list/array, or if you want to be able to navigate both forwards and backwards, you can use a ListIterator:\n\n(This code is identical to the first code block, except for calling listIterator() instead of iterator().)\nThe Iterator, ListIterator, and Arrays classes are all in the java.util package.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73153710,
                        "answer_post": "LinkedBlockingQueue uses synchronization internally, in the form of ReentrantLock -- that's how it implements the 'blocking' part.\nSomething like this should work:\n\nHere threads compete at the busy flag. One of them wins the right to add to the list, others busy-wait until the winning thread clears the flag.\nThe two calls to AtomicBoolean methods establish proper 'happens-before' relationship between list.add() calls done on different threads, so each thread should observe actual state of the list.\nLinkedList can be used for unbounded queues. For bounded ones, maybe ArrayList with initial capacity set.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74664479,
                        "answer_post": "A HashMap makes no guarantees about the internal ordering, other than it being consistent - i.e., if you run the same program twice with the same JDK, you'll get the same order.\nIf you want a HashMap that preserves the order of insertion, you could use a LinkedHashMap.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76808758,
                        "answer_post": "Using Java 9's List.of()-Method you can do:\n\nJust be aware that the resulting List is immutable.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76872017,
                        "answer_post": "\n... the output should be {abc=1, def=1, ghi=1}\n\nThere is no reason to expect this behavior. Every comparison operation yields zero (i.e. \"equal\") for your sample data, and there's no guarantee in the specification (i.e. the Javadoc) that TreeMap preserves insertion order for equal keys.  If you want to preserve insertion order you'll need to use a LinkedHashMap.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72336333,
                        "answer_post": "Iterative or stream based solutions are unnecessarily complicated and slow. Just use System.arraycopy:\n\nSystem.arraycopy is highly optimised: Why is System.arraycopy native in Java?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72931108,
                        "answer_post": "\nO(n) or O(nlogn) ?\n\nNeither of these.\nFirstly, it seems like you're confusing a stream which elements are sorted with an ordered stream, i.e. a stream which has a particular encounter order of elements.\nWhether a stream is ordered or not depends on the stream source and intermediate operations in it.\nA stream created over an array, or ordered collection like a List, or a Queue is ordered respectively to order elements in it, but it does not imply that such stream is sorted.\nWe can make a stream unordered by applying unordered() operation on in it. This operation alone will not change the stream data, but it will have an impact on the execution of stateful intermediate operations like takeWhile() that require buffering, and terminal operation like reduce(), collect() that give a guarantee to respect the initial encounter order. As a result, a parallel unordered stream might have better performance because of loosening this constraint.\nHere is a quote from the API documentation:\n\nOrdering\nStreams may or may not have a defined encounter order. Whether or\nnot a stream has an encounter order depends on the source and the\nintermediate operations. Certain stream sources (such as List or arrays) are\nintrinsically ordered, whereas others (such as HashSet)\nare not. Some intermediate operations, such as sorted(), may impose an\nencounter order on an otherwise unordered stream, and others may\nrender an ordered stream unordered, such as BaseStream.unordered().\nFurther, some terminal operations may ignore encounter order, such as\nforEach().\nIf a stream is ordered, most operations are constrained to operate on\nthe elements in their encounter order; if the source of a stream is a\nList containing [1, 2, 3], then the result of executing map(x -> x*2)\nmust be [2, 4, 6]. However, if the source has no defined encounter\norder, then any permutation of the values [2, 4, 6] would be a valid\nresult.\nFor sequential streams, the presence or absence of an encounter order\ndoes not affect performance, only determinism. If a stream is ordered,\nrepeated execution of identical stream pipelines on an identical\nsource will produce an identical result; if it is not ordered,\nrepeated execution might produce different results.\nFor parallel streams, relaxing the ordering constraint can sometimes\nenable more efficient execution. Certain aggregate operations, such as\nfiltering duplicates (distinct()) or grouped reductions\n(Collectors.groupingBy()) can be implemented more efficiently if\nordering of elements is not relevant. Similarly, operations that are\nintrinsically tied to encounter order, such as limit(), may require\nbuffering to ensure proper ordering, undermining the benefit of\nparallelism. In cases where the stream has an encounter order, but the\nuser does not particularly care about that encounter order, explicitly\nde-ordering the stream with unordered() may improve parallel\nperformance for some stateful or terminal operations. However, most\nstream pipelines, such as the \"sum of weight of blocks\" example above,\nstill parallelize efficiently even under ordering constraints.\n\nSecondly, because you're assuming that creating a stream over an array will cost at list O(n) you might have a misconception regarding the nature of streams.\nIn essence, stream is a mean of iteration, it is not a container of data like Collection.\nCreation of a stream doesn't require dumping all the data from the source into memory, we're only creating an internal iterator over the source of data, and this action has a time complexity of O(1).\nStreams are lazy and every action in the stream pipeline occur only when it's needed, and elements from the source are processed one by one.\nFor instance, let's assume we have an integer array containing 1,000,000 elements, and we want to get the first 10 elements from it as hexadecimal strings:\n\nOn execution, only the first 10 elements would be retrieved  from the source array, and then the stream would immediately terminate, producing the result.\nThe overall time complexity of such a stream would be O(1) because we care only about a fixed number of elements at the very beginning, and don't need all the data that the source contains.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75696410,
                        "answer_post": "Time complexity cannot be \"2888 ms\", because complexity isn't a measurement of absolute time. Time complexity only tells you how the runtime of an algorithm scales with input size. Now, different implementations can have the same complexity, but run at different (absolute) speeds. And even O(1) could be far slower than O(n) for small to medium inputs (but O(1) will always take the same time).\nJava's java.util.Stack is a really old class and should not be used anymore. It builds on top of Vector and every single call to its methods is synchronized. That means for every method call, you need to perform a lock when calling the method and unlocking when leaving the method. This can add considerable runtime overhead.\nA modern alternative to Stack is an ArrayDeque, which is even suggested by the JavaDoc of Stack itself:\n\nA more complete and consistent set of LIFO stack operations is provided by the Deque interface and its implementations, which should be used in preference to this class. For example:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72340560,
                        "answer_post": "According to the JavaDoc of class Process some platforms have a limited buffer for the output:\n\nAll its standard I/O (i.e. stdin, stdout, stderr) operations [..] can be accessed via [..] getOutputStream(), getInputStream(), and getErrorStream().\nBecause some native platforms only provide limited buffer size for standard input and output streams, failure to promptly write the input stream or read the output stream of the subprocess may cause the subprocess to block, or even deadlock.\n\nTry the following, before you call process.waitFor():\n\nget the output-streams from the process using getErrorStream() and getOutputStream() and\nread their contents to flush the buffer\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72605934,
                        "answer_post": "Try with post method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75956015,
                        "answer_post": "thy this in the application.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77619571,
                        "answer_post": "Using in your Activity onBackPressed Method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72888526,
                        "answer_post": "\nUse the Character API\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73482220,
                        "answer_post": "use setGravity method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73354616,
                        "answer_post": "It requires multi dimensional array\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74891193,
                        "answer_post": "You looking for takeWhile() method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73276718,
                        "answer_post": "In the application.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76095804,
                        "answer_post": "See this please\nfor Java\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "The filter criteria may not be specified correctly: Make sure that the filter criteria you're using is valid and matches the data types and values in the file.\nThe filter criteria may not be compatible with the data type of the column being filtered: Ensure that the data type of the column you're filtering on matches the data type expected by the filter.\nThere may be a bug in the implementation of the filter or in the ParquetFileReader class itself: Check the documentation and known issues for the Parquet library you're using, and try updating to the latest version of the library.\nTo further diagnose the issue, you can try debugging the code and examining the values of the filter criteria and the data being filtered on. You may also want to consider reaching out to the Parquet library community or support team for assistance.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "For cases when it is not possible to edit the classes to add validation annotations to it there are two options:\nSpecifying the constraints via XML\nTo use this approach you'd need to add a META-INF/validation.xml and then inside of it you can define/redefine your constraints:\n\nfor more details you should check this section of the specification.\nProgrammatic constraint definition\nAlternatively, Hibernate Validator provides a way to add constraints programmatically:\n\nFor more details, check this section of the Hibernate Validator documentation.\nIf you do not know which fields will need not empty/blank constraint being applied you can try to iterate through the fields using the reflection and then based on that information define the constraints via programmatic API. once constraints are added to the validator you should be able to just use Validator#validate(..)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This looks tls algorithm is part of your disabledAlgorithms list in jdk which is running in your system.\nWhile link shared by Marc Stroebel might help you but if you want to set this programatically as well, then you can use below in your spring startup :\n\nThis will allow all algorithms while app execution.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "TL;DR\n:: or && are not part of the JPA Criteria API standard. You could use a native SQL query.\n\nIf you want to use specific features or functions unique to a database system like PostgreSQL, it may not be possible to use them directly within the JPA Criteria API.\nSome queries, you can avoid the headache by specifying the escape sequence completely, but for this query; There is no way to simultaneously escape special types such as overlap (&&), double colon (::), and tsrange (cast(string as tsrange)).\nIt would be appropriate to create this query using a native query (@Query) instead of the Criteria API, or alternatively; if you are using Hibernate you can create a FunctionContributor for this statement.\nCreate a FunctionContributor, here we give our function a special name and set our pattern:\n(It is a simple function definition approach, it can be made more usable.)\n\nWe use this function with the Criteria API:\n\nThe class must be then registered via Java ServiceLoader mechanism by adding full name of the class with its packages into the file with name org.hibernate.boot.model.FunctionContributor into the java module\u2019s META-INF/services directory.\nYou use this specification your query will look like this:\n\nIt was prepared with Spring Boot 3.2.1 and Hibernate 6.2.7.Final.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "My assumption is that you shouldn't be keeping the criteria builder around. It's meant to be used in a case-by-case execution, so in this method you would rather run:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Admittedly this is only tangenitally related to your question, but depending on what version of java your using, you might not have the full suite of cryptographic algorithms available to you.\nInitially, as strong encryption algorithms could not be shipped everywhere due to various legal restrictions, java was shipped with limited crypto algorithms.  To have the full suite of crypto algorithms (including the 'strong' ones), you'll need to apply the official oracle Java Cryptographic Extension patch to both of your java installations.\nSee https://www.baeldung.com/jce-enable-unlimited-strength for more details.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "See the answer I posted here: Equivalent of Hibernate's Restrictions.sqlRestriction in JPA2 Criteria API?\nWe had very complex queries being dynamically generated and I did not want to have to replace them with criteria based sub queries.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "It supposed to be:\n\nBecause .publishOn(..) doesn't spin off new threads, it just defines the current thread. But .parallel().runOn(..) uses parallel threads for execution.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You need to pass the -parameters argument to the java compiler. The -g:vars argument provides information regarding all local variables, but the attribute which defines this is never accessible using the reflection API. When using -parameters, a special attribute is used which is explicitly designed for being accessed by the reflection API.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You have to join the two conditions with and. This is how it looks with JPA JPQL\n\nAnd this would be JPA Criteria API\n\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "performance": {
                "finetuned_dpr": [
                    {
                        "id": 74771450,
                        "answer_post": "In your case, your input size n = high - low which is exactly the number of iterations your algorithm is executing. Hence the time complexity is O(n)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72983240,
                        "answer_post": "You will need to change your domain; from Cost, I can see you require the Jobs to be ordered, but Job does not have any problem properties (i.e. non-planning variable fields) that can be used to determine the order (for example, a datetime field).\nTo enforce an order,there are two different models you can use:\n\nthe chained model, where each Job point to the previous Job (and the first Job points to Employee). This is explained by https://www.optaplanner.org/docs/optaplanner/latest/planner-configuration/planner-configuration.html#chainedPlanningVariable and https://www.optaplanner.org/docs/optaplanner/latest/design-patterns/design-patterns.html#chainedThroughTimePattern .\n\nUsing @PlanningListVariable, where each Employee is assigned an ordered List of jobs (and each job goes to exactly one employee). This changes Employee to the @PlanningEntity with a @PlanningListVariable for jobs, and Job to a shadow entity (changing its @PlanningVariable to an @InverseRelationShadowVariable). An example of this is https://github.com/kiegroup/optaplanner-quickstarts/tree/stable/use-cases/vehicle-routing .\n\n\nThe final form of the constraints will vary depending on which model is used.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75887067,
                        "answer_post": "Fine-tuning the solver is an art on its own. Please find out more in benchmarking and tweaking OptaPlanner.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75059735,
                        "answer_post": "Time complexity describes how an algorithm's time grows, as a function of the input, as time approaches infinity.\nIn this case, it is clear that the running time depends only on the size of the input, not on its content. So it is up to you to define a variable that describes your input size.\nIn your code example, the input size is constant 3x3, so if this never changes, then you can just say the algorithm has constant time complexity, O(1).\nIf the input can change, then it is up to you to decide how it can change, and how it makes sense to define it. For example, you can say that it is an n * n quadratic grid. Fine. Then, clearly both your loops run n times, so you get a total complexity of O(n * n) = O(n2).\nIt is also perfectly correct to define n as the total number of elements in your array. Then, we have some n = a * b. One of your loops runs a times, the other b times, so in total the complexity becomes O(a * b) = O(n).\nAs for your second question, yes if you apply this for a board m times, then your complexity would be O(m n2) or O(m n), depending on your chosen definition.\nWhat matters is that you make your definitions clear and define your variables in a way that makes sense for what you are trying to say.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76811028,
                        "answer_post": "You can integrate any Java code into Karate, so if you really want you can go direct to JDBC.\nWhen it comes to APIs I'm pretty sure you can't control transactions, because you are at an outer layer of the architecture. From experience, the strategy I've seen work is that each test creates data that is \"scoped\" to that flow at the start. When you GET data, you can filter by the data you are interested in either by the API parameters, or you can do it in Karate (typically a match contains when arrays are involved).\nYou can see a typical example here.\nAlso see this thread: https://stackoverflow.com/a/60944060/143475\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76762979,
                        "answer_post": "Normally teams use karate.callSingle() for this kind of use-case: https://stackoverflow.com/a/56853597/143475\nIf you insist on using Java, use a singleton as described here: https://stackoverflow.com/a/54571844/143475\nPlease note that tests that depend on each other is not a good practice and not supported by Karate: https://stackoverflow.com/a/46080568/143475\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77041295,
                        "answer_post": "When optimizing code first analyze the code and determine where the bottleneck is, then address the bottleneck. Optimizing anything else is a waste of time.\nMost applications have issues like slow network calls or unindexed queries, etc, that will be slowing things down. If virtual method lookups really are your bottleneck, then congratulations, you have a super fast program. At some point optimizing won't be cost effective and won't yield significant benefits, it is overwhelmingly likely you will hit that point way before virtual methods become an issue.  Part of optimization is knowing when to quit.\nWhat we try to optimize for in real life is developer time, where we try to write code that is clear and not confusing. The benefit of polymorphism is that the flow of the program doesnt have to care about details of subclasses, which stay out of the way, unlike your if-tests which are mixed into the logic flow. Think of what a hassle it would be to add another subclass in the if-test version, how you would have to search for all the if checks and add another case.\n2 main lessons:\n\nMeasure before performance tuning so you can make an informed decision about whether it's worthwhile, don't make assumptions.\n\nOptimize for your time, it is a lot more costly than a few cpu cycles.\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74864595,
                        "answer_post": "For your scenario, you can use the Template Method pattern.\n\nTemplate method defines the steps to execute an algorithm\nand it can provide a default implementation that might be common for\nall or some of the subclasses\n\nAn Example below\n\n\nUsage:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74686751,
                        "answer_post": "Although the order of insertion is significant as that is generally the order in which OptaPlanner will iterate over the facts and entities, it should have no impact on the quality of the solution.\nWhat does have impact on solution quality is your constraints. In your case, there is no constraint to tell OptaPlanner that SKU1 is preferrable to SKU2, or vice versa. How is OptaPlanner supposed to know to prefer one or the other?\nAsk yourself that question, and turn the answer into a constraint. If that answer is capacity multiplied by price, then there should be a constraint that takes it into account. I do not see one in your problem description.\nIn the absence of such information, OptaPlanner will treat all facts as equivalent in terms of solution quality, and therefore it will pick an arbitrary one. (In this case, one that was inserted earlier.)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74978826,
                        "answer_post": "Time complexity is just how long an algorithm will take to run as a function of the size of the input.\nSo for this specific example (and most cases tbh) yes, it\u2019ll run in the same time complexity regardless of programming language.\nThe only exception I can think of are built in functions, for which every language may have their own time complexity\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 72280675,
                        "answer_post": "Try using Environment.getDataDirectory().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77389748,
                        "answer_post": "As Slaw pointed out, Iterator does what you want:\n\nIf you want to keep track of the current index in the list/array, or if you want to be able to navigate both forwards and backwards, you can use a ListIterator:\n\n(This code is identical to the first code block, except for calling listIterator() instead of iterator().)\nThe Iterator, ListIterator, and Arrays classes are all in the java.util package.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73153710,
                        "answer_post": "LinkedBlockingQueue uses synchronization internally, in the form of ReentrantLock -- that's how it implements the 'blocking' part.\nSomething like this should work:\n\nHere threads compete at the busy flag. One of them wins the right to add to the list, others busy-wait until the winning thread clears the flag.\nThe two calls to AtomicBoolean methods establish proper 'happens-before' relationship between list.add() calls done on different threads, so each thread should observe actual state of the list.\nLinkedList can be used for unbounded queues. For bounded ones, maybe ArrayList with initial capacity set.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74664479,
                        "answer_post": "A HashMap makes no guarantees about the internal ordering, other than it being consistent - i.e., if you run the same program twice with the same JDK, you'll get the same order.\nIf you want a HashMap that preserves the order of insertion, you could use a LinkedHashMap.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76872017,
                        "answer_post": "\n... the output should be {abc=1, def=1, ghi=1}\n\nThere is no reason to expect this behavior. Every comparison operation yields zero (i.e. \"equal\") for your sample data, and there's no guarantee in the specification (i.e. the Javadoc) that TreeMap preserves insertion order for equal keys.  If you want to preserve insertion order you'll need to use a LinkedHashMap.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72336333,
                        "answer_post": "Iterative or stream based solutions are unnecessarily complicated and slow. Just use System.arraycopy:\n\nSystem.arraycopy is highly optimised: Why is System.arraycopy native in Java?\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74850838,
                        "answer_post": "HashMap.Node is declared with package private visibility (the default visibility if public, private or protected is not used).\n\nThis means that the class is only visible to classes in the same package.\nSee this question for more details: What is the difference between public, protected, package-private and private in Java?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76808758,
                        "answer_post": "Using Java 9's List.of()-Method you can do:\n\nJust be aware that the resulting List is immutable.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72653515,
                        "answer_post": "Try this.\n\noutput:\n\nIf you use class instead of record, you need to override equals() and hashCode() appropriately.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72626462,
                        "answer_post": "Yes exactly, but if you look in the book, they took this assumption:\n\nImprovedList assumes that once a list is passed to its constructor,\nthe client will not use the underlying list directly again, accessing\nit only via ImprovedList\n\nBased on this assumption the code is thread-safe.\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75956015,
                        "answer_post": "thy this in the application.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72888526,
                        "answer_post": "\nUse the Character API\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72605934,
                        "answer_post": "Try with post method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73276718,
                        "answer_post": "In the application.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73482220,
                        "answer_post": "use setGravity method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77619571,
                        "answer_post": "Using in your Activity onBackPressed Method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77198249,
                        "answer_post": "Using java.time\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73354616,
                        "answer_post": "It requires multi dimensional array\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74891193,
                        "answer_post": "You looking for takeWhile() method\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "\nThis happens in a sequential manner and creates a performs lag , can this be converted to parallel execution using java thread?\n\nYes can improve the performance this way.\nPossible solution with Java Thread:\n\nFurthermore I suggest other option.\nYou can use java Stream API.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The filter criteria may not be specified correctly: Make sure that the filter criteria you're using is valid and matches the data types and values in the file.\nThe filter criteria may not be compatible with the data type of the column being filtered: Ensure that the data type of the column you're filtering on matches the data type expected by the filter.\nThere may be a bug in the implementation of the filter or in the ParquetFileReader class itself: Check the documentation and known issues for the Parquet library you're using, and try updating to the latest version of the library.\nTo further diagnose the issue, you can try debugging the code and examining the values of the filter criteria and the data being filtered on. You may also want to consider reaching out to the Parquet library community or support team for assistance.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "For cases when it is not possible to edit the classes to add validation annotations to it there are two options:\nSpecifying the constraints via XML\nTo use this approach you'd need to add a META-INF/validation.xml and then inside of it you can define/redefine your constraints:\n\nfor more details you should check this section of the specification.\nProgrammatic constraint definition\nAlternatively, Hibernate Validator provides a way to add constraints programmatically:\n\nFor more details, check this section of the Hibernate Validator documentation.\nIf you do not know which fields will need not empty/blank constraint being applied you can try to iterate through the fields using the reflection and then based on that information define the constraints via programmatic API. once constraints are added to the validator you should be able to just use Validator#validate(..)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This looks tls algorithm is part of your disabledAlgorithms list in jdk which is running in your system.\nWhile link shared by Marc Stroebel might help you but if you want to set this programatically as well, then you can use below in your spring startup :\n\nThis will allow all algorithms while app execution.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "TL;DR\n:: or && are not part of the JPA Criteria API standard. You could use a native SQL query.\n\nIf you want to use specific features or functions unique to a database system like PostgreSQL, it may not be possible to use them directly within the JPA Criteria API.\nSome queries, you can avoid the headache by specifying the escape sequence completely, but for this query; There is no way to simultaneously escape special types such as overlap (&&), double colon (::), and tsrange (cast(string as tsrange)).\nIt would be appropriate to create this query using a native query (@Query) instead of the Criteria API, or alternatively; if you are using Hibernate you can create a FunctionContributor for this statement.\nCreate a FunctionContributor, here we give our function a special name and set our pattern:\n(It is a simple function definition approach, it can be made more usable.)\n\nWe use this function with the Criteria API:\n\nThe class must be then registered via Java ServiceLoader mechanism by adding full name of the class with its packages into the file with name org.hibernate.boot.model.FunctionContributor into the java module\u2019s META-INF/services directory.\nYou use this specification your query will look like this:\n\nIt was prepared with Spring Boot 3.2.1 and Hibernate 6.2.7.Final.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "My assumption is that you shouldn't be keeping the criteria builder around. It's meant to be used in a case-by-case execution, so in this method you would rather run:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nIf garbage collector comes, doesn't it collect all \"dead\" links?\n\nShort answer: no\nLonger answer: there are no guarantees of what will happen at garbage collection time. You have to understand that modern JVMs have implemented several GC algorithms which are usually very complex. What they will do and when will vary wildly. We don't which one your version of the JVM in your particular environment is using right now. One thing these complex algorithms try to avoid is doing a full garbage collection, where most objects that are not referenced are garbage collected. That's because such full GC events mean that the JVM needs to be stopped for some time to ensure everything is consistent. Those pause impact application performance and can cause issues like timeouts or freezes. Developers of GC algorithms try very hard to avoid those issues. So you should not assume a GC implementation will work in the way you are expecting.\nI recommend to read about the different GC algorithms current JVM implement to understand better their complexities.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Admittedly this is only tangenitally related to your question, but depending on what version of java your using, you might not have the full suite of cryptographic algorithms available to you.\nInitially, as strong encryption algorithms could not be shipped everywhere due to various legal restrictions, java was shipped with limited crypto algorithms.  To have the full suite of crypto algorithms (including the 'strong' ones), you'll need to apply the official oracle Java Cryptographic Extension patch to both of your java installations.\nSee https://www.baeldung.com/jce-enable-unlimited-strength for more details.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Generally speaking, depends on your constraints. If performance is an issue, allocate more resources and go for the faster solution. If memory is an issue, do the reverse.\nWith BufferedReader you can also use the reader and int constructor to set buffer size, which suits your needs.\n\nAnother general rule of thumb, don't do premature optimizations, be it memory or performance. Strive for clean code, if a problem arises, use a profiler to identify the bottlenecks and then deal with them.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "See the answer I posted here: Equivalent of Hibernate's Restrictions.sqlRestriction in JPA2 Criteria API?\nWe had very complex queries being dynamically generated and I did not want to have to replace them with criteria based sub queries.\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "directive": {
                "finetuned_dpr": [
                    {
                        "id": 74771450,
                        "answer_post": "In your case, your input size n = high - low which is exactly the number of iterations your algorithm is executing. Hence the time complexity is O(n)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72983240,
                        "answer_post": "You will need to change your domain; from Cost, I can see you require the Jobs to be ordered, but Job does not have any problem properties (i.e. non-planning variable fields) that can be used to determine the order (for example, a datetime field).\nTo enforce an order,there are two different models you can use:\n\nthe chained model, where each Job point to the previous Job (and the first Job points to Employee). This is explained by https://www.optaplanner.org/docs/optaplanner/latest/planner-configuration/planner-configuration.html#chainedPlanningVariable and https://www.optaplanner.org/docs/optaplanner/latest/design-patterns/design-patterns.html#chainedThroughTimePattern .\n\nUsing @PlanningListVariable, where each Employee is assigned an ordered List of jobs (and each job goes to exactly one employee). This changes Employee to the @PlanningEntity with a @PlanningListVariable for jobs, and Job to a shadow entity (changing its @PlanningVariable to an @InverseRelationShadowVariable). An example of this is https://github.com/kiegroup/optaplanner-quickstarts/tree/stable/use-cases/vehicle-routing .\n\n\nThe final form of the constraints will vary depending on which model is used.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74864595,
                        "answer_post": "For your scenario, you can use the Template Method pattern.\n\nTemplate method defines the steps to execute an algorithm\nand it can provide a default implementation that might be common for\nall or some of the subclasses\n\nAn Example below\n\n\nUsage:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75887067,
                        "answer_post": "Fine-tuning the solver is an art on its own. Please find out more in benchmarking and tweaking OptaPlanner.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75059735,
                        "answer_post": "Time complexity describes how an algorithm's time grows, as a function of the input, as time approaches infinity.\nIn this case, it is clear that the running time depends only on the size of the input, not on its content. So it is up to you to define a variable that describes your input size.\nIn your code example, the input size is constant 3x3, so if this never changes, then you can just say the algorithm has constant time complexity, O(1).\nIf the input can change, then it is up to you to decide how it can change, and how it makes sense to define it. For example, you can say that it is an n * n quadratic grid. Fine. Then, clearly both your loops run n times, so you get a total complexity of O(n * n) = O(n2).\nIt is also perfectly correct to define n as the total number of elements in your array. Then, we have some n = a * b. One of your loops runs a times, the other b times, so in total the complexity becomes O(a * b) = O(n).\nAs for your second question, yes if you apply this for a board m times, then your complexity would be O(m n2) or O(m n), depending on your chosen definition.\nWhat matters is that you make your definitions clear and define your variables in a way that makes sense for what you are trying to say.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74686751,
                        "answer_post": "Although the order of insertion is significant as that is generally the order in which OptaPlanner will iterate over the facts and entities, it should have no impact on the quality of the solution.\nWhat does have impact on solution quality is your constraints. In your case, there is no constraint to tell OptaPlanner that SKU1 is preferrable to SKU2, or vice versa. How is OptaPlanner supposed to know to prefer one or the other?\nAsk yourself that question, and turn the answer into a constraint. If that answer is capacity multiplied by price, then there should be a constraint that takes it into account. I do not see one in your problem description.\nIn the absence of such information, OptaPlanner will treat all facts as equivalent in terms of solution quality, and therefore it will pick an arbitrary one. (In this case, one that was inserted earlier.)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76811028,
                        "answer_post": "You can integrate any Java code into Karate, so if you really want you can go direct to JDBC.\nWhen it comes to APIs I'm pretty sure you can't control transactions, because you are at an outer layer of the architecture. From experience, the strategy I've seen work is that each test creates data that is \"scoped\" to that flow at the start. When you GET data, you can filter by the data you are interested in either by the API parameters, or you can do it in Karate (typically a match contains when arrays are involved).\nYou can see a typical example here.\nAlso see this thread: https://stackoverflow.com/a/60944060/143475\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77041295,
                        "answer_post": "When optimizing code first analyze the code and determine where the bottleneck is, then address the bottleneck. Optimizing anything else is a waste of time.\nMost applications have issues like slow network calls or unindexed queries, etc, that will be slowing things down. If virtual method lookups really are your bottleneck, then congratulations, you have a super fast program. At some point optimizing won't be cost effective and won't yield significant benefits, it is overwhelmingly likely you will hit that point way before virtual methods become an issue.  Part of optimization is knowing when to quit.\nWhat we try to optimize for in real life is developer time, where we try to write code that is clear and not confusing. The benefit of polymorphism is that the flow of the program doesnt have to care about details of subclasses, which stay out of the way, unlike your if-tests which are mixed into the logic flow. Think of what a hassle it would be to add another subclass in the if-test version, how you would have to search for all the if checks and add another case.\n2 main lessons:\n\nMeasure before performance tuning so you can make an informed decision about whether it's worthwhile, don't make assumptions.\n\nOptimize for your time, it is a lot more costly than a few cpu cycles.\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76762979,
                        "answer_post": "Normally teams use karate.callSingle() for this kind of use-case: https://stackoverflow.com/a/56853597/143475\nIf you insist on using Java, use a singleton as described here: https://stackoverflow.com/a/54571844/143475\nPlease note that tests that depend on each other is not a good practice and not supported by Karate: https://stackoverflow.com/a/46080568/143475\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74978826,
                        "answer_post": "Time complexity is just how long an algorithm will take to run as a function of the size of the input.\nSo for this specific example (and most cases tbh) yes, it\u2019ll run in the same time complexity regardless of programming language.\nThe only exception I can think of are built in functions, for which every language may have their own time complexity\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 72280675,
                        "answer_post": "Try using Environment.getDataDirectory().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74664479,
                        "answer_post": "A HashMap makes no guarantees about the internal ordering, other than it being consistent - i.e., if you run the same program twice with the same JDK, you'll get the same order.\nIf you want a HashMap that preserves the order of insertion, you could use a LinkedHashMap.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73153710,
                        "answer_post": "LinkedBlockingQueue uses synchronization internally, in the form of ReentrantLock -- that's how it implements the 'blocking' part.\nSomething like this should work:\n\nHere threads compete at the busy flag. One of them wins the right to add to the list, others busy-wait until the winning thread clears the flag.\nThe two calls to AtomicBoolean methods establish proper 'happens-before' relationship between list.add() calls done on different threads, so each thread should observe actual state of the list.\nLinkedList can be used for unbounded queues. For bounded ones, maybe ArrayList with initial capacity set.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76872017,
                        "answer_post": "\n... the output should be {abc=1, def=1, ghi=1}\n\nThere is no reason to expect this behavior. Every comparison operation yields zero (i.e. \"equal\") for your sample data, and there's no guarantee in the specification (i.e. the Javadoc) that TreeMap preserves insertion order for equal keys.  If you want to preserve insertion order you'll need to use a LinkedHashMap.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72653515,
                        "answer_post": "Try this.\n\noutput:\n\nIf you use class instead of record, you need to override equals() and hashCode() appropriately.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77389748,
                        "answer_post": "As Slaw pointed out, Iterator does what you want:\n\nIf you want to keep track of the current index in the list/array, or if you want to be able to navigate both forwards and backwards, you can use a ListIterator:\n\n(This code is identical to the first code block, except for calling listIterator() instead of iterator().)\nThe Iterator, ListIterator, and Arrays classes are all in the java.util package.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77278161,
                        "answer_post": "As suggested by doc that order is indeed non-deterministic.\nTry running the code with more data in HashMap to see the difference.\nSet is unordered by design.\nIf order is necessary for your requirement (in main data structure) try LinkedHashMap which maintains order of insertion. (As it implements LinkedList internally.)\nHope this helps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72626462,
                        "answer_post": "Yes exactly, but if you look in the book, they took this assumption:\n\nImprovedList assumes that once a list is passed to its constructor,\nthe client will not use the underlying list directly again, accessing\nit only via ImprovedList\n\nBased on this assumption the code is thread-safe.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72931108,
                        "answer_post": "\nO(n) or O(nlogn) ?\n\nNeither of these.\nFirstly, it seems like you're confusing a stream which elements are sorted with an ordered stream, i.e. a stream which has a particular encounter order of elements.\nWhether a stream is ordered or not depends on the stream source and intermediate operations in it.\nA stream created over an array, or ordered collection like a List, or a Queue is ordered respectively to order elements in it, but it does not imply that such stream is sorted.\nWe can make a stream unordered by applying unordered() operation on in it. This operation alone will not change the stream data, but it will have an impact on the execution of stateful intermediate operations like takeWhile() that require buffering, and terminal operation like reduce(), collect() that give a guarantee to respect the initial encounter order. As a result, a parallel unordered stream might have better performance because of loosening this constraint.\nHere is a quote from the API documentation:\n\nOrdering\nStreams may or may not have a defined encounter order. Whether or\nnot a stream has an encounter order depends on the source and the\nintermediate operations. Certain stream sources (such as List or arrays) are\nintrinsically ordered, whereas others (such as HashSet)\nare not. Some intermediate operations, such as sorted(), may impose an\nencounter order on an otherwise unordered stream, and others may\nrender an ordered stream unordered, such as BaseStream.unordered().\nFurther, some terminal operations may ignore encounter order, such as\nforEach().\nIf a stream is ordered, most operations are constrained to operate on\nthe elements in their encounter order; if the source of a stream is a\nList containing [1, 2, 3], then the result of executing map(x -> x*2)\nmust be [2, 4, 6]. However, if the source has no defined encounter\norder, then any permutation of the values [2, 4, 6] would be a valid\nresult.\nFor sequential streams, the presence or absence of an encounter order\ndoes not affect performance, only determinism. If a stream is ordered,\nrepeated execution of identical stream pipelines on an identical\nsource will produce an identical result; if it is not ordered,\nrepeated execution might produce different results.\nFor parallel streams, relaxing the ordering constraint can sometimes\nenable more efficient execution. Certain aggregate operations, such as\nfiltering duplicates (distinct()) or grouped reductions\n(Collectors.groupingBy()) can be implemented more efficiently if\nordering of elements is not relevant. Similarly, operations that are\nintrinsically tied to encounter order, such as limit(), may require\nbuffering to ensure proper ordering, undermining the benefit of\nparallelism. In cases where the stream has an encounter order, but the\nuser does not particularly care about that encounter order, explicitly\nde-ordering the stream with unordered() may improve parallel\nperformance for some stateful or terminal operations. However, most\nstream pipelines, such as the \"sum of weight of blocks\" example above,\nstill parallelize efficiently even under ordering constraints.\n\nSecondly, because you're assuming that creating a stream over an array will cost at list O(n) you might have a misconception regarding the nature of streams.\nIn essence, stream is a mean of iteration, it is not a container of data like Collection.\nCreation of a stream doesn't require dumping all the data from the source into memory, we're only creating an internal iterator over the source of data, and this action has a time complexity of O(1).\nStreams are lazy and every action in the stream pipeline occur only when it's needed, and elements from the source are processed one by one.\nFor instance, let's assume we have an integer array containing 1,000,000 elements, and we want to get the first 10 elements from it as hexadecimal strings:\n\nOn execution, only the first 10 elements would be retrieved  from the source array, and then the stream would immediately terminate, producing the result.\nThe overall time complexity of such a stream would be O(1) because we care only about a fixed number of elements at the very beginning, and don't need all the data that the source contains.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74850838,
                        "answer_post": "HashMap.Node is declared with package private visibility (the default visibility if public, private or protected is not used).\n\nThis means that the class is only visible to classes in the same package.\nSee this question for more details: What is the difference between public, protected, package-private and private in Java?\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72888526,
                        "answer_post": "\nUse the Character API\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72605934,
                        "answer_post": "Try with post method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75956015,
                        "answer_post": "thy this in the application.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77619571,
                        "answer_post": "Using in your Activity onBackPressed Method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73482220,
                        "answer_post": "use setGravity method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74891193,
                        "answer_post": "You looking for takeWhile() method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73276718,
                        "answer_post": "In the application.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72278856,
                        "answer_post": "Try this I have made proper constraint with UI\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73354616,
                        "answer_post": "It requires multi dimensional array\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "The filter criteria may not be specified correctly: Make sure that the filter criteria you're using is valid and matches the data types and values in the file.\nThe filter criteria may not be compatible with the data type of the column being filtered: Ensure that the data type of the column you're filtering on matches the data type expected by the filter.\nThere may be a bug in the implementation of the filter or in the ParquetFileReader class itself: Check the documentation and known issues for the Parquet library you're using, and try updating to the latest version of the library.\nTo further diagnose the issue, you can try debugging the code and examining the values of the filter criteria and the data being filtered on. You may also want to consider reaching out to the Parquet library community or support team for assistance.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "To ensure that the connection is closed after the query execution, you should move the close statement inside the queryWithParams callback.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You are on the right track, as others have stated you just need to validate the output string to ensure it meets your criteria.\n\nWhich results in:\n\nUpdate for the evaluation issue in the most recent edit:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "you can use retrofit and ensure you had created API client server to retrieve and read your data :)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You could be missing something.\nPlease check your build.gradle file for the set compileSdkVersion and the targetSdkVersion. Ensure that those SDKs are downloaded and installed and that you are testing with a device matching the minimum requirements you have defined.\nE.g You could have specified a minimum SDK of 30 and maybe the emulator or other device you are using to test is SDK 28 i.e., lower than your minimum requirements.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You can install the java using below-mentioned command:\n\nTo ensure that you are using java 8, you need to add path into bash file(~/.bashrc or ~/.zshrc)\nCommand to set path:\n\nAfter that do:\n\ncheck the java version again. Hope, it helps you.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Your ANT build file uses the property ${src.dir} that is either not defined at all or it uses that property in a target that does not depend on the target that defines said property.\nEither ensure that <property name=\"src.dir\" .../> is defined in your ANT build file and that all targets that use the property depend on the target that defines the property or (if you do not want to specify a src.dir property in your build file) invoke ANT with a -Dsrc.dir=... command line option. In the latter case you should add a condition to your build file that fails the build if the src.dir property is not set.\nSee the ANT manual for more information.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Regarding 1.\nDo you want to make two concurrent API requests?\nIn this case, to ensure that the hotel will be booked only once, you should look at optimistic/pessimistic locking.\nRegarding 2.\nIt really depends what do the logic that will emit nested event.\nFor sure you can take a look at the outbox pattern if you want to ensure that operation will be transactional and eventually consistent\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "For cases when it is not possible to edit the classes to add validation annotations to it there are two options:\nSpecifying the constraints via XML\nTo use this approach you'd need to add a META-INF/validation.xml and then inside of it you can define/redefine your constraints:\n\nfor more details you should check this section of the specification.\nProgrammatic constraint definition\nAlternatively, Hibernate Validator provides a way to add constraints programmatically:\n\nFor more details, check this section of the Hibernate Validator documentation.\nIf you do not know which fields will need not empty/blank constraint being applied you can try to iterate through the fields using the reflection and then based on that information define the constraints via programmatic API. once constraints are added to the validator you should be able to just use Validator#validate(..)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This looks tls algorithm is part of your disabledAlgorithms list in jdk which is running in your system.\nWhile link shared by Marc Stroebel might help you but if you want to set this programatically as well, then you can use below in your spring startup :\n\nThis will allow all algorithms while app execution.\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "pattern": {
                "finetuned_dpr": [
                    {
                        "id": 74771450,
                        "answer_post": "In your case, your input size n = high - low which is exactly the number of iterations your algorithm is executing. Hence the time complexity is O(n)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72983240,
                        "answer_post": "You will need to change your domain; from Cost, I can see you require the Jobs to be ordered, but Job does not have any problem properties (i.e. non-planning variable fields) that can be used to determine the order (for example, a datetime field).\nTo enforce an order,there are two different models you can use:\n\nthe chained model, where each Job point to the previous Job (and the first Job points to Employee). This is explained by https://www.optaplanner.org/docs/optaplanner/latest/planner-configuration/planner-configuration.html#chainedPlanningVariable and https://www.optaplanner.org/docs/optaplanner/latest/design-patterns/design-patterns.html#chainedThroughTimePattern .\n\nUsing @PlanningListVariable, where each Employee is assigned an ordered List of jobs (and each job goes to exactly one employee). This changes Employee to the @PlanningEntity with a @PlanningListVariable for jobs, and Job to a shadow entity (changing its @PlanningVariable to an @InverseRelationShadowVariable). An example of this is https://github.com/kiegroup/optaplanner-quickstarts/tree/stable/use-cases/vehicle-routing .\n\n\nThe final form of the constraints will vary depending on which model is used.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74864595,
                        "answer_post": "For your scenario, you can use the Template Method pattern.\n\nTemplate method defines the steps to execute an algorithm\nand it can provide a default implementation that might be common for\nall or some of the subclasses\n\nAn Example below\n\n\nUsage:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76762979,
                        "answer_post": "Normally teams use karate.callSingle() for this kind of use-case: https://stackoverflow.com/a/56853597/143475\nIf you insist on using Java, use a singleton as described here: https://stackoverflow.com/a/54571844/143475\nPlease note that tests that depend on each other is not a good practice and not supported by Karate: https://stackoverflow.com/a/46080568/143475\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75059735,
                        "answer_post": "Time complexity describes how an algorithm's time grows, as a function of the input, as time approaches infinity.\nIn this case, it is clear that the running time depends only on the size of the input, not on its content. So it is up to you to define a variable that describes your input size.\nIn your code example, the input size is constant 3x3, so if this never changes, then you can just say the algorithm has constant time complexity, O(1).\nIf the input can change, then it is up to you to decide how it can change, and how it makes sense to define it. For example, you can say that it is an n * n quadratic grid. Fine. Then, clearly both your loops run n times, so you get a total complexity of O(n * n) = O(n2).\nIt is also perfectly correct to define n as the total number of elements in your array. Then, we have some n = a * b. One of your loops runs a times, the other b times, so in total the complexity becomes O(a * b) = O(n).\nAs for your second question, yes if you apply this for a board m times, then your complexity would be O(m n2) or O(m n), depending on your chosen definition.\nWhat matters is that you make your definitions clear and define your variables in a way that makes sense for what you are trying to say.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75887067,
                        "answer_post": "Fine-tuning the solver is an art on its own. Please find out more in benchmarking and tweaking OptaPlanner.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76811028,
                        "answer_post": "You can integrate any Java code into Karate, so if you really want you can go direct to JDBC.\nWhen it comes to APIs I'm pretty sure you can't control transactions, because you are at an outer layer of the architecture. From experience, the strategy I've seen work is that each test creates data that is \"scoped\" to that flow at the start. When you GET data, you can filter by the data you are interested in either by the API parameters, or you can do it in Karate (typically a match contains when arrays are involved).\nYou can see a typical example here.\nAlso see this thread: https://stackoverflow.com/a/60944060/143475\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77041295,
                        "answer_post": "When optimizing code first analyze the code and determine where the bottleneck is, then address the bottleneck. Optimizing anything else is a waste of time.\nMost applications have issues like slow network calls or unindexed queries, etc, that will be slowing things down. If virtual method lookups really are your bottleneck, then congratulations, you have a super fast program. At some point optimizing won't be cost effective and won't yield significant benefits, it is overwhelmingly likely you will hit that point way before virtual methods become an issue.  Part of optimization is knowing when to quit.\nWhat we try to optimize for in real life is developer time, where we try to write code that is clear and not confusing. The benefit of polymorphism is that the flow of the program doesnt have to care about details of subclasses, which stay out of the way, unlike your if-tests which are mixed into the logic flow. Think of what a hassle it would be to add another subclass in the if-test version, how you would have to search for all the if checks and add another case.\n2 main lessons:\n\nMeasure before performance tuning so you can make an informed decision about whether it's worthwhile, don't make assumptions.\n\nOptimize for your time, it is a lot more costly than a few cpu cycles.\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74686751,
                        "answer_post": "Although the order of insertion is significant as that is generally the order in which OptaPlanner will iterate over the facts and entities, it should have no impact on the quality of the solution.\nWhat does have impact on solution quality is your constraints. In your case, there is no constraint to tell OptaPlanner that SKU1 is preferrable to SKU2, or vice versa. How is OptaPlanner supposed to know to prefer one or the other?\nAsk yourself that question, and turn the answer into a constraint. If that answer is capacity multiplied by price, then there should be a constraint that takes it into account. I do not see one in your problem description.\nIn the absence of such information, OptaPlanner will treat all facts as equivalent in terms of solution quality, and therefore it will pick an arbitrary one. (In this case, one that was inserted earlier.)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74978826,
                        "answer_post": "Time complexity is just how long an algorithm will take to run as a function of the size of the input.\nSo for this specific example (and most cases tbh) yes, it\u2019ll run in the same time complexity regardless of programming language.\nThe only exception I can think of are built in functions, for which every language may have their own time complexity\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 72280675,
                        "answer_post": "Try using Environment.getDataDirectory().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77389748,
                        "answer_post": "As Slaw pointed out, Iterator does what you want:\n\nIf you want to keep track of the current index in the list/array, or if you want to be able to navigate both forwards and backwards, you can use a ListIterator:\n\n(This code is identical to the first code block, except for calling listIterator() instead of iterator().)\nThe Iterator, ListIterator, and Arrays classes are all in the java.util package.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74664479,
                        "answer_post": "A HashMap makes no guarantees about the internal ordering, other than it being consistent - i.e., if you run the same program twice with the same JDK, you'll get the same order.\nIf you want a HashMap that preserves the order of insertion, you could use a LinkedHashMap.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73153710,
                        "answer_post": "LinkedBlockingQueue uses synchronization internally, in the form of ReentrantLock -- that's how it implements the 'blocking' part.\nSomething like this should work:\n\nHere threads compete at the busy flag. One of them wins the right to add to the list, others busy-wait until the winning thread clears the flag.\nThe two calls to AtomicBoolean methods establish proper 'happens-before' relationship between list.add() calls done on different threads, so each thread should observe actual state of the list.\nLinkedList can be used for unbounded queues. For bounded ones, maybe ArrayList with initial capacity set.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76808758,
                        "answer_post": "Using Java 9's List.of()-Method you can do:\n\nJust be aware that the resulting List is immutable.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74850838,
                        "answer_post": "HashMap.Node is declared with package private visibility (the default visibility if public, private or protected is not used).\n\nThis means that the class is only visible to classes in the same package.\nSee this question for more details: What is the difference between public, protected, package-private and private in Java?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72340560,
                        "answer_post": "According to the JavaDoc of class Process some platforms have a limited buffer for the output:\n\nAll its standard I/O (i.e. stdin, stdout, stderr) operations [..] can be accessed via [..] getOutputStream(), getInputStream(), and getErrorStream().\nBecause some native platforms only provide limited buffer size for standard input and output streams, failure to promptly write the input stream or read the output stream of the subprocess may cause the subprocess to block, or even deadlock.\n\nTry the following, before you call process.waitFor():\n\nget the output-streams from the process using getErrorStream() and getOutputStream() and\nread their contents to flush the buffer\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72931108,
                        "answer_post": "\nO(n) or O(nlogn) ?\n\nNeither of these.\nFirstly, it seems like you're confusing a stream which elements are sorted with an ordered stream, i.e. a stream which has a particular encounter order of elements.\nWhether a stream is ordered or not depends on the stream source and intermediate operations in it.\nA stream created over an array, or ordered collection like a List, or a Queue is ordered respectively to order elements in it, but it does not imply that such stream is sorted.\nWe can make a stream unordered by applying unordered() operation on in it. This operation alone will not change the stream data, but it will have an impact on the execution of stateful intermediate operations like takeWhile() that require buffering, and terminal operation like reduce(), collect() that give a guarantee to respect the initial encounter order. As a result, a parallel unordered stream might have better performance because of loosening this constraint.\nHere is a quote from the API documentation:\n\nOrdering\nStreams may or may not have a defined encounter order. Whether or\nnot a stream has an encounter order depends on the source and the\nintermediate operations. Certain stream sources (such as List or arrays) are\nintrinsically ordered, whereas others (such as HashSet)\nare not. Some intermediate operations, such as sorted(), may impose an\nencounter order on an otherwise unordered stream, and others may\nrender an ordered stream unordered, such as BaseStream.unordered().\nFurther, some terminal operations may ignore encounter order, such as\nforEach().\nIf a stream is ordered, most operations are constrained to operate on\nthe elements in their encounter order; if the source of a stream is a\nList containing [1, 2, 3], then the result of executing map(x -> x*2)\nmust be [2, 4, 6]. However, if the source has no defined encounter\norder, then any permutation of the values [2, 4, 6] would be a valid\nresult.\nFor sequential streams, the presence or absence of an encounter order\ndoes not affect performance, only determinism. If a stream is ordered,\nrepeated execution of identical stream pipelines on an identical\nsource will produce an identical result; if it is not ordered,\nrepeated execution might produce different results.\nFor parallel streams, relaxing the ordering constraint can sometimes\nenable more efficient execution. Certain aggregate operations, such as\nfiltering duplicates (distinct()) or grouped reductions\n(Collectors.groupingBy()) can be implemented more efficiently if\nordering of elements is not relevant. Similarly, operations that are\nintrinsically tied to encounter order, such as limit(), may require\nbuffering to ensure proper ordering, undermining the benefit of\nparallelism. In cases where the stream has an encounter order, but the\nuser does not particularly care about that encounter order, explicitly\nde-ordering the stream with unordered() may improve parallel\nperformance for some stateful or terminal operations. However, most\nstream pipelines, such as the \"sum of weight of blocks\" example above,\nstill parallelize efficiently even under ordering constraints.\n\nSecondly, because you're assuming that creating a stream over an array will cost at list O(n) you might have a misconception regarding the nature of streams.\nIn essence, stream is a mean of iteration, it is not a container of data like Collection.\nCreation of a stream doesn't require dumping all the data from the source into memory, we're only creating an internal iterator over the source of data, and this action has a time complexity of O(1).\nStreams are lazy and every action in the stream pipeline occur only when it's needed, and elements from the source are processed one by one.\nFor instance, let's assume we have an integer array containing 1,000,000 elements, and we want to get the first 10 elements from it as hexadecimal strings:\n\nOn execution, only the first 10 elements would be retrieved  from the source array, and then the stream would immediately terminate, producing the result.\nThe overall time complexity of such a stream would be O(1) because we care only about a fixed number of elements at the very beginning, and don't need all the data that the source contains.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72653515,
                        "answer_post": "Try this.\n\noutput:\n\nIf you use class instead of record, you need to override equals() and hashCode() appropriately.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76872017,
                        "answer_post": "\n... the output should be {abc=1, def=1, ghi=1}\n\nThere is no reason to expect this behavior. Every comparison operation yields zero (i.e. \"equal\") for your sample data, and there's no guarantee in the specification (i.e. the Javadoc) that TreeMap preserves insertion order for equal keys.  If you want to preserve insertion order you'll need to use a LinkedHashMap.\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77619571,
                        "answer_post": "Using in your Activity onBackPressed Method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72888526,
                        "answer_post": "\nUse the Character API\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73482220,
                        "answer_post": "use setGravity method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72605934,
                        "answer_post": "Try with post method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74390718,
                        "answer_post": "Use MethodSource:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75956015,
                        "answer_post": "thy this in the application.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72628261,
                        "answer_post": "Resolved with the following method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72711160,
                        "answer_post": "use this data class\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74891193,
                        "answer_post": "You looking for takeWhile() method\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "The filter criteria may not be specified correctly: Make sure that the filter criteria you're using is valid and matches the data types and values in the file.\nThe filter criteria may not be compatible with the data type of the column being filtered: Ensure that the data type of the column you're filtering on matches the data type expected by the filter.\nThere may be a bug in the implementation of the filter or in the ParquetFileReader class itself: Check the documentation and known issues for the Parquet library you're using, and try updating to the latest version of the library.\nTo further diagnose the issue, you can try debugging the code and examining the values of the filter criteria and the data being filtered on. You may also want to consider reaching out to the Parquet library community or support team for assistance.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "For cases when it is not possible to edit the classes to add validation annotations to it there are two options:\nSpecifying the constraints via XML\nTo use this approach you'd need to add a META-INF/validation.xml and then inside of it you can define/redefine your constraints:\n\nfor more details you should check this section of the specification.\nProgrammatic constraint definition\nAlternatively, Hibernate Validator provides a way to add constraints programmatically:\n\nFor more details, check this section of the Hibernate Validator documentation.\nIf you do not know which fields will need not empty/blank constraint being applied you can try to iterate through the fields using the reflection and then based on that information define the constraints via programmatic API. once constraints are added to the validator you should be able to just use Validator#validate(..)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "This looks tls algorithm is part of your disabledAlgorithms list in jdk which is running in your system.\nWhile link shared by Marc Stroebel might help you but if you want to set this programatically as well, then you can use below in your spring startup :\n\nThis will allow all algorithms while app execution.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "TL;DR\n:: or && are not part of the JPA Criteria API standard. You could use a native SQL query.\n\nIf you want to use specific features or functions unique to a database system like PostgreSQL, it may not be possible to use them directly within the JPA Criteria API.\nSome queries, you can avoid the headache by specifying the escape sequence completely, but for this query; There is no way to simultaneously escape special types such as overlap (&&), double colon (::), and tsrange (cast(string as tsrange)).\nIt would be appropriate to create this query using a native query (@Query) instead of the Criteria API, or alternatively; if you are using Hibernate you can create a FunctionContributor for this statement.\nCreate a FunctionContributor, here we give our function a special name and set our pattern:\n(It is a simple function definition approach, it can be made more usable.)\n\nWe use this function with the Criteria API:\n\nThe class must be then registered via Java ServiceLoader mechanism by adding full name of the class with its packages into the file with name org.hibernate.boot.model.FunctionContributor into the java module\u2019s META-INF/services directory.\nYou use this specification your query will look like this:\n\nIt was prepared with Spring Boot 3.2.1 and Hibernate 6.2.7.Final.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "My assumption is that you shouldn't be keeping the criteria builder around. It's meant to be used in a case-by-case execution, so in this method you would rather run:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Admittedly this is only tangenitally related to your question, but depending on what version of java your using, you might not have the full suite of cryptographic algorithms available to you.\nInitially, as strong encryption algorithms could not be shipped everywhere due to various legal restrictions, java was shipped with limited crypto algorithms.  To have the full suite of crypto algorithms (including the 'strong' ones), you'll need to apply the official oracle Java Cryptographic Extension patch to both of your java installations.\nSee https://www.baeldung.com/jce-enable-unlimited-strength for more details.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "See the answer I posted here: Equivalent of Hibernate's Restrictions.sqlRestriction in JPA2 Criteria API?\nWe had very complex queries being dynamically generated and I did not want to have to replace them with criteria based sub queries.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "It supposed to be:\n\nBecause .publishOn(..) doesn't spin off new threads, it just defines the current thread. But .parallel().runOn(..) uses parallel threads for execution.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You need to pass the -parameters argument to the java compiler. The -g:vars argument provides information regarding all local variables, but the attribute which defines this is never accessible using the reflection API. When using -parameters, a special attribute is used which is explicitly designed for being accessed by the reflection API.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You have to join the two conditions with and. This is how it looks with JPA JPQL\n\nAnd this would be JPA Criteria API\n\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "environment": {
                "finetuned_dpr": [
                    {
                        "id": 74771450,
                        "answer_post": "In your case, your input size n = high - low which is exactly the number of iterations your algorithm is executing. Hence the time complexity is O(n)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72983240,
                        "answer_post": "You will need to change your domain; from Cost, I can see you require the Jobs to be ordered, but Job does not have any problem properties (i.e. non-planning variable fields) that can be used to determine the order (for example, a datetime field).\nTo enforce an order,there are two different models you can use:\n\nthe chained model, where each Job point to the previous Job (and the first Job points to Employee). This is explained by https://www.optaplanner.org/docs/optaplanner/latest/planner-configuration/planner-configuration.html#chainedPlanningVariable and https://www.optaplanner.org/docs/optaplanner/latest/design-patterns/design-patterns.html#chainedThroughTimePattern .\n\nUsing @PlanningListVariable, where each Employee is assigned an ordered List of jobs (and each job goes to exactly one employee). This changes Employee to the @PlanningEntity with a @PlanningListVariable for jobs, and Job to a shadow entity (changing its @PlanningVariable to an @InverseRelationShadowVariable). An example of this is https://github.com/kiegroup/optaplanner-quickstarts/tree/stable/use-cases/vehicle-routing .\n\n\nThe final form of the constraints will vary depending on which model is used.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74864595,
                        "answer_post": "For your scenario, you can use the Template Method pattern.\n\nTemplate method defines the steps to execute an algorithm\nand it can provide a default implementation that might be common for\nall or some of the subclasses\n\nAn Example below\n\n\nUsage:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75059735,
                        "answer_post": "Time complexity describes how an algorithm's time grows, as a function of the input, as time approaches infinity.\nIn this case, it is clear that the running time depends only on the size of the input, not on its content. So it is up to you to define a variable that describes your input size.\nIn your code example, the input size is constant 3x3, so if this never changes, then you can just say the algorithm has constant time complexity, O(1).\nIf the input can change, then it is up to you to decide how it can change, and how it makes sense to define it. For example, you can say that it is an n * n quadratic grid. Fine. Then, clearly both your loops run n times, so you get a total complexity of O(n * n) = O(n2).\nIt is also perfectly correct to define n as the total number of elements in your array. Then, we have some n = a * b. One of your loops runs a times, the other b times, so in total the complexity becomes O(a * b) = O(n).\nAs for your second question, yes if you apply this for a board m times, then your complexity would be O(m n2) or O(m n), depending on your chosen definition.\nWhat matters is that you make your definitions clear and define your variables in a way that makes sense for what you are trying to say.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77041295,
                        "answer_post": "When optimizing code first analyze the code and determine where the bottleneck is, then address the bottleneck. Optimizing anything else is a waste of time.\nMost applications have issues like slow network calls or unindexed queries, etc, that will be slowing things down. If virtual method lookups really are your bottleneck, then congratulations, you have a super fast program. At some point optimizing won't be cost effective and won't yield significant benefits, it is overwhelmingly likely you will hit that point way before virtual methods become an issue.  Part of optimization is knowing when to quit.\nWhat we try to optimize for in real life is developer time, where we try to write code that is clear and not confusing. The benefit of polymorphism is that the flow of the program doesnt have to care about details of subclasses, which stay out of the way, unlike your if-tests which are mixed into the logic flow. Think of what a hassle it would be to add another subclass in the if-test version, how you would have to search for all the if checks and add another case.\n2 main lessons:\n\nMeasure before performance tuning so you can make an informed decision about whether it's worthwhile, don't make assumptions.\n\nOptimize for your time, it is a lot more costly than a few cpu cycles.\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75887067,
                        "answer_post": "Fine-tuning the solver is an art on its own. Please find out more in benchmarking and tweaking OptaPlanner.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76811028,
                        "answer_post": "You can integrate any Java code into Karate, so if you really want you can go direct to JDBC.\nWhen it comes to APIs I'm pretty sure you can't control transactions, because you are at an outer layer of the architecture. From experience, the strategy I've seen work is that each test creates data that is \"scoped\" to that flow at the start. When you GET data, you can filter by the data you are interested in either by the API parameters, or you can do it in Karate (typically a match contains when arrays are involved).\nYou can see a typical example here.\nAlso see this thread: https://stackoverflow.com/a/60944060/143475\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76762979,
                        "answer_post": "Normally teams use karate.callSingle() for this kind of use-case: https://stackoverflow.com/a/56853597/143475\nIf you insist on using Java, use a singleton as described here: https://stackoverflow.com/a/54571844/143475\nPlease note that tests that depend on each other is not a good practice and not supported by Karate: https://stackoverflow.com/a/46080568/143475\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74686751,
                        "answer_post": "Although the order of insertion is significant as that is generally the order in which OptaPlanner will iterate over the facts and entities, it should have no impact on the quality of the solution.\nWhat does have impact on solution quality is your constraints. In your case, there is no constraint to tell OptaPlanner that SKU1 is preferrable to SKU2, or vice versa. How is OptaPlanner supposed to know to prefer one or the other?\nAsk yourself that question, and turn the answer into a constraint. If that answer is capacity multiplied by price, then there should be a constraint that takes it into account. I do not see one in your problem description.\nIn the absence of such information, OptaPlanner will treat all facts as equivalent in terms of solution quality, and therefore it will pick an arbitrary one. (In this case, one that was inserted earlier.)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74978826,
                        "answer_post": "Time complexity is just how long an algorithm will take to run as a function of the size of the input.\nSo for this specific example (and most cases tbh) yes, it\u2019ll run in the same time complexity regardless of programming language.\nThe only exception I can think of are built in functions, for which every language may have their own time complexity\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 72280675,
                        "answer_post": "Try using Environment.getDataDirectory().\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77389748,
                        "answer_post": "As Slaw pointed out, Iterator does what you want:\n\nIf you want to keep track of the current index in the list/array, or if you want to be able to navigate both forwards and backwards, you can use a ListIterator:\n\n(This code is identical to the first code block, except for calling listIterator() instead of iterator().)\nThe Iterator, ListIterator, and Arrays classes are all in the java.util package.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73153710,
                        "answer_post": "LinkedBlockingQueue uses synchronization internally, in the form of ReentrantLock -- that's how it implements the 'blocking' part.\nSomething like this should work:\n\nHere threads compete at the busy flag. One of them wins the right to add to the list, others busy-wait until the winning thread clears the flag.\nThe two calls to AtomicBoolean methods establish proper 'happens-before' relationship between list.add() calls done on different threads, so each thread should observe actual state of the list.\nLinkedList can be used for unbounded queues. For bounded ones, maybe ArrayList with initial capacity set.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76808758,
                        "answer_post": "Using Java 9's List.of()-Method you can do:\n\nJust be aware that the resulting List is immutable.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73132737,
                        "answer_post": "According to documentation EnvironmentPostProcessors must be registered via META-INF/spring.factories:\n\nAllows for customization of the application's Environment prior to the\napplication context being refreshed. EnvironmentPostProcessor\nimplementations have to be registered in META-INF/spring.factories,\nusing the fully qualified name of this class as the key.\nImplementations may implement the Ordered interface or use an @Order\nannotation if they wish to be invoked in specific order.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73249889,
                        "answer_post": "If you put your files/resources inside your source folder, you can access them through ClassName.getResource() and ClassName.getResourceAsStream() methods.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74850838,
                        "answer_post": "HashMap.Node is declared with package private visibility (the default visibility if public, private or protected is not used).\n\nThis means that the class is only visible to classes in the same package.\nSee this question for more details: What is the difference between public, protected, package-private and private in Java?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74664479,
                        "answer_post": "A HashMap makes no guarantees about the internal ordering, other than it being consistent - i.e., if you run the same program twice with the same JDK, you'll get the same order.\nIf you want a HashMap that preserves the order of insertion, you could use a LinkedHashMap.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72931108,
                        "answer_post": "\nO(n) or O(nlogn) ?\n\nNeither of these.\nFirstly, it seems like you're confusing a stream which elements are sorted with an ordered stream, i.e. a stream which has a particular encounter order of elements.\nWhether a stream is ordered or not depends on the stream source and intermediate operations in it.\nA stream created over an array, or ordered collection like a List, or a Queue is ordered respectively to order elements in it, but it does not imply that such stream is sorted.\nWe can make a stream unordered by applying unordered() operation on in it. This operation alone will not change the stream data, but it will have an impact on the execution of stateful intermediate operations like takeWhile() that require buffering, and terminal operation like reduce(), collect() that give a guarantee to respect the initial encounter order. As a result, a parallel unordered stream might have better performance because of loosening this constraint.\nHere is a quote from the API documentation:\n\nOrdering\nStreams may or may not have a defined encounter order. Whether or\nnot a stream has an encounter order depends on the source and the\nintermediate operations. Certain stream sources (such as List or arrays) are\nintrinsically ordered, whereas others (such as HashSet)\nare not. Some intermediate operations, such as sorted(), may impose an\nencounter order on an otherwise unordered stream, and others may\nrender an ordered stream unordered, such as BaseStream.unordered().\nFurther, some terminal operations may ignore encounter order, such as\nforEach().\nIf a stream is ordered, most operations are constrained to operate on\nthe elements in their encounter order; if the source of a stream is a\nList containing [1, 2, 3], then the result of executing map(x -> x*2)\nmust be [2, 4, 6]. However, if the source has no defined encounter\norder, then any permutation of the values [2, 4, 6] would be a valid\nresult.\nFor sequential streams, the presence or absence of an encounter order\ndoes not affect performance, only determinism. If a stream is ordered,\nrepeated execution of identical stream pipelines on an identical\nsource will produce an identical result; if it is not ordered,\nrepeated execution might produce different results.\nFor parallel streams, relaxing the ordering constraint can sometimes\nenable more efficient execution. Certain aggregate operations, such as\nfiltering duplicates (distinct()) or grouped reductions\n(Collectors.groupingBy()) can be implemented more efficiently if\nordering of elements is not relevant. Similarly, operations that are\nintrinsically tied to encounter order, such as limit(), may require\nbuffering to ensure proper ordering, undermining the benefit of\nparallelism. In cases where the stream has an encounter order, but the\nuser does not particularly care about that encounter order, explicitly\nde-ordering the stream with unordered() may improve parallel\nperformance for some stateful or terminal operations. However, most\nstream pipelines, such as the \"sum of weight of blocks\" example above,\nstill parallelize efficiently even under ordering constraints.\n\nSecondly, because you're assuming that creating a stream over an array will cost at list O(n) you might have a misconception regarding the nature of streams.\nIn essence, stream is a mean of iteration, it is not a container of data like Collection.\nCreation of a stream doesn't require dumping all the data from the source into memory, we're only creating an internal iterator over the source of data, and this action has a time complexity of O(1).\nStreams are lazy and every action in the stream pipeline occur only when it's needed, and elements from the source are processed one by one.\nFor instance, let's assume we have an integer array containing 1,000,000 elements, and we want to get the first 10 elements from it as hexadecimal strings:\n\nOn execution, only the first 10 elements would be retrieved  from the source array, and then the stream would immediately terminate, producing the result.\nThe overall time complexity of such a stream would be O(1) because we care only about a fixed number of elements at the very beginning, and don't need all the data that the source contains.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72340560,
                        "answer_post": "According to the JavaDoc of class Process some platforms have a limited buffer for the output:\n\nAll its standard I/O (i.e. stdin, stdout, stderr) operations [..] can be accessed via [..] getOutputStream(), getInputStream(), and getErrorStream().\nBecause some native platforms only provide limited buffer size for standard input and output streams, failure to promptly write the input stream or read the output stream of the subprocess may cause the subprocess to block, or even deadlock.\n\nTry the following, before you call process.waitFor():\n\nget the output-streams from the process using getErrorStream() and getOutputStream() and\nread their contents to flush the buffer\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75956015,
                        "answer_post": "thy this in the application.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73276718,
                        "answer_post": "In the application.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72888526,
                        "answer_post": "\nUse the Character API\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73482220,
                        "answer_post": "use setGravity method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72605934,
                        "answer_post": "Try with post method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73354616,
                        "answer_post": "It requires multi dimensional array\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77619571,
                        "answer_post": "Using in your Activity onBackPressed Method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76095804,
                        "answer_post": "See this please\nfor Java\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77577353,
                        "answer_post": "set bounds:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You could be missing something.\nPlease check your build.gradle file for the set compileSdkVersion and the targetSdkVersion. Ensure that those SDKs are downloaded and installed and that you are testing with a device matching the minimum requirements you have defined.\nE.g You could have specified a minimum SDK of 30 and maybe the emulator or other device you are using to test is SDK 28 i.e., lower than your minimum requirements.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This looks like a version of a multi-dimensional Knapsack problem, where you want to optimize allocation of assets to specific buckets/requirements.\nYou have a list of requirements (Asset Class Requirement & Ratings requirements) that you need to satisfy. They basically tell you if given bond can be allocated to a 'bucket' that you need to fill.\nYou can solve this problem in a non-optimal way with a greedy algorithm where you just allocate first asset that meets criteria. So you go through the requirements and look up the first bond that meets the criteria there. You continue till you run out of requirements or bonds to satisfy them. It's called heuristic. It will quickly produce solution, but most probably it won't be the best.\nThis will produce some solution. How good it is you can measure by having a cost-function. Cost function will be how much bonds you still need to obtain from the market to satisfy remaining requirements.\nIf you want better or possibly best solution this becomes a hard problem. There are linear-programming algorithms that can help. Google OR-tools is one of established libraries that runs this kind of optimizations.\nYou wouldn't believe how much banks and finance companies use 'dumb' algorithms and how much they lose by not employing smarter tactics.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Implicit Wait:\nImplicit wait sets a maximum time for the WebDriver to wait for an element to be present in the DOM. It is applied globally and is set once for the entire session.\nExplicit Wait with ExpectedConditions:\nUse explicit waits in combination with ExpectedConditions for more fine-grained control over waiting conditions.\nThread.sleep:\nWhile not recommended in all cases due to its static nature, you can use Thread.sleep() to pause the execution for a specified period.\nCustom Wait Functions:\nYou can create your own custom wait functions using loops and conditions based on specific requirements.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "So our task is: How parse html-text with Java on website that's protected by cloudflare.\nThe speed of my method may not meet your requirements, because not every API call is successful. However, it works:\nWe will use Proxy Api web scrapping SCRAPPER-API\nwith the free version, registration takes no more than 5 minutes. We need to get an API key (We can use any one if it's better for you)\n\nFirst step create util class:\n\n\n\nCreate SiteScrapper class:\n\n\n\nLast step you can call the Scrapper method:\n\n\nHow to use checker:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "In your screenshot of your code it looks like you are trying to get your API key by calling System.getenv(\"YOUR_ACTUAL_API_KEY\").\nWhen calling on System.getenv you should pass the name of an environment variable in which you have stored your API key. So, you should store your environment variable in a variable called something like SENDGRID_API_KEY and then retrieve it in your program like:\n\nYou can read more about working with environment variables in Java and how to set environment variables.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The code below compiles and prints the elements of array row1.  You can copy and paste in https://www.onlinegdb.com/online_c_compiler  and select JAVA on the pulldown box, top right of screen. You still need to fix the logic to get meet the requirements\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The following code may meet your requirements.\n\nAfter executing the code, type 16 numbers separated by spaces in the terminal\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The filter criteria may not be specified correctly: Make sure that the filter criteria you're using is valid and matches the data types and values in the file.\nThe filter criteria may not be compatible with the data type of the column being filtered: Ensure that the data type of the column you're filtering on matches the data type expected by the filter.\nThere may be a bug in the implementation of the filter or in the ParquetFileReader class itself: Check the documentation and known issues for the Parquet library you're using, and try updating to the latest version of the library.\nTo further diagnose the issue, you can try debugging the code and examining the values of the filter criteria and the data being filtered on. You may also want to consider reaching out to the Parquet library community or support team for assistance.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "For cases when it is not possible to edit the classes to add validation annotations to it there are two options:\nSpecifying the constraints via XML\nTo use this approach you'd need to add a META-INF/validation.xml and then inside of it you can define/redefine your constraints:\n\nfor more details you should check this section of the specification.\nProgrammatic constraint definition\nAlternatively, Hibernate Validator provides a way to add constraints programmatically:\n\nFor more details, check this section of the Hibernate Validator documentation.\nIf you do not know which fields will need not empty/blank constraint being applied you can try to iterate through the fields using the reflection and then based on that information define the constraints via programmatic API. once constraints are added to the validator you should be able to just use Validator#validate(..)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "This looks tls algorithm is part of your disabledAlgorithms list in jdk which is running in your system.\nWhile link shared by Marc Stroebel might help you but if you want to set this programatically as well, then you can use below in your spring startup :\n\nThis will allow all algorithms while app execution.\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "alternative": {
                "finetuned_dpr": [
                    {
                        "id": 74771450,
                        "answer_post": "In your case, your input size n = high - low which is exactly the number of iterations your algorithm is executing. Hence the time complexity is O(n)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72983240,
                        "answer_post": "You will need to change your domain; from Cost, I can see you require the Jobs to be ordered, but Job does not have any problem properties (i.e. non-planning variable fields) that can be used to determine the order (for example, a datetime field).\nTo enforce an order,there are two different models you can use:\n\nthe chained model, where each Job point to the previous Job (and the first Job points to Employee). This is explained by https://www.optaplanner.org/docs/optaplanner/latest/planner-configuration/planner-configuration.html#chainedPlanningVariable and https://www.optaplanner.org/docs/optaplanner/latest/design-patterns/design-patterns.html#chainedThroughTimePattern .\n\nUsing @PlanningListVariable, where each Employee is assigned an ordered List of jobs (and each job goes to exactly one employee). This changes Employee to the @PlanningEntity with a @PlanningListVariable for jobs, and Job to a shadow entity (changing its @PlanningVariable to an @InverseRelationShadowVariable). An example of this is https://github.com/kiegroup/optaplanner-quickstarts/tree/stable/use-cases/vehicle-routing .\n\n\nThe final form of the constraints will vary depending on which model is used.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76762979,
                        "answer_post": "Normally teams use karate.callSingle() for this kind of use-case: https://stackoverflow.com/a/56853597/143475\nIf you insist on using Java, use a singleton as described here: https://stackoverflow.com/a/54571844/143475\nPlease note that tests that depend on each other is not a good practice and not supported by Karate: https://stackoverflow.com/a/46080568/143475\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74686751,
                        "answer_post": "Although the order of insertion is significant as that is generally the order in which OptaPlanner will iterate over the facts and entities, it should have no impact on the quality of the solution.\nWhat does have impact on solution quality is your constraints. In your case, there is no constraint to tell OptaPlanner that SKU1 is preferrable to SKU2, or vice versa. How is OptaPlanner supposed to know to prefer one or the other?\nAsk yourself that question, and turn the answer into a constraint. If that answer is capacity multiplied by price, then there should be a constraint that takes it into account. I do not see one in your problem description.\nIn the absence of such information, OptaPlanner will treat all facts as equivalent in terms of solution quality, and therefore it will pick an arbitrary one. (In this case, one that was inserted earlier.)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77041295,
                        "answer_post": "When optimizing code first analyze the code and determine where the bottleneck is, then address the bottleneck. Optimizing anything else is a waste of time.\nMost applications have issues like slow network calls or unindexed queries, etc, that will be slowing things down. If virtual method lookups really are your bottleneck, then congratulations, you have a super fast program. At some point optimizing won't be cost effective and won't yield significant benefits, it is overwhelmingly likely you will hit that point way before virtual methods become an issue.  Part of optimization is knowing when to quit.\nWhat we try to optimize for in real life is developer time, where we try to write code that is clear and not confusing. The benefit of polymorphism is that the flow of the program doesnt have to care about details of subclasses, which stay out of the way, unlike your if-tests which are mixed into the logic flow. Think of what a hassle it would be to add another subclass in the if-test version, how you would have to search for all the if checks and add another case.\n2 main lessons:\n\nMeasure before performance tuning so you can make an informed decision about whether it's worthwhile, don't make assumptions.\n\nOptimize for your time, it is a lot more costly than a few cpu cycles.\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74864595,
                        "answer_post": "For your scenario, you can use the Template Method pattern.\n\nTemplate method defines the steps to execute an algorithm\nand it can provide a default implementation that might be common for\nall or some of the subclasses\n\nAn Example below\n\n\nUsage:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75887067,
                        "answer_post": "Fine-tuning the solver is an art on its own. Please find out more in benchmarking and tweaking OptaPlanner.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75059735,
                        "answer_post": "Time complexity describes how an algorithm's time grows, as a function of the input, as time approaches infinity.\nIn this case, it is clear that the running time depends only on the size of the input, not on its content. So it is up to you to define a variable that describes your input size.\nIn your code example, the input size is constant 3x3, so if this never changes, then you can just say the algorithm has constant time complexity, O(1).\nIf the input can change, then it is up to you to decide how it can change, and how it makes sense to define it. For example, you can say that it is an n * n quadratic grid. Fine. Then, clearly both your loops run n times, so you get a total complexity of O(n * n) = O(n2).\nIt is also perfectly correct to define n as the total number of elements in your array. Then, we have some n = a * b. One of your loops runs a times, the other b times, so in total the complexity becomes O(a * b) = O(n).\nAs for your second question, yes if you apply this for a board m times, then your complexity would be O(m n2) or O(m n), depending on your chosen definition.\nWhat matters is that you make your definitions clear and define your variables in a way that makes sense for what you are trying to say.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76811028,
                        "answer_post": "You can integrate any Java code into Karate, so if you really want you can go direct to JDBC.\nWhen it comes to APIs I'm pretty sure you can't control transactions, because you are at an outer layer of the architecture. From experience, the strategy I've seen work is that each test creates data that is \"scoped\" to that flow at the start. When you GET data, you can filter by the data you are interested in either by the API parameters, or you can do it in Karate (typically a match contains when arrays are involved).\nYou can see a typical example here.\nAlso see this thread: https://stackoverflow.com/a/60944060/143475\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74978826,
                        "answer_post": "Time complexity is just how long an algorithm will take to run as a function of the size of the input.\nSo for this specific example (and most cases tbh) yes, it\u2019ll run in the same time complexity regardless of programming language.\nThe only exception I can think of are built in functions, for which every language may have their own time complexity\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 72280675,
                        "answer_post": "Try using Environment.getDataDirectory().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74664479,
                        "answer_post": "A HashMap makes no guarantees about the internal ordering, other than it being consistent - i.e., if you run the same program twice with the same JDK, you'll get the same order.\nIf you want a HashMap that preserves the order of insertion, you could use a LinkedHashMap.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73153710,
                        "answer_post": "LinkedBlockingQueue uses synchronization internally, in the form of ReentrantLock -- that's how it implements the 'blocking' part.\nSomething like this should work:\n\nHere threads compete at the busy flag. One of them wins the right to add to the list, others busy-wait until the winning thread clears the flag.\nThe two calls to AtomicBoolean methods establish proper 'happens-before' relationship between list.add() calls done on different threads, so each thread should observe actual state of the list.\nLinkedList can be used for unbounded queues. For bounded ones, maybe ArrayList with initial capacity set.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72336333,
                        "answer_post": "Iterative or stream based solutions are unnecessarily complicated and slow. Just use System.arraycopy:\n\nSystem.arraycopy is highly optimised: Why is System.arraycopy native in Java?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76808758,
                        "answer_post": "Using Java 9's List.of()-Method you can do:\n\nJust be aware that the resulting List is immutable.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75696410,
                        "answer_post": "Time complexity cannot be \"2888 ms\", because complexity isn't a measurement of absolute time. Time complexity only tells you how the runtime of an algorithm scales with input size. Now, different implementations can have the same complexity, but run at different (absolute) speeds. And even O(1) could be far slower than O(n) for small to medium inputs (but O(1) will always take the same time).\nJava's java.util.Stack is a really old class and should not be used anymore. It builds on top of Vector and every single call to its methods is synchronized. That means for every method call, you need to perform a lock when calling the method and unlocking when leaving the method. This can add considerable runtime overhead.\nA modern alternative to Stack is an ArrayDeque, which is even suggested by the JavaDoc of Stack itself:\n\nA more complete and consistent set of LIFO stack operations is provided by the Deque interface and its implementations, which should be used in preference to this class. For example:\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77389748,
                        "answer_post": "As Slaw pointed out, Iterator does what you want:\n\nIf you want to keep track of the current index in the list/array, or if you want to be able to navigate both forwards and backwards, you can use a ListIterator:\n\n(This code is identical to the first code block, except for calling listIterator() instead of iterator().)\nThe Iterator, ListIterator, and Arrays classes are all in the java.util package.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76872017,
                        "answer_post": "\n... the output should be {abc=1, def=1, ghi=1}\n\nThere is no reason to expect this behavior. Every comparison operation yields zero (i.e. \"equal\") for your sample data, and there's no guarantee in the specification (i.e. the Javadoc) that TreeMap preserves insertion order for equal keys.  If you want to preserve insertion order you'll need to use a LinkedHashMap.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74850838,
                        "answer_post": "HashMap.Node is declared with package private visibility (the default visibility if public, private or protected is not used).\n\nThis means that the class is only visible to classes in the same package.\nSee this question for more details: What is the difference between public, protected, package-private and private in Java?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72931108,
                        "answer_post": "\nO(n) or O(nlogn) ?\n\nNeither of these.\nFirstly, it seems like you're confusing a stream which elements are sorted with an ordered stream, i.e. a stream which has a particular encounter order of elements.\nWhether a stream is ordered or not depends on the stream source and intermediate operations in it.\nA stream created over an array, or ordered collection like a List, or a Queue is ordered respectively to order elements in it, but it does not imply that such stream is sorted.\nWe can make a stream unordered by applying unordered() operation on in it. This operation alone will not change the stream data, but it will have an impact on the execution of stateful intermediate operations like takeWhile() that require buffering, and terminal operation like reduce(), collect() that give a guarantee to respect the initial encounter order. As a result, a parallel unordered stream might have better performance because of loosening this constraint.\nHere is a quote from the API documentation:\n\nOrdering\nStreams may or may not have a defined encounter order. Whether or\nnot a stream has an encounter order depends on the source and the\nintermediate operations. Certain stream sources (such as List or arrays) are\nintrinsically ordered, whereas others (such as HashSet)\nare not. Some intermediate operations, such as sorted(), may impose an\nencounter order on an otherwise unordered stream, and others may\nrender an ordered stream unordered, such as BaseStream.unordered().\nFurther, some terminal operations may ignore encounter order, such as\nforEach().\nIf a stream is ordered, most operations are constrained to operate on\nthe elements in their encounter order; if the source of a stream is a\nList containing [1, 2, 3], then the result of executing map(x -> x*2)\nmust be [2, 4, 6]. However, if the source has no defined encounter\norder, then any permutation of the values [2, 4, 6] would be a valid\nresult.\nFor sequential streams, the presence or absence of an encounter order\ndoes not affect performance, only determinism. If a stream is ordered,\nrepeated execution of identical stream pipelines on an identical\nsource will produce an identical result; if it is not ordered,\nrepeated execution might produce different results.\nFor parallel streams, relaxing the ordering constraint can sometimes\nenable more efficient execution. Certain aggregate operations, such as\nfiltering duplicates (distinct()) or grouped reductions\n(Collectors.groupingBy()) can be implemented more efficiently if\nordering of elements is not relevant. Similarly, operations that are\nintrinsically tied to encounter order, such as limit(), may require\nbuffering to ensure proper ordering, undermining the benefit of\nparallelism. In cases where the stream has an encounter order, but the\nuser does not particularly care about that encounter order, explicitly\nde-ordering the stream with unordered() may improve parallel\nperformance for some stateful or terminal operations. However, most\nstream pipelines, such as the \"sum of weight of blocks\" example above,\nstill parallelize efficiently even under ordering constraints.\n\nSecondly, because you're assuming that creating a stream over an array will cost at list O(n) you might have a misconception regarding the nature of streams.\nIn essence, stream is a mean of iteration, it is not a container of data like Collection.\nCreation of a stream doesn't require dumping all the data from the source into memory, we're only creating an internal iterator over the source of data, and this action has a time complexity of O(1).\nStreams are lazy and every action in the stream pipeline occur only when it's needed, and elements from the source are processed one by one.\nFor instance, let's assume we have an integer array containing 1,000,000 elements, and we want to get the first 10 elements from it as hexadecimal strings:\n\nOn execution, only the first 10 elements would be retrieved  from the source array, and then the stream would immediately terminate, producing the result.\nThe overall time complexity of such a stream would be O(1) because we care only about a fixed number of elements at the very beginning, and don't need all the data that the source contains.\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72605934,
                        "answer_post": "Try with post method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77619571,
                        "answer_post": "Using in your Activity onBackPressed Method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75956015,
                        "answer_post": "thy this in the application.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72888526,
                        "answer_post": "\nUse the Character API\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73482220,
                        "answer_post": "use setGravity method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74891193,
                        "answer_post": "You looking for takeWhile() method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73276718,
                        "answer_post": "In the application.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73205629,
                        "answer_post": "How about different approach\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73354616,
                        "answer_post": "It requires multi dimensional array\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "The filter criteria may not be specified correctly: Make sure that the filter criteria you're using is valid and matches the data types and values in the file.\nThe filter criteria may not be compatible with the data type of the column being filtered: Ensure that the data type of the column you're filtering on matches the data type expected by the filter.\nThere may be a bug in the implementation of the filter or in the ParquetFileReader class itself: Check the documentation and known issues for the Parquet library you're using, and try updating to the latest version of the library.\nTo further diagnose the issue, you can try debugging the code and examining the values of the filter criteria and the data being filtered on. You may also want to consider reaching out to the Parquet library community or support team for assistance.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "For cases when it is not possible to edit the classes to add validation annotations to it there are two options:\nSpecifying the constraints via XML\nTo use this approach you'd need to add a META-INF/validation.xml and then inside of it you can define/redefine your constraints:\n\nfor more details you should check this section of the specification.\nProgrammatic constraint definition\nAlternatively, Hibernate Validator provides a way to add constraints programmatically:\n\nFor more details, check this section of the Hibernate Validator documentation.\nIf you do not know which fields will need not empty/blank constraint being applied you can try to iterate through the fields using the reflection and then based on that information define the constraints via programmatic API. once constraints are added to the validator you should be able to just use Validator#validate(..)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "This looks tls algorithm is part of your disabledAlgorithms list in jdk which is running in your system.\nWhile link shared by Marc Stroebel might help you but if you want to set this programatically as well, then you can use below in your spring startup :\n\nThis will allow all algorithms while app execution.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "TL;DR\n:: or && are not part of the JPA Criteria API standard. You could use a native SQL query.\n\nIf you want to use specific features or functions unique to a database system like PostgreSQL, it may not be possible to use them directly within the JPA Criteria API.\nSome queries, you can avoid the headache by specifying the escape sequence completely, but for this query; There is no way to simultaneously escape special types such as overlap (&&), double colon (::), and tsrange (cast(string as tsrange)).\nIt would be appropriate to create this query using a native query (@Query) instead of the Criteria API, or alternatively; if you are using Hibernate you can create a FunctionContributor for this statement.\nCreate a FunctionContributor, here we give our function a special name and set our pattern:\n(It is a simple function definition approach, it can be made more usable.)\n\nWe use this function with the Criteria API:\n\nThe class must be then registered via Java ServiceLoader mechanism by adding full name of the class with its packages into the file with name org.hibernate.boot.model.FunctionContributor into the java module\u2019s META-INF/services directory.\nYou use this specification your query will look like this:\n\nIt was prepared with Spring Boot 3.2.1 and Hibernate 6.2.7.Final.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "My assumption is that you shouldn't be keeping the criteria builder around. It's meant to be used in a case-by-case execution, so in this method you would rather run:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Admittedly this is only tangenitally related to your question, but depending on what version of java your using, you might not have the full suite of cryptographic algorithms available to you.\nInitially, as strong encryption algorithms could not be shipped everywhere due to various legal restrictions, java was shipped with limited crypto algorithms.  To have the full suite of crypto algorithms (including the 'strong' ones), you'll need to apply the official oracle Java Cryptographic Extension patch to both of your java installations.\nSee https://www.baeldung.com/jce-enable-unlimited-strength for more details.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "I'm somewhat confused. You're directly invoking the java command, which will use the java that's already redirected in in the alternatives configuration.  You are literally attempting to set the default java to the java that you've just installed? If you don't change anything, then it should already be pointing to this instance of java.\nSecondly, you're assuming that the path to java is the one you're specifying there. It doesn't have to be the case. When I create a minimal docker container with openjdk-8-jdk (and dpkg, so update-alternatives is available), then the path to java is:\n\nSo the path that you should have been using was this path.\nNow I've manually installed a few more java versions, and because of priorities, java-17 is now the default java, so the output is a bit longer:\n\nIn this case, you're probably better finding the java-8 path from update-alternatives and setting it that way, so something like:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "See the answer I posted here: Equivalent of Hibernate's Restrictions.sqlRestriction in JPA2 Criteria API?\nWe had very complex queries being dynamically generated and I did not want to have to replace them with criteria based sub queries.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "It supposed to be:\n\nBecause .publishOn(..) doesn't spin off new threads, it just defines the current thread. But .parallel().runOn(..) uses parallel threads for execution.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You need to pass the -parameters argument to the java compiler. The -g:vars argument provides information regarding all local variables, but the attribute which defines this is never accessible using the reflection API. When using -parameters, a special attribute is used which is explicitly designed for being accessed by the reflection API.\n",
                        "contain_knowledge": 0
                    }
                ]
            }
        }
    },
    {
        "name": "FragmentManager",
        "language": "android",
        "popularity": "high",
        "label_result": {
            "functionality": {
                "finetuned_dpr": 0.9,
                "dpr": 0.7,
                "e5": 0.0,
                "bm25": 0.9
            },
            "concept": {
                "finetuned_dpr": 0.9,
                "dpr": 1.0,
                "e5": 0.1,
                "bm25": 0.9
            },
            "performance": {
                "finetuned_dpr": 0.7,
                "dpr": 0.9,
                "e5": 0.0,
                "bm25": 0.8
            },
            "directive": {
                "finetuned_dpr": 0.7,
                "dpr": 0.9,
                "e5": 0.0,
                "bm25": 0.7
            },
            "pattern": {
                "finetuned_dpr": 1.0,
                "dpr": 1.0,
                "e5": 0.3,
                "bm25": 0.8
            },
            "environment": {
                "finetuned_dpr": 1.0,
                "dpr": 0.9,
                "e5": 0.0,
                "bm25": 0.9
            },
            "alternative": {
                "finetuned_dpr": 1.0,
                "dpr": 0.8,
                "e5": 0.1,
                "bm25": 0.8
            },
            "total": {
                "finetuned_dpr": 0.8857142857142858,
                "dpr": 0.8857142857142858,
                "e5": 0.07142857142857142,
                "bm25": 0.8285714285714285
            }
        },
        "retrieve_result": {
            "functionality": {
                "finetuned_dpr": [
                    {
                        "id": 68254825,
                        "answer_post": "First of all, FragmentStatePagerAdapter is deprecated now. So, it's better to use FragmentStateAdapter with ViewPager2.\nI couldn't find any proper solution in case if you need to pass something into  Fragment's constructor with ViewPager2 because it ignores FragmentFactory. I was thinking about implementing the FragmentFactory in createFragment method of FragmentStateAdapter but don't know where to get the proper class loader in this case.\nThe only solution I found is to use FragmentManager.FragmentLifecycleCallbacks. Here you have a fragment so you can cast it to you particular implementation. You can set callbacks or whatever you want to your fragment after its (re)creation. So in this case you don't need to pass something in to fragment's constructor but also can avoid creating Bundles.\n\nI tested this code using childFragmentManager and it works fine. But I have to admit that this is not a clear solution. And if you can avoid passing something to Fragment's constructor while using FragmentStateAdapter, avoid it. Because the most proper solution is to use a FragmentFactory.\nAlso, as an option, your fragment knows about the parent Activity. So, you can do callbacks directly to the parent Activity.\nLink to documentation: https://developer.android.com/reference/androidx/fragment/app/FragmentManager#registerFragmentLifecycleCallbacks(androidx.fragment.app.FragmentManager.FragmentLifecycleCallbacks,%20boolean)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62830821,
                        "answer_post": "You could use fragment.\nFirst, use  in your activity layout as a container of Fragment, here we give it a id like, android:id=\"+id/fragment_container\"\nSecond, create a layout xml file for your fragment, here we give it a name, like fragment_page_3.xml\nThen create a subclass of Fragment, and override its onCreateView() method, where you inflate your fragment's layout. Code here\n\nFinally, in clickListener, you could use fragmentManager load your fragment, code like this:\n\nI just want to give you some ideas.\nYou cannot write code like this, this is wrong implementation for your app because you may need several fragment and you need a Callbacks interface implemented by your activity.\nIf you could change your content of UI, it's a better way.\nTo learn more, you could refer https://developer.android.com/guide/components/fragments\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66796997,
                        "answer_post": "It's unclear why you need to retain an instance in memory of a Fragment that is no longer visible; presumably it's expensive to recreate it so you want to save it.\nThis is a code-smell in most cases (but because I don't know your reasons and haven't seen your code, I will give you the benefit of doubt) :)\nAssuming you have a valid reason for this, Android offers Fragments a mechanism to be retained:\nDirectly from the Android's Fragment source:\n\nKeep in mind the implications of doing so, for now your lifecycle is different and so are all the side-effects of expecting a normal lifecycle (and the memory impact of keeping a fragment around).\nAlternatively, consider separating the Fragment's state from it into a ViewModel, Repository, or Beyond\u2122, and let the fragment simply be told what its state it so it can be properly recreated in a \"fast\" and \"efficient\" manner. (I quote these because fast/efficient are in the eye of the beholder and because it's also still subject to Android rules...).\nNow, I haven't also seen how you \"navigate\" and how you \"go back\", so you'll have to test this yourself. Ultimately, if the FragmentManager desires to destroy your Fragment, it's probably because it found no reason to keep it around (you could, keep a hard reference and deal with all that memory wasted... which is why I suggest you keep the \"state\" outside of the Fragment instead, because creating a fragment is not that expensive, if the fragment doesn't contain 2000 lines of code in onCreate...) :)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 68959128,
                        "answer_post": "In this case FragmentContainerView and FragmentManager ,Fragment transactions help us .\n\nFragmentContainerView is a customized Layout designed specifically for Fragments. It extends FrameLayout, so it can reliably handle Fragment Transactions, and it also has additional features to coordinate with fragment behavior.\nAt runtime, a FragmentManager can add, remove, replace, and perform other actions with fragments in response to user interaction.\n\nSo you can take a FragmentContainerView in your activity_main.xml where you can add different fragment by button/user action.\nSo your activity_main.xml looks like now -\n\nNow Create a new Blank Fragment to your project to test . IDE automatically override some methods and layout for your fragment also for this .\n\nSo your BlankFragment.class looks like -\n\nNow From your Activity you can show the Blank Fragment in FragmentContainerView , we define its id fragment_container_view in activity_main.xml .\nHere Your MainActivity.class -\n\nAll of these just for example . You should check documentation to know more .\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66594768,
                        "answer_post": "From what my understanding is regarding Activities and Fragments in Android, fragment is a sub-part of the activity in which it is called.\nYes you are right, fragments are sub parts added dynamically on run time\nSo what I want to know is that if we finish or kill the Activity in which the fragment exists, how will it effect the fragment?\nIf you kill/finish an Activity fragments will also be destroyed\nNOTE: Fragment lifecycle is dependent on Activity life cycle, if an Activity is dead so the fragments are.\nBuilding fragment on an Activity is like building 2,3 or 4 story building. If base is destroyed then other stories are not supposed to be stable. Just keep this rule in mind. This will help you with understanding. And further more you can apply logging on Activity and Fragment lifecycle.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62095513,
                        "answer_post": "Your activity must extend androidx.fragment.app.FragmentActivity.\nFrom the documentation,\n\nBase class for activities that want to use the support-based\n  Fragments.\n\nAlso from Fragment's documentation,\n\n\nYour activity must extend FragmentActivity\nYou must call FragmentActivity.getSupportFragmentManager() to get the    FragmentManager\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71231654,
                        "answer_post": "Do not touch the FragmentManager yourself when using the Navigation library.\nLet Navigation manage Navigation between fragments, that's what it's used for.\nThe message:\n\nI/FragmentNavigator: Ignoring navigate() call: FragmentManager has\nalready saved its state\n\nis defined in the androidx.navigation.fragment.FragmentNavigator#navigate\nThe Fragment state is saved by the Activity. It usually appears when the Activity goes into the onStop state. Means should not be operated the fragmentManger after leaving the current Activity. (but still can use androidx.fragment.app.FragmentTransaction#commitAllowingStateLoss to ignore the warning , but this state will not be restored when the Activity is recreated.)\nIn your scenes, I recommend jumping to the next activity for editing, returning and refreshing the list\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63141419,
                        "answer_post": "You should always, always use childFragmentManager when nesting fragments - the childFragmentManager is never executing transactions when its parent is going through lifecycle changes (which I assume is when you're calling your transaction).\nThis is actually silently causing issues for you when you use the <fragment> tag as those lifecycle events don't actually occur as a transaction, but directly as part of inflation. Using the wrong FragmentManager means that the fragment and its views will not properly save and restore their state.\nThe reason it fails with FragmentContainerView is that FragmentContainerView actually does the same FragmentTransaction as you'd do normally.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66494990,
                        "answer_post": "After some debugging in FragmentContainerView itself, I have hopefully found all the cases of the FragmentManager used whilst adding a fragment via the android:name attribute.\n\nFragments in the activity view hierarchy (from Activity.setContentView(Int)): Activity.getSupportFragmentManager()\n\nFragments in another fragments hierarchy (from Fragment.onCreateView(...)): Fragment.getChildFragmentManager\n\nFragments in a RecyclerView row, where the RecyclerView is either in a Fragment or an Activity: Activity.getSupportFragmentManager()\n\n\nNow the first two are well documented and not of interest here, but I found the third case to be surprising, especially as it doesn't seem to make a difference what the RecyclerView has been inflated into. If I had to take a guess of why this is, it would probably be in onCreateViewHolder.When you inflate your row you pass false into the inflate function's attachToRoot, so as the FragmentContainerView is not attached to a parent when it is initialised, it has to use the highest level fragment manager - from the activity. However this is just speculation.\nRegardless, in answer to your question - it is definitely the activities fragment manager.\n\nYou also said that you have tried using all the fragment managers anyway and they all couldn't find your fragment, but I wasn't able to replicate this problem. I managed to find my fragment in the RecyclerView just fine so I would expect there's something else going on that we can't find from the code you've shown, in theory it works.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75043723,
                        "answer_post": "Disclaimer: This answer might work/not work based on the architecture of your app.\nTo begin with ,quite strange why microsoft requires Fragment and not sure about what is the usecase behind it.\nIt seems issue raised here.Have to wait for update regarding that.\nLets assume for now Fragment is compulsory. Actually we can use Fragment in compose app. Because legacy apps using xml must have support to gradual migration from fragment architecture to compose ui.By the way, Android provides that flexibility to integrate composable to legacy activity/fragment architecture.\n2 Cases .\n\nIf you have single activity app architecture and all other are compose UI. You might need to do little more work to adapt fragment in compose app.\n\nIf the signin/signup screen where you are using msal is separate activity and for core features you have other activity , you can integrate fragment only to activity where msal is being used.\n\n\nLets jump in to implementation.\n\nFirst thing ,you need fragment dependancy.\n\n\nAssuming you are having activity.\n\n\n\nHere your activity should extend FragmentActivity or any activity classes extending FragmentActivity. ComponentActivity may not work.\nYou need to have your xml file for activity and use setcontent view. You might need to create layout resource folder and layout file if not present.\n\nYour activity xml.\n\n\n\n\nHere were are having FragmentContainerView and refer to the fragment class we are going to create. No need to inflate.\n\nMy Fragment class.\n\n\n\nHere Fragment does not need xml file. Fragment will now be the root of all your compose content.  Here we are using CompositionLocalProvider to hold the fragment instance and later it can be used in multiple composables.\nYou can also use LocalCurrent.context and typecast to fragment. But that you might need to do everytime. Better way is to use CompositionLocalProvider.\n\nYou can add staticCompositionLocalOf outside of your fragment class in.\n\n\n\nSo you can access fragment instance in any composables which are in same activity and fragment layout tree.\n\nHere this is the composable function ui. Here I am getting the fragment instance and passing to MSAL.\n\n\nThe most important thing is your composable's direct parent should be fragment instead of activity. And its instance will be provided to all child composables via CompositionLocalProvider.  And this migration is wholly based on existing architecture and size of the project.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 64096217,
                        "answer_post": "Fragment manager has a putFragment and getFragment method you can use to save and restore instance state of your Fragments.\nThis allowed me to save my Fragment Instance Variables so they didn't return null after process death.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64157718,
                        "answer_post": "The FragmentManager returned by Activity.getSupportFragmentManager() is different from the one returned by Fragment.getChildFragmentManager().\nIf you want to perform a fragment transaction from the Fragment level, but be able to \"see\" it at the Activity level, then you should use Fragment.getParentFragmentManager() (or Fragment.getFragmentManager() on older versions of the AndroidX library).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64043740,
                        "answer_post": "You should use FragmentActivity (from androidx) instead of Activity as the argument type in myMethod() and call getSupportFragmentManager() to get the FragmentManager on it. This should solve your problem.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65096917,
                        "answer_post": "Fragment transactions are asynchronous (unless you use executePendingTransactions()). Your transaction has likely not completed yet. You use runOnCommit on FragmentTransaction (in the support library) to execute code after it is done.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66504608,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67770402,
                        "answer_post": "View pager can't detach cause memory leak. To avoid this, change the code to create the instance of TabsPagerAdapter according to the following code\n\nNote:\n\nrequestActivity().supportFragmentManager -> childFragmentManger : All its children should be managed by itself instead of activity.\n\nlifecycle -> viewLifecycleOwner.lifecycle : The fragment has 2 lifecycles, one for the view (viewLifecycleOwner.lifecycle), one for itself (lifecycle). In this case, the adapter is the view so we just need to use the lifecycle for the view (viewLifecycleOwner.lifecycle)\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67975369,
                        "answer_post": "You can get fragments by Ids using Fragment manager's findFragmentByTag(\"f$id\")\nBut to do that you need to override getItemId() in the FragmentStateAdapter to return the position, so that the id now equals to the position.\n\nThen to get a fragment at a position:\n\nIf the ViewPager2 is hosted by an activity use supportFragmentManager:\n\n\n\nAnd if it's hosted by a fragment use childFragmentManager:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66580660,
                        "answer_post": "Fragments should have an empty constructor since they are managed by Android, same as activities. Anything you want to inject you have to inject inside the fragment, not through the constructor.\nFor view-models, it's trivial through the viewModels() API:\n\nDon't forget to annotate the fragment with @AndroidEntryPoint and the view-model with @HiltViewModel.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65833033,
                        "answer_post": "viewPagerAdapter.addFragment() is an anti-pattern because it will inevitably cause crashes after process death in production.\nThe correct way to implement a regular FragmentPagerAdapter is:\n\nTo get a reference to a Fragment created by a ViewPager, use the following findFragmentByTag scheme:\n\nIf you need a dynamic FragmentPagerAdapter (which you do, according to your clear() method), then you can do:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76191984,
                        "answer_post": "\nIf you use Fragment.viewLifecycleOwner.lifecycle.addObserver(\u2026), DefaultLifecycleObserver.onDestory(\u2026) will be called at the same time as Fragment.onDestoryView(\u2026).\nIf you use Fragment.lifecycle.addObserver(\u2026), DefaultLifecycleObserver.onDestory(\u2026) will be called at the same time as Fragment.onDestory(\u2026).\n\nHere is an example.\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 71723371,
                        "answer_post": "\nhere how it works with fragment\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72966333,
                        "answer_post": "Write a function in your Activity\n\nIn your Fragment\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64454162,
                        "answer_post": "DialogLayout:\n\nFragmentLayout\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64315790,
                        "answer_post": "Fragment code\n\n\n\nShould be\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66121178,
                        "answer_post": "SupportFragmentManager & FragmentManager are relatively old ways of navigating an user through different fragments. They were widely used before, but have some drawbacks like:\n\nHard backstack navigation\nProblems with adding or removing fragments, etc.\n\nThe Navigation component is part of Android Jetpack. It's a new approach and it aims to simplify and solve some of the problems related to the old one described above. Also, it is not restricted to work only with Fragments.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75736322,
                        "answer_post": "try to add\n\nto your fragment / activity\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67337645,
                        "answer_post": "in the fragment\n\nin de activity\n\nand recive the array\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65124461,
                        "answer_post": "in Fragment\nUse\n\ninstead of\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62126425,
                        "answer_post": "create method in your Activity\n\nand use in your Fragment\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63789470,
                        "answer_post": "For Fragment use activity instead of getActivity\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "Bu using Navigation Architecture components, The NavController is the responsible for fragment transaction and managing the back stack instead of the Support FragmentManager.\nSo, instead of making tranditional framgnet transactions with FragmentManager\nYou can move from ThridFragment to the first one by:\n\nWhere action_ThirdFragment_to_FirstFragment is the id of the action you defined in the navigation graph to move from ThridFragment to FirstFragment\nUPDATE:\nAs discussed from comments, besides replacing FragmentManager by NavController in all actions; there is another issue:\nMissing of action_FirstFragment_to_ThirdFragment action  from the navigation graph.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "SupportFragmentManager & FragmentManager are relatively old ways of navigating an user through different fragments. They were widely used before, but have some drawbacks like:\n\nHard backstack navigation\nProblems with adding or removing fragments, etc.\n\nThe Navigation component is part of Android Jetpack. It's a new approach and it aims to simplify and solve some of the problems related to the old one described above. Also, it is not restricted to work only with Fragments.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Your Search class is a Fragment, you cannot start it with the Intent.\nMake Search to be Activity or switch between fragments using FragmentManager.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes, a Viewpager can be setup in a Fragment.\nYou just need to get the right FragmentManager when constructing it i.e use getChildFragmentManager() in mViewPager.setAdapter(new TvShowEpisodeDetailsAdapter(getSupportFragmentManager()));\nFrom https://developer.android.com/guide/fragments/fragmentmanager\n\nAccess the FragmentManager\nAccessing in an activity\nEvery FragmentActivity and subclasses thereof, such as\nAppCompatActivity, have access to the FragmentManager through the\ngetSupportFragmentManager() method.\nAccessing in a Fragment\nFragments are also capable of hosting one or more child fragments.\nInside a fragment, you can get a reference to the FragmentManager that\nmanages the fragment's children through getChildFragmentManager().\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Based on the information provided, it seems that the issue you are experiencing may be related to the lifecycle of the Fragment and how it is being added to the Activity.\nWhen you shift from portrait to landscape mode, the Activity is recreated, and the FragmentManager adds the two Fragments to the Activity. When you shift back to portrait mode, the Activity is recreated again, and the FragmentManager attempts to add both Fragments to the Activity. However, since only one Fragment is meant to be shown in portrait mode, the FragmentManager adds the first Fragment and ignores the second one.\nTo properly handle the lifecycle of Fragments in your Activity, you should create two separate layout files - one for portrait mode and one for landscape mode - and add the appropriate Fragment to each layout. This way, when the Activity is recreated, the FragmentManager will only add the relevant Fragment to the Activity. Here is an example of how you can accomplish this:\nCreate two layout files: one for portrait mode (e.g. activity_main.xml) and one for landscape mode (e.g. activity_main_land.xml).\nactivity_main.xml:\n\nactivity_main_land.xml:\n\nIn your Activity's onCreate() method, inflate the appropriate layout based on the device's orientation, and add the Fragment(s) to the Activity:\nMainActivity.java:\n\nWith this approach, when you shift from portrait to landscape mode, the FragmentManager adds both Fragments to the Activity, and when you shift back to portrait mode, the FragmentManager only adds the relevant Fragment to the Activity. Additionally, since the Fragment is added directly to the layout, you can access its views using findViewById() instead of relying on the FragmentManager.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "If you are adding a Fragment to a View within a Fragment, you must always use the childFragmentManager - using activity?.supportFragmentManager is always the wrong FragmentManager to use in that case.\nBesides fixing cases with restoring state (which would not work when using the wrong FragmentManager), this also ensures that the default behavior for dispatching onBackPressed() down the FragmentManager hierarchy will work out the box - you should not need any logic at all in onBackPressed() to have the pop work correctly.\nIf you need to intercept the back button in Fragment C, you should follow the providing custom back documentation to register an OnBackPressedDispatcher - you should not override onBackPressed() even in those cases.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "In MainActivity the line:\n\nShould be:\n\n\nReturn the FragmentManager for interacting with fragments associated with this activity.\n\nAs you can read in the docs\n\nReturn the FragmentManager for interacting with fragments associated with this fragment's activity. Note that this will be non-null slightly before getActivity(), during the time from when the fragment is placed in a FragmentTransaction until it is committed and attached to its activity.\n\nAnd is returning null for the just created Fragment.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "FragmentStateAdapter requires a FragmentManager and Lifecycle in its constructor. Change your DocAdapter to this:\n\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "concept": {
                "finetuned_dpr": [
                    {
                        "id": 68254825,
                        "answer_post": "First of all, FragmentStatePagerAdapter is deprecated now. So, it's better to use FragmentStateAdapter with ViewPager2.\nI couldn't find any proper solution in case if you need to pass something into  Fragment's constructor with ViewPager2 because it ignores FragmentFactory. I was thinking about implementing the FragmentFactory in createFragment method of FragmentStateAdapter but don't know where to get the proper class loader in this case.\nThe only solution I found is to use FragmentManager.FragmentLifecycleCallbacks. Here you have a fragment so you can cast it to you particular implementation. You can set callbacks or whatever you want to your fragment after its (re)creation. So in this case you don't need to pass something in to fragment's constructor but also can avoid creating Bundles.\n\nI tested this code using childFragmentManager and it works fine. But I have to admit that this is not a clear solution. And if you can avoid passing something to Fragment's constructor while using FragmentStateAdapter, avoid it. Because the most proper solution is to use a FragmentFactory.\nAlso, as an option, your fragment knows about the parent Activity. So, you can do callbacks directly to the parent Activity.\nLink to documentation: https://developer.android.com/reference/androidx/fragment/app/FragmentManager#registerFragmentLifecycleCallbacks(androidx.fragment.app.FragmentManager.FragmentLifecycleCallbacks,%20boolean)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62830821,
                        "answer_post": "You could use fragment.\nFirst, use  in your activity layout as a container of Fragment, here we give it a id like, android:id=\"+id/fragment_container\"\nSecond, create a layout xml file for your fragment, here we give it a name, like fragment_page_3.xml\nThen create a subclass of Fragment, and override its onCreateView() method, where you inflate your fragment's layout. Code here\n\nFinally, in clickListener, you could use fragmentManager load your fragment, code like this:\n\nI just want to give you some ideas.\nYou cannot write code like this, this is wrong implementation for your app because you may need several fragment and you need a Callbacks interface implemented by your activity.\nIf you could change your content of UI, it's a better way.\nTo learn more, you could refer https://developer.android.com/guide/components/fragments\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66796997,
                        "answer_post": "It's unclear why you need to retain an instance in memory of a Fragment that is no longer visible; presumably it's expensive to recreate it so you want to save it.\nThis is a code-smell in most cases (but because I don't know your reasons and haven't seen your code, I will give you the benefit of doubt) :)\nAssuming you have a valid reason for this, Android offers Fragments a mechanism to be retained:\nDirectly from the Android's Fragment source:\n\nKeep in mind the implications of doing so, for now your lifecycle is different and so are all the side-effects of expecting a normal lifecycle (and the memory impact of keeping a fragment around).\nAlternatively, consider separating the Fragment's state from it into a ViewModel, Repository, or Beyond\u2122, and let the fragment simply be told what its state it so it can be properly recreated in a \"fast\" and \"efficient\" manner. (I quote these because fast/efficient are in the eye of the beholder and because it's also still subject to Android rules...).\nNow, I haven't also seen how you \"navigate\" and how you \"go back\", so you'll have to test this yourself. Ultimately, if the FragmentManager desires to destroy your Fragment, it's probably because it found no reason to keep it around (you could, keep a hard reference and deal with all that memory wasted... which is why I suggest you keep the \"state\" outside of the Fragment instead, because creating a fragment is not that expensive, if the fragment doesn't contain 2000 lines of code in onCreate...) :)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 68959128,
                        "answer_post": "In this case FragmentContainerView and FragmentManager ,Fragment transactions help us .\n\nFragmentContainerView is a customized Layout designed specifically for Fragments. It extends FrameLayout, so it can reliably handle Fragment Transactions, and it also has additional features to coordinate with fragment behavior.\nAt runtime, a FragmentManager can add, remove, replace, and perform other actions with fragments in response to user interaction.\n\nSo you can take a FragmentContainerView in your activity_main.xml where you can add different fragment by button/user action.\nSo your activity_main.xml looks like now -\n\nNow Create a new Blank Fragment to your project to test . IDE automatically override some methods and layout for your fragment also for this .\n\nSo your BlankFragment.class looks like -\n\nNow From your Activity you can show the Blank Fragment in FragmentContainerView , we define its id fragment_container_view in activity_main.xml .\nHere Your MainActivity.class -\n\nAll of these just for example . You should check documentation to know more .\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66594768,
                        "answer_post": "From what my understanding is regarding Activities and Fragments in Android, fragment is a sub-part of the activity in which it is called.\nYes you are right, fragments are sub parts added dynamically on run time\nSo what I want to know is that if we finish or kill the Activity in which the fragment exists, how will it effect the fragment?\nIf you kill/finish an Activity fragments will also be destroyed\nNOTE: Fragment lifecycle is dependent on Activity life cycle, if an Activity is dead so the fragments are.\nBuilding fragment on an Activity is like building 2,3 or 4 story building. If base is destroyed then other stories are not supposed to be stable. Just keep this rule in mind. This will help you with understanding. And further more you can apply logging on Activity and Fragment lifecycle.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63141419,
                        "answer_post": "You should always, always use childFragmentManager when nesting fragments - the childFragmentManager is never executing transactions when its parent is going through lifecycle changes (which I assume is when you're calling your transaction).\nThis is actually silently causing issues for you when you use the <fragment> tag as those lifecycle events don't actually occur as a transaction, but directly as part of inflation. Using the wrong FragmentManager means that the fragment and its views will not properly save and restore their state.\nThe reason it fails with FragmentContainerView is that FragmentContainerView actually does the same FragmentTransaction as you'd do normally.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62095513,
                        "answer_post": "Your activity must extend androidx.fragment.app.FragmentActivity.\nFrom the documentation,\n\nBase class for activities that want to use the support-based\n  Fragments.\n\nAlso from Fragment's documentation,\n\n\nYour activity must extend FragmentActivity\nYou must call FragmentActivity.getSupportFragmentManager() to get the    FragmentManager\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66494990,
                        "answer_post": "After some debugging in FragmentContainerView itself, I have hopefully found all the cases of the FragmentManager used whilst adding a fragment via the android:name attribute.\n\nFragments in the activity view hierarchy (from Activity.setContentView(Int)): Activity.getSupportFragmentManager()\n\nFragments in another fragments hierarchy (from Fragment.onCreateView(...)): Fragment.getChildFragmentManager\n\nFragments in a RecyclerView row, where the RecyclerView is either in a Fragment or an Activity: Activity.getSupportFragmentManager()\n\n\nNow the first two are well documented and not of interest here, but I found the third case to be surprising, especially as it doesn't seem to make a difference what the RecyclerView has been inflated into. If I had to take a guess of why this is, it would probably be in onCreateViewHolder.When you inflate your row you pass false into the inflate function's attachToRoot, so as the FragmentContainerView is not attached to a parent when it is initialised, it has to use the highest level fragment manager - from the activity. However this is just speculation.\nRegardless, in answer to your question - it is definitely the activities fragment manager.\n\nYou also said that you have tried using all the fragment managers anyway and they all couldn't find your fragment, but I wasn't able to replicate this problem. I managed to find my fragment in the RecyclerView just fine so I would expect there's something else going on that we can't find from the code you've shown, in theory it works.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71231654,
                        "answer_post": "Do not touch the FragmentManager yourself when using the Navigation library.\nLet Navigation manage Navigation between fragments, that's what it's used for.\nThe message:\n\nI/FragmentNavigator: Ignoring navigate() call: FragmentManager has\nalready saved its state\n\nis defined in the androidx.navigation.fragment.FragmentNavigator#navigate\nThe Fragment state is saved by the Activity. It usually appears when the Activity goes into the onStop state. Means should not be operated the fragmentManger after leaving the current Activity. (but still can use androidx.fragment.app.FragmentTransaction#commitAllowingStateLoss to ignore the warning , but this state will not be restored when the Activity is recreated.)\nIn your scenes, I recommend jumping to the next activity for editing, returning and refreshing the list\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75043723,
                        "answer_post": "Disclaimer: This answer might work/not work based on the architecture of your app.\nTo begin with ,quite strange why microsoft requires Fragment and not sure about what is the usecase behind it.\nIt seems issue raised here.Have to wait for update regarding that.\nLets assume for now Fragment is compulsory. Actually we can use Fragment in compose app. Because legacy apps using xml must have support to gradual migration from fragment architecture to compose ui.By the way, Android provides that flexibility to integrate composable to legacy activity/fragment architecture.\n2 Cases .\n\nIf you have single activity app architecture and all other are compose UI. You might need to do little more work to adapt fragment in compose app.\n\nIf the signin/signup screen where you are using msal is separate activity and for core features you have other activity , you can integrate fragment only to activity where msal is being used.\n\n\nLets jump in to implementation.\n\nFirst thing ,you need fragment dependancy.\n\n\nAssuming you are having activity.\n\n\n\nHere your activity should extend FragmentActivity or any activity classes extending FragmentActivity. ComponentActivity may not work.\nYou need to have your xml file for activity and use setcontent view. You might need to create layout resource folder and layout file if not present.\n\nYour activity xml.\n\n\n\n\nHere were are having FragmentContainerView and refer to the fragment class we are going to create. No need to inflate.\n\nMy Fragment class.\n\n\n\nHere Fragment does not need xml file. Fragment will now be the root of all your compose content.  Here we are using CompositionLocalProvider to hold the fragment instance and later it can be used in multiple composables.\nYou can also use LocalCurrent.context and typecast to fragment. But that you might need to do everytime. Better way is to use CompositionLocalProvider.\n\nYou can add staticCompositionLocalOf outside of your fragment class in.\n\n\n\nSo you can access fragment instance in any composables which are in same activity and fragment layout tree.\n\nHere this is the composable function ui. Here I am getting the fragment instance and passing to MSAL.\n\n\nThe most important thing is your composable's direct parent should be fragment instead of activity. And its instance will be provided to all child composables via CompositionLocalProvider.  And this migration is wholly based on existing architecture and size of the project.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 64096217,
                        "answer_post": "Fragment manager has a putFragment and getFragment method you can use to save and restore instance state of your Fragments.\nThis allowed me to save my Fragment Instance Variables so they didn't return null after process death.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64157718,
                        "answer_post": "The FragmentManager returned by Activity.getSupportFragmentManager() is different from the one returned by Fragment.getChildFragmentManager().\nIf you want to perform a fragment transaction from the Fragment level, but be able to \"see\" it at the Activity level, then you should use Fragment.getParentFragmentManager() (or Fragment.getFragmentManager() on older versions of the AndroidX library).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67770402,
                        "answer_post": "View pager can't detach cause memory leak. To avoid this, change the code to create the instance of TabsPagerAdapter according to the following code\n\nNote:\n\nrequestActivity().supportFragmentManager -> childFragmentManger : All its children should be managed by itself instead of activity.\n\nlifecycle -> viewLifecycleOwner.lifecycle : The fragment has 2 lifecycles, one for the view (viewLifecycleOwner.lifecycle), one for itself (lifecycle). In this case, the adapter is the view so we just need to use the lifecycle for the view (viewLifecycleOwner.lifecycle)\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64043740,
                        "answer_post": "You should use FragmentActivity (from androidx) instead of Activity as the argument type in myMethod() and call getSupportFragmentManager() to get the FragmentManager on it. This should solve your problem.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66504608,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65096917,
                        "answer_post": "Fragment transactions are asynchronous (unless you use executePendingTransactions()). Your transaction has likely not completed yet. You use runOnCommit on FragmentTransaction (in the support library) to execute code after it is done.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66580660,
                        "answer_post": "Fragments should have an empty constructor since they are managed by Android, same as activities. Anything you want to inject you have to inject inside the fragment, not through the constructor.\nFor view-models, it's trivial through the viewModels() API:\n\nDon't forget to annotate the fragment with @AndroidEntryPoint and the view-model with @HiltViewModel.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67975369,
                        "answer_post": "You can get fragments by Ids using Fragment manager's findFragmentByTag(\"f$id\")\nBut to do that you need to override getItemId() in the FragmentStateAdapter to return the position, so that the id now equals to the position.\n\nThen to get a fragment at a position:\n\nIf the ViewPager2 is hosted by an activity use supportFragmentManager:\n\n\n\nAnd if it's hosted by a fragment use childFragmentManager:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66946260,
                        "answer_post": "There's actually three constructors for FragmentStateAdapter:\n\nFragmentStateAdapter(FragmentActivity) - this uses the Activity's getSupportFragmentManager() and the Activity's getLifecycle(). This is what you'd use if your ViewPager2 was directly hosted within an Activity\nFragmentStateAdapter(Fragment) - this uses the Fragment's getChildFragmentManager() and the Fragment's getLifecycle(). This is what you'd use if your ViewPager2 was hosted within another Fragment\nFragmentStateAdapter(FragmentManager, Lifecycle) - this is what the other two constructors call internally. You wouldn't ever use this unless you were adding fragments to a service, etc. where you don't have a FragmentActivity at all.\n\nYou must always use the one that takes a Fragment (or use getChildFragmentManager()+getLifecycle() if you want to write more code for the same effect) when hosting a ViewPager2 within a Fragment - this ensures that the Fragment's your FragmentStateAdapter creates correctly have their state restored after a configuration change or process death or recreation - something that is only possible when they are child fragments of the fragment that has your ViewPager2 within it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65833033,
                        "answer_post": "viewPagerAdapter.addFragment() is an anti-pattern because it will inevitably cause crashes after process death in production.\nThe correct way to implement a regular FragmentPagerAdapter is:\n\nTo get a reference to a Fragment created by a ViewPager, use the following findFragmentByTag scheme:\n\nIf you need a dynamic FragmentPagerAdapter (which you do, according to your clear() method), then you can do:\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 71723371,
                        "answer_post": "\nhere how it works with fragment\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64454162,
                        "answer_post": "DialogLayout:\n\nFragmentLayout\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66121178,
                        "answer_post": "SupportFragmentManager & FragmentManager are relatively old ways of navigating an user through different fragments. They were widely used before, but have some drawbacks like:\n\nHard backstack navigation\nProblems with adding or removing fragments, etc.\n\nThe Navigation component is part of Android Jetpack. It's a new approach and it aims to simplify and solve some of the problems related to the old one described above. Also, it is not restricted to work only with Fragments.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72966333,
                        "answer_post": "Write a function in your Activity\n\nIn your Fragment\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64315790,
                        "answer_post": "Fragment code\n\n\n\nShould be\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75736322,
                        "answer_post": "try to add\n\nto your fragment / activity\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67337645,
                        "answer_post": "in the fragment\n\nin de activity\n\nand recive the array\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65684761,
                        "answer_post": "In ViewModel\n\nAnd in the Activity or Fragment :\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65414383,
                        "answer_post": "in your fragment should be\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72328405,
                        "answer_post": "\nand\n\nthen Activity or Fragment with\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "Bu using Navigation Architecture components, The NavController is the responsible for fragment transaction and managing the back stack instead of the Support FragmentManager.\nSo, instead of making tranditional framgnet transactions with FragmentManager\nYou can move from ThridFragment to the first one by:\n\nWhere action_ThirdFragment_to_FirstFragment is the id of the action you defined in the navigation graph to move from ThridFragment to FirstFragment\nUPDATE:\nAs discussed from comments, besides replacing FragmentManager by NavController in all actions; there is another issue:\nMissing of action_FirstFragment_to_ThirdFragment action  from the navigation graph.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Your Search class is a Fragment, you cannot start it with the Intent.\nMake Search to be Activity or switch between fragments using FragmentManager.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes, a Viewpager can be setup in a Fragment.\nYou just need to get the right FragmentManager when constructing it i.e use getChildFragmentManager() in mViewPager.setAdapter(new TvShowEpisodeDetailsAdapter(getSupportFragmentManager()));\nFrom https://developer.android.com/guide/fragments/fragmentmanager\n\nAccess the FragmentManager\nAccessing in an activity\nEvery FragmentActivity and subclasses thereof, such as\nAppCompatActivity, have access to the FragmentManager through the\ngetSupportFragmentManager() method.\nAccessing in a Fragment\nFragments are also capable of hosting one or more child fragments.\nInside a fragment, you can get a reference to the FragmentManager that\nmanages the fragment's children through getChildFragmentManager().\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Based on the information provided, it seems that the issue you are experiencing may be related to the lifecycle of the Fragment and how it is being added to the Activity.\nWhen you shift from portrait to landscape mode, the Activity is recreated, and the FragmentManager adds the two Fragments to the Activity. When you shift back to portrait mode, the Activity is recreated again, and the FragmentManager attempts to add both Fragments to the Activity. However, since only one Fragment is meant to be shown in portrait mode, the FragmentManager adds the first Fragment and ignores the second one.\nTo properly handle the lifecycle of Fragments in your Activity, you should create two separate layout files - one for portrait mode and one for landscape mode - and add the appropriate Fragment to each layout. This way, when the Activity is recreated, the FragmentManager will only add the relevant Fragment to the Activity. Here is an example of how you can accomplish this:\nCreate two layout files: one for portrait mode (e.g. activity_main.xml) and one for landscape mode (e.g. activity_main_land.xml).\nactivity_main.xml:\n\nactivity_main_land.xml:\n\nIn your Activity's onCreate() method, inflate the appropriate layout based on the device's orientation, and add the Fragment(s) to the Activity:\nMainActivity.java:\n\nWith this approach, when you shift from portrait to landscape mode, the FragmentManager adds both Fragments to the Activity, and when you shift back to portrait mode, the FragmentManager only adds the relevant Fragment to the Activity. Additionally, since the Fragment is added directly to the layout, you can access its views using findViewById() instead of relying on the FragmentManager.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "SupportFragmentManager & FragmentManager are relatively old ways of navigating an user through different fragments. They were widely used before, but have some drawbacks like:\n\nHard backstack navigation\nProblems with adding or removing fragments, etc.\n\nThe Navigation component is part of Android Jetpack. It's a new approach and it aims to simplify and solve some of the problems related to the old one described above. Also, it is not restricted to work only with Fragments.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "In MainActivity the line:\n\nShould be:\n\n\nReturn the FragmentManager for interacting with fragments associated with this activity.\n\nAs you can read in the docs\n\nReturn the FragmentManager for interacting with fragments associated with this fragment's activity. Note that this will be non-null slightly before getActivity(), during the time from when the fragment is placed in a FragmentTransaction until it is committed and attached to its activity.\n\nAnd is returning null for the just created Fragment.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "FragmentStateAdapter requires a FragmentManager and Lifecycle in its constructor. Change your DocAdapter to this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The displaying of Fragments is managed by FragmentManager. You must pass an instance of FragmentManager to CNNAdapter as follows:\n\nAnd then you display the fragment as follows:\n\nR.id.fragment_container is the view ID of the container in the layout xml of the activity that hosts the fragment. The container is usually a FrameLayout.\nAnd then you instantiate CNNAdapter in the Fragment like this:\n\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "performance": {
                "finetuned_dpr": [
                    {
                        "id": 68254825,
                        "answer_post": "First of all, FragmentStatePagerAdapter is deprecated now. So, it's better to use FragmentStateAdapter with ViewPager2.\nI couldn't find any proper solution in case if you need to pass something into  Fragment's constructor with ViewPager2 because it ignores FragmentFactory. I was thinking about implementing the FragmentFactory in createFragment method of FragmentStateAdapter but don't know where to get the proper class loader in this case.\nThe only solution I found is to use FragmentManager.FragmentLifecycleCallbacks. Here you have a fragment so you can cast it to you particular implementation. You can set callbacks or whatever you want to your fragment after its (re)creation. So in this case you don't need to pass something in to fragment's constructor but also can avoid creating Bundles.\n\nI tested this code using childFragmentManager and it works fine. But I have to admit that this is not a clear solution. And if you can avoid passing something to Fragment's constructor while using FragmentStateAdapter, avoid it. Because the most proper solution is to use a FragmentFactory.\nAlso, as an option, your fragment knows about the parent Activity. So, you can do callbacks directly to the parent Activity.\nLink to documentation: https://developer.android.com/reference/androidx/fragment/app/FragmentManager#registerFragmentLifecycleCallbacks(androidx.fragment.app.FragmentManager.FragmentLifecycleCallbacks,%20boolean)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62830821,
                        "answer_post": "You could use fragment.\nFirst, use  in your activity layout as a container of Fragment, here we give it a id like, android:id=\"+id/fragment_container\"\nSecond, create a layout xml file for your fragment, here we give it a name, like fragment_page_3.xml\nThen create a subclass of Fragment, and override its onCreateView() method, where you inflate your fragment's layout. Code here\n\nFinally, in clickListener, you could use fragmentManager load your fragment, code like this:\n\nI just want to give you some ideas.\nYou cannot write code like this, this is wrong implementation for your app because you may need several fragment and you need a Callbacks interface implemented by your activity.\nIf you could change your content of UI, it's a better way.\nTo learn more, you could refer https://developer.android.com/guide/components/fragments\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66796997,
                        "answer_post": "It's unclear why you need to retain an instance in memory of a Fragment that is no longer visible; presumably it's expensive to recreate it so you want to save it.\nThis is a code-smell in most cases (but because I don't know your reasons and haven't seen your code, I will give you the benefit of doubt) :)\nAssuming you have a valid reason for this, Android offers Fragments a mechanism to be retained:\nDirectly from the Android's Fragment source:\n\nKeep in mind the implications of doing so, for now your lifecycle is different and so are all the side-effects of expecting a normal lifecycle (and the memory impact of keeping a fragment around).\nAlternatively, consider separating the Fragment's state from it into a ViewModel, Repository, or Beyond\u2122, and let the fragment simply be told what its state it so it can be properly recreated in a \"fast\" and \"efficient\" manner. (I quote these because fast/efficient are in the eye of the beholder and because it's also still subject to Android rules...).\nNow, I haven't also seen how you \"navigate\" and how you \"go back\", so you'll have to test this yourself. Ultimately, if the FragmentManager desires to destroy your Fragment, it's probably because it found no reason to keep it around (you could, keep a hard reference and deal with all that memory wasted... which is why I suggest you keep the \"state\" outside of the Fragment instead, because creating a fragment is not that expensive, if the fragment doesn't contain 2000 lines of code in onCreate...) :)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66594768,
                        "answer_post": "From what my understanding is regarding Activities and Fragments in Android, fragment is a sub-part of the activity in which it is called.\nYes you are right, fragments are sub parts added dynamically on run time\nSo what I want to know is that if we finish or kill the Activity in which the fragment exists, how will it effect the fragment?\nIf you kill/finish an Activity fragments will also be destroyed\nNOTE: Fragment lifecycle is dependent on Activity life cycle, if an Activity is dead so the fragments are.\nBuilding fragment on an Activity is like building 2,3 or 4 story building. If base is destroyed then other stories are not supposed to be stable. Just keep this rule in mind. This will help you with understanding. And further more you can apply logging on Activity and Fragment lifecycle.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 68959128,
                        "answer_post": "In this case FragmentContainerView and FragmentManager ,Fragment transactions help us .\n\nFragmentContainerView is a customized Layout designed specifically for Fragments. It extends FrameLayout, so it can reliably handle Fragment Transactions, and it also has additional features to coordinate with fragment behavior.\nAt runtime, a FragmentManager can add, remove, replace, and perform other actions with fragments in response to user interaction.\n\nSo you can take a FragmentContainerView in your activity_main.xml where you can add different fragment by button/user action.\nSo your activity_main.xml looks like now -\n\nNow Create a new Blank Fragment to your project to test . IDE automatically override some methods and layout for your fragment also for this .\n\nSo your BlankFragment.class looks like -\n\nNow From your Activity you can show the Blank Fragment in FragmentContainerView , we define its id fragment_container_view in activity_main.xml .\nHere Your MainActivity.class -\n\nAll of these just for example . You should check documentation to know more .\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62095513,
                        "answer_post": "Your activity must extend androidx.fragment.app.FragmentActivity.\nFrom the documentation,\n\nBase class for activities that want to use the support-based\n  Fragments.\n\nAlso from Fragment's documentation,\n\n\nYour activity must extend FragmentActivity\nYou must call FragmentActivity.getSupportFragmentManager() to get the    FragmentManager\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71231654,
                        "answer_post": "Do not touch the FragmentManager yourself when using the Navigation library.\nLet Navigation manage Navigation between fragments, that's what it's used for.\nThe message:\n\nI/FragmentNavigator: Ignoring navigate() call: FragmentManager has\nalready saved its state\n\nis defined in the androidx.navigation.fragment.FragmentNavigator#navigate\nThe Fragment state is saved by the Activity. It usually appears when the Activity goes into the onStop state. Means should not be operated the fragmentManger after leaving the current Activity. (but still can use androidx.fragment.app.FragmentTransaction#commitAllowingStateLoss to ignore the warning , but this state will not be restored when the Activity is recreated.)\nIn your scenes, I recommend jumping to the next activity for editing, returning and refreshing the list\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63141419,
                        "answer_post": "You should always, always use childFragmentManager when nesting fragments - the childFragmentManager is never executing transactions when its parent is going through lifecycle changes (which I assume is when you're calling your transaction).\nThis is actually silently causing issues for you when you use the <fragment> tag as those lifecycle events don't actually occur as a transaction, but directly as part of inflation. Using the wrong FragmentManager means that the fragment and its views will not properly save and restore their state.\nThe reason it fails with FragmentContainerView is that FragmentContainerView actually does the same FragmentTransaction as you'd do normally.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66494990,
                        "answer_post": "After some debugging in FragmentContainerView itself, I have hopefully found all the cases of the FragmentManager used whilst adding a fragment via the android:name attribute.\n\nFragments in the activity view hierarchy (from Activity.setContentView(Int)): Activity.getSupportFragmentManager()\n\nFragments in another fragments hierarchy (from Fragment.onCreateView(...)): Fragment.getChildFragmentManager\n\nFragments in a RecyclerView row, where the RecyclerView is either in a Fragment or an Activity: Activity.getSupportFragmentManager()\n\n\nNow the first two are well documented and not of interest here, but I found the third case to be surprising, especially as it doesn't seem to make a difference what the RecyclerView has been inflated into. If I had to take a guess of why this is, it would probably be in onCreateViewHolder.When you inflate your row you pass false into the inflate function's attachToRoot, so as the FragmentContainerView is not attached to a parent when it is initialised, it has to use the highest level fragment manager - from the activity. However this is just speculation.\nRegardless, in answer to your question - it is definitely the activities fragment manager.\n\nYou also said that you have tried using all the fragment managers anyway and they all couldn't find your fragment, but I wasn't able to replicate this problem. I managed to find my fragment in the RecyclerView just fine so I would expect there's something else going on that we can't find from the code you've shown, in theory it works.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71947197,
                        "answer_post": "I would not suggest you put any toolbar in your fragment as Fragments are not usually meant for holding toolbars. Your fragment is basically a mini activity on it's own with no knowledge of the UI components of it's activity. It would make more sense to adapt the Activity's toolbar according to the fragment loaded. You could look into Android Navigation Component for this.\nHowever, I'm not sure of your use case since you want the collapsing toolbar effect. If you still want to hide the activity toolbar on collapse of your fragments CoordinatorLayout you could look into the the solution provided here and using that access your activities toolbar programmatically and change it's visibility. Or rather use the offset to smoothly decrease/increase the activity's toolbar opacity property.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 64096217,
                        "answer_post": "Fragment manager has a putFragment and getFragment method you can use to save and restore instance state of your Fragments.\nThis allowed me to save my Fragment Instance Variables so they didn't return null after process death.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64157718,
                        "answer_post": "The FragmentManager returned by Activity.getSupportFragmentManager() is different from the one returned by Fragment.getChildFragmentManager().\nIf you want to perform a fragment transaction from the Fragment level, but be able to \"see\" it at the Activity level, then you should use Fragment.getParentFragmentManager() (or Fragment.getFragmentManager() on older versions of the AndroidX library).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64043740,
                        "answer_post": "You should use FragmentActivity (from androidx) instead of Activity as the argument type in myMethod() and call getSupportFragmentManager() to get the FragmentManager on it. This should solve your problem.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66504608,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67770402,
                        "answer_post": "View pager can't detach cause memory leak. To avoid this, change the code to create the instance of TabsPagerAdapter according to the following code\n\nNote:\n\nrequestActivity().supportFragmentManager -> childFragmentManger : All its children should be managed by itself instead of activity.\n\nlifecycle -> viewLifecycleOwner.lifecycle : The fragment has 2 lifecycles, one for the view (viewLifecycleOwner.lifecycle), one for itself (lifecycle). In this case, the adapter is the view so we just need to use the lifecycle for the view (viewLifecycleOwner.lifecycle)\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65096917,
                        "answer_post": "Fragment transactions are asynchronous (unless you use executePendingTransactions()). Your transaction has likely not completed yet. You use runOnCommit on FragmentTransaction (in the support library) to execute code after it is done.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67975369,
                        "answer_post": "You can get fragments by Ids using Fragment manager's findFragmentByTag(\"f$id\")\nBut to do that you need to override getItemId() in the FragmentStateAdapter to return the position, so that the id now equals to the position.\n\nThen to get a fragment at a position:\n\nIf the ViewPager2 is hosted by an activity use supportFragmentManager:\n\n\n\nAnd if it's hosted by a fragment use childFragmentManager:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65833033,
                        "answer_post": "viewPagerAdapter.addFragment() is an anti-pattern because it will inevitably cause crashes after process death in production.\nThe correct way to implement a regular FragmentPagerAdapter is:\n\nTo get a reference to a Fragment created by a ViewPager, use the following findFragmentByTag scheme:\n\nIf you need a dynamic FragmentPagerAdapter (which you do, according to your clear() method), then you can do:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66580660,
                        "answer_post": "Fragments should have an empty constructor since they are managed by Android, same as activities. Anything you want to inject you have to inject inside the fragment, not through the constructor.\nFor view-models, it's trivial through the viewModels() API:\n\nDon't forget to annotate the fragment with @AndroidEntryPoint and the view-model with @HiltViewModel.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65120870,
                        "answer_post": "Since FragmentManager operations is async, you should send a callback from your fragment to the activity in the fragment OnViewCreated or maybe OnResume and only then send the data from the activity to the fragment.\nOr you can just use ViewModel and LiveData to provide your data to fragments\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 71723371,
                        "answer_post": "\nhere how it works with fragment\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72966333,
                        "answer_post": "Write a function in your Activity\n\nIn your Fragment\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64315790,
                        "answer_post": "Fragment code\n\n\n\nShould be\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64454162,
                        "answer_post": "DialogLayout:\n\nFragmentLayout\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66121178,
                        "answer_post": "SupportFragmentManager & FragmentManager are relatively old ways of navigating an user through different fragments. They were widely used before, but have some drawbacks like:\n\nHard backstack navigation\nProblems with adding or removing fragments, etc.\n\nThe Navigation component is part of Android Jetpack. It's a new approach and it aims to simplify and solve some of the problems related to the old one described above. Also, it is not restricted to work only with Fragments.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75736322,
                        "answer_post": "try to add\n\nto your fragment / activity\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67337645,
                        "answer_post": "in the fragment\n\nin de activity\n\nand recive the array\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65124461,
                        "answer_post": "in Fragment\nUse\n\ninstead of\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65414383,
                        "answer_post": "in your fragment should be\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63789470,
                        "answer_post": "For Fragment use activity instead of getActivity\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "Bu using Navigation Architecture components, The NavController is the responsible for fragment transaction and managing the back stack instead of the Support FragmentManager.\nSo, instead of making tranditional framgnet transactions with FragmentManager\nYou can move from ThridFragment to the first one by:\n\nWhere action_ThirdFragment_to_FirstFragment is the id of the action you defined in the navigation graph to move from ThridFragment to FirstFragment\nUPDATE:\nAs discussed from comments, besides replacing FragmentManager by NavController in all actions; there is another issue:\nMissing of action_FirstFragment_to_ThirdFragment action  from the navigation graph.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Your Search class is a Fragment, you cannot start it with the Intent.\nMake Search to be Activity or switch between fragments using FragmentManager.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes, a Viewpager can be setup in a Fragment.\nYou just need to get the right FragmentManager when constructing it i.e use getChildFragmentManager() in mViewPager.setAdapter(new TvShowEpisodeDetailsAdapter(getSupportFragmentManager()));\nFrom https://developer.android.com/guide/fragments/fragmentmanager\n\nAccess the FragmentManager\nAccessing in an activity\nEvery FragmentActivity and subclasses thereof, such as\nAppCompatActivity, have access to the FragmentManager through the\ngetSupportFragmentManager() method.\nAccessing in a Fragment\nFragments are also capable of hosting one or more child fragments.\nInside a fragment, you can get a reference to the FragmentManager that\nmanages the fragment's children through getChildFragmentManager().\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Based on the information provided, it seems that the issue you are experiencing may be related to the lifecycle of the Fragment and how it is being added to the Activity.\nWhen you shift from portrait to landscape mode, the Activity is recreated, and the FragmentManager adds the two Fragments to the Activity. When you shift back to portrait mode, the Activity is recreated again, and the FragmentManager attempts to add both Fragments to the Activity. However, since only one Fragment is meant to be shown in portrait mode, the FragmentManager adds the first Fragment and ignores the second one.\nTo properly handle the lifecycle of Fragments in your Activity, you should create two separate layout files - one for portrait mode and one for landscape mode - and add the appropriate Fragment to each layout. This way, when the Activity is recreated, the FragmentManager will only add the relevant Fragment to the Activity. Here is an example of how you can accomplish this:\nCreate two layout files: one for portrait mode (e.g. activity_main.xml) and one for landscape mode (e.g. activity_main_land.xml).\nactivity_main.xml:\n\nactivity_main_land.xml:\n\nIn your Activity's onCreate() method, inflate the appropriate layout based on the device's orientation, and add the Fragment(s) to the Activity:\nMainActivity.java:\n\nWith this approach, when you shift from portrait to landscape mode, the FragmentManager adds both Fragments to the Activity, and when you shift back to portrait mode, the FragmentManager only adds the relevant Fragment to the Activity. Additionally, since the Fragment is added directly to the layout, you can access its views using findViewById() instead of relying on the FragmentManager.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "SupportFragmentManager & FragmentManager are relatively old ways of navigating an user through different fragments. They were widely used before, but have some drawbacks like:\n\nHard backstack navigation\nProblems with adding or removing fragments, etc.\n\nThe Navigation component is part of Android Jetpack. It's a new approach and it aims to simplify and solve some of the problems related to the old one described above. Also, it is not restricted to work only with Fragments.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "In MainActivity the line:\n\nShould be:\n\n\nReturn the FragmentManager for interacting with fragments associated with this activity.\n\nAs you can read in the docs\n\nReturn the FragmentManager for interacting with fragments associated with this fragment's activity. Note that this will be non-null slightly before getActivity(), during the time from when the fragment is placed in a FragmentTransaction until it is committed and attached to its activity.\n\nAnd is returning null for the just created Fragment.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "FragmentStateAdapter requires a FragmentManager and Lifecycle in its constructor. Change your DocAdapter to this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The displaying of Fragments is managed by FragmentManager. You must pass an instance of FragmentManager to CNNAdapter as follows:\n\nAnd then you display the fragment as follows:\n\nR.id.fragment_container is the view ID of the container in the layout xml of the activity that hosts the fragment. The container is usually a FrameLayout.\nAnd then you instantiate CNNAdapter in the Fragment like this:\n\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "directive": {
                "finetuned_dpr": [
                    {
                        "id": 68254825,
                        "answer_post": "First of all, FragmentStatePagerAdapter is deprecated now. So, it's better to use FragmentStateAdapter with ViewPager2.\nI couldn't find any proper solution in case if you need to pass something into  Fragment's constructor with ViewPager2 because it ignores FragmentFactory. I was thinking about implementing the FragmentFactory in createFragment method of FragmentStateAdapter but don't know where to get the proper class loader in this case.\nThe only solution I found is to use FragmentManager.FragmentLifecycleCallbacks. Here you have a fragment so you can cast it to you particular implementation. You can set callbacks or whatever you want to your fragment after its (re)creation. So in this case you don't need to pass something in to fragment's constructor but also can avoid creating Bundles.\n\nI tested this code using childFragmentManager and it works fine. But I have to admit that this is not a clear solution. And if you can avoid passing something to Fragment's constructor while using FragmentStateAdapter, avoid it. Because the most proper solution is to use a FragmentFactory.\nAlso, as an option, your fragment knows about the parent Activity. So, you can do callbacks directly to the parent Activity.\nLink to documentation: https://developer.android.com/reference/androidx/fragment/app/FragmentManager#registerFragmentLifecycleCallbacks(androidx.fragment.app.FragmentManager.FragmentLifecycleCallbacks,%20boolean)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62830821,
                        "answer_post": "You could use fragment.\nFirst, use  in your activity layout as a container of Fragment, here we give it a id like, android:id=\"+id/fragment_container\"\nSecond, create a layout xml file for your fragment, here we give it a name, like fragment_page_3.xml\nThen create a subclass of Fragment, and override its onCreateView() method, where you inflate your fragment's layout. Code here\n\nFinally, in clickListener, you could use fragmentManager load your fragment, code like this:\n\nI just want to give you some ideas.\nYou cannot write code like this, this is wrong implementation for your app because you may need several fragment and you need a Callbacks interface implemented by your activity.\nIf you could change your content of UI, it's a better way.\nTo learn more, you could refer https://developer.android.com/guide/components/fragments\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66796997,
                        "answer_post": "It's unclear why you need to retain an instance in memory of a Fragment that is no longer visible; presumably it's expensive to recreate it so you want to save it.\nThis is a code-smell in most cases (but because I don't know your reasons and haven't seen your code, I will give you the benefit of doubt) :)\nAssuming you have a valid reason for this, Android offers Fragments a mechanism to be retained:\nDirectly from the Android's Fragment source:\n\nKeep in mind the implications of doing so, for now your lifecycle is different and so are all the side-effects of expecting a normal lifecycle (and the memory impact of keeping a fragment around).\nAlternatively, consider separating the Fragment's state from it into a ViewModel, Repository, or Beyond\u2122, and let the fragment simply be told what its state it so it can be properly recreated in a \"fast\" and \"efficient\" manner. (I quote these because fast/efficient are in the eye of the beholder and because it's also still subject to Android rules...).\nNow, I haven't also seen how you \"navigate\" and how you \"go back\", so you'll have to test this yourself. Ultimately, if the FragmentManager desires to destroy your Fragment, it's probably because it found no reason to keep it around (you could, keep a hard reference and deal with all that memory wasted... which is why I suggest you keep the \"state\" outside of the Fragment instead, because creating a fragment is not that expensive, if the fragment doesn't contain 2000 lines of code in onCreate...) :)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68959128,
                        "answer_post": "In this case FragmentContainerView and FragmentManager ,Fragment transactions help us .\n\nFragmentContainerView is a customized Layout designed specifically for Fragments. It extends FrameLayout, so it can reliably handle Fragment Transactions, and it also has additional features to coordinate with fragment behavior.\nAt runtime, a FragmentManager can add, remove, replace, and perform other actions with fragments in response to user interaction.\n\nSo you can take a FragmentContainerView in your activity_main.xml where you can add different fragment by button/user action.\nSo your activity_main.xml looks like now -\n\nNow Create a new Blank Fragment to your project to test . IDE automatically override some methods and layout for your fragment also for this .\n\nSo your BlankFragment.class looks like -\n\nNow From your Activity you can show the Blank Fragment in FragmentContainerView , we define its id fragment_container_view in activity_main.xml .\nHere Your MainActivity.class -\n\nAll of these just for example . You should check documentation to know more .\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63141419,
                        "answer_post": "You should always, always use childFragmentManager when nesting fragments - the childFragmentManager is never executing transactions when its parent is going through lifecycle changes (which I assume is when you're calling your transaction).\nThis is actually silently causing issues for you when you use the <fragment> tag as those lifecycle events don't actually occur as a transaction, but directly as part of inflation. Using the wrong FragmentManager means that the fragment and its views will not properly save and restore their state.\nThe reason it fails with FragmentContainerView is that FragmentContainerView actually does the same FragmentTransaction as you'd do normally.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71231654,
                        "answer_post": "Do not touch the FragmentManager yourself when using the Navigation library.\nLet Navigation manage Navigation between fragments, that's what it's used for.\nThe message:\n\nI/FragmentNavigator: Ignoring navigate() call: FragmentManager has\nalready saved its state\n\nis defined in the androidx.navigation.fragment.FragmentNavigator#navigate\nThe Fragment state is saved by the Activity. It usually appears when the Activity goes into the onStop state. Means should not be operated the fragmentManger after leaving the current Activity. (but still can use androidx.fragment.app.FragmentTransaction#commitAllowingStateLoss to ignore the warning , but this state will not be restored when the Activity is recreated.)\nIn your scenes, I recommend jumping to the next activity for editing, returning and refreshing the list\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62095513,
                        "answer_post": "Your activity must extend androidx.fragment.app.FragmentActivity.\nFrom the documentation,\n\nBase class for activities that want to use the support-based\n  Fragments.\n\nAlso from Fragment's documentation,\n\n\nYour activity must extend FragmentActivity\nYou must call FragmentActivity.getSupportFragmentManager() to get the    FragmentManager\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66594768,
                        "answer_post": "From what my understanding is regarding Activities and Fragments in Android, fragment is a sub-part of the activity in which it is called.\nYes you are right, fragments are sub parts added dynamically on run time\nSo what I want to know is that if we finish or kill the Activity in which the fragment exists, how will it effect the fragment?\nIf you kill/finish an Activity fragments will also be destroyed\nNOTE: Fragment lifecycle is dependent on Activity life cycle, if an Activity is dead so the fragments are.\nBuilding fragment on an Activity is like building 2,3 or 4 story building. If base is destroyed then other stories are not supposed to be stable. Just keep this rule in mind. This will help you with understanding. And further more you can apply logging on Activity and Fragment lifecycle.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66494990,
                        "answer_post": "After some debugging in FragmentContainerView itself, I have hopefully found all the cases of the FragmentManager used whilst adding a fragment via the android:name attribute.\n\nFragments in the activity view hierarchy (from Activity.setContentView(Int)): Activity.getSupportFragmentManager()\n\nFragments in another fragments hierarchy (from Fragment.onCreateView(...)): Fragment.getChildFragmentManager\n\nFragments in a RecyclerView row, where the RecyclerView is either in a Fragment or an Activity: Activity.getSupportFragmentManager()\n\n\nNow the first two are well documented and not of interest here, but I found the third case to be surprising, especially as it doesn't seem to make a difference what the RecyclerView has been inflated into. If I had to take a guess of why this is, it would probably be in onCreateViewHolder.When you inflate your row you pass false into the inflate function's attachToRoot, so as the FragmentContainerView is not attached to a parent when it is initialised, it has to use the highest level fragment manager - from the activity. However this is just speculation.\nRegardless, in answer to your question - it is definitely the activities fragment manager.\n\nYou also said that you have tried using all the fragment managers anyway and they all couldn't find your fragment, but I wasn't able to replicate this problem. I managed to find my fragment in the RecyclerView just fine so I would expect there's something else going on that we can't find from the code you've shown, in theory it works.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65618500,
                        "answer_post": "The issue with your code is that you are accessing getView() of your fragment before the fragment has gone through the initialization of the view. The reason why you don't have the crash when you execute the transaction in your activity's onCreate() method is that by the time you click on a button your fragment has already gone through onCreateView() and initialized its view. Check out fragment lifecycle guide and bear in mind that you should not access your fragment view before it was created or after it was destroyed. For more information about why your fragment view is not initialized instantly check out this guide.\nAs for the solution, consider setting arguments for your fragment before adding it to your transaction like here:\n\nThen in your onCreateView() or onViewCreated() methods of your fragment restore the arguments like here and set the image resource:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 64096217,
                        "answer_post": "Fragment manager has a putFragment and getFragment method you can use to save and restore instance state of your Fragments.\nThis allowed me to save my Fragment Instance Variables so they didn't return null after process death.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64157718,
                        "answer_post": "The FragmentManager returned by Activity.getSupportFragmentManager() is different from the one returned by Fragment.getChildFragmentManager().\nIf you want to perform a fragment transaction from the Fragment level, but be able to \"see\" it at the Activity level, then you should use Fragment.getParentFragmentManager() (or Fragment.getFragmentManager() on older versions of the AndroidX library).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64043740,
                        "answer_post": "You should use FragmentActivity (from androidx) instead of Activity as the argument type in myMethod() and call getSupportFragmentManager() to get the FragmentManager on it. This should solve your problem.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65096917,
                        "answer_post": "Fragment transactions are asynchronous (unless you use executePendingTransactions()). Your transaction has likely not completed yet. You use runOnCommit on FragmentTransaction (in the support library) to execute code after it is done.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66504608,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67975369,
                        "answer_post": "You can get fragments by Ids using Fragment manager's findFragmentByTag(\"f$id\")\nBut to do that you need to override getItemId() in the FragmentStateAdapter to return the position, so that the id now equals to the position.\n\nThen to get a fragment at a position:\n\nIf the ViewPager2 is hosted by an activity use supportFragmentManager:\n\n\n\nAnd if it's hosted by a fragment use childFragmentManager:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66433048,
                        "answer_post": "Using .observe(requireActivity(), savedTextObserver); in a Fragment's onCreateView is never the correct thing: that's saying you want to observe using the Activity's lifecycle, which will continue even if you remove the Fragment or put the Fragment on the back stack.\nInstead, you should use .observe(getViewLifecycleOwner(), savedTextObserver); to get the Lifecycle specifically associated with the Fragment's view, which is the correct scope for any Observer that updates your Fragment's UI (such as yoursetAdapter`).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67770402,
                        "answer_post": "View pager can't detach cause memory leak. To avoid this, change the code to create the instance of TabsPagerAdapter according to the following code\n\nNote:\n\nrequestActivity().supportFragmentManager -> childFragmentManger : All its children should be managed by itself instead of activity.\n\nlifecycle -> viewLifecycleOwner.lifecycle : The fragment has 2 lifecycles, one for the view (viewLifecycleOwner.lifecycle), one for itself (lifecycle). In this case, the adapter is the view so we just need to use the lifecycle for the view (viewLifecycleOwner.lifecycle)\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66946260,
                        "answer_post": "There's actually three constructors for FragmentStateAdapter:\n\nFragmentStateAdapter(FragmentActivity) - this uses the Activity's getSupportFragmentManager() and the Activity's getLifecycle(). This is what you'd use if your ViewPager2 was directly hosted within an Activity\nFragmentStateAdapter(Fragment) - this uses the Fragment's getChildFragmentManager() and the Fragment's getLifecycle(). This is what you'd use if your ViewPager2 was hosted within another Fragment\nFragmentStateAdapter(FragmentManager, Lifecycle) - this is what the other two constructors call internally. You wouldn't ever use this unless you were adding fragments to a service, etc. where you don't have a FragmentActivity at all.\n\nYou must always use the one that takes a Fragment (or use getChildFragmentManager()+getLifecycle() if you want to write more code for the same effect) when hosting a ViewPager2 within a Fragment - this ensures that the Fragment's your FragmentStateAdapter creates correctly have their state restored after a configuration change or process death or recreation - something that is only possible when they are child fragments of the fragment that has your ViewPager2 within it.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65833033,
                        "answer_post": "viewPagerAdapter.addFragment() is an anti-pattern because it will inevitably cause crashes after process death in production.\nThe correct way to implement a regular FragmentPagerAdapter is:\n\nTo get a reference to a Fragment created by a ViewPager, use the following findFragmentByTag scheme:\n\nIf you need a dynamic FragmentPagerAdapter (which you do, according to your clear() method), then you can do:\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 71723371,
                        "answer_post": "\nhere how it works with fragment\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72966333,
                        "answer_post": "Write a function in your Activity\n\nIn your Fragment\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64315790,
                        "answer_post": "Fragment code\n\n\n\nShould be\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66121178,
                        "answer_post": "SupportFragmentManager & FragmentManager are relatively old ways of navigating an user through different fragments. They were widely used before, but have some drawbacks like:\n\nHard backstack navigation\nProblems with adding or removing fragments, etc.\n\nThe Navigation component is part of Android Jetpack. It's a new approach and it aims to simplify and solve some of the problems related to the old one described above. Also, it is not restricted to work only with Fragments.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64454162,
                        "answer_post": "DialogLayout:\n\nFragmentLayout\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75736322,
                        "answer_post": "try to add\n\nto your fragment / activity\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65414383,
                        "answer_post": "in your fragment should be\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65124461,
                        "answer_post": "in Fragment\nUse\n\ninstead of\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67337645,
                        "answer_post": "in the fragment\n\nin de activity\n\nand recive the array\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72328405,
                        "answer_post": "\nand\n\nthen Activity or Fragment with\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "Bu using Navigation Architecture components, The NavController is the responsible for fragment transaction and managing the back stack instead of the Support FragmentManager.\nSo, instead of making tranditional framgnet transactions with FragmentManager\nYou can move from ThridFragment to the first one by:\n\nWhere action_ThirdFragment_to_FirstFragment is the id of the action you defined in the navigation graph to move from ThridFragment to FirstFragment\nUPDATE:\nAs discussed from comments, besides replacing FragmentManager by NavController in all actions; there is another issue:\nMissing of action_FirstFragment_to_ThirdFragment action  from the navigation graph.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Your Search class is a Fragment, you cannot start it with the Intent.\nMake Search to be Activity or switch between fragments using FragmentManager.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes, a Viewpager can be setup in a Fragment.\nYou just need to get the right FragmentManager when constructing it i.e use getChildFragmentManager() in mViewPager.setAdapter(new TvShowEpisodeDetailsAdapter(getSupportFragmentManager()));\nFrom https://developer.android.com/guide/fragments/fragmentmanager\n\nAccess the FragmentManager\nAccessing in an activity\nEvery FragmentActivity and subclasses thereof, such as\nAppCompatActivity, have access to the FragmentManager through the\ngetSupportFragmentManager() method.\nAccessing in a Fragment\nFragments are also capable of hosting one or more child fragments.\nInside a fragment, you can get a reference to the FragmentManager that\nmanages the fragment's children through getChildFragmentManager().\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Based on the information provided, it seems that the issue you are experiencing may be related to the lifecycle of the Fragment and how it is being added to the Activity.\nWhen you shift from portrait to landscape mode, the Activity is recreated, and the FragmentManager adds the two Fragments to the Activity. When you shift back to portrait mode, the Activity is recreated again, and the FragmentManager attempts to add both Fragments to the Activity. However, since only one Fragment is meant to be shown in portrait mode, the FragmentManager adds the first Fragment and ignores the second one.\nTo properly handle the lifecycle of Fragments in your Activity, you should create two separate layout files - one for portrait mode and one for landscape mode - and add the appropriate Fragment to each layout. This way, when the Activity is recreated, the FragmentManager will only add the relevant Fragment to the Activity. Here is an example of how you can accomplish this:\nCreate two layout files: one for portrait mode (e.g. activity_main.xml) and one for landscape mode (e.g. activity_main_land.xml).\nactivity_main.xml:\n\nactivity_main_land.xml:\n\nIn your Activity's onCreate() method, inflate the appropriate layout based on the device's orientation, and add the Fragment(s) to the Activity:\nMainActivity.java:\n\nWith this approach, when you shift from portrait to landscape mode, the FragmentManager adds both Fragments to the Activity, and when you shift back to portrait mode, the FragmentManager only adds the relevant Fragment to the Activity. Additionally, since the Fragment is added directly to the layout, you can access its views using findViewById() instead of relying on the FragmentManager.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "SupportFragmentManager & FragmentManager are relatively old ways of navigating an user through different fragments. They were widely used before, but have some drawbacks like:\n\nHard backstack navigation\nProblems with adding or removing fragments, etc.\n\nThe Navigation component is part of Android Jetpack. It's a new approach and it aims to simplify and solve some of the problems related to the old one described above. Also, it is not restricted to work only with Fragments.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "In MainActivity the line:\n\nShould be:\n\n\nReturn the FragmentManager for interacting with fragments associated with this activity.\n\nAs you can read in the docs\n\nReturn the FragmentManager for interacting with fragments associated with this fragment's activity. Note that this will be non-null slightly before getActivity(), during the time from when the fragment is placed in a FragmentTransaction until it is committed and attached to its activity.\n\nAnd is returning null for the just created Fragment.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You're using the wrong FragmentManager - for every fragment that is fully contained within the layout of another (such as your ViewPager2 managed fragments), you must use childFragmentManager to properly nest the fragments.\n\nThis is required not only to restore your state properly (something which using the activity's supportFragmentManager will not do), but to ensure that the parent fragment goes through its state transitions first and only then does the child fragments go through their transitions, fixing the \"already executing transactions\" issue.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You're using the wrong FragmentManager - for every fragment that is fully contained within the layout of another (such as your ViewPager2 managed fragments), you must use childFragmentManager to properly nest the fragments.\n\nThis is required not only to restore your state properly (something which using the activity's supportFragmentManager will not do), but to ensure that the parent fragment goes through its state transitions first and only then does the child fragments go through their transitions, fixing the \"already executing transactions\" issue.\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "pattern": {
                "finetuned_dpr": [
                    {
                        "id": 68254825,
                        "answer_post": "First of all, FragmentStatePagerAdapter is deprecated now. So, it's better to use FragmentStateAdapter with ViewPager2.\nI couldn't find any proper solution in case if you need to pass something into  Fragment's constructor with ViewPager2 because it ignores FragmentFactory. I was thinking about implementing the FragmentFactory in createFragment method of FragmentStateAdapter but don't know where to get the proper class loader in this case.\nThe only solution I found is to use FragmentManager.FragmentLifecycleCallbacks. Here you have a fragment so you can cast it to you particular implementation. You can set callbacks or whatever you want to your fragment after its (re)creation. So in this case you don't need to pass something in to fragment's constructor but also can avoid creating Bundles.\n\nI tested this code using childFragmentManager and it works fine. But I have to admit that this is not a clear solution. And if you can avoid passing something to Fragment's constructor while using FragmentStateAdapter, avoid it. Because the most proper solution is to use a FragmentFactory.\nAlso, as an option, your fragment knows about the parent Activity. So, you can do callbacks directly to the parent Activity.\nLink to documentation: https://developer.android.com/reference/androidx/fragment/app/FragmentManager#registerFragmentLifecycleCallbacks(androidx.fragment.app.FragmentManager.FragmentLifecycleCallbacks,%20boolean)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62830821,
                        "answer_post": "You could use fragment.\nFirst, use  in your activity layout as a container of Fragment, here we give it a id like, android:id=\"+id/fragment_container\"\nSecond, create a layout xml file for your fragment, here we give it a name, like fragment_page_3.xml\nThen create a subclass of Fragment, and override its onCreateView() method, where you inflate your fragment's layout. Code here\n\nFinally, in clickListener, you could use fragmentManager load your fragment, code like this:\n\nI just want to give you some ideas.\nYou cannot write code like this, this is wrong implementation for your app because you may need several fragment and you need a Callbacks interface implemented by your activity.\nIf you could change your content of UI, it's a better way.\nTo learn more, you could refer https://developer.android.com/guide/components/fragments\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66796997,
                        "answer_post": "It's unclear why you need to retain an instance in memory of a Fragment that is no longer visible; presumably it's expensive to recreate it so you want to save it.\nThis is a code-smell in most cases (but because I don't know your reasons and haven't seen your code, I will give you the benefit of doubt) :)\nAssuming you have a valid reason for this, Android offers Fragments a mechanism to be retained:\nDirectly from the Android's Fragment source:\n\nKeep in mind the implications of doing so, for now your lifecycle is different and so are all the side-effects of expecting a normal lifecycle (and the memory impact of keeping a fragment around).\nAlternatively, consider separating the Fragment's state from it into a ViewModel, Repository, or Beyond\u2122, and let the fragment simply be told what its state it so it can be properly recreated in a \"fast\" and \"efficient\" manner. (I quote these because fast/efficient are in the eye of the beholder and because it's also still subject to Android rules...).\nNow, I haven't also seen how you \"navigate\" and how you \"go back\", so you'll have to test this yourself. Ultimately, if the FragmentManager desires to destroy your Fragment, it's probably because it found no reason to keep it around (you could, keep a hard reference and deal with all that memory wasted... which is why I suggest you keep the \"state\" outside of the Fragment instead, because creating a fragment is not that expensive, if the fragment doesn't contain 2000 lines of code in onCreate...) :)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 68959128,
                        "answer_post": "In this case FragmentContainerView and FragmentManager ,Fragment transactions help us .\n\nFragmentContainerView is a customized Layout designed specifically for Fragments. It extends FrameLayout, so it can reliably handle Fragment Transactions, and it also has additional features to coordinate with fragment behavior.\nAt runtime, a FragmentManager can add, remove, replace, and perform other actions with fragments in response to user interaction.\n\nSo you can take a FragmentContainerView in your activity_main.xml where you can add different fragment by button/user action.\nSo your activity_main.xml looks like now -\n\nNow Create a new Blank Fragment to your project to test . IDE automatically override some methods and layout for your fragment also for this .\n\nSo your BlankFragment.class looks like -\n\nNow From your Activity you can show the Blank Fragment in FragmentContainerView , we define its id fragment_container_view in activity_main.xml .\nHere Your MainActivity.class -\n\nAll of these just for example . You should check documentation to know more .\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66594768,
                        "answer_post": "From what my understanding is regarding Activities and Fragments in Android, fragment is a sub-part of the activity in which it is called.\nYes you are right, fragments are sub parts added dynamically on run time\nSo what I want to know is that if we finish or kill the Activity in which the fragment exists, how will it effect the fragment?\nIf you kill/finish an Activity fragments will also be destroyed\nNOTE: Fragment lifecycle is dependent on Activity life cycle, if an Activity is dead so the fragments are.\nBuilding fragment on an Activity is like building 2,3 or 4 story building. If base is destroyed then other stories are not supposed to be stable. Just keep this rule in mind. This will help you with understanding. And further more you can apply logging on Activity and Fragment lifecycle.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62095513,
                        "answer_post": "Your activity must extend androidx.fragment.app.FragmentActivity.\nFrom the documentation,\n\nBase class for activities that want to use the support-based\n  Fragments.\n\nAlso from Fragment's documentation,\n\n\nYour activity must extend FragmentActivity\nYou must call FragmentActivity.getSupportFragmentManager() to get the    FragmentManager\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71231654,
                        "answer_post": "Do not touch the FragmentManager yourself when using the Navigation library.\nLet Navigation manage Navigation between fragments, that's what it's used for.\nThe message:\n\nI/FragmentNavigator: Ignoring navigate() call: FragmentManager has\nalready saved its state\n\nis defined in the androidx.navigation.fragment.FragmentNavigator#navigate\nThe Fragment state is saved by the Activity. It usually appears when the Activity goes into the onStop state. Means should not be operated the fragmentManger after leaving the current Activity. (but still can use androidx.fragment.app.FragmentTransaction#commitAllowingStateLoss to ignore the warning , but this state will not be restored when the Activity is recreated.)\nIn your scenes, I recommend jumping to the next activity for editing, returning and refreshing the list\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63141419,
                        "answer_post": "You should always, always use childFragmentManager when nesting fragments - the childFragmentManager is never executing transactions when its parent is going through lifecycle changes (which I assume is when you're calling your transaction).\nThis is actually silently causing issues for you when you use the <fragment> tag as those lifecycle events don't actually occur as a transaction, but directly as part of inflation. Using the wrong FragmentManager means that the fragment and its views will not properly save and restore their state.\nThe reason it fails with FragmentContainerView is that FragmentContainerView actually does the same FragmentTransaction as you'd do normally.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66494990,
                        "answer_post": "After some debugging in FragmentContainerView itself, I have hopefully found all the cases of the FragmentManager used whilst adding a fragment via the android:name attribute.\n\nFragments in the activity view hierarchy (from Activity.setContentView(Int)): Activity.getSupportFragmentManager()\n\nFragments in another fragments hierarchy (from Fragment.onCreateView(...)): Fragment.getChildFragmentManager\n\nFragments in a RecyclerView row, where the RecyclerView is either in a Fragment or an Activity: Activity.getSupportFragmentManager()\n\n\nNow the first two are well documented and not of interest here, but I found the third case to be surprising, especially as it doesn't seem to make a difference what the RecyclerView has been inflated into. If I had to take a guess of why this is, it would probably be in onCreateViewHolder.When you inflate your row you pass false into the inflate function's attachToRoot, so as the FragmentContainerView is not attached to a parent when it is initialised, it has to use the highest level fragment manager - from the activity. However this is just speculation.\nRegardless, in answer to your question - it is definitely the activities fragment manager.\n\nYou also said that you have tried using all the fragment managers anyway and they all couldn't find your fragment, but I wasn't able to replicate this problem. I managed to find my fragment in the RecyclerView just fine so I would expect there's something else going on that we can't find from the code you've shown, in theory it works.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75043723,
                        "answer_post": "Disclaimer: This answer might work/not work based on the architecture of your app.\nTo begin with ,quite strange why microsoft requires Fragment and not sure about what is the usecase behind it.\nIt seems issue raised here.Have to wait for update regarding that.\nLets assume for now Fragment is compulsory. Actually we can use Fragment in compose app. Because legacy apps using xml must have support to gradual migration from fragment architecture to compose ui.By the way, Android provides that flexibility to integrate composable to legacy activity/fragment architecture.\n2 Cases .\n\nIf you have single activity app architecture and all other are compose UI. You might need to do little more work to adapt fragment in compose app.\n\nIf the signin/signup screen where you are using msal is separate activity and for core features you have other activity , you can integrate fragment only to activity where msal is being used.\n\n\nLets jump in to implementation.\n\nFirst thing ,you need fragment dependancy.\n\n\nAssuming you are having activity.\n\n\n\nHere your activity should extend FragmentActivity or any activity classes extending FragmentActivity. ComponentActivity may not work.\nYou need to have your xml file for activity and use setcontent view. You might need to create layout resource folder and layout file if not present.\n\nYour activity xml.\n\n\n\n\nHere were are having FragmentContainerView and refer to the fragment class we are going to create. No need to inflate.\n\nMy Fragment class.\n\n\n\nHere Fragment does not need xml file. Fragment will now be the root of all your compose content.  Here we are using CompositionLocalProvider to hold the fragment instance and later it can be used in multiple composables.\nYou can also use LocalCurrent.context and typecast to fragment. But that you might need to do everytime. Better way is to use CompositionLocalProvider.\n\nYou can add staticCompositionLocalOf outside of your fragment class in.\n\n\n\nSo you can access fragment instance in any composables which are in same activity and fragment layout tree.\n\nHere this is the composable function ui. Here I am getting the fragment instance and passing to MSAL.\n\n\nThe most important thing is your composable's direct parent should be fragment instead of activity. And its instance will be provided to all child composables via CompositionLocalProvider.  And this migration is wholly based on existing architecture and size of the project.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 64157718,
                        "answer_post": "The FragmentManager returned by Activity.getSupportFragmentManager() is different from the one returned by Fragment.getChildFragmentManager().\nIf you want to perform a fragment transaction from the Fragment level, but be able to \"see\" it at the Activity level, then you should use Fragment.getParentFragmentManager() (or Fragment.getFragmentManager() on older versions of the AndroidX library).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64096217,
                        "answer_post": "Fragment manager has a putFragment and getFragment method you can use to save and restore instance state of your Fragments.\nThis allowed me to save my Fragment Instance Variables so they didn't return null after process death.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64043740,
                        "answer_post": "You should use FragmentActivity (from androidx) instead of Activity as the argument type in myMethod() and call getSupportFragmentManager() to get the FragmentManager on it. This should solve your problem.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66504608,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65096917,
                        "answer_post": "Fragment transactions are asynchronous (unless you use executePendingTransactions()). Your transaction has likely not completed yet. You use runOnCommit on FragmentTransaction (in the support library) to execute code after it is done.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67975369,
                        "answer_post": "You can get fragments by Ids using Fragment manager's findFragmentByTag(\"f$id\")\nBut to do that you need to override getItemId() in the FragmentStateAdapter to return the position, so that the id now equals to the position.\n\nThen to get a fragment at a position:\n\nIf the ViewPager2 is hosted by an activity use supportFragmentManager:\n\n\n\nAnd if it's hosted by a fragment use childFragmentManager:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67770402,
                        "answer_post": "View pager can't detach cause memory leak. To avoid this, change the code to create the instance of TabsPagerAdapter according to the following code\n\nNote:\n\nrequestActivity().supportFragmentManager -> childFragmentManger : All its children should be managed by itself instead of activity.\n\nlifecycle -> viewLifecycleOwner.lifecycle : The fragment has 2 lifecycles, one for the view (viewLifecycleOwner.lifecycle), one for itself (lifecycle). In this case, the adapter is the view so we just need to use the lifecycle for the view (viewLifecycleOwner.lifecycle)\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76191984,
                        "answer_post": "\nIf you use Fragment.viewLifecycleOwner.lifecycle.addObserver(\u2026), DefaultLifecycleObserver.onDestory(\u2026) will be called at the same time as Fragment.onDestoryView(\u2026).\nIf you use Fragment.lifecycle.addObserver(\u2026), DefaultLifecycleObserver.onDestory(\u2026) will be called at the same time as Fragment.onDestory(\u2026).\n\nHere is an example.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65833033,
                        "answer_post": "viewPagerAdapter.addFragment() is an anti-pattern because it will inevitably cause crashes after process death in production.\nThe correct way to implement a regular FragmentPagerAdapter is:\n\nTo get a reference to a Fragment created by a ViewPager, use the following findFragmentByTag scheme:\n\nIf you need a dynamic FragmentPagerAdapter (which you do, according to your clear() method), then you can do:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66580660,
                        "answer_post": "Fragments should have an empty constructor since they are managed by Android, same as activities. Anything you want to inject you have to inject inside the fragment, not through the constructor.\nFor view-models, it's trivial through the viewModels() API:\n\nDon't forget to annotate the fragment with @AndroidEntryPoint and the view-model with @HiltViewModel.\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 71723371,
                        "answer_post": "\nhere how it works with fragment\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72966333,
                        "answer_post": "Write a function in your Activity\n\nIn your Fragment\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64454162,
                        "answer_post": "DialogLayout:\n\nFragmentLayout\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65124461,
                        "answer_post": "in Fragment\nUse\n\ninstead of\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64315790,
                        "answer_post": "Fragment code\n\n\n\nShould be\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66121178,
                        "answer_post": "SupportFragmentManager & FragmentManager are relatively old ways of navigating an user through different fragments. They were widely used before, but have some drawbacks like:\n\nHard backstack navigation\nProblems with adding or removing fragments, etc.\n\nThe Navigation component is part of Android Jetpack. It's a new approach and it aims to simplify and solve some of the problems related to the old one described above. Also, it is not restricted to work only with Fragments.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75736322,
                        "answer_post": "try to add\n\nto your fragment / activity\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63789470,
                        "answer_post": "For Fragment use activity instead of getActivity\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65684761,
                        "answer_post": "In ViewModel\n\nAnd in the Activity or Fragment :\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62126425,
                        "answer_post": "create method in your Activity\n\nand use in your Fragment\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "Bu using Navigation Architecture components, The NavController is the responsible for fragment transaction and managing the back stack instead of the Support FragmentManager.\nSo, instead of making tranditional framgnet transactions with FragmentManager\nYou can move from ThridFragment to the first one by:\n\nWhere action_ThirdFragment_to_FirstFragment is the id of the action you defined in the navigation graph to move from ThridFragment to FirstFragment\nUPDATE:\nAs discussed from comments, besides replacing FragmentManager by NavController in all actions; there is another issue:\nMissing of action_FirstFragment_to_ThirdFragment action  from the navigation graph.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Your Search class is a Fragment, you cannot start it with the Intent.\nMake Search to be Activity or switch between fragments using FragmentManager.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes, a Viewpager can be setup in a Fragment.\nYou just need to get the right FragmentManager when constructing it i.e use getChildFragmentManager() in mViewPager.setAdapter(new TvShowEpisodeDetailsAdapter(getSupportFragmentManager()));\nFrom https://developer.android.com/guide/fragments/fragmentmanager\n\nAccess the FragmentManager\nAccessing in an activity\nEvery FragmentActivity and subclasses thereof, such as\nAppCompatActivity, have access to the FragmentManager through the\ngetSupportFragmentManager() method.\nAccessing in a Fragment\nFragments are also capable of hosting one or more child fragments.\nInside a fragment, you can get a reference to the FragmentManager that\nmanages the fragment's children through getChildFragmentManager().\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Based on the information provided, it seems that the issue you are experiencing may be related to the lifecycle of the Fragment and how it is being added to the Activity.\nWhen you shift from portrait to landscape mode, the Activity is recreated, and the FragmentManager adds the two Fragments to the Activity. When you shift back to portrait mode, the Activity is recreated again, and the FragmentManager attempts to add both Fragments to the Activity. However, since only one Fragment is meant to be shown in portrait mode, the FragmentManager adds the first Fragment and ignores the second one.\nTo properly handle the lifecycle of Fragments in your Activity, you should create two separate layout files - one for portrait mode and one for landscape mode - and add the appropriate Fragment to each layout. This way, when the Activity is recreated, the FragmentManager will only add the relevant Fragment to the Activity. Here is an example of how you can accomplish this:\nCreate two layout files: one for portrait mode (e.g. activity_main.xml) and one for landscape mode (e.g. activity_main_land.xml).\nactivity_main.xml:\n\nactivity_main_land.xml:\n\nIn your Activity's onCreate() method, inflate the appropriate layout based on the device's orientation, and add the Fragment(s) to the Activity:\nMainActivity.java:\n\nWith this approach, when you shift from portrait to landscape mode, the FragmentManager adds both Fragments to the Activity, and when you shift back to portrait mode, the FragmentManager only adds the relevant Fragment to the Activity. Additionally, since the Fragment is added directly to the layout, you can access its views using findViewById() instead of relying on the FragmentManager.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "SupportFragmentManager & FragmentManager are relatively old ways of navigating an user through different fragments. They were widely used before, but have some drawbacks like:\n\nHard backstack navigation\nProblems with adding or removing fragments, etc.\n\nThe Navigation component is part of Android Jetpack. It's a new approach and it aims to simplify and solve some of the problems related to the old one described above. Also, it is not restricted to work only with Fragments.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "In MainActivity the line:\n\nShould be:\n\n\nReturn the FragmentManager for interacting with fragments associated with this activity.\n\nAs you can read in the docs\n\nReturn the FragmentManager for interacting with fragments associated with this fragment's activity. Note that this will be non-null slightly before getActivity(), during the time from when the fragment is placed in a FragmentTransaction until it is committed and attached to its activity.\n\nAnd is returning null for the just created Fragment.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "FragmentStateAdapter requires a FragmentManager and Lifecycle in its constructor. Change your DocAdapter to this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The displaying of Fragments is managed by FragmentManager. You must pass an instance of FragmentManager to CNNAdapter as follows:\n\nAnd then you display the fragment as follows:\n\nR.id.fragment_container is the view ID of the container in the layout xml of the activity that hosts the fragment. The container is usually a FrameLayout.\nAnd then you instantiate CNNAdapter in the Fragment like this:\n\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "environment": {
                "finetuned_dpr": [
                    {
                        "id": 68254825,
                        "answer_post": "First of all, FragmentStatePagerAdapter is deprecated now. So, it's better to use FragmentStateAdapter with ViewPager2.\nI couldn't find any proper solution in case if you need to pass something into  Fragment's constructor with ViewPager2 because it ignores FragmentFactory. I was thinking about implementing the FragmentFactory in createFragment method of FragmentStateAdapter but don't know where to get the proper class loader in this case.\nThe only solution I found is to use FragmentManager.FragmentLifecycleCallbacks. Here you have a fragment so you can cast it to you particular implementation. You can set callbacks or whatever you want to your fragment after its (re)creation. So in this case you don't need to pass something in to fragment's constructor but also can avoid creating Bundles.\n\nI tested this code using childFragmentManager and it works fine. But I have to admit that this is not a clear solution. And if you can avoid passing something to Fragment's constructor while using FragmentStateAdapter, avoid it. Because the most proper solution is to use a FragmentFactory.\nAlso, as an option, your fragment knows about the parent Activity. So, you can do callbacks directly to the parent Activity.\nLink to documentation: https://developer.android.com/reference/androidx/fragment/app/FragmentManager#registerFragmentLifecycleCallbacks(androidx.fragment.app.FragmentManager.FragmentLifecycleCallbacks,%20boolean)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62830821,
                        "answer_post": "You could use fragment.\nFirst, use  in your activity layout as a container of Fragment, here we give it a id like, android:id=\"+id/fragment_container\"\nSecond, create a layout xml file for your fragment, here we give it a name, like fragment_page_3.xml\nThen create a subclass of Fragment, and override its onCreateView() method, where you inflate your fragment's layout. Code here\n\nFinally, in clickListener, you could use fragmentManager load your fragment, code like this:\n\nI just want to give you some ideas.\nYou cannot write code like this, this is wrong implementation for your app because you may need several fragment and you need a Callbacks interface implemented by your activity.\nIf you could change your content of UI, it's a better way.\nTo learn more, you could refer https://developer.android.com/guide/components/fragments\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66796997,
                        "answer_post": "It's unclear why you need to retain an instance in memory of a Fragment that is no longer visible; presumably it's expensive to recreate it so you want to save it.\nThis is a code-smell in most cases (but because I don't know your reasons and haven't seen your code, I will give you the benefit of doubt) :)\nAssuming you have a valid reason for this, Android offers Fragments a mechanism to be retained:\nDirectly from the Android's Fragment source:\n\nKeep in mind the implications of doing so, for now your lifecycle is different and so are all the side-effects of expecting a normal lifecycle (and the memory impact of keeping a fragment around).\nAlternatively, consider separating the Fragment's state from it into a ViewModel, Repository, or Beyond\u2122, and let the fragment simply be told what its state it so it can be properly recreated in a \"fast\" and \"efficient\" manner. (I quote these because fast/efficient are in the eye of the beholder and because it's also still subject to Android rules...).\nNow, I haven't also seen how you \"navigate\" and how you \"go back\", so you'll have to test this yourself. Ultimately, if the FragmentManager desires to destroy your Fragment, it's probably because it found no reason to keep it around (you could, keep a hard reference and deal with all that memory wasted... which is why I suggest you keep the \"state\" outside of the Fragment instead, because creating a fragment is not that expensive, if the fragment doesn't contain 2000 lines of code in onCreate...) :)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 68959128,
                        "answer_post": "In this case FragmentContainerView and FragmentManager ,Fragment transactions help us .\n\nFragmentContainerView is a customized Layout designed specifically for Fragments. It extends FrameLayout, so it can reliably handle Fragment Transactions, and it also has additional features to coordinate with fragment behavior.\nAt runtime, a FragmentManager can add, remove, replace, and perform other actions with fragments in response to user interaction.\n\nSo you can take a FragmentContainerView in your activity_main.xml where you can add different fragment by button/user action.\nSo your activity_main.xml looks like now -\n\nNow Create a new Blank Fragment to your project to test . IDE automatically override some methods and layout for your fragment also for this .\n\nSo your BlankFragment.class looks like -\n\nNow From your Activity you can show the Blank Fragment in FragmentContainerView , we define its id fragment_container_view in activity_main.xml .\nHere Your MainActivity.class -\n\nAll of these just for example . You should check documentation to know more .\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66594768,
                        "answer_post": "From what my understanding is regarding Activities and Fragments in Android, fragment is a sub-part of the activity in which it is called.\nYes you are right, fragments are sub parts added dynamically on run time\nSo what I want to know is that if we finish or kill the Activity in which the fragment exists, how will it effect the fragment?\nIf you kill/finish an Activity fragments will also be destroyed\nNOTE: Fragment lifecycle is dependent on Activity life cycle, if an Activity is dead so the fragments are.\nBuilding fragment on an Activity is like building 2,3 or 4 story building. If base is destroyed then other stories are not supposed to be stable. Just keep this rule in mind. This will help you with understanding. And further more you can apply logging on Activity and Fragment lifecycle.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62095513,
                        "answer_post": "Your activity must extend androidx.fragment.app.FragmentActivity.\nFrom the documentation,\n\nBase class for activities that want to use the support-based\n  Fragments.\n\nAlso from Fragment's documentation,\n\n\nYour activity must extend FragmentActivity\nYou must call FragmentActivity.getSupportFragmentManager() to get the    FragmentManager\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71231654,
                        "answer_post": "Do not touch the FragmentManager yourself when using the Navigation library.\nLet Navigation manage Navigation between fragments, that's what it's used for.\nThe message:\n\nI/FragmentNavigator: Ignoring navigate() call: FragmentManager has\nalready saved its state\n\nis defined in the androidx.navigation.fragment.FragmentNavigator#navigate\nThe Fragment state is saved by the Activity. It usually appears when the Activity goes into the onStop state. Means should not be operated the fragmentManger after leaving the current Activity. (but still can use androidx.fragment.app.FragmentTransaction#commitAllowingStateLoss to ignore the warning , but this state will not be restored when the Activity is recreated.)\nIn your scenes, I recommend jumping to the next activity for editing, returning and refreshing the list\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75043723,
                        "answer_post": "Disclaimer: This answer might work/not work based on the architecture of your app.\nTo begin with ,quite strange why microsoft requires Fragment and not sure about what is the usecase behind it.\nIt seems issue raised here.Have to wait for update regarding that.\nLets assume for now Fragment is compulsory. Actually we can use Fragment in compose app. Because legacy apps using xml must have support to gradual migration from fragment architecture to compose ui.By the way, Android provides that flexibility to integrate composable to legacy activity/fragment architecture.\n2 Cases .\n\nIf you have single activity app architecture and all other are compose UI. You might need to do little more work to adapt fragment in compose app.\n\nIf the signin/signup screen where you are using msal is separate activity and for core features you have other activity , you can integrate fragment only to activity where msal is being used.\n\n\nLets jump in to implementation.\n\nFirst thing ,you need fragment dependancy.\n\n\nAssuming you are having activity.\n\n\n\nHere your activity should extend FragmentActivity or any activity classes extending FragmentActivity. ComponentActivity may not work.\nYou need to have your xml file for activity and use setcontent view. You might need to create layout resource folder and layout file if not present.\n\nYour activity xml.\n\n\n\n\nHere were are having FragmentContainerView and refer to the fragment class we are going to create. No need to inflate.\n\nMy Fragment class.\n\n\n\nHere Fragment does not need xml file. Fragment will now be the root of all your compose content.  Here we are using CompositionLocalProvider to hold the fragment instance and later it can be used in multiple composables.\nYou can also use LocalCurrent.context and typecast to fragment. But that you might need to do everytime. Better way is to use CompositionLocalProvider.\n\nYou can add staticCompositionLocalOf outside of your fragment class in.\n\n\n\nSo you can access fragment instance in any composables which are in same activity and fragment layout tree.\n\nHere this is the composable function ui. Here I am getting the fragment instance and passing to MSAL.\n\n\nThe most important thing is your composable's direct parent should be fragment instead of activity. And its instance will be provided to all child composables via CompositionLocalProvider.  And this migration is wholly based on existing architecture and size of the project.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65618500,
                        "answer_post": "The issue with your code is that you are accessing getView() of your fragment before the fragment has gone through the initialization of the view. The reason why you don't have the crash when you execute the transaction in your activity's onCreate() method is that by the time you click on a button your fragment has already gone through onCreateView() and initialized its view. Check out fragment lifecycle guide and bear in mind that you should not access your fragment view before it was created or after it was destroyed. For more information about why your fragment view is not initialized instantly check out this guide.\nAs for the solution, consider setting arguments for your fragment before adding it to your transaction like here:\n\nThen in your onCreateView() or onViewCreated() methods of your fragment restore the arguments like here and set the image resource:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66494990,
                        "answer_post": "After some debugging in FragmentContainerView itself, I have hopefully found all the cases of the FragmentManager used whilst adding a fragment via the android:name attribute.\n\nFragments in the activity view hierarchy (from Activity.setContentView(Int)): Activity.getSupportFragmentManager()\n\nFragments in another fragments hierarchy (from Fragment.onCreateView(...)): Fragment.getChildFragmentManager\n\nFragments in a RecyclerView row, where the RecyclerView is either in a Fragment or an Activity: Activity.getSupportFragmentManager()\n\n\nNow the first two are well documented and not of interest here, but I found the third case to be surprising, especially as it doesn't seem to make a difference what the RecyclerView has been inflated into. If I had to take a guess of why this is, it would probably be in onCreateViewHolder.When you inflate your row you pass false into the inflate function's attachToRoot, so as the FragmentContainerView is not attached to a parent when it is initialised, it has to use the highest level fragment manager - from the activity. However this is just speculation.\nRegardless, in answer to your question - it is definitely the activities fragment manager.\n\nYou also said that you have tried using all the fragment managers anyway and they all couldn't find your fragment, but I wasn't able to replicate this problem. I managed to find my fragment in the RecyclerView just fine so I would expect there's something else going on that we can't find from the code you've shown, in theory it works.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 64096217,
                        "answer_post": "Fragment manager has a putFragment and getFragment method you can use to save and restore instance state of your Fragments.\nThis allowed me to save my Fragment Instance Variables so they didn't return null after process death.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64157718,
                        "answer_post": "The FragmentManager returned by Activity.getSupportFragmentManager() is different from the one returned by Fragment.getChildFragmentManager().\nIf you want to perform a fragment transaction from the Fragment level, but be able to \"see\" it at the Activity level, then you should use Fragment.getParentFragmentManager() (or Fragment.getFragmentManager() on older versions of the AndroidX library).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64043740,
                        "answer_post": "You should use FragmentActivity (from androidx) instead of Activity as the argument type in myMethod() and call getSupportFragmentManager() to get the FragmentManager on it. This should solve your problem.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65096917,
                        "answer_post": "Fragment transactions are asynchronous (unless you use executePendingTransactions()). Your transaction has likely not completed yet. You use runOnCommit on FragmentTransaction (in the support library) to execute code after it is done.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67770402,
                        "answer_post": "View pager can't detach cause memory leak. To avoid this, change the code to create the instance of TabsPagerAdapter according to the following code\n\nNote:\n\nrequestActivity().supportFragmentManager -> childFragmentManger : All its children should be managed by itself instead of activity.\n\nlifecycle -> viewLifecycleOwner.lifecycle : The fragment has 2 lifecycles, one for the view (viewLifecycleOwner.lifecycle), one for itself (lifecycle). In this case, the adapter is the view so we just need to use the lifecycle for the view (viewLifecycleOwner.lifecycle)\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66504608,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67975369,
                        "answer_post": "You can get fragments by Ids using Fragment manager's findFragmentByTag(\"f$id\")\nBut to do that you need to override getItemId() in the FragmentStateAdapter to return the position, so that the id now equals to the position.\n\nThen to get a fragment at a position:\n\nIf the ViewPager2 is hosted by an activity use supportFragmentManager:\n\n\n\nAnd if it's hosted by a fragment use childFragmentManager:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76191984,
                        "answer_post": "\nIf you use Fragment.viewLifecycleOwner.lifecycle.addObserver(\u2026), DefaultLifecycleObserver.onDestory(\u2026) will be called at the same time as Fragment.onDestoryView(\u2026).\nIf you use Fragment.lifecycle.addObserver(\u2026), DefaultLifecycleObserver.onDestory(\u2026) will be called at the same time as Fragment.onDestory(\u2026).\n\nHere is an example.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66580660,
                        "answer_post": "Fragments should have an empty constructor since they are managed by Android, same as activities. Anything you want to inject you have to inject inside the fragment, not through the constructor.\nFor view-models, it's trivial through the viewModels() API:\n\nDon't forget to annotate the fragment with @AndroidEntryPoint and the view-model with @HiltViewModel.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62948704,
                        "answer_post": "FragmentStateAdapter requires a FragmentManager and Lifecycle in its constructor. Change your DocAdapter to this:\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 71723371,
                        "answer_post": "\nhere how it works with fragment\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64315790,
                        "answer_post": "Fragment code\n\n\n\nShould be\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72966333,
                        "answer_post": "Write a function in your Activity\n\nIn your Fragment\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75736322,
                        "answer_post": "try to add\n\nto your fragment / activity\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66121178,
                        "answer_post": "SupportFragmentManager & FragmentManager are relatively old ways of navigating an user through different fragments. They were widely used before, but have some drawbacks like:\n\nHard backstack navigation\nProblems with adding or removing fragments, etc.\n\nThe Navigation component is part of Android Jetpack. It's a new approach and it aims to simplify and solve some of the problems related to the old one described above. Also, it is not restricted to work only with Fragments.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65414383,
                        "answer_post": "in your fragment should be\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64454162,
                        "answer_post": "DialogLayout:\n\nFragmentLayout\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65474789,
                        "answer_post": "In Context, if you are in Activity.\n\nif you are in Fragment\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65684761,
                        "answer_post": "In ViewModel\n\nAnd in the Activity or Fragment :\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67849127,
                        "answer_post": "in your fragment\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "Bu using Navigation Architecture components, The NavController is the responsible for fragment transaction and managing the back stack instead of the Support FragmentManager.\nSo, instead of making tranditional framgnet transactions with FragmentManager\nYou can move from ThridFragment to the first one by:\n\nWhere action_ThirdFragment_to_FirstFragment is the id of the action you defined in the navigation graph to move from ThridFragment to FirstFragment\nUPDATE:\nAs discussed from comments, besides replacing FragmentManager by NavController in all actions; there is another issue:\nMissing of action_FirstFragment_to_ThirdFragment action  from the navigation graph.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Your Search class is a Fragment, you cannot start it with the Intent.\nMake Search to be Activity or switch between fragments using FragmentManager.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes, a Viewpager can be setup in a Fragment.\nYou just need to get the right FragmentManager when constructing it i.e use getChildFragmentManager() in mViewPager.setAdapter(new TvShowEpisodeDetailsAdapter(getSupportFragmentManager()));\nFrom https://developer.android.com/guide/fragments/fragmentmanager\n\nAccess the FragmentManager\nAccessing in an activity\nEvery FragmentActivity and subclasses thereof, such as\nAppCompatActivity, have access to the FragmentManager through the\ngetSupportFragmentManager() method.\nAccessing in a Fragment\nFragments are also capable of hosting one or more child fragments.\nInside a fragment, you can get a reference to the FragmentManager that\nmanages the fragment's children through getChildFragmentManager().\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Based on the information provided, it seems that the issue you are experiencing may be related to the lifecycle of the Fragment and how it is being added to the Activity.\nWhen you shift from portrait to landscape mode, the Activity is recreated, and the FragmentManager adds the two Fragments to the Activity. When you shift back to portrait mode, the Activity is recreated again, and the FragmentManager attempts to add both Fragments to the Activity. However, since only one Fragment is meant to be shown in portrait mode, the FragmentManager adds the first Fragment and ignores the second one.\nTo properly handle the lifecycle of Fragments in your Activity, you should create two separate layout files - one for portrait mode and one for landscape mode - and add the appropriate Fragment to each layout. This way, when the Activity is recreated, the FragmentManager will only add the relevant Fragment to the Activity. Here is an example of how you can accomplish this:\nCreate two layout files: one for portrait mode (e.g. activity_main.xml) and one for landscape mode (e.g. activity_main_land.xml).\nactivity_main.xml:\n\nactivity_main_land.xml:\n\nIn your Activity's onCreate() method, inflate the appropriate layout based on the device's orientation, and add the Fragment(s) to the Activity:\nMainActivity.java:\n\nWith this approach, when you shift from portrait to landscape mode, the FragmentManager adds both Fragments to the Activity, and when you shift back to portrait mode, the FragmentManager only adds the relevant Fragment to the Activity. Additionally, since the Fragment is added directly to the layout, you can access its views using findViewById() instead of relying on the FragmentManager.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "SupportFragmentManager & FragmentManager are relatively old ways of navigating an user through different fragments. They were widely used before, but have some drawbacks like:\n\nHard backstack navigation\nProblems with adding or removing fragments, etc.\n\nThe Navigation component is part of Android Jetpack. It's a new approach and it aims to simplify and solve some of the problems related to the old one described above. Also, it is not restricted to work only with Fragments.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "In MainActivity the line:\n\nShould be:\n\n\nReturn the FragmentManager for interacting with fragments associated with this activity.\n\nAs you can read in the docs\n\nReturn the FragmentManager for interacting with fragments associated with this fragment's activity. Note that this will be non-null slightly before getActivity(), during the time from when the fragment is placed in a FragmentTransaction until it is committed and attached to its activity.\n\nAnd is returning null for the just created Fragment.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "FragmentStateAdapter requires a FragmentManager and Lifecycle in its constructor. Change your DocAdapter to this:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The displaying of Fragments is managed by FragmentManager. You must pass an instance of FragmentManager to CNNAdapter as follows:\n\nAnd then you display the fragment as follows:\n\nR.id.fragment_container is the view ID of the container in the layout xml of the activity that hosts the fragment. The container is usually a FrameLayout.\nAnd then you instantiate CNNAdapter in the Fragment like this:\n\n",
                        "contain_knowledge": 1
                    }
                ]
            },
            "alternative": {
                "finetuned_dpr": [
                    {
                        "id": 68254825,
                        "answer_post": "First of all, FragmentStatePagerAdapter is deprecated now. So, it's better to use FragmentStateAdapter with ViewPager2.\nI couldn't find any proper solution in case if you need to pass something into  Fragment's constructor with ViewPager2 because it ignores FragmentFactory. I was thinking about implementing the FragmentFactory in createFragment method of FragmentStateAdapter but don't know where to get the proper class loader in this case.\nThe only solution I found is to use FragmentManager.FragmentLifecycleCallbacks. Here you have a fragment so you can cast it to you particular implementation. You can set callbacks or whatever you want to your fragment after its (re)creation. So in this case you don't need to pass something in to fragment's constructor but also can avoid creating Bundles.\n\nI tested this code using childFragmentManager and it works fine. But I have to admit that this is not a clear solution. And if you can avoid passing something to Fragment's constructor while using FragmentStateAdapter, avoid it. Because the most proper solution is to use a FragmentFactory.\nAlso, as an option, your fragment knows about the parent Activity. So, you can do callbacks directly to the parent Activity.\nLink to documentation: https://developer.android.com/reference/androidx/fragment/app/FragmentManager#registerFragmentLifecycleCallbacks(androidx.fragment.app.FragmentManager.FragmentLifecycleCallbacks,%20boolean)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62830821,
                        "answer_post": "You could use fragment.\nFirst, use  in your activity layout as a container of Fragment, here we give it a id like, android:id=\"+id/fragment_container\"\nSecond, create a layout xml file for your fragment, here we give it a name, like fragment_page_3.xml\nThen create a subclass of Fragment, and override its onCreateView() method, where you inflate your fragment's layout. Code here\n\nFinally, in clickListener, you could use fragmentManager load your fragment, code like this:\n\nI just want to give you some ideas.\nYou cannot write code like this, this is wrong implementation for your app because you may need several fragment and you need a Callbacks interface implemented by your activity.\nIf you could change your content of UI, it's a better way.\nTo learn more, you could refer https://developer.android.com/guide/components/fragments\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66796997,
                        "answer_post": "It's unclear why you need to retain an instance in memory of a Fragment that is no longer visible; presumably it's expensive to recreate it so you want to save it.\nThis is a code-smell in most cases (but because I don't know your reasons and haven't seen your code, I will give you the benefit of doubt) :)\nAssuming you have a valid reason for this, Android offers Fragments a mechanism to be retained:\nDirectly from the Android's Fragment source:\n\nKeep in mind the implications of doing so, for now your lifecycle is different and so are all the side-effects of expecting a normal lifecycle (and the memory impact of keeping a fragment around).\nAlternatively, consider separating the Fragment's state from it into a ViewModel, Repository, or Beyond\u2122, and let the fragment simply be told what its state it so it can be properly recreated in a \"fast\" and \"efficient\" manner. (I quote these because fast/efficient are in the eye of the beholder and because it's also still subject to Android rules...).\nNow, I haven't also seen how you \"navigate\" and how you \"go back\", so you'll have to test this yourself. Ultimately, if the FragmentManager desires to destroy your Fragment, it's probably because it found no reason to keep it around (you could, keep a hard reference and deal with all that memory wasted... which is why I suggest you keep the \"state\" outside of the Fragment instead, because creating a fragment is not that expensive, if the fragment doesn't contain 2000 lines of code in onCreate...) :)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 68959128,
                        "answer_post": "In this case FragmentContainerView and FragmentManager ,Fragment transactions help us .\n\nFragmentContainerView is a customized Layout designed specifically for Fragments. It extends FrameLayout, so it can reliably handle Fragment Transactions, and it also has additional features to coordinate with fragment behavior.\nAt runtime, a FragmentManager can add, remove, replace, and perform other actions with fragments in response to user interaction.\n\nSo you can take a FragmentContainerView in your activity_main.xml where you can add different fragment by button/user action.\nSo your activity_main.xml looks like now -\n\nNow Create a new Blank Fragment to your project to test . IDE automatically override some methods and layout for your fragment also for this .\n\nSo your BlankFragment.class looks like -\n\nNow From your Activity you can show the Blank Fragment in FragmentContainerView , we define its id fragment_container_view in activity_main.xml .\nHere Your MainActivity.class -\n\nAll of these just for example . You should check documentation to know more .\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66594768,
                        "answer_post": "From what my understanding is regarding Activities and Fragments in Android, fragment is a sub-part of the activity in which it is called.\nYes you are right, fragments are sub parts added dynamically on run time\nSo what I want to know is that if we finish or kill the Activity in which the fragment exists, how will it effect the fragment?\nIf you kill/finish an Activity fragments will also be destroyed\nNOTE: Fragment lifecycle is dependent on Activity life cycle, if an Activity is dead so the fragments are.\nBuilding fragment on an Activity is like building 2,3 or 4 story building. If base is destroyed then other stories are not supposed to be stable. Just keep this rule in mind. This will help you with understanding. And further more you can apply logging on Activity and Fragment lifecycle.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62095513,
                        "answer_post": "Your activity must extend androidx.fragment.app.FragmentActivity.\nFrom the documentation,\n\nBase class for activities that want to use the support-based\n  Fragments.\n\nAlso from Fragment's documentation,\n\n\nYour activity must extend FragmentActivity\nYou must call FragmentActivity.getSupportFragmentManager() to get the    FragmentManager\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63141419,
                        "answer_post": "You should always, always use childFragmentManager when nesting fragments - the childFragmentManager is never executing transactions when its parent is going through lifecycle changes (which I assume is when you're calling your transaction).\nThis is actually silently causing issues for you when you use the <fragment> tag as those lifecycle events don't actually occur as a transaction, but directly as part of inflation. Using the wrong FragmentManager means that the fragment and its views will not properly save and restore their state.\nThe reason it fails with FragmentContainerView is that FragmentContainerView actually does the same FragmentTransaction as you'd do normally.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71231654,
                        "answer_post": "Do not touch the FragmentManager yourself when using the Navigation library.\nLet Navigation manage Navigation between fragments, that's what it's used for.\nThe message:\n\nI/FragmentNavigator: Ignoring navigate() call: FragmentManager has\nalready saved its state\n\nis defined in the androidx.navigation.fragment.FragmentNavigator#navigate\nThe Fragment state is saved by the Activity. It usually appears when the Activity goes into the onStop state. Means should not be operated the fragmentManger after leaving the current Activity. (but still can use androidx.fragment.app.FragmentTransaction#commitAllowingStateLoss to ignore the warning , but this state will not be restored when the Activity is recreated.)\nIn your scenes, I recommend jumping to the next activity for editing, returning and refreshing the list\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66494990,
                        "answer_post": "After some debugging in FragmentContainerView itself, I have hopefully found all the cases of the FragmentManager used whilst adding a fragment via the android:name attribute.\n\nFragments in the activity view hierarchy (from Activity.setContentView(Int)): Activity.getSupportFragmentManager()\n\nFragments in another fragments hierarchy (from Fragment.onCreateView(...)): Fragment.getChildFragmentManager\n\nFragments in a RecyclerView row, where the RecyclerView is either in a Fragment or an Activity: Activity.getSupportFragmentManager()\n\n\nNow the first two are well documented and not of interest here, but I found the third case to be surprising, especially as it doesn't seem to make a difference what the RecyclerView has been inflated into. If I had to take a guess of why this is, it would probably be in onCreateViewHolder.When you inflate your row you pass false into the inflate function's attachToRoot, so as the FragmentContainerView is not attached to a parent when it is initialised, it has to use the highest level fragment manager - from the activity. However this is just speculation.\nRegardless, in answer to your question - it is definitely the activities fragment manager.\n\nYou also said that you have tried using all the fragment managers anyway and they all couldn't find your fragment, but I wasn't able to replicate this problem. I managed to find my fragment in the RecyclerView just fine so I would expect there's something else going on that we can't find from the code you've shown, in theory it works.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65618500,
                        "answer_post": "The issue with your code is that you are accessing getView() of your fragment before the fragment has gone through the initialization of the view. The reason why you don't have the crash when you execute the transaction in your activity's onCreate() method is that by the time you click on a button your fragment has already gone through onCreateView() and initialized its view. Check out fragment lifecycle guide and bear in mind that you should not access your fragment view before it was created or after it was destroyed. For more information about why your fragment view is not initialized instantly check out this guide.\nAs for the solution, consider setting arguments for your fragment before adding it to your transaction like here:\n\nThen in your onCreateView() or onViewCreated() methods of your fragment restore the arguments like here and set the image resource:\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 64096217,
                        "answer_post": "Fragment manager has a putFragment and getFragment method you can use to save and restore instance state of your Fragments.\nThis allowed me to save my Fragment Instance Variables so they didn't return null after process death.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64157718,
                        "answer_post": "The FragmentManager returned by Activity.getSupportFragmentManager() is different from the one returned by Fragment.getChildFragmentManager().\nIf you want to perform a fragment transaction from the Fragment level, but be able to \"see\" it at the Activity level, then you should use Fragment.getParentFragmentManager() (or Fragment.getFragmentManager() on older versions of the AndroidX library).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 66504608,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64043740,
                        "answer_post": "You should use FragmentActivity (from androidx) instead of Activity as the argument type in myMethod() and call getSupportFragmentManager() to get the FragmentManager on it. This should solve your problem.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65096917,
                        "answer_post": "Fragment transactions are asynchronous (unless you use executePendingTransactions()). Your transaction has likely not completed yet. You use runOnCommit on FragmentTransaction (in the support library) to execute code after it is done.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67770402,
                        "answer_post": "View pager can't detach cause memory leak. To avoid this, change the code to create the instance of TabsPagerAdapter according to the following code\n\nNote:\n\nrequestActivity().supportFragmentManager -> childFragmentManger : All its children should be managed by itself instead of activity.\n\nlifecycle -> viewLifecycleOwner.lifecycle : The fragment has 2 lifecycles, one for the view (viewLifecycleOwner.lifecycle), one for itself (lifecycle). In this case, the adapter is the view so we just need to use the lifecycle for the view (viewLifecycleOwner.lifecycle)\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67975369,
                        "answer_post": "You can get fragments by Ids using Fragment manager's findFragmentByTag(\"f$id\")\nBut to do that you need to override getItemId() in the FragmentStateAdapter to return the position, so that the id now equals to the position.\n\nThen to get a fragment at a position:\n\nIf the ViewPager2 is hosted by an activity use supportFragmentManager:\n\n\n\nAnd if it's hosted by a fragment use childFragmentManager:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65833033,
                        "answer_post": "viewPagerAdapter.addFragment() is an anti-pattern because it will inevitably cause crashes after process death in production.\nThe correct way to implement a regular FragmentPagerAdapter is:\n\nTo get a reference to a Fragment created by a ViewPager, use the following findFragmentByTag scheme:\n\nIf you need a dynamic FragmentPagerAdapter (which you do, according to your clear() method), then you can do:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76191984,
                        "answer_post": "\nIf you use Fragment.viewLifecycleOwner.lifecycle.addObserver(\u2026), DefaultLifecycleObserver.onDestory(\u2026) will be called at the same time as Fragment.onDestoryView(\u2026).\nIf you use Fragment.lifecycle.addObserver(\u2026), DefaultLifecycleObserver.onDestory(\u2026) will be called at the same time as Fragment.onDestory(\u2026).\n\nHere is an example.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65120870,
                        "answer_post": "Since FragmentManager operations is async, you should send a callback from your fragment to the activity in the fragment OnViewCreated or maybe OnResume and only then send the data from the activity to the fragment.\nOr you can just use ViewModel and LiveData to provide your data to fragments\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 71723371,
                        "answer_post": "\nhere how it works with fragment\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 65124461,
                        "answer_post": "in Fragment\nUse\n\ninstead of\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63789470,
                        "answer_post": "For Fragment use activity instead of getActivity\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 66121178,
                        "answer_post": "SupportFragmentManager & FragmentManager are relatively old ways of navigating an user through different fragments. They were widely used before, but have some drawbacks like:\n\nHard backstack navigation\nProblems with adding or removing fragments, etc.\n\nThe Navigation component is part of Android Jetpack. It's a new approach and it aims to simplify and solve some of the problems related to the old one described above. Also, it is not restricted to work only with Fragments.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 72966333,
                        "answer_post": "Write a function in your Activity\n\nIn your Fragment\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64454162,
                        "answer_post": "DialogLayout:\n\nFragmentLayout\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75736322,
                        "answer_post": "try to add\n\nto your fragment / activity\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67337645,
                        "answer_post": "in the fragment\n\nin de activity\n\nand recive the array\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64315790,
                        "answer_post": "Fragment code\n\n\n\nShould be\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72328405,
                        "answer_post": "\nand\n\nthen Activity or Fragment with\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "Bu using Navigation Architecture components, The NavController is the responsible for fragment transaction and managing the back stack instead of the Support FragmentManager.\nSo, instead of making tranditional framgnet transactions with FragmentManager\nYou can move from ThridFragment to the first one by:\n\nWhere action_ThirdFragment_to_FirstFragment is the id of the action you defined in the navigation graph to move from ThridFragment to FirstFragment\nUPDATE:\nAs discussed from comments, besides replacing FragmentManager by NavController in all actions; there is another issue:\nMissing of action_FirstFragment_to_ThirdFragment action  from the navigation graph.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Your Search class is a Fragment, you cannot start it with the Intent.\nMake Search to be Activity or switch between fragments using FragmentManager.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes, a Viewpager can be setup in a Fragment.\nYou just need to get the right FragmentManager when constructing it i.e use getChildFragmentManager() in mViewPager.setAdapter(new TvShowEpisodeDetailsAdapter(getSupportFragmentManager()));\nFrom https://developer.android.com/guide/fragments/fragmentmanager\n\nAccess the FragmentManager\nAccessing in an activity\nEvery FragmentActivity and subclasses thereof, such as\nAppCompatActivity, have access to the FragmentManager through the\ngetSupportFragmentManager() method.\nAccessing in a Fragment\nFragments are also capable of hosting one or more child fragments.\nInside a fragment, you can get a reference to the FragmentManager that\nmanages the fragment's children through getChildFragmentManager().\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Based on the information provided, it seems that the issue you are experiencing may be related to the lifecycle of the Fragment and how it is being added to the Activity.\nWhen you shift from portrait to landscape mode, the Activity is recreated, and the FragmentManager adds the two Fragments to the Activity. When you shift back to portrait mode, the Activity is recreated again, and the FragmentManager attempts to add both Fragments to the Activity. However, since only one Fragment is meant to be shown in portrait mode, the FragmentManager adds the first Fragment and ignores the second one.\nTo properly handle the lifecycle of Fragments in your Activity, you should create two separate layout files - one for portrait mode and one for landscape mode - and add the appropriate Fragment to each layout. This way, when the Activity is recreated, the FragmentManager will only add the relevant Fragment to the Activity. Here is an example of how you can accomplish this:\nCreate two layout files: one for portrait mode (e.g. activity_main.xml) and one for landscape mode (e.g. activity_main_land.xml).\nactivity_main.xml:\n\nactivity_main_land.xml:\n\nIn your Activity's onCreate() method, inflate the appropriate layout based on the device's orientation, and add the Fragment(s) to the Activity:\nMainActivity.java:\n\nWith this approach, when you shift from portrait to landscape mode, the FragmentManager adds both Fragments to the Activity, and when you shift back to portrait mode, the FragmentManager only adds the relevant Fragment to the Activity. Additionally, since the Fragment is added directly to the layout, you can access its views using findViewById() instead of relying on the FragmentManager.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "SupportFragmentManager & FragmentManager are relatively old ways of navigating an user through different fragments. They were widely used before, but have some drawbacks like:\n\nHard backstack navigation\nProblems with adding or removing fragments, etc.\n\nThe Navigation component is part of Android Jetpack. It's a new approach and it aims to simplify and solve some of the problems related to the old one described above. Also, it is not restricted to work only with Fragments.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You cannot call final FragmentManager fragmentManager = getSupportFragmentManager(); during class initialization, because fragment manager in superclass has not been initialized yet. Remove all your class members and replace all mFragmentManager and fragmentManager with getSupportFragmentManager()\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "In MainActivity the line:\n\nShould be:\n\n\nReturn the FragmentManager for interacting with fragments associated with this activity.\n\nAs you can read in the docs\n\nReturn the FragmentManager for interacting with fragments associated with this fragment's activity. Note that this will be non-null slightly before getActivity(), during the time from when the fragment is placed in a FragmentTransaction until it is committed and attached to its activity.\n\nAnd is returning null for the just created Fragment.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "FragmentStateAdapter requires a FragmentManager and Lifecycle in its constructor. Change your DocAdapter to this:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The displaying of Fragments is managed by FragmentManager. You must pass an instance of FragmentManager to CNNAdapter as follows:\n\nAnd then you display the fragment as follows:\n\nR.id.fragment_container is the view ID of the container in the layout xml of the activity that hosts the fragment. The container is usually a FrameLayout.\nAnd then you instantiate CNNAdapter in the Fragment like this:\n\n",
                        "contain_knowledge": 1
                    }
                ]
            }
        }
    },
    {
        "name": "X509TrustManager",
        "language": "java",
        "popularity": "low",
        "label_result": {
            "functionality": {
                "finetuned_dpr": 0.3,
                "dpr": 0.0,
                "e5": 0.0,
                "bm25": 0.1
            },
            "concept": {
                "finetuned_dpr": 0.7,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.6
            },
            "performance": {
                "finetuned_dpr": 0.2,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.4
            },
            "directive": {
                "finetuned_dpr": 0.3,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.2
            },
            "pattern": {
                "finetuned_dpr": 0.5,
                "dpr": 0.2,
                "e5": 0.1,
                "bm25": 0.4
            },
            "environment": {
                "finetuned_dpr": 0.8,
                "dpr": 0.2,
                "e5": 0.1,
                "bm25": 0.6
            },
            "alternative": {
                "finetuned_dpr": 0.6,
                "dpr": 0.1,
                "e5": 0.0,
                "bm25": 0.2
            },
            "total": {
                "finetuned_dpr": 0.4857142857142857,
                "dpr": 0.11428571428571428,
                "e5": 0.028571428571428574,
                "bm25": 0.3571428571428572
            }
        },
        "retrieve_result": {
            "functionality": {
                "finetuned_dpr": [
                    {
                        "id": 77567231,
                        "answer_post": "There's a difference between the sample app and your code.\nThe sample app comes with a pre-configured list of trusted roots (EU LOTL).\nYour code comes with an empty CommonTrustedCertificateSource (i.e., no certificate is trusted)\nSee the DSS FAQ\n\nWhen validating a signature I receive INDETERMINATE/NO_CERTIFICATE_CHAIN_FOUND indication\n\n\nThe result means the validator was not able to reach a trust anchor when validating the certificate chain of the signature. More likely the issue is caused by the fact you have not configured a trusted certificate source within the used CertificateVerifier. To do it, you need to add trust anchors to the instance of CertificateVerifier you use within DocumentValidator:\n\nSo you need to add some certificates to the CommonTrustedCertificateSource. If you're only verifying signatures created by yourself, add your CA root/your signing certificate to the trusted source. If you're verifying third-party signatures, the solution is more complex. For example, you could extract all certificated from a PDF and add them to the trusted list before validation\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77269126,
                        "answer_post": "If the certificate is added to the truststore that the socket uses (creating an array of TrustManagers and passing that to an SSLContext), then the SSLSocket seems to treat it as valid. Testing this using a dummy certificate that expires 1 second after creation, this seems to be correct; the client connects without exceptions or issues and can send messages.\nTherefore, if the client in question explicitly trusts the certificate, the client should be able to connect.\nHowever, if another implementation is being used that rejects expired certificates, the client will most likely throw an exception.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77390571,
                        "answer_post": "\nunable to find valid certification path to requested target\n\nThe server's certificate is not trusted. You should get a CA to issue a certificate for the server. If it is already a valid cert, make sure to provide the \"certificate chain\" when configuring the server, not just the bare server certificate.\nIf you didn't intend to use a typical \"browser-trusted CA,\" you can sign the certificate with your own CA and use that CA's certificate as a trust source:\n\nThere are many sites and scripts that describe how to make your own CA and sign server certificates, if that is what you end up wanting. For reference, this is the process for gRPC's tests.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77291978,
                        "answer_post": "This is default behavior when your make use of self signed certificate in server machine.\n\"I want to avoid adding the .p12 certificate to the truststore.\" this is exact same reason why server certificates are added to the truststore as a client.\nThink about it ideally request to server should only and only come from legitimate clients (in your case spring app is client to redis server). adding certificate to truststore will make sure that only trusted clients are authorized to make the request.\nSo to answer your question adding certs to truststore is a common/well known practice done in web world.\nHope this helps. Thanks.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74553954,
                        "answer_post": "I think I solved the issue.\nI have a routine that programmatically downloads certificates from SSL protected servers through a socket that handshake and retrieve certificates.\nCurrently the certificate SSL server has some problems in returning the whole chain of certificates (including the intermediary certificates of the CAs that signed the certificate).\nIt is likely that they are problems related to a misconfiguration.\nThis problem can be verified with the command:\nopenssl s_client -showcerts -connect host:port\nThese are the intermediary CAs irrecoverable certs:\ncerts\ncerts\nThese are the intermediary certificates of the CAs:\nIntermediate cert CAs chain\nOn a programmatic level, when JAVA persists the trusted certificates in the Trust-Store, it writes information related to the fact that it was not possible to recover the whole CA chain.\nIt is as if the certificate is self-signed for the trust-store when it is not. In fact, the certificate is not actually trusted (unless you enter it \"manually\" in the trust store).\nWhen making an external call to an application-side https server, the client is not fully aware of the certificate.\nThe error was: \"PKIX path building failed\".\nIt was necessary to use a custom built HTTP client to accept single certificates of which it was not possible to download the whole CA chain.\nObviously it is not a client that can accept self-signed certificates.\nThis client is \"satisfied\" with the single certificate but it is actually a necessary and sufficient condition to perform a secure SSL handshake.\nIn other words to make an external call with RestTemplate what you have to do is change it from:\n\nto:\n\nI think I have given an explanation. What do you think about it?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75941010,
                        "answer_post": "First, I assume you are using Paketo buildpacks, and the documentation explains how you can provide a CA certificate to your JVM Truststore, either at\n\nbuildtime (if you use the same CA certificate for your image across your environments; that's the easiest solution since you just need to provide your CA cert during buildtime and the image is ready to be deployed) or at\nruntime (if your CA cert is going to be different across environments; that's a more complicated option since at deployment time, in kpack, you will need to provide and bind the CA certificate)\n\nIf you choose runtime, then you would need to create a service binding that would link to your CA certificate\nHope that helps!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76800264,
                        "answer_post": "The reason why a trust store exists is because you are trying to create a secure communication to a web server, and you need to trust the server certificate that they offer. So a trust store contains the trust anchors for that to happen: if a valid trust path can be build to a trust anchor in the trust store then the certificate is deemed valid and - after some additional checks of e.g. the server name - the private key can be used by the server to indicate that it is the server named within the server certificate.\nGreat, so what kind of security needs to be present on your trust store? Well, it is that the trust store is available and unaltered. Having the trust store unavailable will obviously be a big issue. So downloading the trust store every time you need to secure a connection is adding another high availability component to your infrastructure. Maybe you already need one for CRL or OCSP service, but still.\nThe other thing is that the trust store should not be altered in traffic. That basically means that the connection to your service should be free from attacks. The most logical way to do this is to have it protected by TLS. In that case of course you need a trusted certificate. In the end you cannot operate without trusting something. This is why you either have to trust a server based on the cacerts, or to distribute a certificate with the application.\n\"it shouldn't be a problem because it's not accessible by anyone else\". That's not a requirement. Other people may well access the server, as long as they cannot alter the security (and availability) of the connection or the trust store. Read access to the P12 file wouldn't directly influence the availability or trustworthiness of the trust store. That said, the stricter the security of the service that contains the trust store, the better.\nI was kind of afraid that the P12 would not just be a trust store but also a key store containing a private key. Preferably, a private key should not be distributed that way. I didn't see any hint of this happening in your question, so I'll just leave it here for other readers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74518957,
                        "answer_post": "Yes. Just adding the root certificate to your client trust store suffice to create the HTTPs successful connection. During the handshake, the certificate is validated from bottom-up way. It means that your Intermediate certificate must be signed by the root CA, and your leaf certificate must be signed by your intermediate CA. As long as your root CA is valid and present in your client's trust store, the connection will be successful.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75795924,
                        "answer_post": "In simple terms, a party (client or server) will trust another party (server or client) if the other party\u2019s certificate chain as provided on the wire can be traced back (recursively via signers) to the CACERTS stored in the original party\u2019s JRE. (or is in the original party\u2019s truststore)\nIt is fairly unusual to use mutually authenticated TLS so client side certificates are rare. In most cases authentication of a client is done with user credentials, api keys, etc. Anyway, it looks like you have the client cert setup correctly.\nIf the server certificate is signed by a Intermediate CA that has a cert held in the client\u2019s CACERTS then no client side intervention is necessary. On the server a keychain from a CACERTS cert down to the server cert needs to be configured via application.yaml, as you correctly show in your question.\nIf the Intermediate CA\u2019s signing cert is not registered in the official Java CACERTS in the client\u2019s JRE then it must be added like this. I find it easier to add untrusted Intermediate CA certs to CACERTS rather than adding the server cert to the client truststore (as you correctly show) because that allows multiple servers to be trusted (because, in a typical corporate environment, they will all have certs signed by the Intermediate CA)\nIf a client can\u2019t build a trusted cert chain to the cert provided by a server an SSL connection will fail with the dreaded \u201cPKIX path building failed\u201d error.\nI find it helpful to load a server GET path (eg /welcome) in a browser to get a look at what cert the server is passing back.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73214423,
                        "answer_post": "Either you can add the certificates require to validate the server identity in the default java truststore i.e cacerts or you can set the application environment to use different truststore as mentioned below.\n\napplication.properties\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 77625340,
                        "answer_post": "If you want to specifically use Java SSLContext, you can use a custom TrustManager that directly trusts the specified certificate.\n\nThen use the created TrustManager to create the SSLContext,\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73153710,
                        "answer_post": "LinkedBlockingQueue uses synchronization internally, in the form of ReentrantLock -- that's how it implements the 'blocking' part.\nSomething like this should work:\n\nHere threads compete at the busy flag. One of them wins the right to add to the list, others busy-wait until the winning thread clears the flag.\nThe two calls to AtomicBoolean methods establish proper 'happens-before' relationship between list.add() calls done on different threads, so each thread should observe actual state of the list.\nLinkedList can be used for unbounded queues. For bounded ones, maybe ArrayList with initial capacity set.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73058786,
                        "answer_post": "This works as designed. As the Javadoc suggests, clearAutomatically triggers persistence context clearance, i.e. calls EntityManager.clear(). The Javadoc of that clearly states:\n\nClear the persistence context, causing all managed entities to become detached. Changes made to entities that have not been flushed to the database will not be persisted.\n\nThat's why your modification of s does not get persisted. I guess an explicit call settingsRepository.save(s) should do the trick as it merges the now detached instance to the persistence context again.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76030715,
                        "answer_post": "You configured your resource-server with a JWT decoder and not introspection (opaquetoken in spring configuration) => the access token validation is local to your resource server, not submitted to authorization server.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72819015,
                        "answer_post": "If suddenly someone is faced with a similar problem, then here is the solution.\nYou must have 2 certificates: server and client.\nThen you put the server one in the cacerts repository in Java with the command:\n\nkeytool -importcert -storetype PKCS12 -keystore trustStore.p12\n-storepass password -alias mpzCA -file root.crt -noprompt\n\nThen, in the code, do as below:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72716284,
                        "answer_post": "By design, LDAP protocol automatically switches the authentication from \"simple\" to \"none\" if a password is not supplied (see documentation), resulting in an unauthenticated (but successful) binding, hence no error at this moment but only after when doing an operation that requires to be authenticated.\nSo I guess it's fine to make the code throw an AuthenticationException if the password string is empty, just as InitialDirContext does when a wrong password is supplied, so that you can catch both seamlessly.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73465151,
                        "answer_post": "Using a browser to access https://performance.infoworks.technology and checking the certificate confirms that the certificate is not trusted.\nIt is signed by an issuer which is not trusted: IW Root CA.\nYou need to make IW Root CA available on the client, put it into the certificate storage which is used in the context of running your java application to make sure is trusted at the time the request is made.\nAlternatively, for testing only (!), you can disable the certificate validation when making the request.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72280675,
                        "answer_post": "Try using Environment.getDataDirectory().\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75885986,
                        "answer_post": "Make sure you have the following property set in your application.properties\n\nThis ensures that your server port (8081) is registered with Nacos instead of the management port (8079).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74842221,
                        "answer_post": "At runtime, you can get or create a custom Configuration instance.\nFor Spark, hadoopConfiguration is part of the SparkContext\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77556752,
                        "answer_post": "\ntry this in pom file\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75301625,
                        "answer_post": "Try $JAVA_HOME/lib/security/cacerts\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76883763,
                        "answer_post": "For CORS Configuration\n\nFor Token\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73482220,
                        "answer_post": "use setGravity method\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77654306,
                        "answer_post": "try use in your POM file\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74738107,
                        "answer_post": "what is //fullname mock here?\nits working\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74213490,
                        "answer_post": "Add Following to monitor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77289237,
                        "answer_post": "you can use authenticationManagerResolver interface\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77410074,
                        "answer_post": "Thread.setUncaughtExceptionHandler\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "The easiest way is to let Java download the server certificate for you and then just grab and save it.\nThis can be done by using a custom X509TrustManager implementation as it it shown for example in this answer.\nThe part you need to modify is checkServerTrusted:\n\nIn the end you only have to call getEncoded() on the saved serverCert to get it's ASN.1 DER encoded representation as byte[] which you can save to a file like server.cer.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The easiest way is to let Java download the server certificate for you and then just grab and save it.\nThis can be done by using a custom X509TrustManager implementation as it it shown for example in this answer.\nThe part you need to modify is checkServerTrusted:\n\nIn the end you only have to call getEncoded() on the saved serverCert to get it's ASN.1 DER encoded representation as byte[] which you can save to a file like server.cer.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I think I solved the issue.\nI have a routine that programmatically downloads certificates from SSL protected servers through a socket that handshake and retrieve certificates.\nCurrently the certificate SSL server has some problems in returning the whole chain of certificates (including the intermediary certificates of the CAs that signed the certificate).\nIt is likely that they are problems related to a misconfiguration.\nThis problem can be verified with the command:\nopenssl s_client -showcerts -connect host:port\nThese are the intermediary CAs irrecoverable certs:\ncerts\ncerts\nThese are the intermediary certificates of the CAs:\nIntermediate cert CAs chain\nOn a programmatic level, when JAVA persists the trusted certificates in the Trust-Store, it writes information related to the fact that it was not possible to recover the whole CA chain.\nIt is as if the certificate is self-signed for the trust-store when it is not. In fact, the certificate is not actually trusted (unless you enter it \"manually\" in the trust store).\nWhen making an external call to an application-side https server, the client is not fully aware of the certificate.\nThe error was: \"PKIX path building failed\".\nIt was necessary to use a custom built HTTP client to accept single certificates of which it was not possible to download the whole CA chain.\nObviously it is not a client that can accept self-signed certificates.\nThis client is \"satisfied\" with the single certificate but it is actually a necessary and sufficient condition to perform a secure SSL handshake.\nIn other words to make an external call with RestTemplate what you have to do is change it from:\n\nto:\n\nI think I have given an explanation. What do you think about it?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nHow do keystores really work? From my understanding, you generate a keystore with the keytool command and that generates a keystore file that is like a small database(?) that contains a self-signed certificate and a public/private key pair.\n\nWell preferably a certificate chain with a leaf and one or more CA certificates; self signed certificates are usually just a way to \"get it working\" without a lot of key management. And the certificate contains the public key, so you only need to store the chain + the private key of the server certificate.\n\nWe then create a truststore that's like a keystore but where we only import the self-signed certificate and the public key and this is what the client uses to connect to the server (I don't really understand this very last part).\n\nNo, again, the public key doesn't need to store separately, it is already included. And you don't need to have the truststore to connect, you need it to verify the trust path to a trust anchor. Usually that is a known root certificate, but for self-signed certificates it is just the one certificate.\n\nHow do we actually use these keys that we generated inside our code? What is the recommended/secure way to do it? I have a feeling that setting system properties and typing a password in plain text in the class isn't the right way to do it but this might be the way to do it.\n\nUsually you try and store the private key in the least accessible way possible while you are still able to use it economically. Banks store private keys in HSM's, hardware security modules. Generally, if you just have a computer, you try to store it in the most secure place possible, e.g. in a system provided key store.\nUsing a key store based on password based encryption (PKCS#12 or PFX keystores and the Java JKS key stores) are indeed not the most secure options. Better choose a very secure password to at least not leak the private key if the store gets stolen.\nNote that Java does contain a PKCS#11 provider that works with HSM's as well as providers to use the Windows certificates / keys.\n\nIf I were to develop an app that uses TLS how would I go about storing the keys in the Client? Would it be possible to pack the key inside the jar file that I'd release for the users to download?\n\nYes, it certainly can be a resource that is packed with the program, but you might need to update your program if you want it to remain current. Actually, that is exactly how most browsers get the trust store; the certificates are delivered with the updates of Firefox and Chrome.\nFor others they are part of OS updates such as with Edge, and you may also have a network specific method of distributing trusted certificates such as the Group Policy in the Windows ecosystem.\n\nLike I said, I followed the tutorial from the docs and combining that with some knowledge I got from other stackoverflow posts I managed to make it work but I'd like to understand how everything really works.\n\nWell, PKIX and TLS operation is a lot of information to take in and understand for sure. One way of making sure that you get the right information is to simply read the X.509 standard. There are many tutorials on the Internet as well.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "There are two issues here:\n\nFirst, when connecting locally, you can't connect directly - you need to connect through an SSH tunnel instead. See Connecting to an Amazon DocumentDB Cluster from Outside an Amazon VPC for details on how to do this.\nSecond, the .pem certificate file isn't directly usable as a Java trust store. Instead, it contains the certificates which should be imported into a Java trust store (using the keytool Java utility), so that your program can then reference that trust store (via the javax.net.ssl.trustStore system property) in verifying the identity of the DocumentDB server.\n\nContext: The sun.security.* packages (referenced in the Fargate logs you posted) verify the DocumentDB server's identity by attempting to build a valid PKIX certification path from the root CA certificates found in the Java trust store to the certificate presented by the particular DocumentDB server you are targeting. If the Java trust store found at javax.net.ssl.trustStore is either invalid (e.g., because it's a .pem file instead of a valid .jks file), or if it doesn't contain the necessary certificates (e.g., because the root CA certificates found in global-bundle.pem were never imported using the Java keytool utility), PKIX path building fails, meaning the identity of the DocumentDB server cannot be established. See Connecting with TLS Enabled for more details (and be sure to select the \"Java\" tab to see Java-specific instructions.)\n\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The fact you're mentioning /etc/pki/ca-trust/extracted/java/cacerts suggests you're using a cacerts file managed by your Linux distribution (presumably based on RedHat/CentOS).\nRemoving the specific certificate from that cacerts file is indeed possible with keytool manually. However, it's likely to be re-generated, and possibly placed back into that file the next time update-ca-trust is executed automatically (e.g. package upgrade) or not.\nWhen using the distribution-managed cacerts file, it's generally better to use the distribution's mechanism.\nOn RedHat/CentOS-based distributions, this can be done by managing individual certificates in /etc/pki/ca-trust/source/anchors/ and using update-ca-trust.\nOn Debian/Ubuntu-based distributions, there is an equivalent with certificates in /usr/share/ca-certificates, assuming the ca-certificates-java package is installed (and then, you can run update-ca-certificates).\n\nAs a side-note, you've tagged your question with client-certificate.\nClient-certificates (and more so their matching private key, i.e. PrivateKeyEntry entries) normally don't belong in the cacerts file at all, which is a \"keystore\" used as a \"truststore\" (typically used as the default truststore for all Java applications running on that system). Those belong to a \"keystore used as a keystore\", not a \"keystore used as a truststore\" (which shouldn't contain private keys).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First, you have to extract the CA certificate from the .pfx file using openssl:\nopenssl pkcs12 -in filename.pfx -passin pass:<password> -info -nokeys > filename.pem.\nDouble check that extraction worked:\nopenssl x509 -in test.pem -noout -text\nThen either create new JKS using the key tool:\nkeytool -import -trustcacerts -keystore test.jks -storepass choose-password -file test.pem -alias CANAME\nOr you can import the certificate into the existing trust store:\nkeytool -import -keystore cacerts -storepass changeit -file test.pem -alias CANAME -storetype JKS\nUsually you would use openssl to interact with most certificate file formats and keytool with java key stores only (JKS)\n==============.\nUpdate\nPKCS12 is an archive file format for storing private keys and X.509 certificates with filename extensions .p12 or .pfx\nTo be able to work with .pfx files you would use openssl pkcs12 command.  I am guessing x509 command returns first certificate it finds.\nPKCS12 wiki\nkeytool Manages a keystore (database) of cryptographic keys, X.509 certificate chains, and trusted certificates.\nI think it only works with java keystores .jks or .bcfks (Bouncy Castle FIPS keyStore) etc..\nI think you might actually be able to import certificates directly from .pfx file to a java keystore using keytool.\nkeytool -importkeystore -srckeystore mypfxfile.pfx -srcstoretype pkcs12 -destkeystore clientcert.jks -deststoretype JKS\nThat could also import the private key if it's in the .pfx file but I am not sure.\nHope that helps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The reason why a trust store exists is because you are trying to create a secure communication to a web server, and you need to trust the server certificate that they offer. So a trust store contains the trust anchors for that to happen: if a valid trust path can be build to a trust anchor in the trust store then the certificate is deemed valid and - after some additional checks of e.g. the server name - the private key can be used by the server to indicate that it is the server named within the server certificate.\nGreat, so what kind of security needs to be present on your trust store? Well, it is that the trust store is available and unaltered. Having the trust store unavailable will obviously be a big issue. So downloading the trust store every time you need to secure a connection is adding another high availability component to your infrastructure. Maybe you already need one for CRL or OCSP service, but still.\nThe other thing is that the trust store should not be altered in traffic. That basically means that the connection to your service should be free from attacks. The most logical way to do this is to have it protected by TLS. In that case of course you need a trusted certificate. In the end you cannot operate without trusting something. This is why you either have to trust a server based on the cacerts, or to distribute a certificate with the application.\n\"it shouldn't be a problem because it's not accessible by anyone else\". That's not a requirement. Other people may well access the server, as long as they cannot alter the security (and availability) of the connection or the trust store. Read access to the P12 file wouldn't directly influence the availability or trustworthiness of the trust store. That said, the stricter the security of the service that contains the trust store, the better.\nI was kind of afraid that the P12 would not just be a trust store but also a key store containing a private key. Preferably, a private key should not be distributed that way. I didn't see any hint of this happening in your question, so I'll just leave it here for other readers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "I think this could be caused by that you're configuring only a keystore, but not a truststore.\nKey stores are typically used for keeping the keys or certs to provide to a third party. But for validating the provided certificates trust stores are used.\nTry to do something like:\n\nYour trust store has to contain the certificate that is returned by your service or the certificate chain that was used to sign service certificate.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You have actually created a certificate signing request with the above command.\nTo generate just a public-private key pair, you can use:\n\nHowever, a trust store contains certificates, not public keys.\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "concept": {
                "finetuned_dpr": [
                    {
                        "id": 77567231,
                        "answer_post": "There's a difference between the sample app and your code.\nThe sample app comes with a pre-configured list of trusted roots (EU LOTL).\nYour code comes with an empty CommonTrustedCertificateSource (i.e., no certificate is trusted)\nSee the DSS FAQ\n\nWhen validating a signature I receive INDETERMINATE/NO_CERTIFICATE_CHAIN_FOUND indication\n\n\nThe result means the validator was not able to reach a trust anchor when validating the certificate chain of the signature. More likely the issue is caused by the fact you have not configured a trusted certificate source within the used CertificateVerifier. To do it, you need to add trust anchors to the instance of CertificateVerifier you use within DocumentValidator:\n\nSo you need to add some certificates to the CommonTrustedCertificateSource. If you're only verifying signatures created by yourself, add your CA root/your signing certificate to the trusted source. If you're verifying third-party signatures, the solution is more complex. For example, you could extract all certificated from a PDF and add them to the trusted list before validation\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77269126,
                        "answer_post": "If the certificate is added to the truststore that the socket uses (creating an array of TrustManagers and passing that to an SSLContext), then the SSLSocket seems to treat it as valid. Testing this using a dummy certificate that expires 1 second after creation, this seems to be correct; the client connects without exceptions or issues and can send messages.\nTherefore, if the client in question explicitly trusts the certificate, the client should be able to connect.\nHowever, if another implementation is being used that rejects expired certificates, the client will most likely throw an exception.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77390571,
                        "answer_post": "\nunable to find valid certification path to requested target\n\nThe server's certificate is not trusted. You should get a CA to issue a certificate for the server. If it is already a valid cert, make sure to provide the \"certificate chain\" when configuring the server, not just the bare server certificate.\nIf you didn't intend to use a typical \"browser-trusted CA,\" you can sign the certificate with your own CA and use that CA's certificate as a trust source:\n\nThere are many sites and scripts that describe how to make your own CA and sign server certificates, if that is what you end up wanting. For reference, this is the process for gRPC's tests.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76800264,
                        "answer_post": "The reason why a trust store exists is because you are trying to create a secure communication to a web server, and you need to trust the server certificate that they offer. So a trust store contains the trust anchors for that to happen: if a valid trust path can be build to a trust anchor in the trust store then the certificate is deemed valid and - after some additional checks of e.g. the server name - the private key can be used by the server to indicate that it is the server named within the server certificate.\nGreat, so what kind of security needs to be present on your trust store? Well, it is that the trust store is available and unaltered. Having the trust store unavailable will obviously be a big issue. So downloading the trust store every time you need to secure a connection is adding another high availability component to your infrastructure. Maybe you already need one for CRL or OCSP service, but still.\nThe other thing is that the trust store should not be altered in traffic. That basically means that the connection to your service should be free from attacks. The most logical way to do this is to have it protected by TLS. In that case of course you need a trusted certificate. In the end you cannot operate without trusting something. This is why you either have to trust a server based on the cacerts, or to distribute a certificate with the application.\n\"it shouldn't be a problem because it's not accessible by anyone else\". That's not a requirement. Other people may well access the server, as long as they cannot alter the security (and availability) of the connection or the trust store. Read access to the P12 file wouldn't directly influence the availability or trustworthiness of the trust store. That said, the stricter the security of the service that contains the trust store, the better.\nI was kind of afraid that the P12 would not just be a trust store but also a key store containing a private key. Preferably, a private key should not be distributed that way. I didn't see any hint of this happening in your question, so I'll just leave it here for other readers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74553954,
                        "answer_post": "I think I solved the issue.\nI have a routine that programmatically downloads certificates from SSL protected servers through a socket that handshake and retrieve certificates.\nCurrently the certificate SSL server has some problems in returning the whole chain of certificates (including the intermediary certificates of the CAs that signed the certificate).\nIt is likely that they are problems related to a misconfiguration.\nThis problem can be verified with the command:\nopenssl s_client -showcerts -connect host:port\nThese are the intermediary CAs irrecoverable certs:\ncerts\ncerts\nThese are the intermediary certificates of the CAs:\nIntermediate cert CAs chain\nOn a programmatic level, when JAVA persists the trusted certificates in the Trust-Store, it writes information related to the fact that it was not possible to recover the whole CA chain.\nIt is as if the certificate is self-signed for the trust-store when it is not. In fact, the certificate is not actually trusted (unless you enter it \"manually\" in the trust store).\nWhen making an external call to an application-side https server, the client is not fully aware of the certificate.\nThe error was: \"PKIX path building failed\".\nIt was necessary to use a custom built HTTP client to accept single certificates of which it was not possible to download the whole CA chain.\nObviously it is not a client that can accept self-signed certificates.\nThis client is \"satisfied\" with the single certificate but it is actually a necessary and sufficient condition to perform a secure SSL handshake.\nIn other words to make an external call with RestTemplate what you have to do is change it from:\n\nto:\n\nI think I have given an explanation. What do you think about it?\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77291978,
                        "answer_post": "This is default behavior when your make use of self signed certificate in server machine.\n\"I want to avoid adding the .p12 certificate to the truststore.\" this is exact same reason why server certificates are added to the truststore as a client.\nThink about it ideally request to server should only and only come from legitimate clients (in your case spring app is client to redis server). adding certificate to truststore will make sure that only trusted clients are authorized to make the request.\nSo to answer your question adding certs to truststore is a common/well known practice done in web world.\nHope this helps. Thanks.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77625340,
                        "answer_post": "If you want to specifically use Java SSLContext, you can use a custom TrustManager that directly trusts the specified certificate.\n\nThen use the created TrustManager to create the SSLContext,\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75795924,
                        "answer_post": "In simple terms, a party (client or server) will trust another party (server or client) if the other party\u2019s certificate chain as provided on the wire can be traced back (recursively via signers) to the CACERTS stored in the original party\u2019s JRE. (or is in the original party\u2019s truststore)\nIt is fairly unusual to use mutually authenticated TLS so client side certificates are rare. In most cases authentication of a client is done with user credentials, api keys, etc. Anyway, it looks like you have the client cert setup correctly.\nIf the server certificate is signed by a Intermediate CA that has a cert held in the client\u2019s CACERTS then no client side intervention is necessary. On the server a keychain from a CACERTS cert down to the server cert needs to be configured via application.yaml, as you correctly show in your question.\nIf the Intermediate CA\u2019s signing cert is not registered in the official Java CACERTS in the client\u2019s JRE then it must be added like this. I find it easier to add untrusted Intermediate CA certs to CACERTS rather than adding the server cert to the client truststore (as you correctly show) because that allows multiple servers to be trusted (because, in a typical corporate environment, they will all have certs signed by the Intermediate CA)\nIf a client can\u2019t build a trusted cert chain to the cert provided by a server an SSL connection will fail with the dreaded \u201cPKIX path building failed\u201d error.\nI find it helpful to load a server GET path (eg /welcome) in a browser to get a look at what cert the server is passing back.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73214423,
                        "answer_post": "Either you can add the certificates require to validate the server identity in the default java truststore i.e cacerts or you can set the application environment to use different truststore as mentioned below.\n\napplication.properties\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77586871,
                        "answer_post": "To configure a custom trust store for your Spring Boot project without modifying the JDK's cacerts file, you can use the following approach. This involves specifying the trust store location and password through application properties.\nPlace the Trust Store in Your Project:\nPlace your custom trust store file (e.g., custom-truststore.jks) in a location within your project. Let's assume it's in the src/main/resources directory.\nUpdate Your application.properties or application.yml file:\nAdd the following properties to your application.properties or application.yml file:\n\nMake sure to replace your-trust-store-password with the actual password for your trust store.\nConfigure SSL for Your Spring Boot Application:\nEnsure that you have the necessary SSL configuration in your application.properties or application.yml for both of your Spring Boot applications. For example:\n\nAdjust these settings based on your specific SSL requirements.\nRepeat for the Other Spring Boot Application:\nRepeat the same configuration for the second Spring Boot application, making sure to use the same trust store and password if they need to trust each other.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 73153710,
                        "answer_post": "LinkedBlockingQueue uses synchronization internally, in the form of ReentrantLock -- that's how it implements the 'blocking' part.\nSomething like this should work:\n\nHere threads compete at the busy flag. One of them wins the right to add to the list, others busy-wait until the winning thread clears the flag.\nThe two calls to AtomicBoolean methods establish proper 'happens-before' relationship between list.add() calls done on different threads, so each thread should observe actual state of the list.\nLinkedList can be used for unbounded queues. For bounded ones, maybe ArrayList with initial capacity set.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77625340,
                        "answer_post": "If you want to specifically use Java SSLContext, you can use a custom TrustManager that directly trusts the specified certificate.\n\nThen use the created TrustManager to create the SSLContext,\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73058786,
                        "answer_post": "This works as designed. As the Javadoc suggests, clearAutomatically triggers persistence context clearance, i.e. calls EntityManager.clear(). The Javadoc of that clearly states:\n\nClear the persistence context, causing all managed entities to become detached. Changes made to entities that have not been flushed to the database will not be persisted.\n\nThat's why your modification of s does not get persisted. I guess an explicit call settingsRepository.save(s) should do the trick as it merges the now detached instance to the persistence context again.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72716284,
                        "answer_post": "By design, LDAP protocol automatically switches the authentication from \"simple\" to \"none\" if a password is not supplied (see documentation), resulting in an unauthenticated (but successful) binding, hence no error at this moment but only after when doing an operation that requires to be authenticated.\nSo I guess it's fine to make the code throw an AuthenticationException if the password string is empty, just as InitialDirContext does when a wrong password is supplied, so that you can catch both seamlessly.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76030715,
                        "answer_post": "You configured your resource-server with a JWT decoder and not introspection (opaquetoken in spring configuration) => the access token validation is local to your resource server, not submitted to authorization server.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72819015,
                        "answer_post": "If suddenly someone is faced with a similar problem, then here is the solution.\nYou must have 2 certificates: server and client.\nThen you put the server one in the cacerts repository in Java with the command:\n\nkeytool -importcert -storetype PKCS12 -keystore trustStore.p12\n-storepass password -alias mpzCA -file root.crt -noprompt\n\nThen, in the code, do as below:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76865006,
                        "answer_post": "As pointed out in a comment, the problem here has nothing to do with VaadinSession.\nInstead, the problem is that one part of the code uses \"IdCliente\" as the session attribute name and another part of the code uses \"idCliente\". It's recommended to use a constant for magic string values like this to avoid these types of mistakes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77728159,
                        "answer_post": "Based on the comments, only a single user can access your application at once. In that case, it is both correct and reasonable to simply store the currently active session's ID in a global variable when the users logs in and wipe it on logout.\nIf the application was concurrently accessible, I'd make a couple of changes first:\n\nInitialize the singleton inline:\n\n\nSince the initializations happens when the class is loaded, and the JVM guarantees that happening once per class loader, you no longer have to worry about synchronization or volatility. And the class will be loaded on first access anyway, so this is already as lazy as it needs to be. For edge cases, you can employ the holder idiom.\n\nMake the active sessions map thread-safe:\n\n\nThis way, many threads (handling many user requests) can safely read and update the map concurrently.\nWith all that said, your original question remains: how to know what is the current session?\nNormally, it's the client's responsibility to identify itself. E.g. when the user logs in via a (web/mobile/desktop) client application, you return the newly generated session ID to the client (perhaps in a cookie, or a custom header, or just in the response payload itself). The client (and not your server application) then stores this somewhere (a browser might store it in the local storage, or in a cookie, a mobile client might store it in the phone's Shared Preferences, a desktop client might keep it a file somewhere) and then sends it back with each subsequent request to the application. Your application can then use the ID the client sends and associate the correct session with each request. If each request is served by a separate dedicated thread (as in the traditional Servlet model), the application might also store the current session in a ThreadLocal variable to make it implicitly accessible from anywhere (without passing it around as an argument to each method), and clean it up at the end of the request. This is commonly handled by the framework and not the application itself.\nIf you wanted to simulate a concurrently accessible application, you could print out or otherwise display the new session ID when a user logs in, and require that same ID to be passed to all entry points in the application. It will be cumbersome, but this is basically what a server application really does.\nDoes this help?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76900976,
                        "answer_post": "If you're using Active Directory, you can match against the userAccountControl attribute to query users with disabled accounts. LdapWiki example:\n\nThe same is mentioned in these AD examples with a note that provides some context.\n\n\nThe string 1.2.840.113556.1.4.803 specifies LDAP_MATCHING_RULE_BIT_AND. This specifies a bitwise AND of a flag attribute (an integer), like userAccountControl, groupType, or systemFlags, and a bit mask (like 2, 32, or 65536). The clause is True if the bitwise AND of the attribute value and the bit mask is non-zero, indicating the bit is set.\n\nThe value 2 is significant in this context because it is a magic bit defined in Active Directory Technical Specification 2.2.16 - userAccountControl Bits:\n\nD (ADS_UF_ACCOUNT_DISABLE, 0x00000002): Specifies that the account is not enabled for authentication.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75885986,
                        "answer_post": "Make sure you have the following property set in your application.properties\n\nThis ensures that your server port (8081) is registered with Nacos instead of the management port (8079).\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77556752,
                        "answer_post": "\ntry this in pom file\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75301625,
                        "answer_post": "Try $JAVA_HOME/lib/security/cacerts\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76883763,
                        "answer_post": "For CORS Configuration\n\nFor Token\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74213490,
                        "answer_post": "Add Following to monitor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77075486,
                        "answer_post": "pom.xml\n\napplication.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77410074,
                        "answer_post": "Thread.setUncaughtExceptionHandler\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73145198,
                        "answer_post": "Since version 6.3.3 the Microsoft JDBC Driver for SQL allows, to specify a custom implementation of javax.net.ssl.TrustManager through connection properties. You can specify a class name and a constructor parameter (e.g. a file name or the certificate in PEM format).\nSee here, for more detailed instructions and a simple example of a custom TrustManager. The functionality of the sslrootcert option of the Postgres driver is implemented in a similar way here.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73489047,
                        "answer_post": "java version:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76095804,
                        "answer_post": "See this please\nfor Java\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "The easiest way is to let Java download the server certificate for you and then just grab and save it.\nThis can be done by using a custom X509TrustManager implementation as it it shown for example in this answer.\nThe part you need to modify is checkServerTrusted:\n\nIn the end you only have to call getEncoded() on the saved serverCert to get it's ASN.1 DER encoded representation as byte[] which you can save to a file like server.cer.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The easiest way is to let Java download the server certificate for you and then just grab and save it.\nThis can be done by using a custom X509TrustManager implementation as it it shown for example in this answer.\nThe part you need to modify is checkServerTrusted:\n\nIn the end you only have to call getEncoded() on the saved serverCert to get it's ASN.1 DER encoded representation as byte[] which you can save to a file like server.cer.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I think I solved the issue.\nI have a routine that programmatically downloads certificates from SSL protected servers through a socket that handshake and retrieve certificates.\nCurrently the certificate SSL server has some problems in returning the whole chain of certificates (including the intermediary certificates of the CAs that signed the certificate).\nIt is likely that they are problems related to a misconfiguration.\nThis problem can be verified with the command:\nopenssl s_client -showcerts -connect host:port\nThese are the intermediary CAs irrecoverable certs:\ncerts\ncerts\nThese are the intermediary certificates of the CAs:\nIntermediate cert CAs chain\nOn a programmatic level, when JAVA persists the trusted certificates in the Trust-Store, it writes information related to the fact that it was not possible to recover the whole CA chain.\nIt is as if the certificate is self-signed for the trust-store when it is not. In fact, the certificate is not actually trusted (unless you enter it \"manually\" in the trust store).\nWhen making an external call to an application-side https server, the client is not fully aware of the certificate.\nThe error was: \"PKIX path building failed\".\nIt was necessary to use a custom built HTTP client to accept single certificates of which it was not possible to download the whole CA chain.\nObviously it is not a client that can accept self-signed certificates.\nThis client is \"satisfied\" with the single certificate but it is actually a necessary and sufficient condition to perform a secure SSL handshake.\nIn other words to make an external call with RestTemplate what you have to do is change it from:\n\nto:\n\nI think I have given an explanation. What do you think about it?\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "There are two issues here:\n\nFirst, when connecting locally, you can't connect directly - you need to connect through an SSH tunnel instead. See Connecting to an Amazon DocumentDB Cluster from Outside an Amazon VPC for details on how to do this.\nSecond, the .pem certificate file isn't directly usable as a Java trust store. Instead, it contains the certificates which should be imported into a Java trust store (using the keytool Java utility), so that your program can then reference that trust store (via the javax.net.ssl.trustStore system property) in verifying the identity of the DocumentDB server.\n\nContext: The sun.security.* packages (referenced in the Fargate logs you posted) verify the DocumentDB server's identity by attempting to build a valid PKIX certification path from the root CA certificates found in the Java trust store to the certificate presented by the particular DocumentDB server you are targeting. If the Java trust store found at javax.net.ssl.trustStore is either invalid (e.g., because it's a .pem file instead of a valid .jks file), or if it doesn't contain the necessary certificates (e.g., because the root CA certificates found in global-bundle.pem were never imported using the Java keytool utility), PKIX path building fails, meaning the identity of the DocumentDB server cannot be established. See Connecting with TLS Enabled for more details (and be sure to select the \"Java\" tab to see Java-specific instructions.)\n\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nHow do keystores really work? From my understanding, you generate a keystore with the keytool command and that generates a keystore file that is like a small database(?) that contains a self-signed certificate and a public/private key pair.\n\nWell preferably a certificate chain with a leaf and one or more CA certificates; self signed certificates are usually just a way to \"get it working\" without a lot of key management. And the certificate contains the public key, so you only need to store the chain + the private key of the server certificate.\n\nWe then create a truststore that's like a keystore but where we only import the self-signed certificate and the public key and this is what the client uses to connect to the server (I don't really understand this very last part).\n\nNo, again, the public key doesn't need to store separately, it is already included. And you don't need to have the truststore to connect, you need it to verify the trust path to a trust anchor. Usually that is a known root certificate, but for self-signed certificates it is just the one certificate.\n\nHow do we actually use these keys that we generated inside our code? What is the recommended/secure way to do it? I have a feeling that setting system properties and typing a password in plain text in the class isn't the right way to do it but this might be the way to do it.\n\nUsually you try and store the private key in the least accessible way possible while you are still able to use it economically. Banks store private keys in HSM's, hardware security modules. Generally, if you just have a computer, you try to store it in the most secure place possible, e.g. in a system provided key store.\nUsing a key store based on password based encryption (PKCS#12 or PFX keystores and the Java JKS key stores) are indeed not the most secure options. Better choose a very secure password to at least not leak the private key if the store gets stolen.\nNote that Java does contain a PKCS#11 provider that works with HSM's as well as providers to use the Windows certificates / keys.\n\nIf I were to develop an app that uses TLS how would I go about storing the keys in the Client? Would it be possible to pack the key inside the jar file that I'd release for the users to download?\n\nYes, it certainly can be a resource that is packed with the program, but you might need to update your program if you want it to remain current. Actually, that is exactly how most browsers get the trust store; the certificates are delivered with the updates of Firefox and Chrome.\nFor others they are part of OS updates such as with Edge, and you may also have a network specific method of distributing trusted certificates such as the Group Policy in the Windows ecosystem.\n\nLike I said, I followed the tutorial from the docs and combining that with some knowledge I got from other stackoverflow posts I managed to make it work but I'd like to understand how everything really works.\n\nWell, PKIX and TLS operation is a lot of information to take in and understand for sure. One way of making sure that you get the right information is to simply read the X.509 standard. There are many tutorials on the Internet as well.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The fact you're mentioning /etc/pki/ca-trust/extracted/java/cacerts suggests you're using a cacerts file managed by your Linux distribution (presumably based on RedHat/CentOS).\nRemoving the specific certificate from that cacerts file is indeed possible with keytool manually. However, it's likely to be re-generated, and possibly placed back into that file the next time update-ca-trust is executed automatically (e.g. package upgrade) or not.\nWhen using the distribution-managed cacerts file, it's generally better to use the distribution's mechanism.\nOn RedHat/CentOS-based distributions, this can be done by managing individual certificates in /etc/pki/ca-trust/source/anchors/ and using update-ca-trust.\nOn Debian/Ubuntu-based distributions, there is an equivalent with certificates in /usr/share/ca-certificates, assuming the ca-certificates-java package is installed (and then, you can run update-ca-certificates).\n\nAs a side-note, you've tagged your question with client-certificate.\nClient-certificates (and more so their matching private key, i.e. PrivateKeyEntry entries) normally don't belong in the cacerts file at all, which is a \"keystore\" used as a \"truststore\" (typically used as the default truststore for all Java applications running on that system). Those belong to a \"keystore used as a keystore\", not a \"keystore used as a truststore\" (which shouldn't contain private keys).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The reason why a trust store exists is because you are trying to create a secure communication to a web server, and you need to trust the server certificate that they offer. So a trust store contains the trust anchors for that to happen: if a valid trust path can be build to a trust anchor in the trust store then the certificate is deemed valid and - after some additional checks of e.g. the server name - the private key can be used by the server to indicate that it is the server named within the server certificate.\nGreat, so what kind of security needs to be present on your trust store? Well, it is that the trust store is available and unaltered. Having the trust store unavailable will obviously be a big issue. So downloading the trust store every time you need to secure a connection is adding another high availability component to your infrastructure. Maybe you already need one for CRL or OCSP service, but still.\nThe other thing is that the trust store should not be altered in traffic. That basically means that the connection to your service should be free from attacks. The most logical way to do this is to have it protected by TLS. In that case of course you need a trusted certificate. In the end you cannot operate without trusting something. This is why you either have to trust a server based on the cacerts, or to distribute a certificate with the application.\n\"it shouldn't be a problem because it's not accessible by anyone else\". That's not a requirement. Other people may well access the server, as long as they cannot alter the security (and availability) of the connection or the trust store. Read access to the P12 file wouldn't directly influence the availability or trustworthiness of the trust store. That said, the stricter the security of the service that contains the trust store, the better.\nI was kind of afraid that the P12 would not just be a trust store but also a key store containing a private key. Preferably, a private key should not be distributed that way. I didn't see any hint of this happening in your question, so I'll just leave it here for other readers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "I think this could be caused by that you're configuring only a keystore, but not a truststore.\nKey stores are typically used for keeping the keys or certs to provide to a third party. But for validating the provided certificates trust stores are used.\nTry to do something like:\n\nYour trust store has to contain the certificate that is returned by your service or the certificate chain that was used to sign service certificate.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "First, you have to extract the CA certificate from the .pfx file using openssl:\nopenssl pkcs12 -in filename.pfx -passin pass:<password> -info -nokeys > filename.pem.\nDouble check that extraction worked:\nopenssl x509 -in test.pem -noout -text\nThen either create new JKS using the key tool:\nkeytool -import -trustcacerts -keystore test.jks -storepass choose-password -file test.pem -alias CANAME\nOr you can import the certificate into the existing trust store:\nkeytool -import -keystore cacerts -storepass changeit -file test.pem -alias CANAME -storetype JKS\nUsually you would use openssl to interact with most certificate file formats and keytool with java key stores only (JKS)\n==============.\nUpdate\nPKCS12 is an archive file format for storing private keys and X.509 certificates with filename extensions .p12 or .pfx\nTo be able to work with .pfx files you would use openssl pkcs12 command.  I am guessing x509 command returns first certificate it finds.\nPKCS12 wiki\nkeytool Manages a keystore (database) of cryptographic keys, X.509 certificate chains, and trusted certificates.\nI think it only works with java keystores .jks or .bcfks (Bouncy Castle FIPS keyStore) etc..\nI think you might actually be able to import certificates directly from .pfx file to a java keystore using keytool.\nkeytool -importkeystore -srckeystore mypfxfile.pfx -srcstoretype pkcs12 -destkeystore clientcert.jks -deststoretype JKS\nThat could also import the private key if it's in the .pfx file but I am not sure.\nHope that helps.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You have actually created a certificate signing request with the above command.\nTo generate just a public-private key pair, you can use:\n\nHowever, a trust store contains certificates, not public keys.\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "performance": {
                "finetuned_dpr": [
                    {
                        "id": 77567231,
                        "answer_post": "There's a difference between the sample app and your code.\nThe sample app comes with a pre-configured list of trusted roots (EU LOTL).\nYour code comes with an empty CommonTrustedCertificateSource (i.e., no certificate is trusted)\nSee the DSS FAQ\n\nWhen validating a signature I receive INDETERMINATE/NO_CERTIFICATE_CHAIN_FOUND indication\n\n\nThe result means the validator was not able to reach a trust anchor when validating the certificate chain of the signature. More likely the issue is caused by the fact you have not configured a trusted certificate source within the used CertificateVerifier. To do it, you need to add trust anchors to the instance of CertificateVerifier you use within DocumentValidator:\n\nSo you need to add some certificates to the CommonTrustedCertificateSource. If you're only verifying signatures created by yourself, add your CA root/your signing certificate to the trusted source. If you're verifying third-party signatures, the solution is more complex. For example, you could extract all certificated from a PDF and add them to the trusted list before validation\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77269126,
                        "answer_post": "If the certificate is added to the truststore that the socket uses (creating an array of TrustManagers and passing that to an SSLContext), then the SSLSocket seems to treat it as valid. Testing this using a dummy certificate that expires 1 second after creation, this seems to be correct; the client connects without exceptions or issues and can send messages.\nTherefore, if the client in question explicitly trusts the certificate, the client should be able to connect.\nHowever, if another implementation is being used that rejects expired certificates, the client will most likely throw an exception.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77390571,
                        "answer_post": "\nunable to find valid certification path to requested target\n\nThe server's certificate is not trusted. You should get a CA to issue a certificate for the server. If it is already a valid cert, make sure to provide the \"certificate chain\" when configuring the server, not just the bare server certificate.\nIf you didn't intend to use a typical \"browser-trusted CA,\" you can sign the certificate with your own CA and use that CA's certificate as a trust source:\n\nThere are many sites and scripts that describe how to make your own CA and sign server certificates, if that is what you end up wanting. For reference, this is the process for gRPC's tests.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77291978,
                        "answer_post": "This is default behavior when your make use of self signed certificate in server machine.\n\"I want to avoid adding the .p12 certificate to the truststore.\" this is exact same reason why server certificates are added to the truststore as a client.\nThink about it ideally request to server should only and only come from legitimate clients (in your case spring app is client to redis server). adding certificate to truststore will make sure that only trusted clients are authorized to make the request.\nSo to answer your question adding certs to truststore is a common/well known practice done in web world.\nHope this helps. Thanks.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74553954,
                        "answer_post": "I think I solved the issue.\nI have a routine that programmatically downloads certificates from SSL protected servers through a socket that handshake and retrieve certificates.\nCurrently the certificate SSL server has some problems in returning the whole chain of certificates (including the intermediary certificates of the CAs that signed the certificate).\nIt is likely that they are problems related to a misconfiguration.\nThis problem can be verified with the command:\nopenssl s_client -showcerts -connect host:port\nThese are the intermediary CAs irrecoverable certs:\ncerts\ncerts\nThese are the intermediary certificates of the CAs:\nIntermediate cert CAs chain\nOn a programmatic level, when JAVA persists the trusted certificates in the Trust-Store, it writes information related to the fact that it was not possible to recover the whole CA chain.\nIt is as if the certificate is self-signed for the trust-store when it is not. In fact, the certificate is not actually trusted (unless you enter it \"manually\" in the trust store).\nWhen making an external call to an application-side https server, the client is not fully aware of the certificate.\nThe error was: \"PKIX path building failed\".\nIt was necessary to use a custom built HTTP client to accept single certificates of which it was not possible to download the whole CA chain.\nObviously it is not a client that can accept self-signed certificates.\nThis client is \"satisfied\" with the single certificate but it is actually a necessary and sufficient condition to perform a secure SSL handshake.\nIn other words to make an external call with RestTemplate what you have to do is change it from:\n\nto:\n\nI think I have given an explanation. What do you think about it?\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76800264,
                        "answer_post": "The reason why a trust store exists is because you are trying to create a secure communication to a web server, and you need to trust the server certificate that they offer. So a trust store contains the trust anchors for that to happen: if a valid trust path can be build to a trust anchor in the trust store then the certificate is deemed valid and - after some additional checks of e.g. the server name - the private key can be used by the server to indicate that it is the server named within the server certificate.\nGreat, so what kind of security needs to be present on your trust store? Well, it is that the trust store is available and unaltered. Having the trust store unavailable will obviously be a big issue. So downloading the trust store every time you need to secure a connection is adding another high availability component to your infrastructure. Maybe you already need one for CRL or OCSP service, but still.\nThe other thing is that the trust store should not be altered in traffic. That basically means that the connection to your service should be free from attacks. The most logical way to do this is to have it protected by TLS. In that case of course you need a trusted certificate. In the end you cannot operate without trusting something. This is why you either have to trust a server based on the cacerts, or to distribute a certificate with the application.\n\"it shouldn't be a problem because it's not accessible by anyone else\". That's not a requirement. Other people may well access the server, as long as they cannot alter the security (and availability) of the connection or the trust store. Read access to the P12 file wouldn't directly influence the availability or trustworthiness of the trust store. That said, the stricter the security of the service that contains the trust store, the better.\nI was kind of afraid that the P12 would not just be a trust store but also a key store containing a private key. Preferably, a private key should not be distributed that way. I didn't see any hint of this happening in your question, so I'll just leave it here for other readers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77625340,
                        "answer_post": "If you want to specifically use Java SSLContext, you can use a custom TrustManager that directly trusts the specified certificate.\n\nThen use the created TrustManager to create the SSLContext,\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75941010,
                        "answer_post": "First, I assume you are using Paketo buildpacks, and the documentation explains how you can provide a CA certificate to your JVM Truststore, either at\n\nbuildtime (if you use the same CA certificate for your image across your environments; that's the easiest solution since you just need to provide your CA cert during buildtime and the image is ready to be deployed) or at\nruntime (if your CA cert is going to be different across environments; that's a more complicated option since at deployment time, in kpack, you will need to provide and bind the CA certificate)\n\nIf you choose runtime, then you would need to create a service binding that would link to your CA certificate\nHope that helps!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73214423,
                        "answer_post": "Either you can add the certificates require to validate the server identity in the default java truststore i.e cacerts or you can set the application environment to use different truststore as mentioned below.\n\napplication.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77586871,
                        "answer_post": "To configure a custom trust store for your Spring Boot project without modifying the JDK's cacerts file, you can use the following approach. This involves specifying the trust store location and password through application properties.\nPlace the Trust Store in Your Project:\nPlace your custom trust store file (e.g., custom-truststore.jks) in a location within your project. Let's assume it's in the src/main/resources directory.\nUpdate Your application.properties or application.yml file:\nAdd the following properties to your application.properties or application.yml file:\n\nMake sure to replace your-trust-store-password with the actual password for your trust store.\nConfigure SSL for Your Spring Boot Application:\nEnsure that you have the necessary SSL configuration in your application.properties or application.yml for both of your Spring Boot applications. For example:\n\nAdjust these settings based on your specific SSL requirements.\nRepeat for the Other Spring Boot Application:\nRepeat the same configuration for the second Spring Boot application, making sure to use the same trust store and password if they need to trust each other.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 77625340,
                        "answer_post": "If you want to specifically use Java SSLContext, you can use a custom TrustManager that directly trusts the specified certificate.\n\nThen use the created TrustManager to create the SSLContext,\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73153710,
                        "answer_post": "LinkedBlockingQueue uses synchronization internally, in the form of ReentrantLock -- that's how it implements the 'blocking' part.\nSomething like this should work:\n\nHere threads compete at the busy flag. One of them wins the right to add to the list, others busy-wait until the winning thread clears the flag.\nThe two calls to AtomicBoolean methods establish proper 'happens-before' relationship between list.add() calls done on different threads, so each thread should observe actual state of the list.\nLinkedList can be used for unbounded queues. For bounded ones, maybe ArrayList with initial capacity set.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73058786,
                        "answer_post": "This works as designed. As the Javadoc suggests, clearAutomatically triggers persistence context clearance, i.e. calls EntityManager.clear(). The Javadoc of that clearly states:\n\nClear the persistence context, causing all managed entities to become detached. Changes made to entities that have not been flushed to the database will not be persisted.\n\nThat's why your modification of s does not get persisted. I guess an explicit call settingsRepository.save(s) should do the trick as it merges the now detached instance to the persistence context again.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76030715,
                        "answer_post": "You configured your resource-server with a JWT decoder and not introspection (opaquetoken in spring configuration) => the access token validation is local to your resource server, not submitted to authorization server.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72716284,
                        "answer_post": "By design, LDAP protocol automatically switches the authentication from \"simple\" to \"none\" if a password is not supplied (see documentation), resulting in an unauthenticated (but successful) binding, hence no error at this moment but only after when doing an operation that requires to be authenticated.\nSo I guess it's fine to make the code throw an AuthenticationException if the password string is empty, just as InitialDirContext does when a wrong password is supplied, so that you can catch both seamlessly.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72819015,
                        "answer_post": "If suddenly someone is faced with a similar problem, then here is the solution.\nYou must have 2 certificates: server and client.\nThen you put the server one in the cacerts repository in Java with the command:\n\nkeytool -importcert -storetype PKCS12 -keystore trustStore.p12\n-storepass password -alias mpzCA -file root.crt -noprompt\n\nThen, in the code, do as below:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 78891266,
                        "answer_post": "The message will continue to be hidden to other consumers until the visibility timeout expires.\nYou can however inject the instance of Visibility into your method and change the visibility to 0 in your exception handler. This will make the message visible to other consumers immediately.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76900976,
                        "answer_post": "If you're using Active Directory, you can match against the userAccountControl attribute to query users with disabled accounts. LdapWiki example:\n\nThe same is mentioned in these AD examples with a note that provides some context.\n\n\nThe string 1.2.840.113556.1.4.803 specifies LDAP_MATCHING_RULE_BIT_AND. This specifies a bitwise AND of a flag attribute (an integer), like userAccountControl, groupType, or systemFlags, and a bit mask (like 2, 32, or 65536). The clause is True if the bitwise AND of the attribute value and the bit mask is non-zero, indicating the bit is set.\n\nThe value 2 is significant in this context because it is a magic bit defined in Active Directory Technical Specification 2.2.16 - userAccountControl Bits:\n\nD (ADS_UF_ACCOUNT_DISABLE, 0x00000002): Specifies that the account is not enabled for authentication.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77049872,
                        "answer_post": "thenApply may block the thread if the previous stage has already completed (in your case it has not). thenApplyAsync is guaranteed to not block the current thread even if it has already completed.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73465151,
                        "answer_post": "Using a browser to access https://performance.infoworks.technology and checking the certificate confirms that the certificate is not trusted.\nIt is signed by an issuer which is not trusted: IW Root CA.\nYou need to make IW Root CA available on the client, put it into the certificate storage which is used in the context of running your java application to make sure is trusted at the time the request is made.\nAlternatively, for testing only (!), you can disable the certificate validation when making the request.\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77556752,
                        "answer_post": "\ntry this in pom file\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75301625,
                        "answer_post": "Try $JAVA_HOME/lib/security/cacerts\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76883763,
                        "answer_post": "For CORS Configuration\n\nFor Token\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74213490,
                        "answer_post": "Add Following to monitor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73489047,
                        "answer_post": "java version:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77075486,
                        "answer_post": "pom.xml\n\napplication.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77654306,
                        "answer_post": "try use in your POM file\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77289237,
                        "answer_post": "you can use authenticationManagerResolver interface\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73145198,
                        "answer_post": "Since version 6.3.3 the Microsoft JDBC Driver for SQL allows, to specify a custom implementation of javax.net.ssl.TrustManager through connection properties. You can specify a class name and a constructor parameter (e.g. a file name or the certificate in PEM format).\nSee here, for more detailed instructions and a simple example of a custom TrustManager. The functionality of the sslrootcert option of the Postgres driver is implemented in a similar way here.\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "The easiest way is to let Java download the server certificate for you and then just grab and save it.\nThis can be done by using a custom X509TrustManager implementation as it it shown for example in this answer.\nThe part you need to modify is checkServerTrusted:\n\nIn the end you only have to call getEncoded() on the saved serverCert to get it's ASN.1 DER encoded representation as byte[] which you can save to a file like server.cer.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The easiest way is to let Java download the server certificate for you and then just grab and save it.\nThis can be done by using a custom X509TrustManager implementation as it it shown for example in this answer.\nThe part you need to modify is checkServerTrusted:\n\nIn the end you only have to call getEncoded() on the saved serverCert to get it's ASN.1 DER encoded representation as byte[] which you can save to a file like server.cer.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I think I solved the issue.\nI have a routine that programmatically downloads certificates from SSL protected servers through a socket that handshake and retrieve certificates.\nCurrently the certificate SSL server has some problems in returning the whole chain of certificates (including the intermediary certificates of the CAs that signed the certificate).\nIt is likely that they are problems related to a misconfiguration.\nThis problem can be verified with the command:\nopenssl s_client -showcerts -connect host:port\nThese are the intermediary CAs irrecoverable certs:\ncerts\ncerts\nThese are the intermediary certificates of the CAs:\nIntermediate cert CAs chain\nOn a programmatic level, when JAVA persists the trusted certificates in the Trust-Store, it writes information related to the fact that it was not possible to recover the whole CA chain.\nIt is as if the certificate is self-signed for the trust-store when it is not. In fact, the certificate is not actually trusted (unless you enter it \"manually\" in the trust store).\nWhen making an external call to an application-side https server, the client is not fully aware of the certificate.\nThe error was: \"PKIX path building failed\".\nIt was necessary to use a custom built HTTP client to accept single certificates of which it was not possible to download the whole CA chain.\nObviously it is not a client that can accept self-signed certificates.\nThis client is \"satisfied\" with the single certificate but it is actually a necessary and sufficient condition to perform a secure SSL handshake.\nIn other words to make an external call with RestTemplate what you have to do is change it from:\n\nto:\n\nI think I have given an explanation. What do you think about it?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "There are two issues here:\n\nFirst, when connecting locally, you can't connect directly - you need to connect through an SSH tunnel instead. See Connecting to an Amazon DocumentDB Cluster from Outside an Amazon VPC for details on how to do this.\nSecond, the .pem certificate file isn't directly usable as a Java trust store. Instead, it contains the certificates which should be imported into a Java trust store (using the keytool Java utility), so that your program can then reference that trust store (via the javax.net.ssl.trustStore system property) in verifying the identity of the DocumentDB server.\n\nContext: The sun.security.* packages (referenced in the Fargate logs you posted) verify the DocumentDB server's identity by attempting to build a valid PKIX certification path from the root CA certificates found in the Java trust store to the certificate presented by the particular DocumentDB server you are targeting. If the Java trust store found at javax.net.ssl.trustStore is either invalid (e.g., because it's a .pem file instead of a valid .jks file), or if it doesn't contain the necessary certificates (e.g., because the root CA certificates found in global-bundle.pem were never imported using the Java keytool utility), PKIX path building fails, meaning the identity of the DocumentDB server cannot be established. See Connecting with TLS Enabled for more details (and be sure to select the \"Java\" tab to see Java-specific instructions.)\n\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "\nHow do keystores really work? From my understanding, you generate a keystore with the keytool command and that generates a keystore file that is like a small database(?) that contains a self-signed certificate and a public/private key pair.\n\nWell preferably a certificate chain with a leaf and one or more CA certificates; self signed certificates are usually just a way to \"get it working\" without a lot of key management. And the certificate contains the public key, so you only need to store the chain + the private key of the server certificate.\n\nWe then create a truststore that's like a keystore but where we only import the self-signed certificate and the public key and this is what the client uses to connect to the server (I don't really understand this very last part).\n\nNo, again, the public key doesn't need to store separately, it is already included. And you don't need to have the truststore to connect, you need it to verify the trust path to a trust anchor. Usually that is a known root certificate, but for self-signed certificates it is just the one certificate.\n\nHow do we actually use these keys that we generated inside our code? What is the recommended/secure way to do it? I have a feeling that setting system properties and typing a password in plain text in the class isn't the right way to do it but this might be the way to do it.\n\nUsually you try and store the private key in the least accessible way possible while you are still able to use it economically. Banks store private keys in HSM's, hardware security modules. Generally, if you just have a computer, you try to store it in the most secure place possible, e.g. in a system provided key store.\nUsing a key store based on password based encryption (PKCS#12 or PFX keystores and the Java JKS key stores) are indeed not the most secure options. Better choose a very secure password to at least not leak the private key if the store gets stolen.\nNote that Java does contain a PKCS#11 provider that works with HSM's as well as providers to use the Windows certificates / keys.\n\nIf I were to develop an app that uses TLS how would I go about storing the keys in the Client? Would it be possible to pack the key inside the jar file that I'd release for the users to download?\n\nYes, it certainly can be a resource that is packed with the program, but you might need to update your program if you want it to remain current. Actually, that is exactly how most browsers get the trust store; the certificates are delivered with the updates of Firefox and Chrome.\nFor others they are part of OS updates such as with Edge, and you may also have a network specific method of distributing trusted certificates such as the Group Policy in the Windows ecosystem.\n\nLike I said, I followed the tutorial from the docs and combining that with some knowledge I got from other stackoverflow posts I managed to make it work but I'd like to understand how everything really works.\n\nWell, PKIX and TLS operation is a lot of information to take in and understand for sure. One way of making sure that you get the right information is to simply read the X.509 standard. There are many tutorials on the Internet as well.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The fact you're mentioning /etc/pki/ca-trust/extracted/java/cacerts suggests you're using a cacerts file managed by your Linux distribution (presumably based on RedHat/CentOS).\nRemoving the specific certificate from that cacerts file is indeed possible with keytool manually. However, it's likely to be re-generated, and possibly placed back into that file the next time update-ca-trust is executed automatically (e.g. package upgrade) or not.\nWhen using the distribution-managed cacerts file, it's generally better to use the distribution's mechanism.\nOn RedHat/CentOS-based distributions, this can be done by managing individual certificates in /etc/pki/ca-trust/source/anchors/ and using update-ca-trust.\nOn Debian/Ubuntu-based distributions, there is an equivalent with certificates in /usr/share/ca-certificates, assuming the ca-certificates-java package is installed (and then, you can run update-ca-certificates).\n\nAs a side-note, you've tagged your question with client-certificate.\nClient-certificates (and more so their matching private key, i.e. PrivateKeyEntry entries) normally don't belong in the cacerts file at all, which is a \"keystore\" used as a \"truststore\" (typically used as the default truststore for all Java applications running on that system). Those belong to a \"keystore used as a keystore\", not a \"keystore used as a truststore\" (which shouldn't contain private keys).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The reason why a trust store exists is because you are trying to create a secure communication to a web server, and you need to trust the server certificate that they offer. So a trust store contains the trust anchors for that to happen: if a valid trust path can be build to a trust anchor in the trust store then the certificate is deemed valid and - after some additional checks of e.g. the server name - the private key can be used by the server to indicate that it is the server named within the server certificate.\nGreat, so what kind of security needs to be present on your trust store? Well, it is that the trust store is available and unaltered. Having the trust store unavailable will obviously be a big issue. So downloading the trust store every time you need to secure a connection is adding another high availability component to your infrastructure. Maybe you already need one for CRL or OCSP service, but still.\nThe other thing is that the trust store should not be altered in traffic. That basically means that the connection to your service should be free from attacks. The most logical way to do this is to have it protected by TLS. In that case of course you need a trusted certificate. In the end you cannot operate without trusting something. This is why you either have to trust a server based on the cacerts, or to distribute a certificate with the application.\n\"it shouldn't be a problem because it's not accessible by anyone else\". That's not a requirement. Other people may well access the server, as long as they cannot alter the security (and availability) of the connection or the trust store. Read access to the P12 file wouldn't directly influence the availability or trustworthiness of the trust store. That said, the stricter the security of the service that contains the trust store, the better.\nI was kind of afraid that the P12 would not just be a trust store but also a key store containing a private key. Preferably, a private key should not be distributed that way. I didn't see any hint of this happening in your question, so I'll just leave it here for other readers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "I think this could be caused by that you're configuring only a keystore, but not a truststore.\nKey stores are typically used for keeping the keys or certs to provide to a third party. But for validating the provided certificates trust stores are used.\nTry to do something like:\n\nYour trust store has to contain the certificate that is returned by your service or the certificate chain that was used to sign service certificate.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "First, you have to extract the CA certificate from the .pfx file using openssl:\nopenssl pkcs12 -in filename.pfx -passin pass:<password> -info -nokeys > filename.pem.\nDouble check that extraction worked:\nopenssl x509 -in test.pem -noout -text\nThen either create new JKS using the key tool:\nkeytool -import -trustcacerts -keystore test.jks -storepass choose-password -file test.pem -alias CANAME\nOr you can import the certificate into the existing trust store:\nkeytool -import -keystore cacerts -storepass changeit -file test.pem -alias CANAME -storetype JKS\nUsually you would use openssl to interact with most certificate file formats and keytool with java key stores only (JKS)\n==============.\nUpdate\nPKCS12 is an archive file format for storing private keys and X.509 certificates with filename extensions .p12 or .pfx\nTo be able to work with .pfx files you would use openssl pkcs12 command.  I am guessing x509 command returns first certificate it finds.\nPKCS12 wiki\nkeytool Manages a keystore (database) of cryptographic keys, X.509 certificate chains, and trusted certificates.\nI think it only works with java keystores .jks or .bcfks (Bouncy Castle FIPS keyStore) etc..\nI think you might actually be able to import certificates directly from .pfx file to a java keystore using keytool.\nkeytool -importkeystore -srckeystore mypfxfile.pfx -srcstoretype pkcs12 -destkeystore clientcert.jks -deststoretype JKS\nThat could also import the private key if it's in the .pfx file but I am not sure.\nHope that helps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You have actually created a certificate signing request with the above command.\nTo generate just a public-private key pair, you can use:\n\nHowever, a trust store contains certificates, not public keys.\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "directive": {
                "finetuned_dpr": [
                    {
                        "id": 77567231,
                        "answer_post": "There's a difference between the sample app and your code.\nThe sample app comes with a pre-configured list of trusted roots (EU LOTL).\nYour code comes with an empty CommonTrustedCertificateSource (i.e., no certificate is trusted)\nSee the DSS FAQ\n\nWhen validating a signature I receive INDETERMINATE/NO_CERTIFICATE_CHAIN_FOUND indication\n\n\nThe result means the validator was not able to reach a trust anchor when validating the certificate chain of the signature. More likely the issue is caused by the fact you have not configured a trusted certificate source within the used CertificateVerifier. To do it, you need to add trust anchors to the instance of CertificateVerifier you use within DocumentValidator:\n\nSo you need to add some certificates to the CommonTrustedCertificateSource. If you're only verifying signatures created by yourself, add your CA root/your signing certificate to the trusted source. If you're verifying third-party signatures, the solution is more complex. For example, you could extract all certificated from a PDF and add them to the trusted list before validation\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77269126,
                        "answer_post": "If the certificate is added to the truststore that the socket uses (creating an array of TrustManagers and passing that to an SSLContext), then the SSLSocket seems to treat it as valid. Testing this using a dummy certificate that expires 1 second after creation, this seems to be correct; the client connects without exceptions or issues and can send messages.\nTherefore, if the client in question explicitly trusts the certificate, the client should be able to connect.\nHowever, if another implementation is being used that rejects expired certificates, the client will most likely throw an exception.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77390571,
                        "answer_post": "\nunable to find valid certification path to requested target\n\nThe server's certificate is not trusted. You should get a CA to issue a certificate for the server. If it is already a valid cert, make sure to provide the \"certificate chain\" when configuring the server, not just the bare server certificate.\nIf you didn't intend to use a typical \"browser-trusted CA,\" you can sign the certificate with your own CA and use that CA's certificate as a trust source:\n\nThere are many sites and scripts that describe how to make your own CA and sign server certificates, if that is what you end up wanting. For reference, this is the process for gRPC's tests.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77291978,
                        "answer_post": "This is default behavior when your make use of self signed certificate in server machine.\n\"I want to avoid adding the .p12 certificate to the truststore.\" this is exact same reason why server certificates are added to the truststore as a client.\nThink about it ideally request to server should only and only come from legitimate clients (in your case spring app is client to redis server). adding certificate to truststore will make sure that only trusted clients are authorized to make the request.\nSo to answer your question adding certs to truststore is a common/well known practice done in web world.\nHope this helps. Thanks.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76800264,
                        "answer_post": "The reason why a trust store exists is because you are trying to create a secure communication to a web server, and you need to trust the server certificate that they offer. So a trust store contains the trust anchors for that to happen: if a valid trust path can be build to a trust anchor in the trust store then the certificate is deemed valid and - after some additional checks of e.g. the server name - the private key can be used by the server to indicate that it is the server named within the server certificate.\nGreat, so what kind of security needs to be present on your trust store? Well, it is that the trust store is available and unaltered. Having the trust store unavailable will obviously be a big issue. So downloading the trust store every time you need to secure a connection is adding another high availability component to your infrastructure. Maybe you already need one for CRL or OCSP service, but still.\nThe other thing is that the trust store should not be altered in traffic. That basically means that the connection to your service should be free from attacks. The most logical way to do this is to have it protected by TLS. In that case of course you need a trusted certificate. In the end you cannot operate without trusting something. This is why you either have to trust a server based on the cacerts, or to distribute a certificate with the application.\n\"it shouldn't be a problem because it's not accessible by anyone else\". That's not a requirement. Other people may well access the server, as long as they cannot alter the security (and availability) of the connection or the trust store. Read access to the P12 file wouldn't directly influence the availability or trustworthiness of the trust store. That said, the stricter the security of the service that contains the trust store, the better.\nI was kind of afraid that the P12 would not just be a trust store but also a key store containing a private key. Preferably, a private key should not be distributed that way. I didn't see any hint of this happening in your question, so I'll just leave it here for other readers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74553954,
                        "answer_post": "I think I solved the issue.\nI have a routine that programmatically downloads certificates from SSL protected servers through a socket that handshake and retrieve certificates.\nCurrently the certificate SSL server has some problems in returning the whole chain of certificates (including the intermediary certificates of the CAs that signed the certificate).\nIt is likely that they are problems related to a misconfiguration.\nThis problem can be verified with the command:\nopenssl s_client -showcerts -connect host:port\nThese are the intermediary CAs irrecoverable certs:\ncerts\ncerts\nThese are the intermediary certificates of the CAs:\nIntermediate cert CAs chain\nOn a programmatic level, when JAVA persists the trusted certificates in the Trust-Store, it writes information related to the fact that it was not possible to recover the whole CA chain.\nIt is as if the certificate is self-signed for the trust-store when it is not. In fact, the certificate is not actually trusted (unless you enter it \"manually\" in the trust store).\nWhen making an external call to an application-side https server, the client is not fully aware of the certificate.\nThe error was: \"PKIX path building failed\".\nIt was necessary to use a custom built HTTP client to accept single certificates of which it was not possible to download the whole CA chain.\nObviously it is not a client that can accept self-signed certificates.\nThis client is \"satisfied\" with the single certificate but it is actually a necessary and sufficient condition to perform a secure SSL handshake.\nIn other words to make an external call with RestTemplate what you have to do is change it from:\n\nto:\n\nI think I have given an explanation. What do you think about it?\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74518957,
                        "answer_post": "Yes. Just adding the root certificate to your client trust store suffice to create the HTTPs successful connection. During the handshake, the certificate is validated from bottom-up way. It means that your Intermediate certificate must be signed by the root CA, and your leaf certificate must be signed by your intermediate CA. As long as your root CA is valid and present in your client's trust store, the connection will be successful.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75795924,
                        "answer_post": "In simple terms, a party (client or server) will trust another party (server or client) if the other party\u2019s certificate chain as provided on the wire can be traced back (recursively via signers) to the CACERTS stored in the original party\u2019s JRE. (or is in the original party\u2019s truststore)\nIt is fairly unusual to use mutually authenticated TLS so client side certificates are rare. In most cases authentication of a client is done with user credentials, api keys, etc. Anyway, it looks like you have the client cert setup correctly.\nIf the server certificate is signed by a Intermediate CA that has a cert held in the client\u2019s CACERTS then no client side intervention is necessary. On the server a keychain from a CACERTS cert down to the server cert needs to be configured via application.yaml, as you correctly show in your question.\nIf the Intermediate CA\u2019s signing cert is not registered in the official Java CACERTS in the client\u2019s JRE then it must be added like this. I find it easier to add untrusted Intermediate CA certs to CACERTS rather than adding the server cert to the client truststore (as you correctly show) because that allows multiple servers to be trusted (because, in a typical corporate environment, they will all have certs signed by the Intermediate CA)\nIf a client can\u2019t build a trusted cert chain to the cert provided by a server an SSL connection will fail with the dreaded \u201cPKIX path building failed\u201d error.\nI find it helpful to load a server GET path (eg /welcome) in a browser to get a look at what cert the server is passing back.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77625340,
                        "answer_post": "If you want to specifically use Java SSLContext, you can use a custom TrustManager that directly trusts the specified certificate.\n\nThen use the created TrustManager to create the SSLContext,\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77586871,
                        "answer_post": "To configure a custom trust store for your Spring Boot project without modifying the JDK's cacerts file, you can use the following approach. This involves specifying the trust store location and password through application properties.\nPlace the Trust Store in Your Project:\nPlace your custom trust store file (e.g., custom-truststore.jks) in a location within your project. Let's assume it's in the src/main/resources directory.\nUpdate Your application.properties or application.yml file:\nAdd the following properties to your application.properties or application.yml file:\n\nMake sure to replace your-trust-store-password with the actual password for your trust store.\nConfigure SSL for Your Spring Boot Application:\nEnsure that you have the necessary SSL configuration in your application.properties or application.yml for both of your Spring Boot applications. For example:\n\nAdjust these settings based on your specific SSL requirements.\nRepeat for the Other Spring Boot Application:\nRepeat the same configuration for the second Spring Boot application, making sure to use the same trust store and password if they need to trust each other.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 77625340,
                        "answer_post": "If you want to specifically use Java SSLContext, you can use a custom TrustManager that directly trusts the specified certificate.\n\nThen use the created TrustManager to create the SSLContext,\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73153710,
                        "answer_post": "LinkedBlockingQueue uses synchronization internally, in the form of ReentrantLock -- that's how it implements the 'blocking' part.\nSomething like this should work:\n\nHere threads compete at the busy flag. One of them wins the right to add to the list, others busy-wait until the winning thread clears the flag.\nThe two calls to AtomicBoolean methods establish proper 'happens-before' relationship between list.add() calls done on different threads, so each thread should observe actual state of the list.\nLinkedList can be used for unbounded queues. For bounded ones, maybe ArrayList with initial capacity set.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73058786,
                        "answer_post": "This works as designed. As the Javadoc suggests, clearAutomatically triggers persistence context clearance, i.e. calls EntityManager.clear(). The Javadoc of that clearly states:\n\nClear the persistence context, causing all managed entities to become detached. Changes made to entities that have not been flushed to the database will not be persisted.\n\nThat's why your modification of s does not get persisted. I guess an explicit call settingsRepository.save(s) should do the trick as it merges the now detached instance to the persistence context again.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76030715,
                        "answer_post": "You configured your resource-server with a JWT decoder and not introspection (opaquetoken in spring configuration) => the access token validation is local to your resource server, not submitted to authorization server.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72716284,
                        "answer_post": "By design, LDAP protocol automatically switches the authentication from \"simple\" to \"none\" if a password is not supplied (see documentation), resulting in an unauthenticated (but successful) binding, hence no error at this moment but only after when doing an operation that requires to be authenticated.\nSo I guess it's fine to make the code throw an AuthenticationException if the password string is empty, just as InitialDirContext does when a wrong password is supplied, so that you can catch both seamlessly.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72819015,
                        "answer_post": "If suddenly someone is faced with a similar problem, then here is the solution.\nYou must have 2 certificates: server and client.\nThen you put the server one in the cacerts repository in Java with the command:\n\nkeytool -importcert -storetype PKCS12 -keystore trustStore.p12\n-storepass password -alias mpzCA -file root.crt -noprompt\n\nThen, in the code, do as below:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73465151,
                        "answer_post": "Using a browser to access https://performance.infoworks.technology and checking the certificate confirms that the certificate is not trusted.\nIt is signed by an issuer which is not trusted: IW Root CA.\nYou need to make IW Root CA available on the client, put it into the certificate storage which is used in the context of running your java application to make sure is trusted at the time the request is made.\nAlternatively, for testing only (!), you can disable the certificate validation when making the request.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75885986,
                        "answer_post": "Make sure you have the following property set in your application.properties\n\nThis ensures that your server port (8081) is registered with Nacos instead of the management port (8079).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76900976,
                        "answer_post": "If you're using Active Directory, you can match against the userAccountControl attribute to query users with disabled accounts. LdapWiki example:\n\nThe same is mentioned in these AD examples with a note that provides some context.\n\n\nThe string 1.2.840.113556.1.4.803 specifies LDAP_MATCHING_RULE_BIT_AND. This specifies a bitwise AND of a flag attribute (an integer), like userAccountControl, groupType, or systemFlags, and a bit mask (like 2, 32, or 65536). The clause is True if the bitwise AND of the attribute value and the bit mask is non-zero, indicating the bit is set.\n\nThe value 2 is significant in this context because it is a magic bit defined in Active Directory Technical Specification 2.2.16 - userAccountControl Bits:\n\nD (ADS_UF_ACCOUNT_DISABLE, 0x00000002): Specifies that the account is not enabled for authentication.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 78891266,
                        "answer_post": "The message will continue to be hidden to other consumers until the visibility timeout expires.\nYou can however inject the instance of Visibility into your method and change the visibility to 0 in your exception handler. This will make the message visible to other consumers immediately.\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77556752,
                        "answer_post": "\ntry this in pom file\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75301625,
                        "answer_post": "Try $JAVA_HOME/lib/security/cacerts\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76883763,
                        "answer_post": "For CORS Configuration\n\nFor Token\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77654306,
                        "answer_post": "try use in your POM file\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74213490,
                        "answer_post": "Add Following to monitor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77075486,
                        "answer_post": "pom.xml\n\napplication.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77289237,
                        "answer_post": "you can use authenticationManagerResolver interface\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73145198,
                        "answer_post": "Since version 6.3.3 the Microsoft JDBC Driver for SQL allows, to specify a custom implementation of javax.net.ssl.TrustManager through connection properties. You can specify a class name and a constructor parameter (e.g. a file name or the certificate in PEM format).\nSee here, for more detailed instructions and a simple example of a custom TrustManager. The functionality of the sslrootcert option of the Postgres driver is implemented in a similar way here.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73489047,
                        "answer_post": "java version:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "The easiest way is to let Java download the server certificate for you and then just grab and save it.\nThis can be done by using a custom X509TrustManager implementation as it it shown for example in this answer.\nThe part you need to modify is checkServerTrusted:\n\nIn the end you only have to call getEncoded() on the saved serverCert to get it's ASN.1 DER encoded representation as byte[] which you can save to a file like server.cer.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The easiest way is to let Java download the server certificate for you and then just grab and save it.\nThis can be done by using a custom X509TrustManager implementation as it it shown for example in this answer.\nThe part you need to modify is checkServerTrusted:\n\nIn the end you only have to call getEncoded() on the saved serverCert to get it's ASN.1 DER encoded representation as byte[] which you can save to a file like server.cer.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I think I solved the issue.\nI have a routine that programmatically downloads certificates from SSL protected servers through a socket that handshake and retrieve certificates.\nCurrently the certificate SSL server has some problems in returning the whole chain of certificates (including the intermediary certificates of the CAs that signed the certificate).\nIt is likely that they are problems related to a misconfiguration.\nThis problem can be verified with the command:\nopenssl s_client -showcerts -connect host:port\nThese are the intermediary CAs irrecoverable certs:\ncerts\ncerts\nThese are the intermediary certificates of the CAs:\nIntermediate cert CAs chain\nOn a programmatic level, when JAVA persists the trusted certificates in the Trust-Store, it writes information related to the fact that it was not possible to recover the whole CA chain.\nIt is as if the certificate is self-signed for the trust-store when it is not. In fact, the certificate is not actually trusted (unless you enter it \"manually\" in the trust store).\nWhen making an external call to an application-side https server, the client is not fully aware of the certificate.\nThe error was: \"PKIX path building failed\".\nIt was necessary to use a custom built HTTP client to accept single certificates of which it was not possible to download the whole CA chain.\nObviously it is not a client that can accept self-signed certificates.\nThis client is \"satisfied\" with the single certificate but it is actually a necessary and sufficient condition to perform a secure SSL handshake.\nIn other words to make an external call with RestTemplate what you have to do is change it from:\n\nto:\n\nI think I have given an explanation. What do you think about it?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "There are two issues here:\n\nFirst, when connecting locally, you can't connect directly - you need to connect through an SSH tunnel instead. See Connecting to an Amazon DocumentDB Cluster from Outside an Amazon VPC for details on how to do this.\nSecond, the .pem certificate file isn't directly usable as a Java trust store. Instead, it contains the certificates which should be imported into a Java trust store (using the keytool Java utility), so that your program can then reference that trust store (via the javax.net.ssl.trustStore system property) in verifying the identity of the DocumentDB server.\n\nContext: The sun.security.* packages (referenced in the Fargate logs you posted) verify the DocumentDB server's identity by attempting to build a valid PKIX certification path from the root CA certificates found in the Java trust store to the certificate presented by the particular DocumentDB server you are targeting. If the Java trust store found at javax.net.ssl.trustStore is either invalid (e.g., because it's a .pem file instead of a valid .jks file), or if it doesn't contain the necessary certificates (e.g., because the root CA certificates found in global-bundle.pem were never imported using the Java keytool utility), PKIX path building fails, meaning the identity of the DocumentDB server cannot be established. See Connecting with TLS Enabled for more details (and be sure to select the \"Java\" tab to see Java-specific instructions.)\n\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nHow do keystores really work? From my understanding, you generate a keystore with the keytool command and that generates a keystore file that is like a small database(?) that contains a self-signed certificate and a public/private key pair.\n\nWell preferably a certificate chain with a leaf and one or more CA certificates; self signed certificates are usually just a way to \"get it working\" without a lot of key management. And the certificate contains the public key, so you only need to store the chain + the private key of the server certificate.\n\nWe then create a truststore that's like a keystore but where we only import the self-signed certificate and the public key and this is what the client uses to connect to the server (I don't really understand this very last part).\n\nNo, again, the public key doesn't need to store separately, it is already included. And you don't need to have the truststore to connect, you need it to verify the trust path to a trust anchor. Usually that is a known root certificate, but for self-signed certificates it is just the one certificate.\n\nHow do we actually use these keys that we generated inside our code? What is the recommended/secure way to do it? I have a feeling that setting system properties and typing a password in plain text in the class isn't the right way to do it but this might be the way to do it.\n\nUsually you try and store the private key in the least accessible way possible while you are still able to use it economically. Banks store private keys in HSM's, hardware security modules. Generally, if you just have a computer, you try to store it in the most secure place possible, e.g. in a system provided key store.\nUsing a key store based on password based encryption (PKCS#12 or PFX keystores and the Java JKS key stores) are indeed not the most secure options. Better choose a very secure password to at least not leak the private key if the store gets stolen.\nNote that Java does contain a PKCS#11 provider that works with HSM's as well as providers to use the Windows certificates / keys.\n\nIf I were to develop an app that uses TLS how would I go about storing the keys in the Client? Would it be possible to pack the key inside the jar file that I'd release for the users to download?\n\nYes, it certainly can be a resource that is packed with the program, but you might need to update your program if you want it to remain current. Actually, that is exactly how most browsers get the trust store; the certificates are delivered with the updates of Firefox and Chrome.\nFor others they are part of OS updates such as with Edge, and you may also have a network specific method of distributing trusted certificates such as the Group Policy in the Windows ecosystem.\n\nLike I said, I followed the tutorial from the docs and combining that with some knowledge I got from other stackoverflow posts I managed to make it work but I'd like to understand how everything really works.\n\nWell, PKIX and TLS operation is a lot of information to take in and understand for sure. One way of making sure that you get the right information is to simply read the X.509 standard. There are many tutorials on the Internet as well.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The fact you're mentioning /etc/pki/ca-trust/extracted/java/cacerts suggests you're using a cacerts file managed by your Linux distribution (presumably based on RedHat/CentOS).\nRemoving the specific certificate from that cacerts file is indeed possible with keytool manually. However, it's likely to be re-generated, and possibly placed back into that file the next time update-ca-trust is executed automatically (e.g. package upgrade) or not.\nWhen using the distribution-managed cacerts file, it's generally better to use the distribution's mechanism.\nOn RedHat/CentOS-based distributions, this can be done by managing individual certificates in /etc/pki/ca-trust/source/anchors/ and using update-ca-trust.\nOn Debian/Ubuntu-based distributions, there is an equivalent with certificates in /usr/share/ca-certificates, assuming the ca-certificates-java package is installed (and then, you can run update-ca-certificates).\n\nAs a side-note, you've tagged your question with client-certificate.\nClient-certificates (and more so their matching private key, i.e. PrivateKeyEntry entries) normally don't belong in the cacerts file at all, which is a \"keystore\" used as a \"truststore\" (typically used as the default truststore for all Java applications running on that system). Those belong to a \"keystore used as a keystore\", not a \"keystore used as a truststore\" (which shouldn't contain private keys).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The reason why a trust store exists is because you are trying to create a secure communication to a web server, and you need to trust the server certificate that they offer. So a trust store contains the trust anchors for that to happen: if a valid trust path can be build to a trust anchor in the trust store then the certificate is deemed valid and - after some additional checks of e.g. the server name - the private key can be used by the server to indicate that it is the server named within the server certificate.\nGreat, so what kind of security needs to be present on your trust store? Well, it is that the trust store is available and unaltered. Having the trust store unavailable will obviously be a big issue. So downloading the trust store every time you need to secure a connection is adding another high availability component to your infrastructure. Maybe you already need one for CRL or OCSP service, but still.\nThe other thing is that the trust store should not be altered in traffic. That basically means that the connection to your service should be free from attacks. The most logical way to do this is to have it protected by TLS. In that case of course you need a trusted certificate. In the end you cannot operate without trusting something. This is why you either have to trust a server based on the cacerts, or to distribute a certificate with the application.\n\"it shouldn't be a problem because it's not accessible by anyone else\". That's not a requirement. Other people may well access the server, as long as they cannot alter the security (and availability) of the connection or the trust store. Read access to the P12 file wouldn't directly influence the availability or trustworthiness of the trust store. That said, the stricter the security of the service that contains the trust store, the better.\nI was kind of afraid that the P12 would not just be a trust store but also a key store containing a private key. Preferably, a private key should not be distributed that way. I didn't see any hint of this happening in your question, so I'll just leave it here for other readers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "I think this could be caused by that you're configuring only a keystore, but not a truststore.\nKey stores are typically used for keeping the keys or certs to provide to a third party. But for validating the provided certificates trust stores are used.\nTry to do something like:\n\nYour trust store has to contain the certificate that is returned by your service or the certificate chain that was used to sign service certificate.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First, you have to extract the CA certificate from the .pfx file using openssl:\nopenssl pkcs12 -in filename.pfx -passin pass:<password> -info -nokeys > filename.pem.\nDouble check that extraction worked:\nopenssl x509 -in test.pem -noout -text\nThen either create new JKS using the key tool:\nkeytool -import -trustcacerts -keystore test.jks -storepass choose-password -file test.pem -alias CANAME\nOr you can import the certificate into the existing trust store:\nkeytool -import -keystore cacerts -storepass changeit -file test.pem -alias CANAME -storetype JKS\nUsually you would use openssl to interact with most certificate file formats and keytool with java key stores only (JKS)\n==============.\nUpdate\nPKCS12 is an archive file format for storing private keys and X.509 certificates with filename extensions .p12 or .pfx\nTo be able to work with .pfx files you would use openssl pkcs12 command.  I am guessing x509 command returns first certificate it finds.\nPKCS12 wiki\nkeytool Manages a keystore (database) of cryptographic keys, X.509 certificate chains, and trusted certificates.\nI think it only works with java keystores .jks or .bcfks (Bouncy Castle FIPS keyStore) etc..\nI think you might actually be able to import certificates directly from .pfx file to a java keystore using keytool.\nkeytool -importkeystore -srckeystore mypfxfile.pfx -srcstoretype pkcs12 -destkeystore clientcert.jks -deststoretype JKS\nThat could also import the private key if it's in the .pfx file but I am not sure.\nHope that helps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You have actually created a certificate signing request with the above command.\nTo generate just a public-private key pair, you can use:\n\nHowever, a trust store contains certificates, not public keys.\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "pattern": {
                "finetuned_dpr": [
                    {
                        "id": 77567231,
                        "answer_post": "There's a difference between the sample app and your code.\nThe sample app comes with a pre-configured list of trusted roots (EU LOTL).\nYour code comes with an empty CommonTrustedCertificateSource (i.e., no certificate is trusted)\nSee the DSS FAQ\n\nWhen validating a signature I receive INDETERMINATE/NO_CERTIFICATE_CHAIN_FOUND indication\n\n\nThe result means the validator was not able to reach a trust anchor when validating the certificate chain of the signature. More likely the issue is caused by the fact you have not configured a trusted certificate source within the used CertificateVerifier. To do it, you need to add trust anchors to the instance of CertificateVerifier you use within DocumentValidator:\n\nSo you need to add some certificates to the CommonTrustedCertificateSource. If you're only verifying signatures created by yourself, add your CA root/your signing certificate to the trusted source. If you're verifying third-party signatures, the solution is more complex. For example, you could extract all certificated from a PDF and add them to the trusted list before validation\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77269126,
                        "answer_post": "If the certificate is added to the truststore that the socket uses (creating an array of TrustManagers and passing that to an SSLContext), then the SSLSocket seems to treat it as valid. Testing this using a dummy certificate that expires 1 second after creation, this seems to be correct; the client connects without exceptions or issues and can send messages.\nTherefore, if the client in question explicitly trusts the certificate, the client should be able to connect.\nHowever, if another implementation is being used that rejects expired certificates, the client will most likely throw an exception.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77390571,
                        "answer_post": "\nunable to find valid certification path to requested target\n\nThe server's certificate is not trusted. You should get a CA to issue a certificate for the server. If it is already a valid cert, make sure to provide the \"certificate chain\" when configuring the server, not just the bare server certificate.\nIf you didn't intend to use a typical \"browser-trusted CA,\" you can sign the certificate with your own CA and use that CA's certificate as a trust source:\n\nThere are many sites and scripts that describe how to make your own CA and sign server certificates, if that is what you end up wanting. For reference, this is the process for gRPC's tests.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77291978,
                        "answer_post": "This is default behavior when your make use of self signed certificate in server machine.\n\"I want to avoid adding the .p12 certificate to the truststore.\" this is exact same reason why server certificates are added to the truststore as a client.\nThink about it ideally request to server should only and only come from legitimate clients (in your case spring app is client to redis server). adding certificate to truststore will make sure that only trusted clients are authorized to make the request.\nSo to answer your question adding certs to truststore is a common/well known practice done in web world.\nHope this helps. Thanks.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74553954,
                        "answer_post": "I think I solved the issue.\nI have a routine that programmatically downloads certificates from SSL protected servers through a socket that handshake and retrieve certificates.\nCurrently the certificate SSL server has some problems in returning the whole chain of certificates (including the intermediary certificates of the CAs that signed the certificate).\nIt is likely that they are problems related to a misconfiguration.\nThis problem can be verified with the command:\nopenssl s_client -showcerts -connect host:port\nThese are the intermediary CAs irrecoverable certs:\ncerts\ncerts\nThese are the intermediary certificates of the CAs:\nIntermediate cert CAs chain\nOn a programmatic level, when JAVA persists the trusted certificates in the Trust-Store, it writes information related to the fact that it was not possible to recover the whole CA chain.\nIt is as if the certificate is self-signed for the trust-store when it is not. In fact, the certificate is not actually trusted (unless you enter it \"manually\" in the trust store).\nWhen making an external call to an application-side https server, the client is not fully aware of the certificate.\nThe error was: \"PKIX path building failed\".\nIt was necessary to use a custom built HTTP client to accept single certificates of which it was not possible to download the whole CA chain.\nObviously it is not a client that can accept self-signed certificates.\nThis client is \"satisfied\" with the single certificate but it is actually a necessary and sufficient condition to perform a secure SSL handshake.\nIn other words to make an external call with RestTemplate what you have to do is change it from:\n\nto:\n\nI think I have given an explanation. What do you think about it?\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76800264,
                        "answer_post": "The reason why a trust store exists is because you are trying to create a secure communication to a web server, and you need to trust the server certificate that they offer. So a trust store contains the trust anchors for that to happen: if a valid trust path can be build to a trust anchor in the trust store then the certificate is deemed valid and - after some additional checks of e.g. the server name - the private key can be used by the server to indicate that it is the server named within the server certificate.\nGreat, so what kind of security needs to be present on your trust store? Well, it is that the trust store is available and unaltered. Having the trust store unavailable will obviously be a big issue. So downloading the trust store every time you need to secure a connection is adding another high availability component to your infrastructure. Maybe you already need one for CRL or OCSP service, but still.\nThe other thing is that the trust store should not be altered in traffic. That basically means that the connection to your service should be free from attacks. The most logical way to do this is to have it protected by TLS. In that case of course you need a trusted certificate. In the end you cannot operate without trusting something. This is why you either have to trust a server based on the cacerts, or to distribute a certificate with the application.\n\"it shouldn't be a problem because it's not accessible by anyone else\". That's not a requirement. Other people may well access the server, as long as they cannot alter the security (and availability) of the connection or the trust store. Read access to the P12 file wouldn't directly influence the availability or trustworthiness of the trust store. That said, the stricter the security of the service that contains the trust store, the better.\nI was kind of afraid that the P12 would not just be a trust store but also a key store containing a private key. Preferably, a private key should not be distributed that way. I didn't see any hint of this happening in your question, so I'll just leave it here for other readers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75795924,
                        "answer_post": "In simple terms, a party (client or server) will trust another party (server or client) if the other party\u2019s certificate chain as provided on the wire can be traced back (recursively via signers) to the CACERTS stored in the original party\u2019s JRE. (or is in the original party\u2019s truststore)\nIt is fairly unusual to use mutually authenticated TLS so client side certificates are rare. In most cases authentication of a client is done with user credentials, api keys, etc. Anyway, it looks like you have the client cert setup correctly.\nIf the server certificate is signed by a Intermediate CA that has a cert held in the client\u2019s CACERTS then no client side intervention is necessary. On the server a keychain from a CACERTS cert down to the server cert needs to be configured via application.yaml, as you correctly show in your question.\nIf the Intermediate CA\u2019s signing cert is not registered in the official Java CACERTS in the client\u2019s JRE then it must be added like this. I find it easier to add untrusted Intermediate CA certs to CACERTS rather than adding the server cert to the client truststore (as you correctly show) because that allows multiple servers to be trusted (because, in a typical corporate environment, they will all have certs signed by the Intermediate CA)\nIf a client can\u2019t build a trusted cert chain to the cert provided by a server an SSL connection will fail with the dreaded \u201cPKIX path building failed\u201d error.\nI find it helpful to load a server GET path (eg /welcome) in a browser to get a look at what cert the server is passing back.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74518957,
                        "answer_post": "Yes. Just adding the root certificate to your client trust store suffice to create the HTTPs successful connection. During the handshake, the certificate is validated from bottom-up way. It means that your Intermediate certificate must be signed by the root CA, and your leaf certificate must be signed by your intermediate CA. As long as your root CA is valid and present in your client's trust store, the connection will be successful.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75941010,
                        "answer_post": "First, I assume you are using Paketo buildpacks, and the documentation explains how you can provide a CA certificate to your JVM Truststore, either at\n\nbuildtime (if you use the same CA certificate for your image across your environments; that's the easiest solution since you just need to provide your CA cert during buildtime and the image is ready to be deployed) or at\nruntime (if your CA cert is going to be different across environments; that's a more complicated option since at deployment time, in kpack, you will need to provide and bind the CA certificate)\n\nIf you choose runtime, then you would need to create a service binding that would link to your CA certificate\nHope that helps!\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73214423,
                        "answer_post": "Either you can add the certificates require to validate the server identity in the default java truststore i.e cacerts or you can set the application environment to use different truststore as mentioned below.\n\napplication.properties\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 77625340,
                        "answer_post": "If you want to specifically use Java SSLContext, you can use a custom TrustManager that directly trusts the specified certificate.\n\nThen use the created TrustManager to create the SSLContext,\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73153710,
                        "answer_post": "LinkedBlockingQueue uses synchronization internally, in the form of ReentrantLock -- that's how it implements the 'blocking' part.\nSomething like this should work:\n\nHere threads compete at the busy flag. One of them wins the right to add to the list, others busy-wait until the winning thread clears the flag.\nThe two calls to AtomicBoolean methods establish proper 'happens-before' relationship between list.add() calls done on different threads, so each thread should observe actual state of the list.\nLinkedList can be used for unbounded queues. For bounded ones, maybe ArrayList with initial capacity set.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73058786,
                        "answer_post": "This works as designed. As the Javadoc suggests, clearAutomatically triggers persistence context clearance, i.e. calls EntityManager.clear(). The Javadoc of that clearly states:\n\nClear the persistence context, causing all managed entities to become detached. Changes made to entities that have not been flushed to the database will not be persisted.\n\nThat's why your modification of s does not get persisted. I guess an explicit call settingsRepository.save(s) should do the trick as it merges the now detached instance to the persistence context again.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76030715,
                        "answer_post": "You configured your resource-server with a JWT decoder and not introspection (opaquetoken in spring configuration) => the access token validation is local to your resource server, not submitted to authorization server.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72716284,
                        "answer_post": "By design, LDAP protocol automatically switches the authentication from \"simple\" to \"none\" if a password is not supplied (see documentation), resulting in an unauthenticated (but successful) binding, hence no error at this moment but only after when doing an operation that requires to be authenticated.\nSo I guess it's fine to make the code throw an AuthenticationException if the password string is empty, just as InitialDirContext does when a wrong password is supplied, so that you can catch both seamlessly.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72819015,
                        "answer_post": "If suddenly someone is faced with a similar problem, then here is the solution.\nYou must have 2 certificates: server and client.\nThen you put the server one in the cacerts repository in Java with the command:\n\nkeytool -importcert -storetype PKCS12 -keystore trustStore.p12\n-storepass password -alias mpzCA -file root.crt -noprompt\n\nThen, in the code, do as below:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73465151,
                        "answer_post": "Using a browser to access https://performance.infoworks.technology and checking the certificate confirms that the certificate is not trusted.\nIt is signed by an issuer which is not trusted: IW Root CA.\nYou need to make IW Root CA available on the client, put it into the certificate storage which is used in the context of running your java application to make sure is trusted at the time the request is made.\nAlternatively, for testing only (!), you can disable the certificate validation when making the request.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73507891,
                        "answer_post": "Setting -> BuildTool -> Gradle -> choose java 11 or download something as request\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76865006,
                        "answer_post": "As pointed out in a comment, the problem here has nothing to do with VaadinSession.\nInstead, the problem is that one part of the code uses \"IdCliente\" as the session attribute name and another part of the code uses \"idCliente\". It's recommended to use a constant for magic string values like this to avoid these types of mistakes.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75885986,
                        "answer_post": "Make sure you have the following property set in your application.properties\n\nThis ensures that your server port (8081) is registered with Nacos instead of the management port (8079).\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75301625,
                        "answer_post": "Try $JAVA_HOME/lib/security/cacerts\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77556752,
                        "answer_post": "\ntry this in pom file\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77654306,
                        "answer_post": "try use in your POM file\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73489047,
                        "answer_post": "java version:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76883763,
                        "answer_post": "For CORS Configuration\n\nFor Token\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77289237,
                        "answer_post": "you can use authenticationManagerResolver interface\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72711160,
                        "answer_post": "use this data class\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74213490,
                        "answer_post": "Add Following to monitor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73145198,
                        "answer_post": "Since version 6.3.3 the Microsoft JDBC Driver for SQL allows, to specify a custom implementation of javax.net.ssl.TrustManager through connection properties. You can specify a class name and a constructor parameter (e.g. a file name or the certificate in PEM format).\nSee here, for more detailed instructions and a simple example of a custom TrustManager. The functionality of the sslrootcert option of the Postgres driver is implemented in a similar way here.\n",
                        "contain_knowledge": 1
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "The easiest way is to let Java download the server certificate for you and then just grab and save it.\nThis can be done by using a custom X509TrustManager implementation as it it shown for example in this answer.\nThe part you need to modify is checkServerTrusted:\n\nIn the end you only have to call getEncoded() on the saved serverCert to get it's ASN.1 DER encoded representation as byte[] which you can save to a file like server.cer.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The easiest way is to let Java download the server certificate for you and then just grab and save it.\nThis can be done by using a custom X509TrustManager implementation as it it shown for example in this answer.\nThe part you need to modify is checkServerTrusted:\n\nIn the end you only have to call getEncoded() on the saved serverCert to get it's ASN.1 DER encoded representation as byte[] which you can save to a file like server.cer.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I think I solved the issue.\nI have a routine that programmatically downloads certificates from SSL protected servers through a socket that handshake and retrieve certificates.\nCurrently the certificate SSL server has some problems in returning the whole chain of certificates (including the intermediary certificates of the CAs that signed the certificate).\nIt is likely that they are problems related to a misconfiguration.\nThis problem can be verified with the command:\nopenssl s_client -showcerts -connect host:port\nThese are the intermediary CAs irrecoverable certs:\ncerts\ncerts\nThese are the intermediary certificates of the CAs:\nIntermediate cert CAs chain\nOn a programmatic level, when JAVA persists the trusted certificates in the Trust-Store, it writes information related to the fact that it was not possible to recover the whole CA chain.\nIt is as if the certificate is self-signed for the trust-store when it is not. In fact, the certificate is not actually trusted (unless you enter it \"manually\" in the trust store).\nWhen making an external call to an application-side https server, the client is not fully aware of the certificate.\nThe error was: \"PKIX path building failed\".\nIt was necessary to use a custom built HTTP client to accept single certificates of which it was not possible to download the whole CA chain.\nObviously it is not a client that can accept self-signed certificates.\nThis client is \"satisfied\" with the single certificate but it is actually a necessary and sufficient condition to perform a secure SSL handshake.\nIn other words to make an external call with RestTemplate what you have to do is change it from:\n\nto:\n\nI think I have given an explanation. What do you think about it?\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "There are two issues here:\n\nFirst, when connecting locally, you can't connect directly - you need to connect through an SSH tunnel instead. See Connecting to an Amazon DocumentDB Cluster from Outside an Amazon VPC for details on how to do this.\nSecond, the .pem certificate file isn't directly usable as a Java trust store. Instead, it contains the certificates which should be imported into a Java trust store (using the keytool Java utility), so that your program can then reference that trust store (via the javax.net.ssl.trustStore system property) in verifying the identity of the DocumentDB server.\n\nContext: The sun.security.* packages (referenced in the Fargate logs you posted) verify the DocumentDB server's identity by attempting to build a valid PKIX certification path from the root CA certificates found in the Java trust store to the certificate presented by the particular DocumentDB server you are targeting. If the Java trust store found at javax.net.ssl.trustStore is either invalid (e.g., because it's a .pem file instead of a valid .jks file), or if it doesn't contain the necessary certificates (e.g., because the root CA certificates found in global-bundle.pem were never imported using the Java keytool utility), PKIX path building fails, meaning the identity of the DocumentDB server cannot be established. See Connecting with TLS Enabled for more details (and be sure to select the \"Java\" tab to see Java-specific instructions.)\n\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nHow do keystores really work? From my understanding, you generate a keystore with the keytool command and that generates a keystore file that is like a small database(?) that contains a self-signed certificate and a public/private key pair.\n\nWell preferably a certificate chain with a leaf and one or more CA certificates; self signed certificates are usually just a way to \"get it working\" without a lot of key management. And the certificate contains the public key, so you only need to store the chain + the private key of the server certificate.\n\nWe then create a truststore that's like a keystore but where we only import the self-signed certificate and the public key and this is what the client uses to connect to the server (I don't really understand this very last part).\n\nNo, again, the public key doesn't need to store separately, it is already included. And you don't need to have the truststore to connect, you need it to verify the trust path to a trust anchor. Usually that is a known root certificate, but for self-signed certificates it is just the one certificate.\n\nHow do we actually use these keys that we generated inside our code? What is the recommended/secure way to do it? I have a feeling that setting system properties and typing a password in plain text in the class isn't the right way to do it but this might be the way to do it.\n\nUsually you try and store the private key in the least accessible way possible while you are still able to use it economically. Banks store private keys in HSM's, hardware security modules. Generally, if you just have a computer, you try to store it in the most secure place possible, e.g. in a system provided key store.\nUsing a key store based on password based encryption (PKCS#12 or PFX keystores and the Java JKS key stores) are indeed not the most secure options. Better choose a very secure password to at least not leak the private key if the store gets stolen.\nNote that Java does contain a PKCS#11 provider that works with HSM's as well as providers to use the Windows certificates / keys.\n\nIf I were to develop an app that uses TLS how would I go about storing the keys in the Client? Would it be possible to pack the key inside the jar file that I'd release for the users to download?\n\nYes, it certainly can be a resource that is packed with the program, but you might need to update your program if you want it to remain current. Actually, that is exactly how most browsers get the trust store; the certificates are delivered with the updates of Firefox and Chrome.\nFor others they are part of OS updates such as with Edge, and you may also have a network specific method of distributing trusted certificates such as the Group Policy in the Windows ecosystem.\n\nLike I said, I followed the tutorial from the docs and combining that with some knowledge I got from other stackoverflow posts I managed to make it work but I'd like to understand how everything really works.\n\nWell, PKIX and TLS operation is a lot of information to take in and understand for sure. One way of making sure that you get the right information is to simply read the X.509 standard. There are many tutorials on the Internet as well.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The fact you're mentioning /etc/pki/ca-trust/extracted/java/cacerts suggests you're using a cacerts file managed by your Linux distribution (presumably based on RedHat/CentOS).\nRemoving the specific certificate from that cacerts file is indeed possible with keytool manually. However, it's likely to be re-generated, and possibly placed back into that file the next time update-ca-trust is executed automatically (e.g. package upgrade) or not.\nWhen using the distribution-managed cacerts file, it's generally better to use the distribution's mechanism.\nOn RedHat/CentOS-based distributions, this can be done by managing individual certificates in /etc/pki/ca-trust/source/anchors/ and using update-ca-trust.\nOn Debian/Ubuntu-based distributions, there is an equivalent with certificates in /usr/share/ca-certificates, assuming the ca-certificates-java package is installed (and then, you can run update-ca-certificates).\n\nAs a side-note, you've tagged your question with client-certificate.\nClient-certificates (and more so their matching private key, i.e. PrivateKeyEntry entries) normally don't belong in the cacerts file at all, which is a \"keystore\" used as a \"truststore\" (typically used as the default truststore for all Java applications running on that system). Those belong to a \"keystore used as a keystore\", not a \"keystore used as a truststore\" (which shouldn't contain private keys).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The reason why a trust store exists is because you are trying to create a secure communication to a web server, and you need to trust the server certificate that they offer. So a trust store contains the trust anchors for that to happen: if a valid trust path can be build to a trust anchor in the trust store then the certificate is deemed valid and - after some additional checks of e.g. the server name - the private key can be used by the server to indicate that it is the server named within the server certificate.\nGreat, so what kind of security needs to be present on your trust store? Well, it is that the trust store is available and unaltered. Having the trust store unavailable will obviously be a big issue. So downloading the trust store every time you need to secure a connection is adding another high availability component to your infrastructure. Maybe you already need one for CRL or OCSP service, but still.\nThe other thing is that the trust store should not be altered in traffic. That basically means that the connection to your service should be free from attacks. The most logical way to do this is to have it protected by TLS. In that case of course you need a trusted certificate. In the end you cannot operate without trusting something. This is why you either have to trust a server based on the cacerts, or to distribute a certificate with the application.\n\"it shouldn't be a problem because it's not accessible by anyone else\". That's not a requirement. Other people may well access the server, as long as they cannot alter the security (and availability) of the connection or the trust store. Read access to the P12 file wouldn't directly influence the availability or trustworthiness of the trust store. That said, the stricter the security of the service that contains the trust store, the better.\nI was kind of afraid that the P12 would not just be a trust store but also a key store containing a private key. Preferably, a private key should not be distributed that way. I didn't see any hint of this happening in your question, so I'll just leave it here for other readers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "I think this could be caused by that you're configuring only a keystore, but not a truststore.\nKey stores are typically used for keeping the keys or certs to provide to a third party. But for validating the provided certificates trust stores are used.\nTry to do something like:\n\nYour trust store has to contain the certificate that is returned by your service or the certificate chain that was used to sign service certificate.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "First, you have to extract the CA certificate from the .pfx file using openssl:\nopenssl pkcs12 -in filename.pfx -passin pass:<password> -info -nokeys > filename.pem.\nDouble check that extraction worked:\nopenssl x509 -in test.pem -noout -text\nThen either create new JKS using the key tool:\nkeytool -import -trustcacerts -keystore test.jks -storepass choose-password -file test.pem -alias CANAME\nOr you can import the certificate into the existing trust store:\nkeytool -import -keystore cacerts -storepass changeit -file test.pem -alias CANAME -storetype JKS\nUsually you would use openssl to interact with most certificate file formats and keytool with java key stores only (JKS)\n==============.\nUpdate\nPKCS12 is an archive file format for storing private keys and X.509 certificates with filename extensions .p12 or .pfx\nTo be able to work with .pfx files you would use openssl pkcs12 command.  I am guessing x509 command returns first certificate it finds.\nPKCS12 wiki\nkeytool Manages a keystore (database) of cryptographic keys, X.509 certificate chains, and trusted certificates.\nI think it only works with java keystores .jks or .bcfks (Bouncy Castle FIPS keyStore) etc..\nI think you might actually be able to import certificates directly from .pfx file to a java keystore using keytool.\nkeytool -importkeystore -srckeystore mypfxfile.pfx -srcstoretype pkcs12 -destkeystore clientcert.jks -deststoretype JKS\nThat could also import the private key if it's in the .pfx file but I am not sure.\nHope that helps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You have actually created a certificate signing request with the above command.\nTo generate just a public-private key pair, you can use:\n\nHowever, a trust store contains certificates, not public keys.\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "environment": {
                "finetuned_dpr": [
                    {
                        "id": 77567231,
                        "answer_post": "There's a difference between the sample app and your code.\nThe sample app comes with a pre-configured list of trusted roots (EU LOTL).\nYour code comes with an empty CommonTrustedCertificateSource (i.e., no certificate is trusted)\nSee the DSS FAQ\n\nWhen validating a signature I receive INDETERMINATE/NO_CERTIFICATE_CHAIN_FOUND indication\n\n\nThe result means the validator was not able to reach a trust anchor when validating the certificate chain of the signature. More likely the issue is caused by the fact you have not configured a trusted certificate source within the used CertificateVerifier. To do it, you need to add trust anchors to the instance of CertificateVerifier you use within DocumentValidator:\n\nSo you need to add some certificates to the CommonTrustedCertificateSource. If you're only verifying signatures created by yourself, add your CA root/your signing certificate to the trusted source. If you're verifying third-party signatures, the solution is more complex. For example, you could extract all certificated from a PDF and add them to the trusted list before validation\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77390571,
                        "answer_post": "\nunable to find valid certification path to requested target\n\nThe server's certificate is not trusted. You should get a CA to issue a certificate for the server. If it is already a valid cert, make sure to provide the \"certificate chain\" when configuring the server, not just the bare server certificate.\nIf you didn't intend to use a typical \"browser-trusted CA,\" you can sign the certificate with your own CA and use that CA's certificate as a trust source:\n\nThere are many sites and scripts that describe how to make your own CA and sign server certificates, if that is what you end up wanting. For reference, this is the process for gRPC's tests.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77269126,
                        "answer_post": "If the certificate is added to the truststore that the socket uses (creating an array of TrustManagers and passing that to an SSLContext), then the SSLSocket seems to treat it as valid. Testing this using a dummy certificate that expires 1 second after creation, this seems to be correct; the client connects without exceptions or issues and can send messages.\nTherefore, if the client in question explicitly trusts the certificate, the client should be able to connect.\nHowever, if another implementation is being used that rejects expired certificates, the client will most likely throw an exception.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75941010,
                        "answer_post": "First, I assume you are using Paketo buildpacks, and the documentation explains how you can provide a CA certificate to your JVM Truststore, either at\n\nbuildtime (if you use the same CA certificate for your image across your environments; that's the easiest solution since you just need to provide your CA cert during buildtime and the image is ready to be deployed) or at\nruntime (if your CA cert is going to be different across environments; that's a more complicated option since at deployment time, in kpack, you will need to provide and bind the CA certificate)\n\nIf you choose runtime, then you would need to create a service binding that would link to your CA certificate\nHope that helps!\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77291978,
                        "answer_post": "This is default behavior when your make use of self signed certificate in server machine.\n\"I want to avoid adding the .p12 certificate to the truststore.\" this is exact same reason why server certificates are added to the truststore as a client.\nThink about it ideally request to server should only and only come from legitimate clients (in your case spring app is client to redis server). adding certificate to truststore will make sure that only trusted clients are authorized to make the request.\nSo to answer your question adding certs to truststore is a common/well known practice done in web world.\nHope this helps. Thanks.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74518957,
                        "answer_post": "Yes. Just adding the root certificate to your client trust store suffice to create the HTTPs successful connection. During the handshake, the certificate is validated from bottom-up way. It means that your Intermediate certificate must be signed by the root CA, and your leaf certificate must be signed by your intermediate CA. As long as your root CA is valid and present in your client's trust store, the connection will be successful.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74553954,
                        "answer_post": "I think I solved the issue.\nI have a routine that programmatically downloads certificates from SSL protected servers through a socket that handshake and retrieve certificates.\nCurrently the certificate SSL server has some problems in returning the whole chain of certificates (including the intermediary certificates of the CAs that signed the certificate).\nIt is likely that they are problems related to a misconfiguration.\nThis problem can be verified with the command:\nopenssl s_client -showcerts -connect host:port\nThese are the intermediary CAs irrecoverable certs:\ncerts\ncerts\nThese are the intermediary certificates of the CAs:\nIntermediate cert CAs chain\nOn a programmatic level, when JAVA persists the trusted certificates in the Trust-Store, it writes information related to the fact that it was not possible to recover the whole CA chain.\nIt is as if the certificate is self-signed for the trust-store when it is not. In fact, the certificate is not actually trusted (unless you enter it \"manually\" in the trust store).\nWhen making an external call to an application-side https server, the client is not fully aware of the certificate.\nThe error was: \"PKIX path building failed\".\nIt was necessary to use a custom built HTTP client to accept single certificates of which it was not possible to download the whole CA chain.\nObviously it is not a client that can accept self-signed certificates.\nThis client is \"satisfied\" with the single certificate but it is actually a necessary and sufficient condition to perform a secure SSL handshake.\nIn other words to make an external call with RestTemplate what you have to do is change it from:\n\nto:\n\nI think I have given an explanation. What do you think about it?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76800264,
                        "answer_post": "The reason why a trust store exists is because you are trying to create a secure communication to a web server, and you need to trust the server certificate that they offer. So a trust store contains the trust anchors for that to happen: if a valid trust path can be build to a trust anchor in the trust store then the certificate is deemed valid and - after some additional checks of e.g. the server name - the private key can be used by the server to indicate that it is the server named within the server certificate.\nGreat, so what kind of security needs to be present on your trust store? Well, it is that the trust store is available and unaltered. Having the trust store unavailable will obviously be a big issue. So downloading the trust store every time you need to secure a connection is adding another high availability component to your infrastructure. Maybe you already need one for CRL or OCSP service, but still.\nThe other thing is that the trust store should not be altered in traffic. That basically means that the connection to your service should be free from attacks. The most logical way to do this is to have it protected by TLS. In that case of course you need a trusted certificate. In the end you cannot operate without trusting something. This is why you either have to trust a server based on the cacerts, or to distribute a certificate with the application.\n\"it shouldn't be a problem because it's not accessible by anyone else\". That's not a requirement. Other people may well access the server, as long as they cannot alter the security (and availability) of the connection or the trust store. Read access to the P12 file wouldn't directly influence the availability or trustworthiness of the trust store. That said, the stricter the security of the service that contains the trust store, the better.\nI was kind of afraid that the P12 would not just be a trust store but also a key store containing a private key. Preferably, a private key should not be distributed that way. I didn't see any hint of this happening in your question, so I'll just leave it here for other readers.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 75795924,
                        "answer_post": "In simple terms, a party (client or server) will trust another party (server or client) if the other party\u2019s certificate chain as provided on the wire can be traced back (recursively via signers) to the CACERTS stored in the original party\u2019s JRE. (or is in the original party\u2019s truststore)\nIt is fairly unusual to use mutually authenticated TLS so client side certificates are rare. In most cases authentication of a client is done with user credentials, api keys, etc. Anyway, it looks like you have the client cert setup correctly.\nIf the server certificate is signed by a Intermediate CA that has a cert held in the client\u2019s CACERTS then no client side intervention is necessary. On the server a keychain from a CACERTS cert down to the server cert needs to be configured via application.yaml, as you correctly show in your question.\nIf the Intermediate CA\u2019s signing cert is not registered in the official Java CACERTS in the client\u2019s JRE then it must be added like this. I find it easier to add untrusted Intermediate CA certs to CACERTS rather than adding the server cert to the client truststore (as you correctly show) because that allows multiple servers to be trusted (because, in a typical corporate environment, they will all have certs signed by the Intermediate CA)\nIf a client can\u2019t build a trusted cert chain to the cert provided by a server an SSL connection will fail with the dreaded \u201cPKIX path building failed\u201d error.\nI find it helpful to load a server GET path (eg /welcome) in a browser to get a look at what cert the server is passing back.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73214423,
                        "answer_post": "Either you can add the certificates require to validate the server identity in the default java truststore i.e cacerts or you can set the application environment to use different truststore as mentioned below.\n\napplication.properties\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 77625340,
                        "answer_post": "If you want to specifically use Java SSLContext, you can use a custom TrustManager that directly trusts the specified certificate.\n\nThen use the created TrustManager to create the SSLContext,\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73058786,
                        "answer_post": "This works as designed. As the Javadoc suggests, clearAutomatically triggers persistence context clearance, i.e. calls EntityManager.clear(). The Javadoc of that clearly states:\n\nClear the persistence context, causing all managed entities to become detached. Changes made to entities that have not been flushed to the database will not be persisted.\n\nThat's why your modification of s does not get persisted. I guess an explicit call settingsRepository.save(s) should do the trick as it merges the now detached instance to the persistence context again.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73153710,
                        "answer_post": "LinkedBlockingQueue uses synchronization internally, in the form of ReentrantLock -- that's how it implements the 'blocking' part.\nSomething like this should work:\n\nHere threads compete at the busy flag. One of them wins the right to add to the list, others busy-wait until the winning thread clears the flag.\nThe two calls to AtomicBoolean methods establish proper 'happens-before' relationship between list.add() calls done on different threads, so each thread should observe actual state of the list.\nLinkedList can be used for unbounded queues. For bounded ones, maybe ArrayList with initial capacity set.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76030715,
                        "answer_post": "You configured your resource-server with a JWT decoder and not introspection (opaquetoken in spring configuration) => the access token validation is local to your resource server, not submitted to authorization server.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73465151,
                        "answer_post": "Using a browser to access https://performance.infoworks.technology and checking the certificate confirms that the certificate is not trusted.\nIt is signed by an issuer which is not trusted: IW Root CA.\nYou need to make IW Root CA available on the client, put it into the certificate storage which is used in the context of running your java application to make sure is trusted at the time the request is made.\nAlternatively, for testing only (!), you can disable the certificate validation when making the request.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75885986,
                        "answer_post": "Make sure you have the following property set in your application.properties\n\nThis ensures that your server port (8081) is registered with Nacos instead of the management port (8079).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72819015,
                        "answer_post": "If suddenly someone is faced with a similar problem, then here is the solution.\nYou must have 2 certificates: server and client.\nThen you put the server one in the cacerts repository in Java with the command:\n\nkeytool -importcert -storetype PKCS12 -keystore trustStore.p12\n-storepass password -alias mpzCA -file root.crt -noprompt\n\nThen, in the code, do as below:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76370147,
                        "answer_post": "First, you must create a context source, which includes your LDAP url (url), your Manager DN or the Base DN from which your users belong (managerDn), your LDAP password to authenticate yourself / your app to the server, and, last but not least, the connection pooling flag for LDAP (setPooled), which is recommended if you have a large number of users.\n\nSecond, you must configure the authentication manager object, which will assist spring boot in recognising that you will be using LDAP for authentication.\n\nFinally, this is entirely optional. If you need to look up an LDAP user in your app, this interface will come in handy.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74817070,
                        "answer_post": "The ContextResourceLoaderAutoConfiguration class indirectly imports ContextResourceLoaderConfiguration.Registrar, which has a hard-coded bean registration for an AmazonS3Client buried inside it. Neither the registrar nor the auto-configuration class supports the usual well-behaved property conditions to disable S3 client creation (e.g., cloud.aws.{s3,loader}.enabled=false).\nIn order to suppress creation of the S3 client (which is unconditional), the ContextResourceLoaderAutoConfiguration class must be listed in the exclude parameter of the @EnableAutoConfiguration or @SpringBootApplication annotation.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72716284,
                        "answer_post": "By design, LDAP protocol automatically switches the authentication from \"simple\" to \"none\" if a password is not supplied (see documentation), resulting in an unauthenticated (but successful) binding, hence no error at this moment but only after when doing an operation that requires to be authenticated.\nSo I guess it's fine to make the code throw an AuthenticationException if the password string is empty, just as InitialDirContext does when a wrong password is supplied, so that you can catch both seamlessly.\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76883763,
                        "answer_post": "For CORS Configuration\n\nFor Token\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77556752,
                        "answer_post": "\ntry this in pom file\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75301625,
                        "answer_post": "Try $JAVA_HOME/lib/security/cacerts\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77075486,
                        "answer_post": "pom.xml\n\napplication.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74213490,
                        "answer_post": "Add Following to monitor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73145198,
                        "answer_post": "Since version 6.3.3 the Microsoft JDBC Driver for SQL allows, to specify a custom implementation of javax.net.ssl.TrustManager through connection properties. You can specify a class name and a constructor parameter (e.g. a file name or the certificate in PEM format).\nSee here, for more detailed instructions and a simple example of a custom TrustManager. The functionality of the sslrootcert option of the Postgres driver is implemented in a similar way here.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73489047,
                        "answer_post": "java version:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77410074,
                        "answer_post": "Thread.setUncaughtExceptionHandler\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77654306,
                        "answer_post": "try use in your POM file\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "The easiest way is to let Java download the server certificate for you and then just grab and save it.\nThis can be done by using a custom X509TrustManager implementation as it it shown for example in this answer.\nThe part you need to modify is checkServerTrusted:\n\nIn the end you only have to call getEncoded() on the saved serverCert to get it's ASN.1 DER encoded representation as byte[] which you can save to a file like server.cer.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The easiest way is to let Java download the server certificate for you and then just grab and save it.\nThis can be done by using a custom X509TrustManager implementation as it it shown for example in this answer.\nThe part you need to modify is checkServerTrusted:\n\nIn the end you only have to call getEncoded() on the saved serverCert to get it's ASN.1 DER encoded representation as byte[] which you can save to a file like server.cer.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I think I solved the issue.\nI have a routine that programmatically downloads certificates from SSL protected servers through a socket that handshake and retrieve certificates.\nCurrently the certificate SSL server has some problems in returning the whole chain of certificates (including the intermediary certificates of the CAs that signed the certificate).\nIt is likely that they are problems related to a misconfiguration.\nThis problem can be verified with the command:\nopenssl s_client -showcerts -connect host:port\nThese are the intermediary CAs irrecoverable certs:\ncerts\ncerts\nThese are the intermediary certificates of the CAs:\nIntermediate cert CAs chain\nOn a programmatic level, when JAVA persists the trusted certificates in the Trust-Store, it writes information related to the fact that it was not possible to recover the whole CA chain.\nIt is as if the certificate is self-signed for the trust-store when it is not. In fact, the certificate is not actually trusted (unless you enter it \"manually\" in the trust store).\nWhen making an external call to an application-side https server, the client is not fully aware of the certificate.\nThe error was: \"PKIX path building failed\".\nIt was necessary to use a custom built HTTP client to accept single certificates of which it was not possible to download the whole CA chain.\nObviously it is not a client that can accept self-signed certificates.\nThis client is \"satisfied\" with the single certificate but it is actually a necessary and sufficient condition to perform a secure SSL handshake.\nIn other words to make an external call with RestTemplate what you have to do is change it from:\n\nto:\n\nI think I have given an explanation. What do you think about it?\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "There are two issues here:\n\nFirst, when connecting locally, you can't connect directly - you need to connect through an SSH tunnel instead. See Connecting to an Amazon DocumentDB Cluster from Outside an Amazon VPC for details on how to do this.\nSecond, the .pem certificate file isn't directly usable as a Java trust store. Instead, it contains the certificates which should be imported into a Java trust store (using the keytool Java utility), so that your program can then reference that trust store (via the javax.net.ssl.trustStore system property) in verifying the identity of the DocumentDB server.\n\nContext: The sun.security.* packages (referenced in the Fargate logs you posted) verify the DocumentDB server's identity by attempting to build a valid PKIX certification path from the root CA certificates found in the Java trust store to the certificate presented by the particular DocumentDB server you are targeting. If the Java trust store found at javax.net.ssl.trustStore is either invalid (e.g., because it's a .pem file instead of a valid .jks file), or if it doesn't contain the necessary certificates (e.g., because the root CA certificates found in global-bundle.pem were never imported using the Java keytool utility), PKIX path building fails, meaning the identity of the DocumentDB server cannot be established. See Connecting with TLS Enabled for more details (and be sure to select the \"Java\" tab to see Java-specific instructions.)\n\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "\nHow do keystores really work? From my understanding, you generate a keystore with the keytool command and that generates a keystore file that is like a small database(?) that contains a self-signed certificate and a public/private key pair.\n\nWell preferably a certificate chain with a leaf and one or more CA certificates; self signed certificates are usually just a way to \"get it working\" without a lot of key management. And the certificate contains the public key, so you only need to store the chain + the private key of the server certificate.\n\nWe then create a truststore that's like a keystore but where we only import the self-signed certificate and the public key and this is what the client uses to connect to the server (I don't really understand this very last part).\n\nNo, again, the public key doesn't need to store separately, it is already included. And you don't need to have the truststore to connect, you need it to verify the trust path to a trust anchor. Usually that is a known root certificate, but for self-signed certificates it is just the one certificate.\n\nHow do we actually use these keys that we generated inside our code? What is the recommended/secure way to do it? I have a feeling that setting system properties and typing a password in plain text in the class isn't the right way to do it but this might be the way to do it.\n\nUsually you try and store the private key in the least accessible way possible while you are still able to use it economically. Banks store private keys in HSM's, hardware security modules. Generally, if you just have a computer, you try to store it in the most secure place possible, e.g. in a system provided key store.\nUsing a key store based on password based encryption (PKCS#12 or PFX keystores and the Java JKS key stores) are indeed not the most secure options. Better choose a very secure password to at least not leak the private key if the store gets stolen.\nNote that Java does contain a PKCS#11 provider that works with HSM's as well as providers to use the Windows certificates / keys.\n\nIf I were to develop an app that uses TLS how would I go about storing the keys in the Client? Would it be possible to pack the key inside the jar file that I'd release for the users to download?\n\nYes, it certainly can be a resource that is packed with the program, but you might need to update your program if you want it to remain current. Actually, that is exactly how most browsers get the trust store; the certificates are delivered with the updates of Firefox and Chrome.\nFor others they are part of OS updates such as with Edge, and you may also have a network specific method of distributing trusted certificates such as the Group Policy in the Windows ecosystem.\n\nLike I said, I followed the tutorial from the docs and combining that with some knowledge I got from other stackoverflow posts I managed to make it work but I'd like to understand how everything really works.\n\nWell, PKIX and TLS operation is a lot of information to take in and understand for sure. One way of making sure that you get the right information is to simply read the X.509 standard. There are many tutorials on the Internet as well.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The fact you're mentioning /etc/pki/ca-trust/extracted/java/cacerts suggests you're using a cacerts file managed by your Linux distribution (presumably based on RedHat/CentOS).\nRemoving the specific certificate from that cacerts file is indeed possible with keytool manually. However, it's likely to be re-generated, and possibly placed back into that file the next time update-ca-trust is executed automatically (e.g. package upgrade) or not.\nWhen using the distribution-managed cacerts file, it's generally better to use the distribution's mechanism.\nOn RedHat/CentOS-based distributions, this can be done by managing individual certificates in /etc/pki/ca-trust/source/anchors/ and using update-ca-trust.\nOn Debian/Ubuntu-based distributions, there is an equivalent with certificates in /usr/share/ca-certificates, assuming the ca-certificates-java package is installed (and then, you can run update-ca-certificates).\n\nAs a side-note, you've tagged your question with client-certificate.\nClient-certificates (and more so their matching private key, i.e. PrivateKeyEntry entries) normally don't belong in the cacerts file at all, which is a \"keystore\" used as a \"truststore\" (typically used as the default truststore for all Java applications running on that system). Those belong to a \"keystore used as a keystore\", not a \"keystore used as a truststore\" (which shouldn't contain private keys).\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The reason why a trust store exists is because you are trying to create a secure communication to a web server, and you need to trust the server certificate that they offer. So a trust store contains the trust anchors for that to happen: if a valid trust path can be build to a trust anchor in the trust store then the certificate is deemed valid and - after some additional checks of e.g. the server name - the private key can be used by the server to indicate that it is the server named within the server certificate.\nGreat, so what kind of security needs to be present on your trust store? Well, it is that the trust store is available and unaltered. Having the trust store unavailable will obviously be a big issue. So downloading the trust store every time you need to secure a connection is adding another high availability component to your infrastructure. Maybe you already need one for CRL or OCSP service, but still.\nThe other thing is that the trust store should not be altered in traffic. That basically means that the connection to your service should be free from attacks. The most logical way to do this is to have it protected by TLS. In that case of course you need a trusted certificate. In the end you cannot operate without trusting something. This is why you either have to trust a server based on the cacerts, or to distribute a certificate with the application.\n\"it shouldn't be a problem because it's not accessible by anyone else\". That's not a requirement. Other people may well access the server, as long as they cannot alter the security (and availability) of the connection or the trust store. Read access to the P12 file wouldn't directly influence the availability or trustworthiness of the trust store. That said, the stricter the security of the service that contains the trust store, the better.\nI was kind of afraid that the P12 would not just be a trust store but also a key store containing a private key. Preferably, a private key should not be distributed that way. I didn't see any hint of this happening in your question, so I'll just leave it here for other readers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "I think this could be caused by that you're configuring only a keystore, but not a truststore.\nKey stores are typically used for keeping the keys or certs to provide to a third party. But for validating the provided certificates trust stores are used.\nTry to do something like:\n\nYour trust store has to contain the certificate that is returned by your service or the certificate chain that was used to sign service certificate.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First, you have to extract the CA certificate from the .pfx file using openssl:\nopenssl pkcs12 -in filename.pfx -passin pass:<password> -info -nokeys > filename.pem.\nDouble check that extraction worked:\nopenssl x509 -in test.pem -noout -text\nThen either create new JKS using the key tool:\nkeytool -import -trustcacerts -keystore test.jks -storepass choose-password -file test.pem -alias CANAME\nOr you can import the certificate into the existing trust store:\nkeytool -import -keystore cacerts -storepass changeit -file test.pem -alias CANAME -storetype JKS\nUsually you would use openssl to interact with most certificate file formats and keytool with java key stores only (JKS)\n==============.\nUpdate\nPKCS12 is an archive file format for storing private keys and X.509 certificates with filename extensions .p12 or .pfx\nTo be able to work with .pfx files you would use openssl pkcs12 command.  I am guessing x509 command returns first certificate it finds.\nPKCS12 wiki\nkeytool Manages a keystore (database) of cryptographic keys, X.509 certificate chains, and trusted certificates.\nI think it only works with java keystores .jks or .bcfks (Bouncy Castle FIPS keyStore) etc..\nI think you might actually be able to import certificates directly from .pfx file to a java keystore using keytool.\nkeytool -importkeystore -srckeystore mypfxfile.pfx -srcstoretype pkcs12 -destkeystore clientcert.jks -deststoretype JKS\nThat could also import the private key if it's in the .pfx file but I am not sure.\nHope that helps.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You have actually created a certificate signing request with the above command.\nTo generate just a public-private key pair, you can use:\n\nHowever, a trust store contains certificates, not public keys.\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "alternative": {
                "finetuned_dpr": [
                    {
                        "id": 77567231,
                        "answer_post": "There's a difference between the sample app and your code.\nThe sample app comes with a pre-configured list of trusted roots (EU LOTL).\nYour code comes with an empty CommonTrustedCertificateSource (i.e., no certificate is trusted)\nSee the DSS FAQ\n\nWhen validating a signature I receive INDETERMINATE/NO_CERTIFICATE_CHAIN_FOUND indication\n\n\nThe result means the validator was not able to reach a trust anchor when validating the certificate chain of the signature. More likely the issue is caused by the fact you have not configured a trusted certificate source within the used CertificateVerifier. To do it, you need to add trust anchors to the instance of CertificateVerifier you use within DocumentValidator:\n\nSo you need to add some certificates to the CommonTrustedCertificateSource. If you're only verifying signatures created by yourself, add your CA root/your signing certificate to the trusted source. If you're verifying third-party signatures, the solution is more complex. For example, you could extract all certificated from a PDF and add them to the trusted list before validation\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77269126,
                        "answer_post": "If the certificate is added to the truststore that the socket uses (creating an array of TrustManagers and passing that to an SSLContext), then the SSLSocket seems to treat it as valid. Testing this using a dummy certificate that expires 1 second after creation, this seems to be correct; the client connects without exceptions or issues and can send messages.\nTherefore, if the client in question explicitly trusts the certificate, the client should be able to connect.\nHowever, if another implementation is being used that rejects expired certificates, the client will most likely throw an exception.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 77390571,
                        "answer_post": "\nunable to find valid certification path to requested target\n\nThe server's certificate is not trusted. You should get a CA to issue a certificate for the server. If it is already a valid cert, make sure to provide the \"certificate chain\" when configuring the server, not just the bare server certificate.\nIf you didn't intend to use a typical \"browser-trusted CA,\" you can sign the certificate with your own CA and use that CA's certificate as a trust source:\n\nThere are many sites and scripts that describe how to make your own CA and sign server certificates, if that is what you end up wanting. For reference, this is the process for gRPC's tests.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77291978,
                        "answer_post": "This is default behavior when your make use of self signed certificate in server machine.\n\"I want to avoid adding the .p12 certificate to the truststore.\" this is exact same reason why server certificates are added to the truststore as a client.\nThink about it ideally request to server should only and only come from legitimate clients (in your case spring app is client to redis server). adding certificate to truststore will make sure that only trusted clients are authorized to make the request.\nSo to answer your question adding certs to truststore is a common/well known practice done in web world.\nHope this helps. Thanks.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74553954,
                        "answer_post": "I think I solved the issue.\nI have a routine that programmatically downloads certificates from SSL protected servers through a socket that handshake and retrieve certificates.\nCurrently the certificate SSL server has some problems in returning the whole chain of certificates (including the intermediary certificates of the CAs that signed the certificate).\nIt is likely that they are problems related to a misconfiguration.\nThis problem can be verified with the command:\nopenssl s_client -showcerts -connect host:port\nThese are the intermediary CAs irrecoverable certs:\ncerts\ncerts\nThese are the intermediary certificates of the CAs:\nIntermediate cert CAs chain\nOn a programmatic level, when JAVA persists the trusted certificates in the Trust-Store, it writes information related to the fact that it was not possible to recover the whole CA chain.\nIt is as if the certificate is self-signed for the trust-store when it is not. In fact, the certificate is not actually trusted (unless you enter it \"manually\" in the trust store).\nWhen making an external call to an application-side https server, the client is not fully aware of the certificate.\nThe error was: \"PKIX path building failed\".\nIt was necessary to use a custom built HTTP client to accept single certificates of which it was not possible to download the whole CA chain.\nObviously it is not a client that can accept self-signed certificates.\nThis client is \"satisfied\" with the single certificate but it is actually a necessary and sufficient condition to perform a secure SSL handshake.\nIn other words to make an external call with RestTemplate what you have to do is change it from:\n\nto:\n\nI think I have given an explanation. What do you think about it?\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 76800264,
                        "answer_post": "The reason why a trust store exists is because you are trying to create a secure communication to a web server, and you need to trust the server certificate that they offer. So a trust store contains the trust anchors for that to happen: if a valid trust path can be build to a trust anchor in the trust store then the certificate is deemed valid and - after some additional checks of e.g. the server name - the private key can be used by the server to indicate that it is the server named within the server certificate.\nGreat, so what kind of security needs to be present on your trust store? Well, it is that the trust store is available and unaltered. Having the trust store unavailable will obviously be a big issue. So downloading the trust store every time you need to secure a connection is adding another high availability component to your infrastructure. Maybe you already need one for CRL or OCSP service, but still.\nThe other thing is that the trust store should not be altered in traffic. That basically means that the connection to your service should be free from attacks. The most logical way to do this is to have it protected by TLS. In that case of course you need a trusted certificate. In the end you cannot operate without trusting something. This is why you either have to trust a server based on the cacerts, or to distribute a certificate with the application.\n\"it shouldn't be a problem because it's not accessible by anyone else\". That's not a requirement. Other people may well access the server, as long as they cannot alter the security (and availability) of the connection or the trust store. Read access to the P12 file wouldn't directly influence the availability or trustworthiness of the trust store. That said, the stricter the security of the service that contains the trust store, the better.\nI was kind of afraid that the P12 would not just be a trust store but also a key store containing a private key. Preferably, a private key should not be distributed that way. I didn't see any hint of this happening in your question, so I'll just leave it here for other readers.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 74518957,
                        "answer_post": "Yes. Just adding the root certificate to your client trust store suffice to create the HTTPs successful connection. During the handshake, the certificate is validated from bottom-up way. It means that your Intermediate certificate must be signed by the root CA, and your leaf certificate must be signed by your intermediate CA. As long as your root CA is valid and present in your client's trust store, the connection will be successful.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73214423,
                        "answer_post": "Either you can add the certificates require to validate the server identity in the default java truststore i.e cacerts or you can set the application environment to use different truststore as mentioned below.\n\napplication.properties\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75795924,
                        "answer_post": "In simple terms, a party (client or server) will trust another party (server or client) if the other party\u2019s certificate chain as provided on the wire can be traced back (recursively via signers) to the CACERTS stored in the original party\u2019s JRE. (or is in the original party\u2019s truststore)\nIt is fairly unusual to use mutually authenticated TLS so client side certificates are rare. In most cases authentication of a client is done with user credentials, api keys, etc. Anyway, it looks like you have the client cert setup correctly.\nIf the server certificate is signed by a Intermediate CA that has a cert held in the client\u2019s CACERTS then no client side intervention is necessary. On the server a keychain from a CACERTS cert down to the server cert needs to be configured via application.yaml, as you correctly show in your question.\nIf the Intermediate CA\u2019s signing cert is not registered in the official Java CACERTS in the client\u2019s JRE then it must be added like this. I find it easier to add untrusted Intermediate CA certs to CACERTS rather than adding the server cert to the client truststore (as you correctly show) because that allows multiple servers to be trusted (because, in a typical corporate environment, they will all have certs signed by the Intermediate CA)\nIf a client can\u2019t build a trusted cert chain to the cert provided by a server an SSL connection will fail with the dreaded \u201cPKIX path building failed\u201d error.\nI find it helpful to load a server GET path (eg /welcome) in a browser to get a look at what cert the server is passing back.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77625340,
                        "answer_post": "If you want to specifically use Java SSLContext, you can use a custom TrustManager that directly trusts the specified certificate.\n\nThen use the created TrustManager to create the SSLContext,\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 77625340,
                        "answer_post": "If you want to specifically use Java SSLContext, you can use a custom TrustManager that directly trusts the specified certificate.\n\nThen use the created TrustManager to create the SSLContext,\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 73153710,
                        "answer_post": "LinkedBlockingQueue uses synchronization internally, in the form of ReentrantLock -- that's how it implements the 'blocking' part.\nSomething like this should work:\n\nHere threads compete at the busy flag. One of them wins the right to add to the list, others busy-wait until the winning thread clears the flag.\nThe two calls to AtomicBoolean methods establish proper 'happens-before' relationship between list.add() calls done on different threads, so each thread should observe actual state of the list.\nLinkedList can be used for unbounded queues. For bounded ones, maybe ArrayList with initial capacity set.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73058786,
                        "answer_post": "This works as designed. As the Javadoc suggests, clearAutomatically triggers persistence context clearance, i.e. calls EntityManager.clear(). The Javadoc of that clearly states:\n\nClear the persistence context, causing all managed entities to become detached. Changes made to entities that have not been flushed to the database will not be persisted.\n\nThat's why your modification of s does not get persisted. I guess an explicit call settingsRepository.save(s) should do the trick as it merges the now detached instance to the persistence context again.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 72716284,
                        "answer_post": "By design, LDAP protocol automatically switches the authentication from \"simple\" to \"none\" if a password is not supplied (see documentation), resulting in an unauthenticated (but successful) binding, hence no error at this moment but only after when doing an operation that requires to be authenticated.\nSo I guess it's fine to make the code throw an AuthenticationException if the password string is empty, just as InitialDirContext does when a wrong password is supplied, so that you can catch both seamlessly.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76030715,
                        "answer_post": "You configured your resource-server with a JWT decoder and not introspection (opaquetoken in spring configuration) => the access token validation is local to your resource server, not submitted to authorization server.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73465151,
                        "answer_post": "Using a browser to access https://performance.infoworks.technology and checking the certificate confirms that the certificate is not trusted.\nIt is signed by an issuer which is not trusted: IW Root CA.\nYou need to make IW Root CA available on the client, put it into the certificate storage which is used in the context of running your java application to make sure is trusted at the time the request is made.\nAlternatively, for testing only (!), you can disable the certificate validation when making the request.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74817070,
                        "answer_post": "The ContextResourceLoaderAutoConfiguration class indirectly imports ContextResourceLoaderConfiguration.Registrar, which has a hard-coded bean registration for an AmazonS3Client buried inside it. Neither the registrar nor the auto-configuration class supports the usual well-behaved property conditions to disable S3 client creation (e.g., cloud.aws.{s3,loader}.enabled=false).\nIn order to suppress creation of the S3 client (which is unconditional), the ContextResourceLoaderAutoConfiguration class must be listed in the exclude parameter of the @EnableAutoConfiguration or @SpringBootApplication annotation.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 78891266,
                        "answer_post": "The message will continue to be hidden to other consumers until the visibility timeout expires.\nYou can however inject the instance of Visibility into your method and change the visibility to 0 in your exception handler. This will make the message visible to other consumers immediately.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77049872,
                        "answer_post": "thenApply may block the thread if the previous stage has already completed (in your case it has not). thenApplyAsync is guaranteed to not block the current thread even if it has already completed.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74987239,
                        "answer_post": "Because JVMS doesn't allow access to private members of a different class, whether it is an inner class or not. JDK 11 added the concept of nestmates to overcome this limitation.\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 72476955,
                        "answer_post": "define in your pom.xml the validation dependency:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 75301625,
                        "answer_post": "Try $JAVA_HOME/lib/security/cacerts\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77556752,
                        "answer_post": "\ntry this in pom file\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73489047,
                        "answer_post": "java version:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74213490,
                        "answer_post": "Add Following to monitor\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76883763,
                        "answer_post": "For CORS Configuration\n\nFor Token\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77410074,
                        "answer_post": "Thread.setUncaughtExceptionHandler\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77289237,
                        "answer_post": "you can use authenticationManagerResolver interface\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 77654306,
                        "answer_post": "try use in your POM file\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 76095804,
                        "answer_post": "See this please\nfor Java\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "The easiest way is to let Java download the server certificate for you and then just grab and save it.\nThis can be done by using a custom X509TrustManager implementation as it it shown for example in this answer.\nThe part you need to modify is checkServerTrusted:\n\nIn the end you only have to call getEncoded() on the saved serverCert to get it's ASN.1 DER encoded representation as byte[] which you can save to a file like server.cer.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The easiest way is to let Java download the server certificate for you and then just grab and save it.\nThis can be done by using a custom X509TrustManager implementation as it it shown for example in this answer.\nThe part you need to modify is checkServerTrusted:\n\nIn the end you only have to call getEncoded() on the saved serverCert to get it's ASN.1 DER encoded representation as byte[] which you can save to a file like server.cer.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I think I solved the issue.\nI have a routine that programmatically downloads certificates from SSL protected servers through a socket that handshake and retrieve certificates.\nCurrently the certificate SSL server has some problems in returning the whole chain of certificates (including the intermediary certificates of the CAs that signed the certificate).\nIt is likely that they are problems related to a misconfiguration.\nThis problem can be verified with the command:\nopenssl s_client -showcerts -connect host:port\nThese are the intermediary CAs irrecoverable certs:\ncerts\ncerts\nThese are the intermediary certificates of the CAs:\nIntermediate cert CAs chain\nOn a programmatic level, when JAVA persists the trusted certificates in the Trust-Store, it writes information related to the fact that it was not possible to recover the whole CA chain.\nIt is as if the certificate is self-signed for the trust-store when it is not. In fact, the certificate is not actually trusted (unless you enter it \"manually\" in the trust store).\nWhen making an external call to an application-side https server, the client is not fully aware of the certificate.\nThe error was: \"PKIX path building failed\".\nIt was necessary to use a custom built HTTP client to accept single certificates of which it was not possible to download the whole CA chain.\nObviously it is not a client that can accept self-signed certificates.\nThis client is \"satisfied\" with the single certificate but it is actually a necessary and sufficient condition to perform a secure SSL handshake.\nIn other words to make an external call with RestTemplate what you have to do is change it from:\n\nto:\n\nI think I have given an explanation. What do you think about it?\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "There are two issues here:\n\nFirst, when connecting locally, you can't connect directly - you need to connect through an SSH tunnel instead. See Connecting to an Amazon DocumentDB Cluster from Outside an Amazon VPC for details on how to do this.\nSecond, the .pem certificate file isn't directly usable as a Java trust store. Instead, it contains the certificates which should be imported into a Java trust store (using the keytool Java utility), so that your program can then reference that trust store (via the javax.net.ssl.trustStore system property) in verifying the identity of the DocumentDB server.\n\nContext: The sun.security.* packages (referenced in the Fargate logs you posted) verify the DocumentDB server's identity by attempting to build a valid PKIX certification path from the root CA certificates found in the Java trust store to the certificate presented by the particular DocumentDB server you are targeting. If the Java trust store found at javax.net.ssl.trustStore is either invalid (e.g., because it's a .pem file instead of a valid .jks file), or if it doesn't contain the necessary certificates (e.g., because the root CA certificates found in global-bundle.pem were never imported using the Java keytool utility), PKIX path building fails, meaning the identity of the DocumentDB server cannot be established. See Connecting with TLS Enabled for more details (and be sure to select the \"Java\" tab to see Java-specific instructions.)\n\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "\nHow do keystores really work? From my understanding, you generate a keystore with the keytool command and that generates a keystore file that is like a small database(?) that contains a self-signed certificate and a public/private key pair.\n\nWell preferably a certificate chain with a leaf and one or more CA certificates; self signed certificates are usually just a way to \"get it working\" without a lot of key management. And the certificate contains the public key, so you only need to store the chain + the private key of the server certificate.\n\nWe then create a truststore that's like a keystore but where we only import the self-signed certificate and the public key and this is what the client uses to connect to the server (I don't really understand this very last part).\n\nNo, again, the public key doesn't need to store separately, it is already included. And you don't need to have the truststore to connect, you need it to verify the trust path to a trust anchor. Usually that is a known root certificate, but for self-signed certificates it is just the one certificate.\n\nHow do we actually use these keys that we generated inside our code? What is the recommended/secure way to do it? I have a feeling that setting system properties and typing a password in plain text in the class isn't the right way to do it but this might be the way to do it.\n\nUsually you try and store the private key in the least accessible way possible while you are still able to use it economically. Banks store private keys in HSM's, hardware security modules. Generally, if you just have a computer, you try to store it in the most secure place possible, e.g. in a system provided key store.\nUsing a key store based on password based encryption (PKCS#12 or PFX keystores and the Java JKS key stores) are indeed not the most secure options. Better choose a very secure password to at least not leak the private key if the store gets stolen.\nNote that Java does contain a PKCS#11 provider that works with HSM's as well as providers to use the Windows certificates / keys.\n\nIf I were to develop an app that uses TLS how would I go about storing the keys in the Client? Would it be possible to pack the key inside the jar file that I'd release for the users to download?\n\nYes, it certainly can be a resource that is packed with the program, but you might need to update your program if you want it to remain current. Actually, that is exactly how most browsers get the trust store; the certificates are delivered with the updates of Firefox and Chrome.\nFor others they are part of OS updates such as with Edge, and you may also have a network specific method of distributing trusted certificates such as the Group Policy in the Windows ecosystem.\n\nLike I said, I followed the tutorial from the docs and combining that with some knowledge I got from other stackoverflow posts I managed to make it work but I'd like to understand how everything really works.\n\nWell, PKIX and TLS operation is a lot of information to take in and understand for sure. One way of making sure that you get the right information is to simply read the X.509 standard. There are many tutorials on the Internet as well.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The fact you're mentioning /etc/pki/ca-trust/extracted/java/cacerts suggests you're using a cacerts file managed by your Linux distribution (presumably based on RedHat/CentOS).\nRemoving the specific certificate from that cacerts file is indeed possible with keytool manually. However, it's likely to be re-generated, and possibly placed back into that file the next time update-ca-trust is executed automatically (e.g. package upgrade) or not.\nWhen using the distribution-managed cacerts file, it's generally better to use the distribution's mechanism.\nOn RedHat/CentOS-based distributions, this can be done by managing individual certificates in /etc/pki/ca-trust/source/anchors/ and using update-ca-trust.\nOn Debian/Ubuntu-based distributions, there is an equivalent with certificates in /usr/share/ca-certificates, assuming the ca-certificates-java package is installed (and then, you can run update-ca-certificates).\n\nAs a side-note, you've tagged your question with client-certificate.\nClient-certificates (and more so their matching private key, i.e. PrivateKeyEntry entries) normally don't belong in the cacerts file at all, which is a \"keystore\" used as a \"truststore\" (typically used as the default truststore for all Java applications running on that system). Those belong to a \"keystore used as a keystore\", not a \"keystore used as a truststore\" (which shouldn't contain private keys).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The reason why a trust store exists is because you are trying to create a secure communication to a web server, and you need to trust the server certificate that they offer. So a trust store contains the trust anchors for that to happen: if a valid trust path can be build to a trust anchor in the trust store then the certificate is deemed valid and - after some additional checks of e.g. the server name - the private key can be used by the server to indicate that it is the server named within the server certificate.\nGreat, so what kind of security needs to be present on your trust store? Well, it is that the trust store is available and unaltered. Having the trust store unavailable will obviously be a big issue. So downloading the trust store every time you need to secure a connection is adding another high availability component to your infrastructure. Maybe you already need one for CRL or OCSP service, but still.\nThe other thing is that the trust store should not be altered in traffic. That basically means that the connection to your service should be free from attacks. The most logical way to do this is to have it protected by TLS. In that case of course you need a trusted certificate. In the end you cannot operate without trusting something. This is why you either have to trust a server based on the cacerts, or to distribute a certificate with the application.\n\"it shouldn't be a problem because it's not accessible by anyone else\". That's not a requirement. Other people may well access the server, as long as they cannot alter the security (and availability) of the connection or the trust store. Read access to the P12 file wouldn't directly influence the availability or trustworthiness of the trust store. That said, the stricter the security of the service that contains the trust store, the better.\nI was kind of afraid that the P12 would not just be a trust store but also a key store containing a private key. Preferably, a private key should not be distributed that way. I didn't see any hint of this happening in your question, so I'll just leave it here for other readers.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "I think this could be caused by that you're configuring only a keystore, but not a truststore.\nKey stores are typically used for keeping the keys or certs to provide to a third party. But for validating the provided certificates trust stores are used.\nTry to do something like:\n\nYour trust store has to contain the certificate that is returned by your service or the certificate chain that was used to sign service certificate.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "First, you have to extract the CA certificate from the .pfx file using openssl:\nopenssl pkcs12 -in filename.pfx -passin pass:<password> -info -nokeys > filename.pem.\nDouble check that extraction worked:\nopenssl x509 -in test.pem -noout -text\nThen either create new JKS using the key tool:\nkeytool -import -trustcacerts -keystore test.jks -storepass choose-password -file test.pem -alias CANAME\nOr you can import the certificate into the existing trust store:\nkeytool -import -keystore cacerts -storepass changeit -file test.pem -alias CANAME -storetype JKS\nUsually you would use openssl to interact with most certificate file formats and keytool with java key stores only (JKS)\n==============.\nUpdate\nPKCS12 is an archive file format for storing private keys and X.509 certificates with filename extensions .p12 or .pfx\nTo be able to work with .pfx files you would use openssl pkcs12 command.  I am guessing x509 command returns first certificate it finds.\nPKCS12 wiki\nkeytool Manages a keystore (database) of cryptographic keys, X.509 certificate chains, and trusted certificates.\nI think it only works with java keystores .jks or .bcfks (Bouncy Castle FIPS keyStore) etc..\nI think you might actually be able to import certificates directly from .pfx file to a java keystore using keytool.\nkeytool -importkeystore -srckeystore mypfxfile.pfx -srcstoretype pkcs12 -destkeystore clientcert.jks -deststoretype JKS\nThat could also import the private key if it's in the .pfx file but I am not sure.\nHope that helps.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You have actually created a certificate signing request with the above command.\nTo generate just a public-private key pair, you can use:\n\nHowever, a trust store contains certificates, not public keys.\n",
                        "contain_knowledge": 0
                    }
                ]
            }
        }
    },
    {
        "name": "CheckpointManager",
        "language": "tf",
        "popularity": "middle",
        "label_result": {
            "functionality": {
                "finetuned_dpr": 0.6,
                "dpr": 0.4,
                "e5": 0.1,
                "bm25": 0.5
            },
            "concept": {
                "finetuned_dpr": 1.0,
                "dpr": 0.6,
                "e5": 0.2,
                "bm25": 0.7
            },
            "performance": {
                "finetuned_dpr": 0.5,
                "dpr": 0.3,
                "e5": 0.0,
                "bm25": 0.4
            },
            "directive": {
                "finetuned_dpr": 0.6,
                "dpr": 0.4,
                "e5": 0.2,
                "bm25": 0.3
            },
            "pattern": {
                "finetuned_dpr": 0.7,
                "dpr": 0.6,
                "e5": 0.3,
                "bm25": 0.7
            },
            "environment": {
                "finetuned_dpr": 0.5,
                "dpr": 0.5,
                "e5": 0.2,
                "bm25": 0.6
            },
            "alternative": {
                "finetuned_dpr": 0.6,
                "dpr": 0.6,
                "e5": 0.2,
                "bm25": 0.3
            },
            "total": {
                "finetuned_dpr": 0.6428571428571429,
                "dpr": 0.48571428571428577,
                "e5": 0.17142857142857143,
                "bm25": 0.5
            }
        },
        "retrieve_result": {
            "functionality": {
                "finetuned_dpr": [
                    {
                        "id": 65364637,
                        "answer_post": "I decided to save on the \"manual\" save of the relevant data.\n\nFirst, I save model.history.history whenever I save the checkpoint and on_train_end with\n\n\n\nWhen I start the program, I check if the checkpoint exists, if yes, I load it and, at the same time, I check if the history exists and if it does I load it and store in model._history variable since model.history.history is only created after you start training!\n\n\nAdditionally, I set model._current_epoch value to keep track of the last epoch:\n\n\nAfter starting training I assign the proper value of model.history.history and remove the old value.\n\n\nNot the most elegant solution but it serves the purpose for now.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67228765,
                        "answer_post": "I also had a hard time differentiating between the checkpoint objects used when I looked at other people's code, so I wrote down some notes about when to use which one and how to use them in general.\nEither-way, I think it might be useful for other people having the same issue:\nSaving model Checkpoints\nThese are 2 ways of saving your model's checkpoints, each is for a different use case:\n1) Checkpoint & CheckpointManager\nThis is use-full when you are managing the training loops yourself.\nYou use them like this:\n1.1) Checkpoint\nDefinition from the docs:\n\"A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file\".\nHow to initialise it:\n\nYou can pass it key value pairs for:\n\nAll the custom function calls or objects that make up your model and you want to keep track of:\nLike a generator, discriminiator, loss function, optimizer etc\n\n\n\n\n1.2) CheckpointManager\nThis literally manages the checkpoints you have defined to be stored at a location and things like how many to to keep.\nDefinition from the docs:\n\"Manages multiple checkpoints by keeping some and deleting unneeded ones\"\nHow to initialise it:\n\nInitialise it with the CheckPoint object you create as first argument.\nThe directory where to save the checkpoint files.\nAnd you probably want to define how much you want to keep, since this can be a lot of complex models\n\n\nHow to use it:\n\nWe have setup the manager object with our specified checkpoints, so it's ready to use.\nCall this at the end of each training epoch\n\n\n2) ModelCheckpoint (callback)\nYou want to use this callback when you are not managing epoch iterations yourself. For example when you have setup a relatively simple Sequential model and you call model.fit(), which manages the training process for you.\nDefinition from the docs:\n\"Callback to save the Keras model or model weights at some frequency.\"\nHow to initialise it:\n\nPass in the path where to save the model\n\nThe option save_weights_only is set to False by default:\n\nIf you want to only save the weights make sure to update this\n\n\nThe option save_best_only is set to False by default:\n\nIf you want to only save the best model instead of all of them, you can set this to True.\n\n\nverbose is set to 0 (False), so you can update this to 1 to validate it\n\n\n\nHow to use it:\n\nThe model checkpoint callback is now ready to for training.\nYou pass in the object in you into your callbacks list when you fit the model:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71129608,
                        "answer_post": "As of 02.2022\nThe Validation process is supposed to run at the same time with the Training process so that whenever a new Checkpoint is saved, the Validation process immediately loads the Checkpoint and starts validating.\nPlease see my other answer in this regard.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64122772,
                        "answer_post": "In your trained folder where checkpoints are, there is checkpoint key file, open that and change the \"model_checkpoint_path\" checkpoint-number in the first line. Generally it will be saved the last checkpoint.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71519403,
                        "answer_post": "These might help: Training checkpoints and tf.train.Checkpoint. According to the documentation, you should be able to load the model using something like this:\n\nI am not sure it will work if the checkpoint contains other variables. You might have to use checkpoint.restore(path).expect_partial().\nYou can also check the content that has been saved (according to the documentation) by Manually inspecting checkpoints :\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 56958434,
                        "answer_post": "If by latest model you mean the model after the final epoch, you can just simply leave the Checkpoint function unchanged and save your final result.\nAfter you fit the model add this line of code:\n\nThe checkpoint function will save the best model, and after you finish training, the model will save one final time, regardless of the result.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55037106,
                        "answer_post": "It's very simple. Create checkpoints while training the model and then use those checkpoints to resume training from where you left of.\n\nAfter this just load the checkpoint from where you want to resume training again\n\nAnd you are done.\nLet me know if you have more questions about this.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 58656237,
                        "answer_post": "The purpose of the validation accuracy is an estimation to see how your model generalises on unseen data. So when you are saving checkpoints with best validation accuracy , what happens is you are saving the weight(the ones which are learned by training) that best predicts results for the unseen data. So by having multiple checkpoints saved you can utilize these checkpoints when testing the model with test data( which may be taken from say a real time use case), and select the model which works well with your test data\nHope this helps\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62292059,
                        "answer_post": "You can use model checkpoint callbacks as follows: for example capture the maximum accuracy obtained so far and save it in the checkpoint file.\n\n\nand then fit the model. \nmodel.fit(epochs=10, callbacks=[model_checkpoint_callback])\nyou can reload it again for update. \nmodel.load(checkpoint_filepath)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 60799059,
                        "answer_post": "There is no 'model' parameter in the saved checkpoint. If you look in train_rcnn.py:106:\n\nyou see that they save just the model parameters. It should've been something like:\n\nso then after loading you get a dictionary with 'model', and the other parameters they appear to be wanting to keep.\nThis seems to be a bug in their code.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 62395329,
                        "answer_post": "This can be done using the ModelCheckpoint callback:\n\nYou can modify the behaviour of the callback using the monitor, mode and save_best_only parameters, which govern the metric to track and whether the checkpoints are overwritten to retain the best model only. \n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62848472,
                        "answer_post": "Checkpoints are used to save your model if in case your system crashes or code interrupted while training so when you start training your model again after crashes you don't have to start from scratch.Checkpoints capture the exact value of all parameters (tf.Variable objects) used by a model. Checkpoints do not contain any description of the computation defined by the model.\nThe SavedModel format on the other hand includes a serialized description of the computation defined by the model in addition to the parameter values (checkpoint). Models in this format are independent of the source code that created the model.\nyou can see the above info in the official doc of tensorflow. @R Nanthak\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67168551,
                        "answer_post": "Assuming you are using a tf.keras.callbacks.ModelCheckpoint with save_freq = int (which is required to save after a certain number of batches), you can create a class that inherits from ModelCheckpoint and modify the class method on_train_batch_end\n\nThen add an instance of this class in model.fit.\n\nThis will add both the epoch and the batch number to the checkpoint filename.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71835386,
                        "answer_post": "The build_federated_averaging_process API builds an iterative process of the full federated learning steps. If you want to verify that the server model is updated, you can print state.model after each iterative_process.next(state, train_data).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63366977,
                        "answer_post": "It depends on whether a custom training loop is required. In most cases, it's not and you can just call model.fit() and pass tf.keras.callbacks.ModelCheckpoint. If you do need to write your custom training loop, then you have to use tf.train.Checkpoint (and tf.train.CheckpointManager) since there's no callback mechanism.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61319129,
                        "answer_post": "are you sure it is stuck? do you get any errors?\nDuring the training process, TF OD API writes logs into an event file (can be opened using tensorboard) in the model directory.\nlook in your model directory and see if there is an eventfile written there, look at its time stamp to see if it is being updated.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74297783,
                        "answer_post": "you can use the checkpoints.restore() method to restore checkpoints of your preference. For example, if you want to load checkpoint at iteration 1000, then you write:\n\nFor more details please refer to this documentation. Thank You.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 58536430,
                        "answer_post": "Using tf.train.CheckpointManager, you can specify how many checkpoints it needs to keep at any given point of time using the argument \"max_to_keep\". \nThis keeps replacing the oldest checkpoint and saves the new one once it reaches the maximum number of checkpoints to be saved. \nPlease refer below link for details:\nhttps://www.tensorflow.org/guide/checkpoint\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 69486380,
                        "answer_post": "validation metrics are only calculated at the end of an epoch, so you can not stop training on a batch by evaluation the validation metric. However you can stop training at the end of an epoch. Below is the code for a custom callback that will stop training at the end of an epoch when the quantity being monitored reaches or exceeds the float value threshold. In the callback parameter monitor can be set to either 'train' or 'valid' If monitor='train' then training will halt if the training accuracy meets or exceeds the threshold value. If monitor='valid' then training will halt when the validation accuracy meets or exceeds the threshold value. In the callback, parameter model is the name of your compiled model. If the threshold level is met or exceeded during training your_model weights are set to the weights for the epoch on which the threshold was exceeded. A message is also printed out on that epoch stating training has been halted and the value of the metric being monitored is printed out.\n\nto use the callback the code is below\n\nIn your_model.fit() include callbacks=callbacks.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54553770,
                        "answer_post": "The session.run() call for validation will be simply feedforward network which will take very less time and also memory. So it should not a big deal if you are using it multiple times. You can try having another validation op with different input placeholders for X1 and Y1 and pass these tensors to your model and validate.\n\nAnd then do something like this\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 69794011,
                        "answer_post": "You can use tf.train.CheckpointManager to load your latest checkpoint or whatever checkpoint you like and then generate some images with your generator model based on random noise:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55917605,
                        "answer_post": "The train_logdir represents the checkpoint directory. The train_logdir is an input to the checkpoint_dir argument of the tf.train.MonitoredTrainingSession utility. The checkpoints are saved/restored to/from this directory.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63699290,
                        "answer_post": "I have solved my problem. To export TF Slim Resnet checkpoint with TF 1.14 to SavedModel, warm start can be used together with export_savedmodel as follows:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56793601,
                        "answer_post": "Here's the code to convert the checkpoint to SavedModel\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68001567,
                        "answer_post": "Here is the model\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71289634,
                        "answer_post": "Try Saving the model again\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55409692,
                        "answer_post": "train.py\n\nmodel.py\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60309119,
                        "answer_post": "You can save the weights in checkpoint format using:\n\nYou can read more about saving weights or models and chepoints here\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71443926,
                        "answer_post": "this works for tf.data\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68184521,
                        "answer_post": "Use tf.where\n\n\n\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You should create a CheckpointManager at the start as:\n\nNow after running for few epoch, to restore latest checkpoint, you should get the latest checkpoint from the CheckpointManager:\n\nThis will restore your session from the latest epoch.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I'm not exactly sure what you mean with\n\nHow (with what methods) can I use these models now?\n\nThe model is not saved in those files but i can be restored with them.\nThose*.ckpt get saved during training but do not contain your model. If you want to \"use\" your model you need to restore those files to it. Take a look at Tensorflow's Checkpoint and CheckpointManager. This tutorial shows a simple snipped of how to restore .ckpt files to your model.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I also had a hard time differentiating between the checkpoint objects used when I looked at other people's code, so I wrote down some notes about when to use which one and how to use them in general.\nEither-way, I think it might be useful for other people having the same issue:\nSaving model Checkpoints\nThese are 2 ways of saving your model's checkpoints, each is for a different use case:\n1) Checkpoint & CheckpointManager\nThis is use-full when you are managing the training loops yourself.\nYou use them like this:\n1.1) Checkpoint\nDefinition from the docs:\n\"A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file\".\nHow to initialise it:\n\nYou can pass it key value pairs for:\n\nAll the custom function calls or objects that make up your model and you want to keep track of:\nLike a generator, discriminiator, loss function, optimizer etc\n\n\n\n\n1.2) CheckpointManager\nThis literally manages the checkpoints you have defined to be stored at a location and things like how many to to keep.\nDefinition from the docs:\n\"Manages multiple checkpoints by keeping some and deleting unneeded ones\"\nHow to initialise it:\n\nInitialise it with the CheckPoint object you create as first argument.\nThe directory where to save the checkpoint files.\nAnd you probably want to define how much you want to keep, since this can be a lot of complex models\n\n\nHow to use it:\n\nWe have setup the manager object with our specified checkpoints, so it's ready to use.\nCall this at the end of each training epoch\n\n\n2) ModelCheckpoint (callback)\nYou want to use this callback when you are not managing epoch iterations yourself. For example when you have setup a relatively simple Sequential model and you call model.fit(), which manages the training process for you.\nDefinition from the docs:\n\"Callback to save the Keras model or model weights at some frequency.\"\nHow to initialise it:\n\nPass in the path where to save the model\n\nThe option save_weights_only is set to False by default:\n\nIf you want to only save the weights make sure to update this\n\n\nThe option save_best_only is set to False by default:\n\nIf you want to only save the best model instead of all of them, you can set this to True.\n\n\nverbose is set to 0 (False), so you can update this to 1 to validate it\n\n\n\nHow to use it:\n\nThe model checkpoint callback is now ready to for training.\nYou pass in the object in you into your callbacks list when you fit the model:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "while creating checkpoints you can pass the optimizer argument for saving the optimizer status\n\nThen you can restore optimizer status while restoring those checkpoints.For more details please refer to this documentation. Thank You.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The purpose of the validation accuracy is an estimation to see how your model generalises on unseen data. So when you are saving checkpoints with best validation accuracy , what happens is you are saving the weight(the ones which are learned by training) that best predicts results for the unseen data. So by having multiple checkpoints saved you can utilize these checkpoints when testing the model with test data( which may be taken from say a real time use case), and select the model which works well with your test data\nHope this helps\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes to both questions.\n1) Without recompiling the model the model weights are bound to in the model so \n\nworks to update the model from previous weights but do think about if this is exactly what you want to do.\n\nYes, saving and loading a model works as expected\n\n\nShould do the trick.\nFor saving at checkpoints I'd recommend using the ModelCheckpoint callback. That makes it easy to save the model and specific iterations points so that you can train from that point in the future.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Apart from the discussion above, here is where the pretrained checkpoints are loaded in tensorflow object detection api. As you can see, the checkpoint paths are passed by the variable train_config.fine_tune_checkpoint, this variable is a field under train_config in the config file. It is not the same as model_dir, which is only used for saving the most recent checkpoints. \nIf you use the same command line to resume training, the training seemed to automatically start from the latest checkpoint in model_dir and this is supported by tensorflow Supervisor. See here for reference.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Apart from the discussion above, here is where the pretrained checkpoints are loaded in tensorflow object detection api. As you can see, the checkpoint paths are passed by the variable train_config.fine_tune_checkpoint, this variable is a field under train_config in the config file. It is not the same as model_dir, which is only used for saving the most recent checkpoints. \nIf you use the same command line to resume training, the training seemed to automatically start from the latest checkpoint in model_dir and this is supported by tensorflow Supervisor. See here for reference.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You should fully use the Functional API instead of mixing the Sequential and Functional APIs, and then you will not have this problem. Model management and building is much easier with the Functional API as well.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "There are two states, the state_h which is the last step output; and the state_c which is the carry on state or memory. \nYou should use a functional API model to have more than one input:\n\nFollowing this approach, it's even possible to use outputs of other layers as initial states, if you want trainable initial states.\nThe big change is that you will need to pass the states for training and predicting:\n\nWhere you can use zeros for the states during training. \n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "concept": {
                "finetuned_dpr": [
                    {
                        "id": 65364637,
                        "answer_post": "I decided to save on the \"manual\" save of the relevant data.\n\nFirst, I save model.history.history whenever I save the checkpoint and on_train_end with\n\n\n\nWhen I start the program, I check if the checkpoint exists, if yes, I load it and, at the same time, I check if the history exists and if it does I load it and store in model._history variable since model.history.history is only created after you start training!\n\n\nAdditionally, I set model._current_epoch value to keep track of the last epoch:\n\n\nAfter starting training I assign the proper value of model.history.history and remove the old value.\n\n\nNot the most elegant solution but it serves the purpose for now.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67228765,
                        "answer_post": "I also had a hard time differentiating between the checkpoint objects used when I looked at other people's code, so I wrote down some notes about when to use which one and how to use them in general.\nEither-way, I think it might be useful for other people having the same issue:\nSaving model Checkpoints\nThese are 2 ways of saving your model's checkpoints, each is for a different use case:\n1) Checkpoint & CheckpointManager\nThis is use-full when you are managing the training loops yourself.\nYou use them like this:\n1.1) Checkpoint\nDefinition from the docs:\n\"A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file\".\nHow to initialise it:\n\nYou can pass it key value pairs for:\n\nAll the custom function calls or objects that make up your model and you want to keep track of:\nLike a generator, discriminiator, loss function, optimizer etc\n\n\n\n\n1.2) CheckpointManager\nThis literally manages the checkpoints you have defined to be stored at a location and things like how many to to keep.\nDefinition from the docs:\n\"Manages multiple checkpoints by keeping some and deleting unneeded ones\"\nHow to initialise it:\n\nInitialise it with the CheckPoint object you create as first argument.\nThe directory where to save the checkpoint files.\nAnd you probably want to define how much you want to keep, since this can be a lot of complex models\n\n\nHow to use it:\n\nWe have setup the manager object with our specified checkpoints, so it's ready to use.\nCall this at the end of each training epoch\n\n\n2) ModelCheckpoint (callback)\nYou want to use this callback when you are not managing epoch iterations yourself. For example when you have setup a relatively simple Sequential model and you call model.fit(), which manages the training process for you.\nDefinition from the docs:\n\"Callback to save the Keras model or model weights at some frequency.\"\nHow to initialise it:\n\nPass in the path where to save the model\n\nThe option save_weights_only is set to False by default:\n\nIf you want to only save the weights make sure to update this\n\n\nThe option save_best_only is set to False by default:\n\nIf you want to only save the best model instead of all of them, you can set this to True.\n\n\nverbose is set to 0 (False), so you can update this to 1 to validate it\n\n\n\nHow to use it:\n\nThe model checkpoint callback is now ready to for training.\nYou pass in the object in you into your callbacks list when you fit the model:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64122772,
                        "answer_post": "In your trained folder where checkpoints are, there is checkpoint key file, open that and change the \"model_checkpoint_path\" checkpoint-number in the first line. Generally it will be saved the last checkpoint.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71129608,
                        "answer_post": "As of 02.2022\nThe Validation process is supposed to run at the same time with the Training process so that whenever a new Checkpoint is saved, the Validation process immediately loads the Checkpoint and starts validating.\nPlease see my other answer in this regard.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71519403,
                        "answer_post": "These might help: Training checkpoints and tf.train.Checkpoint. According to the documentation, you should be able to load the model using something like this:\n\nI am not sure it will work if the checkpoint contains other variables. You might have to use checkpoint.restore(path).expect_partial().\nYou can also check the content that has been saved (according to the documentation) by Manually inspecting checkpoints :\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55037106,
                        "answer_post": "It's very simple. Create checkpoints while training the model and then use those checkpoints to resume training from where you left of.\n\nAfter this just load the checkpoint from where you want to resume training again\n\nAnd you are done.\nLet me know if you have more questions about this.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 58656237,
                        "answer_post": "The purpose of the validation accuracy is an estimation to see how your model generalises on unseen data. So when you are saving checkpoints with best validation accuracy , what happens is you are saving the weight(the ones which are learned by training) that best predicts results for the unseen data. So by having multiple checkpoints saved you can utilize these checkpoints when testing the model with test data( which may be taken from say a real time use case), and select the model which works well with your test data\nHope this helps\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 56958434,
                        "answer_post": "If by latest model you mean the model after the final epoch, you can just simply leave the Checkpoint function unchanged and save your final result.\nAfter you fit the model add this line of code:\n\nThe checkpoint function will save the best model, and after you finish training, the model will save one final time, regardless of the result.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62292059,
                        "answer_post": "You can use model checkpoint callbacks as follows: for example capture the maximum accuracy obtained so far and save it in the checkpoint file.\n\n\nand then fit the model. \nmodel.fit(epochs=10, callbacks=[model_checkpoint_callback])\nyou can reload it again for update. \nmodel.load(checkpoint_filepath)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 60799059,
                        "answer_post": "There is no 'model' parameter in the saved checkpoint. If you look in train_rcnn.py:106:\n\nyou see that they save just the model parameters. It should've been something like:\n\nso then after loading you get a dictionary with 'model', and the other parameters they appear to be wanting to keep.\nThis seems to be a bug in their code.\n",
                        "contain_knowledge": 1
                    }
                ],
                "dpr": [
                    {
                        "id": 67168551,
                        "answer_post": "Assuming you are using a tf.keras.callbacks.ModelCheckpoint with save_freq = int (which is required to save after a certain number of batches), you can create a class that inherits from ModelCheckpoint and modify the class method on_train_batch_end\n\nThen add an instance of this class in model.fit.\n\nThis will add both the epoch and the batch number to the checkpoint filename.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62395329,
                        "answer_post": "This can be done using the ModelCheckpoint callback:\n\nYou can modify the behaviour of the callback using the monitor, mode and save_best_only parameters, which govern the metric to track and whether the checkpoints are overwritten to retain the best model only. \n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62848472,
                        "answer_post": "Checkpoints are used to save your model if in case your system crashes or code interrupted while training so when you start training your model again after crashes you don't have to start from scratch.Checkpoints capture the exact value of all parameters (tf.Variable objects) used by a model. Checkpoints do not contain any description of the computation defined by the model.\nThe SavedModel format on the other hand includes a serialized description of the computation defined by the model in addition to the parameter values (checkpoint). Models in this format are independent of the source code that created the model.\nyou can see the above info in the official doc of tensorflow. @R Nanthak\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71835386,
                        "answer_post": "The build_federated_averaging_process API builds an iterative process of the full federated learning steps. If you want to verify that the server model is updated, you can print state.model after each iterative_process.next(state, train_data).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63366977,
                        "answer_post": "It depends on whether a custom training loop is required. In most cases, it's not and you can just call model.fit() and pass tf.keras.callbacks.ModelCheckpoint. If you do need to write your custom training loop, then you have to use tf.train.Checkpoint (and tf.train.CheckpointManager) since there's no callback mechanism.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61319129,
                        "answer_post": "are you sure it is stuck? do you get any errors?\nDuring the training process, TF OD API writes logs into an event file (can be opened using tensorboard) in the model directory.\nlook in your model directory and see if there is an eventfile written there, look at its time stamp to see if it is being updated.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74297783,
                        "answer_post": "you can use the checkpoints.restore() method to restore checkpoints of your preference. For example, if you want to load checkpoint at iteration 1000, then you write:\n\nFor more details please refer to this documentation. Thank You.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61281640,
                        "answer_post": "Setting seeds in the file header will lead to different outcomes, since initialization will consume some of the random values before you get to training.\nSo you should set the seeds after performing initialization. The initialization can use any seed you want, including another fixed seed, but then you have to reset it again for training.\nHere is some very high level pseudo-code, which assumes you have functions to to build, initialize, and train the model. And also functions to save and load the checkpoints.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54553770,
                        "answer_post": "The session.run() call for validation will be simply feedforward network which will take very less time and also memory. So it should not a big deal if you are using it multiple times. You can try having another validation op with different input placeholders for X1 and Y1 and pass these tensors to your model and validate.\n\nAnd then do something like this\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 58536430,
                        "answer_post": "Using tf.train.CheckpointManager, you can specify how many checkpoints it needs to keep at any given point of time using the argument \"max_to_keep\". \nThis keeps replacing the oldest checkpoint and saves the new one once it reaches the maximum number of checkpoints to be saved. \nPlease refer below link for details:\nhttps://www.tensorflow.org/guide/checkpoint\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 69794011,
                        "answer_post": "You can use tf.train.CheckpointManager to load your latest checkpoint or whatever checkpoint you like and then generate some images with your generator model based on random noise:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55917605,
                        "answer_post": "The train_logdir represents the checkpoint directory. The train_logdir is an input to the checkpoint_dir argument of the tf.train.MonitoredTrainingSession utility. The checkpoints are saved/restored to/from this directory.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 68001567,
                        "answer_post": "Here is the model\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55409692,
                        "answer_post": "train.py\n\nmodel.py\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63699290,
                        "answer_post": "I have solved my problem. To export TF Slim Resnet checkpoint with TF 1.14 to SavedModel, warm start can be used together with export_savedmodel as follows:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60309119,
                        "answer_post": "You can save the weights in checkpoint format using:\n\nYou can read more about saving weights or models and chepoints here\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56793601,
                        "answer_post": "Here's the code to convert the checkpoint to SavedModel\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71289634,
                        "answer_post": "Try Saving the model again\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67276788,
                        "answer_post": "Here, the checkpoint is an instance of tf.train.Checkpoint. Somehow you have missed it, check here, it does initiate\n\nAnd thus it calls those functions like .restore or .save.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68184521,
                        "answer_post": "Use tf.where\n\n\n\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You should create a CheckpointManager at the start as:\n\nNow after running for few epoch, to restore latest checkpoint, you should get the latest checkpoint from the CheckpointManager:\n\nThis will restore your session from the latest epoch.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I'm not exactly sure what you mean with\n\nHow (with what methods) can I use these models now?\n\nThe model is not saved in those files but i can be restored with them.\nThose*.ckpt get saved during training but do not contain your model. If you want to \"use\" your model you need to restore those files to it. Take a look at Tensorflow's Checkpoint and CheckpointManager. This tutorial shows a simple snipped of how to restore .ckpt files to your model.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I also had a hard time differentiating between the checkpoint objects used when I looked at other people's code, so I wrote down some notes about when to use which one and how to use them in general.\nEither-way, I think it might be useful for other people having the same issue:\nSaving model Checkpoints\nThese are 2 ways of saving your model's checkpoints, each is for a different use case:\n1) Checkpoint & CheckpointManager\nThis is use-full when you are managing the training loops yourself.\nYou use them like this:\n1.1) Checkpoint\nDefinition from the docs:\n\"A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file\".\nHow to initialise it:\n\nYou can pass it key value pairs for:\n\nAll the custom function calls or objects that make up your model and you want to keep track of:\nLike a generator, discriminiator, loss function, optimizer etc\n\n\n\n\n1.2) CheckpointManager\nThis literally manages the checkpoints you have defined to be stored at a location and things like how many to to keep.\nDefinition from the docs:\n\"Manages multiple checkpoints by keeping some and deleting unneeded ones\"\nHow to initialise it:\n\nInitialise it with the CheckPoint object you create as first argument.\nThe directory where to save the checkpoint files.\nAnd you probably want to define how much you want to keep, since this can be a lot of complex models\n\n\nHow to use it:\n\nWe have setup the manager object with our specified checkpoints, so it's ready to use.\nCall this at the end of each training epoch\n\n\n2) ModelCheckpoint (callback)\nYou want to use this callback when you are not managing epoch iterations yourself. For example when you have setup a relatively simple Sequential model and you call model.fit(), which manages the training process for you.\nDefinition from the docs:\n\"Callback to save the Keras model or model weights at some frequency.\"\nHow to initialise it:\n\nPass in the path where to save the model\n\nThe option save_weights_only is set to False by default:\n\nIf you want to only save the weights make sure to update this\n\n\nThe option save_best_only is set to False by default:\n\nIf you want to only save the best model instead of all of them, you can set this to True.\n\n\nverbose is set to 0 (False), so you can update this to 1 to validate it\n\n\n\nHow to use it:\n\nThe model checkpoint callback is now ready to for training.\nYou pass in the object in you into your callbacks list when you fit the model:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "while creating checkpoints you can pass the optimizer argument for saving the optimizer status\n\nThen you can restore optimizer status while restoring those checkpoints.For more details please refer to this documentation. Thank You.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The purpose of the validation accuracy is an estimation to see how your model generalises on unseen data. So when you are saving checkpoints with best validation accuracy , what happens is you are saving the weight(the ones which are learned by training) that best predicts results for the unseen data. So by having multiple checkpoints saved you can utilize these checkpoints when testing the model with test data( which may be taken from say a real time use case), and select the model which works well with your test data\nHope this helps\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes to both questions.\n1) Without recompiling the model the model weights are bound to in the model so \n\nworks to update the model from previous weights but do think about if this is exactly what you want to do.\n\nYes, saving and loading a model works as expected\n\n\nShould do the trick.\nFor saving at checkpoints I'd recommend using the ModelCheckpoint callback. That makes it easy to save the model and specific iterations points so that you can train from that point in the future.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Apart from the discussion above, here is where the pretrained checkpoints are loaded in tensorflow object detection api. As you can see, the checkpoint paths are passed by the variable train_config.fine_tune_checkpoint, this variable is a field under train_config in the config file. It is not the same as model_dir, which is only used for saving the most recent checkpoints. \nIf you use the same command line to resume training, the training seemed to automatically start from the latest checkpoint in model_dir and this is supported by tensorflow Supervisor. See here for reference.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Apart from the discussion above, here is where the pretrained checkpoints are loaded in tensorflow object detection api. As you can see, the checkpoint paths are passed by the variable train_config.fine_tune_checkpoint, this variable is a field under train_config in the config file. It is not the same as model_dir, which is only used for saving the most recent checkpoints. \nIf you use the same command line to resume training, the training seemed to automatically start from the latest checkpoint in model_dir and this is supported by tensorflow Supervisor. See here for reference.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You should fully use the Functional API instead of mixing the Sequential and Functional APIs, and then you will not have this problem. Model management and building is much easier with the Functional API as well.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "There are two states, the state_h which is the last step output; and the state_c which is the carry on state or memory. \nYou should use a functional API model to have more than one input:\n\nFollowing this approach, it's even possible to use outputs of other layers as initial states, if you want trainable initial states.\nThe big change is that you will need to pass the states for training and predicting:\n\nWhere you can use zeros for the states during training. \n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "performance": {
                "finetuned_dpr": [
                    {
                        "id": 65364637,
                        "answer_post": "I decided to save on the \"manual\" save of the relevant data.\n\nFirst, I save model.history.history whenever I save the checkpoint and on_train_end with\n\n\n\nWhen I start the program, I check if the checkpoint exists, if yes, I load it and, at the same time, I check if the history exists and if it does I load it and store in model._history variable since model.history.history is only created after you start training!\n\n\nAdditionally, I set model._current_epoch value to keep track of the last epoch:\n\n\nAfter starting training I assign the proper value of model.history.history and remove the old value.\n\n\nNot the most elegant solution but it serves the purpose for now.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67228765,
                        "answer_post": "I also had a hard time differentiating between the checkpoint objects used when I looked at other people's code, so I wrote down some notes about when to use which one and how to use them in general.\nEither-way, I think it might be useful for other people having the same issue:\nSaving model Checkpoints\nThese are 2 ways of saving your model's checkpoints, each is for a different use case:\n1) Checkpoint & CheckpointManager\nThis is use-full when you are managing the training loops yourself.\nYou use them like this:\n1.1) Checkpoint\nDefinition from the docs:\n\"A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file\".\nHow to initialise it:\n\nYou can pass it key value pairs for:\n\nAll the custom function calls or objects that make up your model and you want to keep track of:\nLike a generator, discriminiator, loss function, optimizer etc\n\n\n\n\n1.2) CheckpointManager\nThis literally manages the checkpoints you have defined to be stored at a location and things like how many to to keep.\nDefinition from the docs:\n\"Manages multiple checkpoints by keeping some and deleting unneeded ones\"\nHow to initialise it:\n\nInitialise it with the CheckPoint object you create as first argument.\nThe directory where to save the checkpoint files.\nAnd you probably want to define how much you want to keep, since this can be a lot of complex models\n\n\nHow to use it:\n\nWe have setup the manager object with our specified checkpoints, so it's ready to use.\nCall this at the end of each training epoch\n\n\n2) ModelCheckpoint (callback)\nYou want to use this callback when you are not managing epoch iterations yourself. For example when you have setup a relatively simple Sequential model and you call model.fit(), which manages the training process for you.\nDefinition from the docs:\n\"Callback to save the Keras model or model weights at some frequency.\"\nHow to initialise it:\n\nPass in the path where to save the model\n\nThe option save_weights_only is set to False by default:\n\nIf you want to only save the weights make sure to update this\n\n\nThe option save_best_only is set to False by default:\n\nIf you want to only save the best model instead of all of them, you can set this to True.\n\n\nverbose is set to 0 (False), so you can update this to 1 to validate it\n\n\n\nHow to use it:\n\nThe model checkpoint callback is now ready to for training.\nYou pass in the object in you into your callbacks list when you fit the model:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71129608,
                        "answer_post": "As of 02.2022\nThe Validation process is supposed to run at the same time with the Training process so that whenever a new Checkpoint is saved, the Validation process immediately loads the Checkpoint and starts validating.\nPlease see my other answer in this regard.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64122772,
                        "answer_post": "In your trained folder where checkpoints are, there is checkpoint key file, open that and change the \"model_checkpoint_path\" checkpoint-number in the first line. Generally it will be saved the last checkpoint.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 56958434,
                        "answer_post": "If by latest model you mean the model after the final epoch, you can just simply leave the Checkpoint function unchanged and save your final result.\nAfter you fit the model add this line of code:\n\nThe checkpoint function will save the best model, and after you finish training, the model will save one final time, regardless of the result.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 58656237,
                        "answer_post": "The purpose of the validation accuracy is an estimation to see how your model generalises on unseen data. So when you are saving checkpoints with best validation accuracy , what happens is you are saving the weight(the ones which are learned by training) that best predicts results for the unseen data. So by having multiple checkpoints saved you can utilize these checkpoints when testing the model with test data( which may be taken from say a real time use case), and select the model which works well with your test data\nHope this helps\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71519403,
                        "answer_post": "These might help: Training checkpoints and tf.train.Checkpoint. According to the documentation, you should be able to load the model using something like this:\n\nI am not sure it will work if the checkpoint contains other variables. You might have to use checkpoint.restore(path).expect_partial().\nYou can also check the content that has been saved (according to the documentation) by Manually inspecting checkpoints :\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55037106,
                        "answer_post": "It's very simple. Create checkpoints while training the model and then use those checkpoints to resume training from where you left of.\n\nAfter this just load the checkpoint from where you want to resume training again\n\nAnd you are done.\nLet me know if you have more questions about this.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62292059,
                        "answer_post": "You can use model checkpoint callbacks as follows: for example capture the maximum accuracy obtained so far and save it in the checkpoint file.\n\n\nand then fit the model. \nmodel.fit(epochs=10, callbacks=[model_checkpoint_callback])\nyou can reload it again for update. \nmodel.load(checkpoint_filepath)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 60799059,
                        "answer_post": "There is no 'model' parameter in the saved checkpoint. If you look in train_rcnn.py:106:\n\nyou see that they save just the model parameters. It should've been something like:\n\nso then after loading you get a dictionary with 'model', and the other parameters they appear to be wanting to keep.\nThis seems to be a bug in their code.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 62395329,
                        "answer_post": "This can be done using the ModelCheckpoint callback:\n\nYou can modify the behaviour of the callback using the monitor, mode and save_best_only parameters, which govern the metric to track and whether the checkpoints are overwritten to retain the best model only. \n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62848472,
                        "answer_post": "Checkpoints are used to save your model if in case your system crashes or code interrupted while training so when you start training your model again after crashes you don't have to start from scratch.Checkpoints capture the exact value of all parameters (tf.Variable objects) used by a model. Checkpoints do not contain any description of the computation defined by the model.\nThe SavedModel format on the other hand includes a serialized description of the computation defined by the model in addition to the parameter values (checkpoint). Models in this format are independent of the source code that created the model.\nyou can see the above info in the official doc of tensorflow. @R Nanthak\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67168551,
                        "answer_post": "Assuming you are using a tf.keras.callbacks.ModelCheckpoint with save_freq = int (which is required to save after a certain number of batches), you can create a class that inherits from ModelCheckpoint and modify the class method on_train_batch_end\n\nThen add an instance of this class in model.fit.\n\nThis will add both the epoch and the batch number to the checkpoint filename.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71835386,
                        "answer_post": "The build_federated_averaging_process API builds an iterative process of the full federated learning steps. If you want to verify that the server model is updated, you can print state.model after each iterative_process.next(state, train_data).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74297783,
                        "answer_post": "you can use the checkpoints.restore() method to restore checkpoints of your preference. For example, if you want to load checkpoint at iteration 1000, then you write:\n\nFor more details please refer to this documentation. Thank You.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61319129,
                        "answer_post": "are you sure it is stuck? do you get any errors?\nDuring the training process, TF OD API writes logs into an event file (can be opened using tensorboard) in the model directory.\nlook in your model directory and see if there is an eventfile written there, look at its time stamp to see if it is being updated.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63366977,
                        "answer_post": "It depends on whether a custom training loop is required. In most cases, it's not and you can just call model.fit() and pass tf.keras.callbacks.ModelCheckpoint. If you do need to write your custom training loop, then you have to use tf.train.Checkpoint (and tf.train.CheckpointManager) since there's no callback mechanism.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 58536430,
                        "answer_post": "Using tf.train.CheckpointManager, you can specify how many checkpoints it needs to keep at any given point of time using the argument \"max_to_keep\". \nThis keeps replacing the oldest checkpoint and saves the new one once it reaches the maximum number of checkpoints to be saved. \nPlease refer below link for details:\nhttps://www.tensorflow.org/guide/checkpoint\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 69486380,
                        "answer_post": "validation metrics are only calculated at the end of an epoch, so you can not stop training on a batch by evaluation the validation metric. However you can stop training at the end of an epoch. Below is the code for a custom callback that will stop training at the end of an epoch when the quantity being monitored reaches or exceeds the float value threshold. In the callback parameter monitor can be set to either 'train' or 'valid' If monitor='train' then training will halt if the training accuracy meets or exceeds the threshold value. If monitor='valid' then training will halt when the validation accuracy meets or exceeds the threshold value. In the callback, parameter model is the name of your compiled model. If the threshold level is met or exceeded during training your_model weights are set to the weights for the epoch on which the threshold was exceeded. A message is also printed out on that epoch stating training has been halted and the value of the metric being monitored is printed out.\n\nto use the callback the code is below\n\nIn your_model.fit() include callbacks=callbacks.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 54553770,
                        "answer_post": "The session.run() call for validation will be simply feedforward network which will take very less time and also memory. So it should not a big deal if you are using it multiple times. You can try having another validation op with different input placeholders for X1 and Y1 and pass these tensors to your model and validate.\n\nAnd then do something like this\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 69794011,
                        "answer_post": "You can use tf.train.CheckpointManager to load your latest checkpoint or whatever checkpoint you like and then generate some images with your generator model based on random noise:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55917605,
                        "answer_post": "The train_logdir represents the checkpoint directory. The train_logdir is an input to the checkpoint_dir argument of the tf.train.MonitoredTrainingSession utility. The checkpoints are saved/restored to/from this directory.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68001567,
                        "answer_post": "Here is the model\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63699290,
                        "answer_post": "I have solved my problem. To export TF Slim Resnet checkpoint with TF 1.14 to SavedModel, warm start can be used together with export_savedmodel as follows:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56793601,
                        "answer_post": "Here's the code to convert the checkpoint to SavedModel\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60309119,
                        "answer_post": "You can save the weights in checkpoint format using:\n\nYou can read more about saving weights or models and chepoints here\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55409692,
                        "answer_post": "train.py\n\nmodel.py\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71289634,
                        "answer_post": "Try Saving the model again\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68184521,
                        "answer_post": "Use tf.where\n\n\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73923033,
                        "answer_post": "Use tf.cond:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You should create a CheckpointManager at the start as:\n\nNow after running for few epoch, to restore latest checkpoint, you should get the latest checkpoint from the CheckpointManager:\n\nThis will restore your session from the latest epoch.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I'm not exactly sure what you mean with\n\nHow (with what methods) can I use these models now?\n\nThe model is not saved in those files but i can be restored with them.\nThose*.ckpt get saved during training but do not contain your model. If you want to \"use\" your model you need to restore those files to it. Take a look at Tensorflow's Checkpoint and CheckpointManager. This tutorial shows a simple snipped of how to restore .ckpt files to your model.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "I also had a hard time differentiating between the checkpoint objects used when I looked at other people's code, so I wrote down some notes about when to use which one and how to use them in general.\nEither-way, I think it might be useful for other people having the same issue:\nSaving model Checkpoints\nThese are 2 ways of saving your model's checkpoints, each is for a different use case:\n1) Checkpoint & CheckpointManager\nThis is use-full when you are managing the training loops yourself.\nYou use them like this:\n1.1) Checkpoint\nDefinition from the docs:\n\"A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file\".\nHow to initialise it:\n\nYou can pass it key value pairs for:\n\nAll the custom function calls or objects that make up your model and you want to keep track of:\nLike a generator, discriminiator, loss function, optimizer etc\n\n\n\n\n1.2) CheckpointManager\nThis literally manages the checkpoints you have defined to be stored at a location and things like how many to to keep.\nDefinition from the docs:\n\"Manages multiple checkpoints by keeping some and deleting unneeded ones\"\nHow to initialise it:\n\nInitialise it with the CheckPoint object you create as first argument.\nThe directory where to save the checkpoint files.\nAnd you probably want to define how much you want to keep, since this can be a lot of complex models\n\n\nHow to use it:\n\nWe have setup the manager object with our specified checkpoints, so it's ready to use.\nCall this at the end of each training epoch\n\n\n2) ModelCheckpoint (callback)\nYou want to use this callback when you are not managing epoch iterations yourself. For example when you have setup a relatively simple Sequential model and you call model.fit(), which manages the training process for you.\nDefinition from the docs:\n\"Callback to save the Keras model or model weights at some frequency.\"\nHow to initialise it:\n\nPass in the path where to save the model\n\nThe option save_weights_only is set to False by default:\n\nIf you want to only save the weights make sure to update this\n\n\nThe option save_best_only is set to False by default:\n\nIf you want to only save the best model instead of all of them, you can set this to True.\n\n\nverbose is set to 0 (False), so you can update this to 1 to validate it\n\n\n\nHow to use it:\n\nThe model checkpoint callback is now ready to for training.\nYou pass in the object in you into your callbacks list when you fit the model:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "while creating checkpoints you can pass the optimizer argument for saving the optimizer status\n\nThen you can restore optimizer status while restoring those checkpoints.For more details please refer to this documentation. Thank You.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "But the model performance when you try to build the model from the trained checkpoints are not same to the original performance of the model on the local notebook.\nInstead prefer saving the model in the following way below:\n\nWith this method, you don't have to worry about the dependencies of object_detection api. You just need tensorflow library for inference.\nINFERENCE CODE:\n\nKeep in mind about the image_tensor shape.\nSolution from github\nhttps://github.com/tensorflow/models/issues/8862\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The purpose of the validation accuracy is an estimation to see how your model generalises on unseen data. So when you are saving checkpoints with best validation accuracy , what happens is you are saving the weight(the ones which are learned by training) that best predicts results for the unseen data. So by having multiple checkpoints saved you can utilize these checkpoints when testing the model with test data( which may be taken from say a real time use case), and select the model which works well with your test data\nHope this helps\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes to both questions.\n1) Without recompiling the model the model weights are bound to in the model so \n\nworks to update the model from previous weights but do think about if this is exactly what you want to do.\n\nYes, saving and loading a model works as expected\n\n\nShould do the trick.\nFor saving at checkpoints I'd recommend using the ModelCheckpoint callback. That makes it easy to save the model and specific iterations points so that you can train from that point in the future.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Apart from the discussion above, here is where the pretrained checkpoints are loaded in tensorflow object detection api. As you can see, the checkpoint paths are passed by the variable train_config.fine_tune_checkpoint, this variable is a field under train_config in the config file. It is not the same as model_dir, which is only used for saving the most recent checkpoints. \nIf you use the same command line to resume training, the training seemed to automatically start from the latest checkpoint in model_dir and this is supported by tensorflow Supervisor. See here for reference.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Apart from the discussion above, here is where the pretrained checkpoints are loaded in tensorflow object detection api. As you can see, the checkpoint paths are passed by the variable train_config.fine_tune_checkpoint, this variable is a field under train_config in the config file. It is not the same as model_dir, which is only used for saving the most recent checkpoints. \nIf you use the same command line to resume training, the training seemed to automatically start from the latest checkpoint in model_dir and this is supported by tensorflow Supervisor. See here for reference.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You should fully use the Functional API instead of mixing the Sequential and Functional APIs, and then you will not have this problem. Model management and building is much easier with the Functional API as well.\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "directive": {
                "finetuned_dpr": [
                    {
                        "id": 67228765,
                        "answer_post": "I also had a hard time differentiating between the checkpoint objects used when I looked at other people's code, so I wrote down some notes about when to use which one and how to use them in general.\nEither-way, I think it might be useful for other people having the same issue:\nSaving model Checkpoints\nThese are 2 ways of saving your model's checkpoints, each is for a different use case:\n1) Checkpoint & CheckpointManager\nThis is use-full when you are managing the training loops yourself.\nYou use them like this:\n1.1) Checkpoint\nDefinition from the docs:\n\"A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file\".\nHow to initialise it:\n\nYou can pass it key value pairs for:\n\nAll the custom function calls or objects that make up your model and you want to keep track of:\nLike a generator, discriminiator, loss function, optimizer etc\n\n\n\n\n1.2) CheckpointManager\nThis literally manages the checkpoints you have defined to be stored at a location and things like how many to to keep.\nDefinition from the docs:\n\"Manages multiple checkpoints by keeping some and deleting unneeded ones\"\nHow to initialise it:\n\nInitialise it with the CheckPoint object you create as first argument.\nThe directory where to save the checkpoint files.\nAnd you probably want to define how much you want to keep, since this can be a lot of complex models\n\n\nHow to use it:\n\nWe have setup the manager object with our specified checkpoints, so it's ready to use.\nCall this at the end of each training epoch\n\n\n2) ModelCheckpoint (callback)\nYou want to use this callback when you are not managing epoch iterations yourself. For example when you have setup a relatively simple Sequential model and you call model.fit(), which manages the training process for you.\nDefinition from the docs:\n\"Callback to save the Keras model or model weights at some frequency.\"\nHow to initialise it:\n\nPass in the path where to save the model\n\nThe option save_weights_only is set to False by default:\n\nIf you want to only save the weights make sure to update this\n\n\nThe option save_best_only is set to False by default:\n\nIf you want to only save the best model instead of all of them, you can set this to True.\n\n\nverbose is set to 0 (False), so you can update this to 1 to validate it\n\n\n\nHow to use it:\n\nThe model checkpoint callback is now ready to for training.\nYou pass in the object in you into your callbacks list when you fit the model:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 65364637,
                        "answer_post": "I decided to save on the \"manual\" save of the relevant data.\n\nFirst, I save model.history.history whenever I save the checkpoint and on_train_end with\n\n\n\nWhen I start the program, I check if the checkpoint exists, if yes, I load it and, at the same time, I check if the history exists and if it does I load it and store in model._history variable since model.history.history is only created after you start training!\n\n\nAdditionally, I set model._current_epoch value to keep track of the last epoch:\n\n\nAfter starting training I assign the proper value of model.history.history and remove the old value.\n\n\nNot the most elegant solution but it serves the purpose for now.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71129608,
                        "answer_post": "As of 02.2022\nThe Validation process is supposed to run at the same time with the Training process so that whenever a new Checkpoint is saved, the Validation process immediately loads the Checkpoint and starts validating.\nPlease see my other answer in this regard.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64122772,
                        "answer_post": "In your trained folder where checkpoints are, there is checkpoint key file, open that and change the \"model_checkpoint_path\" checkpoint-number in the first line. Generally it will be saved the last checkpoint.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71519403,
                        "answer_post": "These might help: Training checkpoints and tf.train.Checkpoint. According to the documentation, you should be able to load the model using something like this:\n\nI am not sure it will work if the checkpoint contains other variables. You might have to use checkpoint.restore(path).expect_partial().\nYou can also check the content that has been saved (according to the documentation) by Manually inspecting checkpoints :\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 58656237,
                        "answer_post": "The purpose of the validation accuracy is an estimation to see how your model generalises on unseen data. So when you are saving checkpoints with best validation accuracy , what happens is you are saving the weight(the ones which are learned by training) that best predicts results for the unseen data. So by having multiple checkpoints saved you can utilize these checkpoints when testing the model with test data( which may be taken from say a real time use case), and select the model which works well with your test data\nHope this helps\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56958434,
                        "answer_post": "If by latest model you mean the model after the final epoch, you can just simply leave the Checkpoint function unchanged and save your final result.\nAfter you fit the model add this line of code:\n\nThe checkpoint function will save the best model, and after you finish training, the model will save one final time, regardless of the result.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55037106,
                        "answer_post": "It's very simple. Create checkpoints while training the model and then use those checkpoints to resume training from where you left of.\n\nAfter this just load the checkpoint from where you want to resume training again\n\nAnd you are done.\nLet me know if you have more questions about this.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62292059,
                        "answer_post": "You can use model checkpoint callbacks as follows: for example capture the maximum accuracy obtained so far and save it in the checkpoint file.\n\n\nand then fit the model. \nmodel.fit(epochs=10, callbacks=[model_checkpoint_callback])\nyou can reload it again for update. \nmodel.load(checkpoint_filepath)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 69189898,
                        "answer_post": "The tf.train.Saver() constructor takes an optional argument called max_to_keep, which defaults to keeping the 5 most recent checkpoints of your model. To save more models, simply specify a value for that argument:\nTo keep all checkpoints, pass the argument max_to_keep=None to the saver constructor.\nmax_to_keep - indicates the maximum number of recent checkpoint files to keep. As new files are created, older files are deleted. If None or 0, no checkpoints are deleted from the filesystem but only the last one is kept in the checkpoint file. Defaults to 5 (that is, the 5 most recent checkpoint files are kept.)\nkeep_checkpoint_every_n_hours - In addition to keeping the most recent max_to_keep checkpoint files, you might want to keep one checkpoint file for every N hours of training. This can be useful if you want to later analyze how a model progressed during a long training session. For example, passing keep_checkpoint_every_n_hours=2 ensures that you keep one checkpoint file for every 2 hours of training. The default value of 10,000 hours effectively disables the feature.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 62395329,
                        "answer_post": "This can be done using the ModelCheckpoint callback:\n\nYou can modify the behaviour of the callback using the monitor, mode and save_best_only parameters, which govern the metric to track and whether the checkpoints are overwritten to retain the best model only. \n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62848472,
                        "answer_post": "Checkpoints are used to save your model if in case your system crashes or code interrupted while training so when you start training your model again after crashes you don't have to start from scratch.Checkpoints capture the exact value of all parameters (tf.Variable objects) used by a model. Checkpoints do not contain any description of the computation defined by the model.\nThe SavedModel format on the other hand includes a serialized description of the computation defined by the model in addition to the parameter values (checkpoint). Models in this format are independent of the source code that created the model.\nyou can see the above info in the official doc of tensorflow. @R Nanthak\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67168551,
                        "answer_post": "Assuming you are using a tf.keras.callbacks.ModelCheckpoint with save_freq = int (which is required to save after a certain number of batches), you can create a class that inherits from ModelCheckpoint and modify the class method on_train_batch_end\n\nThen add an instance of this class in model.fit.\n\nThis will add both the epoch and the batch number to the checkpoint filename.\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74297783,
                        "answer_post": "you can use the checkpoints.restore() method to restore checkpoints of your preference. For example, if you want to load checkpoint at iteration 1000, then you write:\n\nFor more details please refer to this documentation. Thank You.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71835386,
                        "answer_post": "The build_federated_averaging_process API builds an iterative process of the full federated learning steps. If you want to verify that the server model is updated, you can print state.model after each iterative_process.next(state, train_data).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63366977,
                        "answer_post": "It depends on whether a custom training loop is required. In most cases, it's not and you can just call model.fit() and pass tf.keras.callbacks.ModelCheckpoint. If you do need to write your custom training loop, then you have to use tf.train.Checkpoint (and tf.train.CheckpointManager) since there's no callback mechanism.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61319129,
                        "answer_post": "are you sure it is stuck? do you get any errors?\nDuring the training process, TF OD API writes logs into an event file (can be opened using tensorboard) in the model directory.\nlook in your model directory and see if there is an eventfile written there, look at its time stamp to see if it is being updated.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69486380,
                        "answer_post": "validation metrics are only calculated at the end of an epoch, so you can not stop training on a batch by evaluation the validation metric. However you can stop training at the end of an epoch. Below is the code for a custom callback that will stop training at the end of an epoch when the quantity being monitored reaches or exceeds the float value threshold. In the callback parameter monitor can be set to either 'train' or 'valid' If monitor='train' then training will halt if the training accuracy meets or exceeds the threshold value. If monitor='valid' then training will halt when the validation accuracy meets or exceeds the threshold value. In the callback, parameter model is the name of your compiled model. If the threshold level is met or exceeded during training your_model weights are set to the weights for the epoch on which the threshold was exceeded. A message is also printed out on that epoch stating training has been halted and the value of the metric being monitored is printed out.\n\nto use the callback the code is below\n\nIn your_model.fit() include callbacks=callbacks.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 58536430,
                        "answer_post": "Using tf.train.CheckpointManager, you can specify how many checkpoints it needs to keep at any given point of time using the argument \"max_to_keep\". \nThis keeps replacing the oldest checkpoint and saves the new one once it reaches the maximum number of checkpoints to be saved. \nPlease refer below link for details:\nhttps://www.tensorflow.org/guide/checkpoint\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63475581,
                        "answer_post": "The default monitor for ModelCheckpoint is the validation loss or \"val_loss\".\nAs the warning suggests, the key \"val_loss\" is missing because you didn't use validation data in model.fit().\nEither specify the validation split or validation data in model.fit() or just use training loss or accuracy as a monitor for ModelCheckpoint as in my example below.\n\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 69794011,
                        "answer_post": "You can use tf.train.CheckpointManager to load your latest checkpoint or whatever checkpoint you like and then generate some images with your generator model based on random noise:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55917605,
                        "answer_post": "The train_logdir represents the checkpoint directory. The train_logdir is an input to the checkpoint_dir argument of the tf.train.MonitoredTrainingSession utility. The checkpoints are saved/restored to/from this directory.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 60309119,
                        "answer_post": "You can save the weights in checkpoint format using:\n\nYou can read more about saving weights or models and chepoints here\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63699290,
                        "answer_post": "I have solved my problem. To export TF Slim Resnet checkpoint with TF 1.14 to SavedModel, warm start can be used together with export_savedmodel as follows:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68001567,
                        "answer_post": "Here is the model\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55409692,
                        "answer_post": "train.py\n\nmodel.py\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56793601,
                        "answer_post": "Here's the code to convert the checkpoint to SavedModel\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68184521,
                        "answer_post": "Use tf.where\n\n\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71289634,
                        "answer_post": "Try Saving the model again\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73923033,
                        "answer_post": "Use tf.cond:\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You should create a CheckpointManager at the start as:\n\nNow after running for few epoch, to restore latest checkpoint, you should get the latest checkpoint from the CheckpointManager:\n\nThis will restore your session from the latest epoch.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I'm not exactly sure what you mean with\n\nHow (with what methods) can I use these models now?\n\nThe model is not saved in those files but i can be restored with them.\nThose*.ckpt get saved during training but do not contain your model. If you want to \"use\" your model you need to restore those files to it. Take a look at Tensorflow's Checkpoint and CheckpointManager. This tutorial shows a simple snipped of how to restore .ckpt files to your model.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "I also had a hard time differentiating between the checkpoint objects used when I looked at other people's code, so I wrote down some notes about when to use which one and how to use them in general.\nEither-way, I think it might be useful for other people having the same issue:\nSaving model Checkpoints\nThese are 2 ways of saving your model's checkpoints, each is for a different use case:\n1) Checkpoint & CheckpointManager\nThis is use-full when you are managing the training loops yourself.\nYou use them like this:\n1.1) Checkpoint\nDefinition from the docs:\n\"A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file\".\nHow to initialise it:\n\nYou can pass it key value pairs for:\n\nAll the custom function calls or objects that make up your model and you want to keep track of:\nLike a generator, discriminiator, loss function, optimizer etc\n\n\n\n\n1.2) CheckpointManager\nThis literally manages the checkpoints you have defined to be stored at a location and things like how many to to keep.\nDefinition from the docs:\n\"Manages multiple checkpoints by keeping some and deleting unneeded ones\"\nHow to initialise it:\n\nInitialise it with the CheckPoint object you create as first argument.\nThe directory where to save the checkpoint files.\nAnd you probably want to define how much you want to keep, since this can be a lot of complex models\n\n\nHow to use it:\n\nWe have setup the manager object with our specified checkpoints, so it's ready to use.\nCall this at the end of each training epoch\n\n\n2) ModelCheckpoint (callback)\nYou want to use this callback when you are not managing epoch iterations yourself. For example when you have setup a relatively simple Sequential model and you call model.fit(), which manages the training process for you.\nDefinition from the docs:\n\"Callback to save the Keras model or model weights at some frequency.\"\nHow to initialise it:\n\nPass in the path where to save the model\n\nThe option save_weights_only is set to False by default:\n\nIf you want to only save the weights make sure to update this\n\n\nThe option save_best_only is set to False by default:\n\nIf you want to only save the best model instead of all of them, you can set this to True.\n\n\nverbose is set to 0 (False), so you can update this to 1 to validate it\n\n\n\nHow to use it:\n\nThe model checkpoint callback is now ready to for training.\nYou pass in the object in you into your callbacks list when you fit the model:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "while creating checkpoints you can pass the optimizer argument for saving the optimizer status\n\nThen you can restore optimizer status while restoring those checkpoints.For more details please refer to this documentation. Thank You.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The purpose of the validation accuracy is an estimation to see how your model generalises on unseen data. So when you are saving checkpoints with best validation accuracy , what happens is you are saving the weight(the ones which are learned by training) that best predicts results for the unseen data. So by having multiple checkpoints saved you can utilize these checkpoints when testing the model with test data( which may be taken from say a real time use case), and select the model which works well with your test data\nHope this helps\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes to both questions.\n1) Without recompiling the model the model weights are bound to in the model so \n\nworks to update the model from previous weights but do think about if this is exactly what you want to do.\n\nYes, saving and loading a model works as expected\n\n\nShould do the trick.\nFor saving at checkpoints I'd recommend using the ModelCheckpoint callback. That makes it easy to save the model and specific iterations points so that you can train from that point in the future.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The Traceback has all the information you need, but you need to read it from the top to bottom because the lowest reported error is not always the actual error message.\n\nAssign requires shapes of both tensors to match. lhs shape= [8,15] rhs shape= [8,12]\n\nand further down:\n\nRestoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint.\n\nYou're running the model in a \"dirty\" folder (it contains results from previous attempts with a different model). Delete your old checkpoints or change training directory.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Apart from the discussion above, here is where the pretrained checkpoints are loaded in tensorflow object detection api. As you can see, the checkpoint paths are passed by the variable train_config.fine_tune_checkpoint, this variable is a field under train_config in the config file. It is not the same as model_dir, which is only used for saving the most recent checkpoints. \nIf you use the same command line to resume training, the training seemed to automatically start from the latest checkpoint in model_dir and this is supported by tensorflow Supervisor. See here for reference.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Apart from the discussion above, here is where the pretrained checkpoints are loaded in tensorflow object detection api. As you can see, the checkpoint paths are passed by the variable train_config.fine_tune_checkpoint, this variable is a field under train_config in the config file. It is not the same as model_dir, which is only used for saving the most recent checkpoints. \nIf you use the same command line to resume training, the training seemed to automatically start from the latest checkpoint in model_dir and this is supported by tensorflow Supervisor. See here for reference.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You should fully use the Functional API instead of mixing the Sequential and Functional APIs, and then you will not have this problem. Model management and building is much easier with the Functional API as well.\n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "pattern": {
                "finetuned_dpr": [
                    {
                        "id": 65364637,
                        "answer_post": "I decided to save on the \"manual\" save of the relevant data.\n\nFirst, I save model.history.history whenever I save the checkpoint and on_train_end with\n\n\n\nWhen I start the program, I check if the checkpoint exists, if yes, I load it and, at the same time, I check if the history exists and if it does I load it and store in model._history variable since model.history.history is only created after you start training!\n\n\nAdditionally, I set model._current_epoch value to keep track of the last epoch:\n\n\nAfter starting training I assign the proper value of model.history.history and remove the old value.\n\n\nNot the most elegant solution but it serves the purpose for now.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 67228765,
                        "answer_post": "I also had a hard time differentiating between the checkpoint objects used when I looked at other people's code, so I wrote down some notes about when to use which one and how to use them in general.\nEither-way, I think it might be useful for other people having the same issue:\nSaving model Checkpoints\nThese are 2 ways of saving your model's checkpoints, each is for a different use case:\n1) Checkpoint & CheckpointManager\nThis is use-full when you are managing the training loops yourself.\nYou use them like this:\n1.1) Checkpoint\nDefinition from the docs:\n\"A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file\".\nHow to initialise it:\n\nYou can pass it key value pairs for:\n\nAll the custom function calls or objects that make up your model and you want to keep track of:\nLike a generator, discriminiator, loss function, optimizer etc\n\n\n\n\n1.2) CheckpointManager\nThis literally manages the checkpoints you have defined to be stored at a location and things like how many to to keep.\nDefinition from the docs:\n\"Manages multiple checkpoints by keeping some and deleting unneeded ones\"\nHow to initialise it:\n\nInitialise it with the CheckPoint object you create as first argument.\nThe directory where to save the checkpoint files.\nAnd you probably want to define how much you want to keep, since this can be a lot of complex models\n\n\nHow to use it:\n\nWe have setup the manager object with our specified checkpoints, so it's ready to use.\nCall this at the end of each training epoch\n\n\n2) ModelCheckpoint (callback)\nYou want to use this callback when you are not managing epoch iterations yourself. For example when you have setup a relatively simple Sequential model and you call model.fit(), which manages the training process for you.\nDefinition from the docs:\n\"Callback to save the Keras model or model weights at some frequency.\"\nHow to initialise it:\n\nPass in the path where to save the model\n\nThe option save_weights_only is set to False by default:\n\nIf you want to only save the weights make sure to update this\n\n\nThe option save_best_only is set to False by default:\n\nIf you want to only save the best model instead of all of them, you can set this to True.\n\n\nverbose is set to 0 (False), so you can update this to 1 to validate it\n\n\n\nHow to use it:\n\nThe model checkpoint callback is now ready to for training.\nYou pass in the object in you into your callbacks list when you fit the model:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71129608,
                        "answer_post": "As of 02.2022\nThe Validation process is supposed to run at the same time with the Training process so that whenever a new Checkpoint is saved, the Validation process immediately loads the Checkpoint and starts validating.\nPlease see my other answer in this regard.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64122772,
                        "answer_post": "In your trained folder where checkpoints are, there is checkpoint key file, open that and change the \"model_checkpoint_path\" checkpoint-number in the first line. Generally it will be saved the last checkpoint.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71519403,
                        "answer_post": "These might help: Training checkpoints and tf.train.Checkpoint. According to the documentation, you should be able to load the model using something like this:\n\nI am not sure it will work if the checkpoint contains other variables. You might have to use checkpoint.restore(path).expect_partial().\nYou can also check the content that has been saved (according to the documentation) by Manually inspecting checkpoints :\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 56958434,
                        "answer_post": "If by latest model you mean the model after the final epoch, you can just simply leave the Checkpoint function unchanged and save your final result.\nAfter you fit the model add this line of code:\n\nThe checkpoint function will save the best model, and after you finish training, the model will save one final time, regardless of the result.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 58656237,
                        "answer_post": "The purpose of the validation accuracy is an estimation to see how your model generalises on unseen data. So when you are saving checkpoints with best validation accuracy , what happens is you are saving the weight(the ones which are learned by training) that best predicts results for the unseen data. So by having multiple checkpoints saved you can utilize these checkpoints when testing the model with test data( which may be taken from say a real time use case), and select the model which works well with your test data\nHope this helps\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62292059,
                        "answer_post": "You can use model checkpoint callbacks as follows: for example capture the maximum accuracy obtained so far and save it in the checkpoint file.\n\n\nand then fit the model. \nmodel.fit(epochs=10, callbacks=[model_checkpoint_callback])\nyou can reload it again for update. \nmodel.load(checkpoint_filepath)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55037106,
                        "answer_post": "It's very simple. Create checkpoints while training the model and then use those checkpoints to resume training from where you left of.\n\nAfter this just load the checkpoint from where you want to resume training again\n\nAnd you are done.\nLet me know if you have more questions about this.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60799059,
                        "answer_post": "There is no 'model' parameter in the saved checkpoint. If you look in train_rcnn.py:106:\n\nyou see that they save just the model parameters. It should've been something like:\n\nso then after loading you get a dictionary with 'model', and the other parameters they appear to be wanting to keep.\nThis seems to be a bug in their code.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 67168551,
                        "answer_post": "Assuming you are using a tf.keras.callbacks.ModelCheckpoint with save_freq = int (which is required to save after a certain number of batches), you can create a class that inherits from ModelCheckpoint and modify the class method on_train_batch_end\n\nThen add an instance of this class in model.fit.\n\nThis will add both the epoch and the batch number to the checkpoint filename.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62395329,
                        "answer_post": "This can be done using the ModelCheckpoint callback:\n\nYou can modify the behaviour of the callback using the monitor, mode and save_best_only parameters, which govern the metric to track and whether the checkpoints are overwritten to retain the best model only. \n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62848472,
                        "answer_post": "Checkpoints are used to save your model if in case your system crashes or code interrupted while training so when you start training your model again after crashes you don't have to start from scratch.Checkpoints capture the exact value of all parameters (tf.Variable objects) used by a model. Checkpoints do not contain any description of the computation defined by the model.\nThe SavedModel format on the other hand includes a serialized description of the computation defined by the model in addition to the parameter values (checkpoint). Models in this format are independent of the source code that created the model.\nyou can see the above info in the official doc of tensorflow. @R Nanthak\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71835386,
                        "answer_post": "The build_federated_averaging_process API builds an iterative process of the full federated learning steps. If you want to verify that the server model is updated, you can print state.model after each iterative_process.next(state, train_data).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74297783,
                        "answer_post": "you can use the checkpoints.restore() method to restore checkpoints of your preference. For example, if you want to load checkpoint at iteration 1000, then you write:\n\nFor more details please refer to this documentation. Thank You.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 69486380,
                        "answer_post": "validation metrics are only calculated at the end of an epoch, so you can not stop training on a batch by evaluation the validation metric. However you can stop training at the end of an epoch. Below is the code for a custom callback that will stop training at the end of an epoch when the quantity being monitored reaches or exceeds the float value threshold. In the callback parameter monitor can be set to either 'train' or 'valid' If monitor='train' then training will halt if the training accuracy meets or exceeds the threshold value. If monitor='valid' then training will halt when the validation accuracy meets or exceeds the threshold value. In the callback, parameter model is the name of your compiled model. If the threshold level is met or exceeded during training your_model weights are set to the weights for the epoch on which the threshold was exceeded. A message is also printed out on that epoch stating training has been halted and the value of the metric being monitored is printed out.\n\nto use the callback the code is below\n\nIn your_model.fit() include callbacks=callbacks.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63366977,
                        "answer_post": "It depends on whether a custom training loop is required. In most cases, it's not and you can just call model.fit() and pass tf.keras.callbacks.ModelCheckpoint. If you do need to write your custom training loop, then you have to use tf.train.Checkpoint (and tf.train.CheckpointManager) since there's no callback mechanism.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61319129,
                        "answer_post": "are you sure it is stuck? do you get any errors?\nDuring the training process, TF OD API writes logs into an event file (can be opened using tensorboard) in the model directory.\nlook in your model directory and see if there is an eventfile written there, look at its time stamp to see if it is being updated.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61275169,
                        "answer_post": "The cause of the bug were two Tensorboard callbacks which were called at the end of each epoch to log the training. To be more specific, setting the argument write_images=False of the Tensorboard callback solves the problem.\nHere is the full working code for the callbacks\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55917605,
                        "answer_post": "The train_logdir represents the checkpoint directory. The train_logdir is an input to the checkpoint_dir argument of the tf.train.MonitoredTrainingSession utility. The checkpoints are saved/restored to/from this directory.\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 69794011,
                        "answer_post": "You can use tf.train.CheckpointManager to load your latest checkpoint or whatever checkpoint you like and then generate some images with your generator model based on random noise:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 56793601,
                        "answer_post": "Here's the code to convert the checkpoint to SavedModel\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68001567,
                        "answer_post": "Here is the model\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60309119,
                        "answer_post": "You can save the weights in checkpoint format using:\n\nYou can read more about saving weights or models and chepoints here\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55917605,
                        "answer_post": "The train_logdir represents the checkpoint directory. The train_logdir is an input to the checkpoint_dir argument of the tf.train.MonitoredTrainingSession utility. The checkpoints are saved/restored to/from this directory.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71289634,
                        "answer_post": "Try Saving the model again\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63699290,
                        "answer_post": "I have solved my problem. To export TF Slim Resnet checkpoint with TF 1.14 to SavedModel, warm start can be used together with export_savedmodel as follows:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55409692,
                        "answer_post": "train.py\n\nmodel.py\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 64008257,
                        "answer_post": "Use pickle to save the model\n\n\n\n\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68184521,
                        "answer_post": "Use tf.where\n\n\n\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You should create a CheckpointManager at the start as:\n\nNow after running for few epoch, to restore latest checkpoint, you should get the latest checkpoint from the CheckpointManager:\n\nThis will restore your session from the latest epoch.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I'm not exactly sure what you mean with\n\nHow (with what methods) can I use these models now?\n\nThe model is not saved in those files but i can be restored with them.\nThose*.ckpt get saved during training but do not contain your model. If you want to \"use\" your model you need to restore those files to it. Take a look at Tensorflow's Checkpoint and CheckpointManager. This tutorial shows a simple snipped of how to restore .ckpt files to your model.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "I also had a hard time differentiating between the checkpoint objects used when I looked at other people's code, so I wrote down some notes about when to use which one and how to use them in general.\nEither-way, I think it might be useful for other people having the same issue:\nSaving model Checkpoints\nThese are 2 ways of saving your model's checkpoints, each is for a different use case:\n1) Checkpoint & CheckpointManager\nThis is use-full when you are managing the training loops yourself.\nYou use them like this:\n1.1) Checkpoint\nDefinition from the docs:\n\"A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file\".\nHow to initialise it:\n\nYou can pass it key value pairs for:\n\nAll the custom function calls or objects that make up your model and you want to keep track of:\nLike a generator, discriminiator, loss function, optimizer etc\n\n\n\n\n1.2) CheckpointManager\nThis literally manages the checkpoints you have defined to be stored at a location and things like how many to to keep.\nDefinition from the docs:\n\"Manages multiple checkpoints by keeping some and deleting unneeded ones\"\nHow to initialise it:\n\nInitialise it with the CheckPoint object you create as first argument.\nThe directory where to save the checkpoint files.\nAnd you probably want to define how much you want to keep, since this can be a lot of complex models\n\n\nHow to use it:\n\nWe have setup the manager object with our specified checkpoints, so it's ready to use.\nCall this at the end of each training epoch\n\n\n2) ModelCheckpoint (callback)\nYou want to use this callback when you are not managing epoch iterations yourself. For example when you have setup a relatively simple Sequential model and you call model.fit(), which manages the training process for you.\nDefinition from the docs:\n\"Callback to save the Keras model or model weights at some frequency.\"\nHow to initialise it:\n\nPass in the path where to save the model\n\nThe option save_weights_only is set to False by default:\n\nIf you want to only save the weights make sure to update this\n\n\nThe option save_best_only is set to False by default:\n\nIf you want to only save the best model instead of all of them, you can set this to True.\n\n\nverbose is set to 0 (False), so you can update this to 1 to validate it\n\n\n\nHow to use it:\n\nThe model checkpoint callback is now ready to for training.\nYou pass in the object in you into your callbacks list when you fit the model:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "while creating checkpoints you can pass the optimizer argument for saving the optimizer status\n\nThen you can restore optimizer status while restoring those checkpoints.For more details please refer to this documentation. Thank You.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The purpose of the validation accuracy is an estimation to see how your model generalises on unseen data. So when you are saving checkpoints with best validation accuracy , what happens is you are saving the weight(the ones which are learned by training) that best predicts results for the unseen data. So by having multiple checkpoints saved you can utilize these checkpoints when testing the model with test data( which may be taken from say a real time use case), and select the model which works well with your test data\nHope this helps\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes to both questions.\n1) Without recompiling the model the model weights are bound to in the model so \n\nworks to update the model from previous weights but do think about if this is exactly what you want to do.\n\nYes, saving and loading a model works as expected\n\n\nShould do the trick.\nFor saving at checkpoints I'd recommend using the ModelCheckpoint callback. That makes it easy to save the model and specific iterations points so that you can train from that point in the future.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Apart from the discussion above, here is where the pretrained checkpoints are loaded in tensorflow object detection api. As you can see, the checkpoint paths are passed by the variable train_config.fine_tune_checkpoint, this variable is a field under train_config in the config file. It is not the same as model_dir, which is only used for saving the most recent checkpoints. \nIf you use the same command line to resume training, the training seemed to automatically start from the latest checkpoint in model_dir and this is supported by tensorflow Supervisor. See here for reference.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Apart from the discussion above, here is where the pretrained checkpoints are loaded in tensorflow object detection api. As you can see, the checkpoint paths are passed by the variable train_config.fine_tune_checkpoint, this variable is a field under train_config in the config file. It is not the same as model_dir, which is only used for saving the most recent checkpoints. \nIf you use the same command line to resume training, the training seemed to automatically start from the latest checkpoint in model_dir and this is supported by tensorflow Supervisor. See here for reference.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "You should fully use the Functional API instead of mixing the Sequential and Functional APIs, and then you will not have this problem. Model management and building is much easier with the Functional API as well.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "There are two states, the state_h which is the last step output; and the state_c which is the carry on state or memory. \nYou should use a functional API model to have more than one input:\n\nFollowing this approach, it's even possible to use outputs of other layers as initial states, if you want trainable initial states.\nThe big change is that you will need to pass the states for training and predicting:\n\nWhere you can use zeros for the states during training. \n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "environment": {
                "finetuned_dpr": [
                    {
                        "id": 65364637,
                        "answer_post": "I decided to save on the \"manual\" save of the relevant data.\n\nFirst, I save model.history.history whenever I save the checkpoint and on_train_end with\n\n\n\nWhen I start the program, I check if the checkpoint exists, if yes, I load it and, at the same time, I check if the history exists and if it does I load it and store in model._history variable since model.history.history is only created after you start training!\n\n\nAdditionally, I set model._current_epoch value to keep track of the last epoch:\n\n\nAfter starting training I assign the proper value of model.history.history and remove the old value.\n\n\nNot the most elegant solution but it serves the purpose for now.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67228765,
                        "answer_post": "I also had a hard time differentiating between the checkpoint objects used when I looked at other people's code, so I wrote down some notes about when to use which one and how to use them in general.\nEither-way, I think it might be useful for other people having the same issue:\nSaving model Checkpoints\nThese are 2 ways of saving your model's checkpoints, each is for a different use case:\n1) Checkpoint & CheckpointManager\nThis is use-full when you are managing the training loops yourself.\nYou use them like this:\n1.1) Checkpoint\nDefinition from the docs:\n\"A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file\".\nHow to initialise it:\n\nYou can pass it key value pairs for:\n\nAll the custom function calls or objects that make up your model and you want to keep track of:\nLike a generator, discriminiator, loss function, optimizer etc\n\n\n\n\n1.2) CheckpointManager\nThis literally manages the checkpoints you have defined to be stored at a location and things like how many to to keep.\nDefinition from the docs:\n\"Manages multiple checkpoints by keeping some and deleting unneeded ones\"\nHow to initialise it:\n\nInitialise it with the CheckPoint object you create as first argument.\nThe directory where to save the checkpoint files.\nAnd you probably want to define how much you want to keep, since this can be a lot of complex models\n\n\nHow to use it:\n\nWe have setup the manager object with our specified checkpoints, so it's ready to use.\nCall this at the end of each training epoch\n\n\n2) ModelCheckpoint (callback)\nYou want to use this callback when you are not managing epoch iterations yourself. For example when you have setup a relatively simple Sequential model and you call model.fit(), which manages the training process for you.\nDefinition from the docs:\n\"Callback to save the Keras model or model weights at some frequency.\"\nHow to initialise it:\n\nPass in the path where to save the model\n\nThe option save_weights_only is set to False by default:\n\nIf you want to only save the weights make sure to update this\n\n\nThe option save_best_only is set to False by default:\n\nIf you want to only save the best model instead of all of them, you can set this to True.\n\n\nverbose is set to 0 (False), so you can update this to 1 to validate it\n\n\n\nHow to use it:\n\nThe model checkpoint callback is now ready to for training.\nYou pass in the object in you into your callbacks list when you fit the model:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71129608,
                        "answer_post": "As of 02.2022\nThe Validation process is supposed to run at the same time with the Training process so that whenever a new Checkpoint is saved, the Validation process immediately loads the Checkpoint and starts validating.\nPlease see my other answer in this regard.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64122772,
                        "answer_post": "In your trained folder where checkpoints are, there is checkpoint key file, open that and change the \"model_checkpoint_path\" checkpoint-number in the first line. Generally it will be saved the last checkpoint.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71519403,
                        "answer_post": "These might help: Training checkpoints and tf.train.Checkpoint. According to the documentation, you should be able to load the model using something like this:\n\nI am not sure it will work if the checkpoint contains other variables. You might have to use checkpoint.restore(path).expect_partial().\nYou can also check the content that has been saved (according to the documentation) by Manually inspecting checkpoints :\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 58656237,
                        "answer_post": "The purpose of the validation accuracy is an estimation to see how your model generalises on unseen data. So when you are saving checkpoints with best validation accuracy , what happens is you are saving the weight(the ones which are learned by training) that best predicts results for the unseen data. So by having multiple checkpoints saved you can utilize these checkpoints when testing the model with test data( which may be taken from say a real time use case), and select the model which works well with your test data\nHope this helps\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56958434,
                        "answer_post": "If by latest model you mean the model after the final epoch, you can just simply leave the Checkpoint function unchanged and save your final result.\nAfter you fit the model add this line of code:\n\nThe checkpoint function will save the best model, and after you finish training, the model will save one final time, regardless of the result.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55037106,
                        "answer_post": "It's very simple. Create checkpoints while training the model and then use those checkpoints to resume training from where you left of.\n\nAfter this just load the checkpoint from where you want to resume training again\n\nAnd you are done.\nLet me know if you have more questions about this.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62292059,
                        "answer_post": "You can use model checkpoint callbacks as follows: for example capture the maximum accuracy obtained so far and save it in the checkpoint file.\n\n\nand then fit the model. \nmodel.fit(epochs=10, callbacks=[model_checkpoint_callback])\nyou can reload it again for update. \nmodel.load(checkpoint_filepath)\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60799059,
                        "answer_post": "There is no 'model' parameter in the saved checkpoint. If you look in train_rcnn.py:106:\n\nyou see that they save just the model parameters. It should've been something like:\n\nso then after loading you get a dictionary with 'model', and the other parameters they appear to be wanting to keep.\nThis seems to be a bug in their code.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 67168551,
                        "answer_post": "Assuming you are using a tf.keras.callbacks.ModelCheckpoint with save_freq = int (which is required to save after a certain number of batches), you can create a class that inherits from ModelCheckpoint and modify the class method on_train_batch_end\n\nThen add an instance of this class in model.fit.\n\nThis will add both the epoch and the batch number to the checkpoint filename.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62848472,
                        "answer_post": "Checkpoints are used to save your model if in case your system crashes or code interrupted while training so when you start training your model again after crashes you don't have to start from scratch.Checkpoints capture the exact value of all parameters (tf.Variable objects) used by a model. Checkpoints do not contain any description of the computation defined by the model.\nThe SavedModel format on the other hand includes a serialized description of the computation defined by the model in addition to the parameter values (checkpoint). Models in this format are independent of the source code that created the model.\nyou can see the above info in the official doc of tensorflow. @R Nanthak\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62395329,
                        "answer_post": "This can be done using the ModelCheckpoint callback:\n\nYou can modify the behaviour of the callback using the monitor, mode and save_best_only parameters, which govern the metric to track and whether the checkpoints are overwritten to retain the best model only. \n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74297783,
                        "answer_post": "you can use the checkpoints.restore() method to restore checkpoints of your preference. For example, if you want to load checkpoint at iteration 1000, then you write:\n\nFor more details please refer to this documentation. Thank You.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71835386,
                        "answer_post": "The build_federated_averaging_process API builds an iterative process of the full federated learning steps. If you want to verify that the server model is updated, you can print state.model after each iterative_process.next(state, train_data).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 61319129,
                        "answer_post": "are you sure it is stuck? do you get any errors?\nDuring the training process, TF OD API writes logs into an event file (can be opened using tensorboard) in the model directory.\nlook in your model directory and see if there is an eventfile written there, look at its time stamp to see if it is being updated.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 69486380,
                        "answer_post": "validation metrics are only calculated at the end of an epoch, so you can not stop training on a batch by evaluation the validation metric. However you can stop training at the end of an epoch. Below is the code for a custom callback that will stop training at the end of an epoch when the quantity being monitored reaches or exceeds the float value threshold. In the callback parameter monitor can be set to either 'train' or 'valid' If monitor='train' then training will halt if the training accuracy meets or exceeds the threshold value. If monitor='valid' then training will halt when the validation accuracy meets or exceeds the threshold value. In the callback, parameter model is the name of your compiled model. If the threshold level is met or exceeded during training your_model weights are set to the weights for the epoch on which the threshold was exceeded. A message is also printed out on that epoch stating training has been halted and the value of the metric being monitored is printed out.\n\nto use the callback the code is below\n\nIn your_model.fit() include callbacks=callbacks.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63366977,
                        "answer_post": "It depends on whether a custom training loop is required. In most cases, it's not and you can just call model.fit() and pass tf.keras.callbacks.ModelCheckpoint. If you do need to write your custom training loop, then you have to use tf.train.Checkpoint (and tf.train.CheckpointManager) since there's no callback mechanism.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64122772,
                        "answer_post": "In your trained folder where checkpoints are, there is checkpoint key file, open that and change the \"model_checkpoint_path\" checkpoint-number in the first line. Generally it will be saved the last checkpoint.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 57370836,
                        "answer_post": "A checkpoint is meant for storing during training whereas a frozen graph is meant for inference.\nWhen you store a checkpoint a graph is NOT stored. They store values of variables in a graph as opposed to the whole graph, this is why you cannot resume training without recompiling the model. As it is the ckpt file is not enough.\nWhen a model is stored for inference it not only saves the graph but it also removes any nodes that don't benefit during inference. Some nodes are only required during training and not during inference, like dropout for example. Since ckpts store these training variables along with the rest of the weights, the ckpt may be larger in size. Saved models delete these variables hence are sometimes smaller in size.\nThis can be confirmed via TensorFlow documentation that quotes:\n\nCheckpoints capture the exact value of all parameters (tf.Variable objects) used by a model. Checkpoints do not contain any description of the computation defined by the model and thus are typically only useful when source code that will use the saved parameter values is available.\nThe SavedModel format, on the other hand, includes a serialized description of the computation defined by the model in addition to the parameter values (checkpoint). Models in this format are independent of the source code that created the model. They are thus suitable for deployment via TensorFlow Serving, TensorFlow Lite, TensorFlow.js, or programs in other programming languages (the C, C++, Java, Go, Rust, C# etc. TensorFlow APIs).\n\nFor further reading refer to https://www.tensorflow.org/beta/guide/checkpoints\n",
                        "contain_knowledge": 1
                    }
                ],
                "e5": [
                    {
                        "id": 69794011,
                        "answer_post": "You can use tf.train.CheckpointManager to load your latest checkpoint or whatever checkpoint you like and then generate some images with your generator model based on random noise:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55917605,
                        "answer_post": "The train_logdir represents the checkpoint directory. The train_logdir is an input to the checkpoint_dir argument of the tf.train.MonitoredTrainingSession utility. The checkpoints are saved/restored to/from this directory.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63699290,
                        "answer_post": "I have solved my problem. To export TF Slim Resnet checkpoint with TF 1.14 to SavedModel, warm start can be used together with export_savedmodel as follows:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68001567,
                        "answer_post": "Here is the model\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60309119,
                        "answer_post": "You can save the weights in checkpoint format using:\n\nYou can read more about saving weights or models and chepoints here\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68184521,
                        "answer_post": "Use tf.where\n\n\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55409692,
                        "answer_post": "train.py\n\nmodel.py\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56793601,
                        "answer_post": "Here's the code to convert the checkpoint to SavedModel\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73923033,
                        "answer_post": "Use tf.cond:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71289634,
                        "answer_post": "Try Saving the model again\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You should create a CheckpointManager at the start as:\n\nNow after running for few epoch, to restore latest checkpoint, you should get the latest checkpoint from the CheckpointManager:\n\nThis will restore your session from the latest epoch.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I'm not exactly sure what you mean with\n\nHow (with what methods) can I use these models now?\n\nThe model is not saved in those files but i can be restored with them.\nThose*.ckpt get saved during training but do not contain your model. If you want to \"use\" your model you need to restore those files to it. Take a look at Tensorflow's Checkpoint and CheckpointManager. This tutorial shows a simple snipped of how to restore .ckpt files to your model.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I also had a hard time differentiating between the checkpoint objects used when I looked at other people's code, so I wrote down some notes about when to use which one and how to use them in general.\nEither-way, I think it might be useful for other people having the same issue:\nSaving model Checkpoints\nThese are 2 ways of saving your model's checkpoints, each is for a different use case:\n1) Checkpoint & CheckpointManager\nThis is use-full when you are managing the training loops yourself.\nYou use them like this:\n1.1) Checkpoint\nDefinition from the docs:\n\"A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file\".\nHow to initialise it:\n\nYou can pass it key value pairs for:\n\nAll the custom function calls or objects that make up your model and you want to keep track of:\nLike a generator, discriminiator, loss function, optimizer etc\n\n\n\n\n1.2) CheckpointManager\nThis literally manages the checkpoints you have defined to be stored at a location and things like how many to to keep.\nDefinition from the docs:\n\"Manages multiple checkpoints by keeping some and deleting unneeded ones\"\nHow to initialise it:\n\nInitialise it with the CheckPoint object you create as first argument.\nThe directory where to save the checkpoint files.\nAnd you probably want to define how much you want to keep, since this can be a lot of complex models\n\n\nHow to use it:\n\nWe have setup the manager object with our specified checkpoints, so it's ready to use.\nCall this at the end of each training epoch\n\n\n2) ModelCheckpoint (callback)\nYou want to use this callback when you are not managing epoch iterations yourself. For example when you have setup a relatively simple Sequential model and you call model.fit(), which manages the training process for you.\nDefinition from the docs:\n\"Callback to save the Keras model or model weights at some frequency.\"\nHow to initialise it:\n\nPass in the path where to save the model\n\nThe option save_weights_only is set to False by default:\n\nIf you want to only save the weights make sure to update this\n\n\nThe option save_best_only is set to False by default:\n\nIf you want to only save the best model instead of all of them, you can set this to True.\n\n\nverbose is set to 0 (False), so you can update this to 1 to validate it\n\n\n\nHow to use it:\n\nThe model checkpoint callback is now ready to for training.\nYou pass in the object in you into your callbacks list when you fit the model:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "while creating checkpoints you can pass the optimizer argument for saving the optimizer status\n\nThen you can restore optimizer status while restoring those checkpoints.For more details please refer to this documentation. Thank You.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "The purpose of the validation accuracy is an estimation to see how your model generalises on unseen data. So when you are saving checkpoints with best validation accuracy , what happens is you are saving the weight(the ones which are learned by training) that best predicts results for the unseen data. So by having multiple checkpoints saved you can utilize these checkpoints when testing the model with test data( which may be taken from say a real time use case), and select the model which works well with your test data\nHope this helps\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes to both questions.\n1) Without recompiling the model the model weights are bound to in the model so \n\nworks to update the model from previous weights but do think about if this is exactly what you want to do.\n\nYes, saving and loading a model works as expected\n\n\nShould do the trick.\nFor saving at checkpoints I'd recommend using the ModelCheckpoint callback. That makes it easy to save the model and specific iterations points so that you can train from that point in the future.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Apart from the discussion above, here is where the pretrained checkpoints are loaded in tensorflow object detection api. As you can see, the checkpoint paths are passed by the variable train_config.fine_tune_checkpoint, this variable is a field under train_config in the config file. It is not the same as model_dir, which is only used for saving the most recent checkpoints. \nIf you use the same command line to resume training, the training seemed to automatically start from the latest checkpoint in model_dir and this is supported by tensorflow Supervisor. See here for reference.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Apart from the discussion above, here is where the pretrained checkpoints are loaded in tensorflow object detection api. As you can see, the checkpoint paths are passed by the variable train_config.fine_tune_checkpoint, this variable is a field under train_config in the config file. It is not the same as model_dir, which is only used for saving the most recent checkpoints. \nIf you use the same command line to resume training, the training seemed to automatically start from the latest checkpoint in model_dir and this is supported by tensorflow Supervisor. See here for reference.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You should fully use the Functional API instead of mixing the Sequential and Functional APIs, and then you will not have this problem. Model management and building is much easier with the Functional API as well.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "There are two states, the state_h which is the last step output; and the state_c which is the carry on state or memory. \nYou should use a functional API model to have more than one input:\n\nFollowing this approach, it's even possible to use outputs of other layers as initial states, if you want trainable initial states.\nThe big change is that you will need to pass the states for training and predicting:\n\nWhere you can use zeros for the states during training. \n",
                        "contain_knowledge": 0
                    }
                ]
            },
            "alternative": {
                "finetuned_dpr": [
                    {
                        "id": 65364637,
                        "answer_post": "I decided to save on the \"manual\" save of the relevant data.\n\nFirst, I save model.history.history whenever I save the checkpoint and on_train_end with\n\n\n\nWhen I start the program, I check if the checkpoint exists, if yes, I load it and, at the same time, I check if the history exists and if it does I load it and store in model._history variable since model.history.history is only created after you start training!\n\n\nAdditionally, I set model._current_epoch value to keep track of the last epoch:\n\n\nAfter starting training I assign the proper value of model.history.history and remove the old value.\n\n\nNot the most elegant solution but it serves the purpose for now.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 67228765,
                        "answer_post": "I also had a hard time differentiating between the checkpoint objects used when I looked at other people's code, so I wrote down some notes about when to use which one and how to use them in general.\nEither-way, I think it might be useful for other people having the same issue:\nSaving model Checkpoints\nThese are 2 ways of saving your model's checkpoints, each is for a different use case:\n1) Checkpoint & CheckpointManager\nThis is use-full when you are managing the training loops yourself.\nYou use them like this:\n1.1) Checkpoint\nDefinition from the docs:\n\"A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file\".\nHow to initialise it:\n\nYou can pass it key value pairs for:\n\nAll the custom function calls or objects that make up your model and you want to keep track of:\nLike a generator, discriminiator, loss function, optimizer etc\n\n\n\n\n1.2) CheckpointManager\nThis literally manages the checkpoints you have defined to be stored at a location and things like how many to to keep.\nDefinition from the docs:\n\"Manages multiple checkpoints by keeping some and deleting unneeded ones\"\nHow to initialise it:\n\nInitialise it with the CheckPoint object you create as first argument.\nThe directory where to save the checkpoint files.\nAnd you probably want to define how much you want to keep, since this can be a lot of complex models\n\n\nHow to use it:\n\nWe have setup the manager object with our specified checkpoints, so it's ready to use.\nCall this at the end of each training epoch\n\n\n2) ModelCheckpoint (callback)\nYou want to use this callback when you are not managing epoch iterations yourself. For example when you have setup a relatively simple Sequential model and you call model.fit(), which manages the training process for you.\nDefinition from the docs:\n\"Callback to save the Keras model or model weights at some frequency.\"\nHow to initialise it:\n\nPass in the path where to save the model\n\nThe option save_weights_only is set to False by default:\n\nIf you want to only save the weights make sure to update this\n\n\nThe option save_best_only is set to False by default:\n\nIf you want to only save the best model instead of all of them, you can set this to True.\n\n\nverbose is set to 0 (False), so you can update this to 1 to validate it\n\n\n\nHow to use it:\n\nThe model checkpoint callback is now ready to for training.\nYou pass in the object in you into your callbacks list when you fit the model:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 64122772,
                        "answer_post": "In your trained folder where checkpoints are, there is checkpoint key file, open that and change the \"model_checkpoint_path\" checkpoint-number in the first line. Generally it will be saved the last checkpoint.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71129608,
                        "answer_post": "As of 02.2022\nThe Validation process is supposed to run at the same time with the Training process so that whenever a new Checkpoint is saved, the Validation process immediately loads the Checkpoint and starts validating.\nPlease see my other answer in this regard.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71519403,
                        "answer_post": "These might help: Training checkpoints and tf.train.Checkpoint. According to the documentation, you should be able to load the model using something like this:\n\nI am not sure it will work if the checkpoint contains other variables. You might have to use checkpoint.restore(path).expect_partial().\nYou can also check the content that has been saved (according to the documentation) by Manually inspecting checkpoints :\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 56958434,
                        "answer_post": "If by latest model you mean the model after the final epoch, you can just simply leave the Checkpoint function unchanged and save your final result.\nAfter you fit the model add this line of code:\n\nThe checkpoint function will save the best model, and after you finish training, the model will save one final time, regardless of the result.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55037106,
                        "answer_post": "It's very simple. Create checkpoints while training the model and then use those checkpoints to resume training from where you left of.\n\nAfter this just load the checkpoint from where you want to resume training again\n\nAnd you are done.\nLet me know if you have more questions about this.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 58656237,
                        "answer_post": "The purpose of the validation accuracy is an estimation to see how your model generalises on unseen data. So when you are saving checkpoints with best validation accuracy , what happens is you are saving the weight(the ones which are learned by training) that best predicts results for the unseen data. So by having multiple checkpoints saved you can utilize these checkpoints when testing the model with test data( which may be taken from say a real time use case), and select the model which works well with your test data\nHope this helps\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62292059,
                        "answer_post": "You can use model checkpoint callbacks as follows: for example capture the maximum accuracy obtained so far and save it in the checkpoint file.\n\n\nand then fit the model. \nmodel.fit(epochs=10, callbacks=[model_checkpoint_callback])\nyou can reload it again for update. \nmodel.load(checkpoint_filepath)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 60799059,
                        "answer_post": "There is no 'model' parameter in the saved checkpoint. If you look in train_rcnn.py:106:\n\nyou see that they save just the model parameters. It should've been something like:\n\nso then after loading you get a dictionary with 'model', and the other parameters they appear to be wanting to keep.\nThis seems to be a bug in their code.\n",
                        "contain_knowledge": 0
                    }
                ],
                "dpr": [
                    {
                        "id": 67168551,
                        "answer_post": "Assuming you are using a tf.keras.callbacks.ModelCheckpoint with save_freq = int (which is required to save after a certain number of batches), you can create a class that inherits from ModelCheckpoint and modify the class method on_train_batch_end\n\nThen add an instance of this class in model.fit.\n\nThis will add both the epoch and the batch number to the checkpoint filename.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62395329,
                        "answer_post": "This can be done using the ModelCheckpoint callback:\n\nYou can modify the behaviour of the callback using the monitor, mode and save_best_only parameters, which govern the metric to track and whether the checkpoints are overwritten to retain the best model only. \n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 62848472,
                        "answer_post": "Checkpoints are used to save your model if in case your system crashes or code interrupted while training so when you start training your model again after crashes you don't have to start from scratch.Checkpoints capture the exact value of all parameters (tf.Variable objects) used by a model. Checkpoints do not contain any description of the computation defined by the model.\nThe SavedModel format on the other hand includes a serialized description of the computation defined by the model in addition to the parameter values (checkpoint). Models in this format are independent of the source code that created the model.\nyou can see the above info in the official doc of tensorflow. @R Nanthak\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63366977,
                        "answer_post": "It depends on whether a custom training loop is required. In most cases, it's not and you can just call model.fit() and pass tf.keras.callbacks.ModelCheckpoint. If you do need to write your custom training loop, then you have to use tf.train.Checkpoint (and tf.train.CheckpointManager) since there's no callback mechanism.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 71835386,
                        "answer_post": "The build_federated_averaging_process API builds an iterative process of the full federated learning steps. If you want to verify that the server model is updated, you can print state.model after each iterative_process.next(state, train_data).\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 74297783,
                        "answer_post": "you can use the checkpoints.restore() method to restore checkpoints of your preference. For example, if you want to load checkpoint at iteration 1000, then you write:\n\nFor more details please refer to this documentation. Thank You.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 63494946,
                        "answer_post": "Your session uses the graph created in the load_graph function. However, the MaxBytesInUse operator is created on the default graph (which you can obtain using tf.get_default_graph()). That means the operator is not part of the graph used by the session.\nIn order to solve the issue, you may specify the correct graph when creating the operator:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63475581,
                        "answer_post": "The default monitor for ModelCheckpoint is the validation loss or \"val_loss\".\nAs the warning suggests, the key \"val_loss\" is missing because you didn't use validation data in model.fit().\nEither specify the validation split or validation data in model.fit() or just use training loss or accuracy as a monitor for ModelCheckpoint as in my example below.\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 62292059,
                        "answer_post": "You can use model checkpoint callbacks as follows: for example capture the maximum accuracy obtained so far and save it in the checkpoint file.\n\n\nand then fit the model. \nmodel.fit(epochs=10, callbacks=[model_checkpoint_callback])\nyou can reload it again for update. \nmodel.load(checkpoint_filepath)\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 61319129,
                        "answer_post": "are you sure it is stuck? do you get any errors?\nDuring the training process, TF OD API writes logs into an event file (can be opened using tensorboard) in the model directory.\nlook in your model directory and see if there is an eventfile written there, look at its time stamp to see if it is being updated.\n",
                        "contain_knowledge": 0
                    }
                ],
                "e5": [
                    {
                        "id": 69794011,
                        "answer_post": "You can use tf.train.CheckpointManager to load your latest checkpoint or whatever checkpoint you like and then generate some images with your generator model based on random noise:\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 55917605,
                        "answer_post": "The train_logdir represents the checkpoint directory. The train_logdir is an input to the checkpoint_dir argument of the tf.train.MonitoredTrainingSession utility. The checkpoints are saved/restored to/from this directory.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": 68001567,
                        "answer_post": "Here is the model\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 60309119,
                        "answer_post": "You can save the weights in checkpoint format using:\n\nYou can read more about saving weights or models and chepoints here\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 71289634,
                        "answer_post": "Try Saving the model again\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 63699290,
                        "answer_post": "I have solved my problem. To export TF Slim Resnet checkpoint with TF 1.14 to SavedModel, warm start can be used together with export_savedmodel as follows:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 68184521,
                        "answer_post": "Use tf.where\n\n\n\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 55409692,
                        "answer_post": "train.py\n\nmodel.py\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 73923033,
                        "answer_post": "Use tf.cond:\n\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": 56793601,
                        "answer_post": "Here's the code to convert the checkpoint to SavedModel\n\n",
                        "contain_knowledge": 0
                    }
                ],
                "bm25": [
                    {
                        "id": -999,
                        "answer_post": "You should create a CheckpointManager at the start as:\n\nNow after running for few epoch, to restore latest checkpoint, you should get the latest checkpoint from the CheckpointManager:\n\nThis will restore your session from the latest epoch.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "I'm not exactly sure what you mean with\n\nHow (with what methods) can I use these models now?\n\nThe model is not saved in those files but i can be restored with them.\nThose*.ckpt get saved during training but do not contain your model. If you want to \"use\" your model you need to restore those files to it. Take a look at Tensorflow's Checkpoint and CheckpointManager. This tutorial shows a simple snipped of how to restore .ckpt files to your model.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "I also had a hard time differentiating between the checkpoint objects used when I looked at other people's code, so I wrote down some notes about when to use which one and how to use them in general.\nEither-way, I think it might be useful for other people having the same issue:\nSaving model Checkpoints\nThese are 2 ways of saving your model's checkpoints, each is for a different use case:\n1) Checkpoint & CheckpointManager\nThis is use-full when you are managing the training loops yourself.\nYou use them like this:\n1.1) Checkpoint\nDefinition from the docs:\n\"A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file\".\nHow to initialise it:\n\nYou can pass it key value pairs for:\n\nAll the custom function calls or objects that make up your model and you want to keep track of:\nLike a generator, discriminiator, loss function, optimizer etc\n\n\n\n\n1.2) CheckpointManager\nThis literally manages the checkpoints you have defined to be stored at a location and things like how many to to keep.\nDefinition from the docs:\n\"Manages multiple checkpoints by keeping some and deleting unneeded ones\"\nHow to initialise it:\n\nInitialise it with the CheckPoint object you create as first argument.\nThe directory where to save the checkpoint files.\nAnd you probably want to define how much you want to keep, since this can be a lot of complex models\n\n\nHow to use it:\n\nWe have setup the manager object with our specified checkpoints, so it's ready to use.\nCall this at the end of each training epoch\n\n\n2) ModelCheckpoint (callback)\nYou want to use this callback when you are not managing epoch iterations yourself. For example when you have setup a relatively simple Sequential model and you call model.fit(), which manages the training process for you.\nDefinition from the docs:\n\"Callback to save the Keras model or model weights at some frequency.\"\nHow to initialise it:\n\nPass in the path where to save the model\n\nThe option save_weights_only is set to False by default:\n\nIf you want to only save the weights make sure to update this\n\n\nThe option save_best_only is set to False by default:\n\nIf you want to only save the best model instead of all of them, you can set this to True.\n\n\nverbose is set to 0 (False), so you can update this to 1 to validate it\n\n\n\nHow to use it:\n\nThe model checkpoint callback is now ready to for training.\nYou pass in the object in you into your callbacks list when you fit the model:\n\n\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "while creating checkpoints you can pass the optimizer argument for saving the optimizer status\n\nThen you can restore optimizer status while restoring those checkpoints.For more details please refer to this documentation. Thank You.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "The purpose of the validation accuracy is an estimation to see how your model generalises on unseen data. So when you are saving checkpoints with best validation accuracy , what happens is you are saving the weight(the ones which are learned by training) that best predicts results for the unseen data. So by having multiple checkpoints saved you can utilize these checkpoints when testing the model with test data( which may be taken from say a real time use case), and select the model which works well with your test data\nHope this helps\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Yes to both questions.\n1) Without recompiling the model the model weights are bound to in the model so \n\nworks to update the model from previous weights but do think about if this is exactly what you want to do.\n\nYes, saving and loading a model works as expected\n\n\nShould do the trick.\nFor saving at checkpoints I'd recommend using the ModelCheckpoint callback. That makes it easy to save the model and specific iterations points so that you can train from that point in the future.\n",
                        "contain_knowledge": 1
                    },
                    {
                        "id": -999,
                        "answer_post": "Apart from the discussion above, here is where the pretrained checkpoints are loaded in tensorflow object detection api. As you can see, the checkpoint paths are passed by the variable train_config.fine_tune_checkpoint, this variable is a field under train_config in the config file. It is not the same as model_dir, which is only used for saving the most recent checkpoints. \nIf you use the same command line to resume training, the training seemed to automatically start from the latest checkpoint in model_dir and this is supported by tensorflow Supervisor. See here for reference.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "Apart from the discussion above, here is where the pretrained checkpoints are loaded in tensorflow object detection api. As you can see, the checkpoint paths are passed by the variable train_config.fine_tune_checkpoint, this variable is a field under train_config in the config file. It is not the same as model_dir, which is only used for saving the most recent checkpoints. \nIf you use the same command line to resume training, the training seemed to automatically start from the latest checkpoint in model_dir and this is supported by tensorflow Supervisor. See here for reference.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "You should fully use the Functional API instead of mixing the Sequential and Functional APIs, and then you will not have this problem. Model management and building is much easier with the Functional API as well.\n",
                        "contain_knowledge": 0
                    },
                    {
                        "id": -999,
                        "answer_post": "There are two states, the state_h which is the last step output; and the state_c which is the carry on state or memory. \nYou should use a functional API model to have more than one input:\n\nFollowing this approach, it's even possible to use outputs of other layers as initial states, if you want trainable initial states.\nThe big change is that you will need to pass the states for training and predicting:\n\nWhere you can use zeros for the states during training. \n",
                        "contain_knowledge": 0
                    }
                ]
            }
        }
    }
]